Search.setIndex({"docnames": ["homework/01/hw1.1", "homework/01/index", "homework/02/hw2.1", "homework/02/hw2.2", "homework/02/index", "homework/03/hw3.1", "homework/03/hw3.2", "homework/03/index", "homework/04/hw4.1", "homework/04/hw4.2", "homework/04/index", "index", "lesson_exercises/exercise_01", "lesson_exercises/exercise_02", "lesson_exercises/exercise_03", "lesson_exercises/exercise_04", "lesson_exercises/exercise_05", "lesson_exercises/exercise_06", "lesson_exercises/exercise_07", "lesson_exercises/exercise_08", "lesson_exercises/exercise_09", "lessons/00/aws_setup", "lessons/00/colab", "lessons/00/index", "lessons/00/setup", "lessons/01/bayes_logic", "lessons/01/bayes_model_for_learning", "lessons/01/bayes_notation", "lessons/01/index", "lessons/01/marginalization", "lessons/01/probability_distributions", "lessons/02/bayesian_modeling_example", "lessons/02/bayesian_modeling_tasks", "lessons/02/choice_of_likelihood", "lessons/02/choice_of_prior", "lessons/02/index", "lessons/03/plotting_posteriors", "lessons/04/marginalization_by_numerical_quadrature", "lessons/05/conjugacy", "lessons/06/index", "lessons/06/normal_optimization", "lessons/06/optimization_basics", "lessons/06/variate_covariate_optimization", "lessons/07/Untitled", "lessons/07/further_reading", "lessons/07/index", "lessons/07/mcmc_idea", "lessons/07/metropolis_hastings", "lessons/07/warm_up", "lessons/07/why_mcmc", "lessons/08/index", "lessons/08/parameter_estimation_with_mcmc", "lessons/08/stan_hello_world", "lessons/09/mixture_model_stan", "lessons/10/variate_covariate_with_stan", "lessons/11/display_of_mcmc_samples", "lessons/11/index", "lessons/11/posterior_summaries", "lessons/12/prior_predictive_checks", "lessons/13/posterior_predictive_checks", "lessons/14/box_of_distributions", "lessons/15/mcmc_diagnostics", "lessons/16/funnel_of_hell", "lessons/17/model_comparison", "lessons/18/comparing_regressions", "lessons/18/index", "lessons/18/model_comparison", "lessons/19/choosing_a_hierarchical_prior", "lessons/19/generalization", "lessons/19/implementation", "lessons/19/index", "lessons/19/modeling_repeated_experiments", "lessons/20/hierarchical_implementation", "lessons/21/sbc", "lessons/22/sbc_in_practice", "lessons/23/intro_to_gps", "lessons/24/gp_hyperparams_by_optimization", "lessons/24/gps_and_derivatives", "lessons/24/gps_without_marginalization", "lessons/24/index", "lessons/24/mcmc_with_gps", "lessons/25/variational_inference", "lessons/26/wrapup", "policies", "recitations/01/probability_review", "recitations/02/choosing_priors", "recitations/02/index", "recitations/03/just_hw_help", "recitations/04/hmc", "recitations/04/index", "recitations/04/overview", "recitations/05/practice_model_building", "recitations/06/HPC", "recitations/06/intro_to_hpc", "recitations/07/sampling_discrete_parameters", "recitations/08/project_proposals", "recitations/09/just_hw_help", "resources", "schedule"], "filenames": ["homework/01/hw1.1.ipynb", "homework/01/index.rst", "homework/02/hw2.1.ipynb", "homework/02/hw2.2.ipynb", "homework/02/index.rst", "homework/03/hw3.1.ipynb", "homework/03/hw3.2.ipynb", "homework/03/index.rst", "homework/04/hw4.1.ipynb", "homework/04/hw4.2.ipynb", "homework/04/index.rst", "index.rst", "lesson_exercises/exercise_01.ipynb", "lesson_exercises/exercise_02.ipynb", "lesson_exercises/exercise_03.ipynb", "lesson_exercises/exercise_04.ipynb", "lesson_exercises/exercise_05.ipynb", "lesson_exercises/exercise_06.ipynb", "lesson_exercises/exercise_07.ipynb", "lesson_exercises/exercise_08.ipynb", "lesson_exercises/exercise_09.ipynb", "lessons/00/aws_setup.ipynb", "lessons/00/colab.ipynb", "lessons/00/index.rst", "lessons/00/setup.ipynb", "lessons/01/bayes_logic.rst", "lessons/01/bayes_model_for_learning.rst", "lessons/01/bayes_notation.rst", "lessons/01/index.rst", "lessons/01/marginalization.rst", "lessons/01/probability_distributions.rst", "lessons/02/bayesian_modeling_example.rst", "lessons/02/bayesian_modeling_tasks.rst", "lessons/02/choice_of_likelihood.rst", "lessons/02/choice_of_prior.rst", "lessons/02/index.rst", "lessons/03/plotting_posteriors.ipynb", "lessons/04/marginalization_by_numerical_quadrature.ipynb", "lessons/05/conjugacy.ipynb", "lessons/06/index.rst", "lessons/06/normal_optimization.ipynb", "lessons/06/optimization_basics.ipynb", "lessons/06/variate_covariate_optimization.ipynb", "lessons/07/Untitled.ipynb", "lessons/07/further_reading.rst", "lessons/07/index.rst", "lessons/07/mcmc_idea.rst", "lessons/07/metropolis_hastings.rst", "lessons/07/warm_up.rst", "lessons/07/why_mcmc.rst", "lessons/08/index.rst", "lessons/08/parameter_estimation_with_mcmc.ipynb", "lessons/08/stan_hello_world.ipynb", "lessons/09/mixture_model_stan.ipynb", "lessons/10/variate_covariate_with_stan.ipynb", "lessons/11/display_of_mcmc_samples.ipynb", "lessons/11/index.rst", "lessons/11/posterior_summaries.ipynb", "lessons/12/prior_predictive_checks.ipynb", "lessons/13/posterior_predictive_checks.ipynb", "lessons/14/box_of_distributions.rst", "lessons/15/mcmc_diagnostics.ipynb", "lessons/16/funnel_of_hell.ipynb", "lessons/17/model_comparison.rst", "lessons/18/comparing_regressions.ipynb", "lessons/18/index.rst", "lessons/18/model_comparison.ipynb", "lessons/19/choosing_a_hierarchical_prior.ipynb", "lessons/19/generalization.ipynb", "lessons/19/implementation.ipynb", "lessons/19/index.rst", "lessons/19/modeling_repeated_experiments.ipynb", "lessons/20/hierarchical_implementation.ipynb", "lessons/21/sbc.ipynb", "lessons/22/sbc_in_practice.ipynb", "lessons/23/intro_to_gps.ipynb", "lessons/24/gp_hyperparams_by_optimization.ipynb", "lessons/24/gps_and_derivatives.ipynb", "lessons/24/gps_without_marginalization.ipynb", "lessons/24/index.rst", "lessons/24/mcmc_with_gps.ipynb", "lessons/25/variational_inference.ipynb", "lessons/26/wrapup.rst", "policies.rst", "recitations/01/probability_review.rst", "recitations/02/choosing_priors.rst", "recitations/02/index.rst", "recitations/03/just_hw_help.rst", "recitations/04/hmc.ipynb", "recitations/04/index.rst", "recitations/04/overview.ipynb", "recitations/05/practice_model_building.ipynb", "recitations/06/HPC.ipynb", "recitations/06/intro_to_hpc.rst", "recitations/07/sampling_discrete_parameters.ipynb", "recitations/08/project_proposals.rst", "recitations/09/just_hw_help.rst", "resources.rst", "schedule.rst"], "titles": ["Homework 1.1: First attempts at Bayesian generative modeling (70 pts)", "1. Intuitive generative modeling", "Homework 2.1: Overwhelming a prior (45 pts)", "Homework 2.2: Exponential conjugate prior (55 pts)", "2. Analytical and graphical methods for analysis of the posterior", "Homework 3.1: Least squares (20 pts)", "Homework 3.2: MAP estimates and zero-inflation for Drop-Seq controls (80 pts)", "3. Maximum a posteriori parameter estimation", "Homework 4.1: Writing your own MCMC sampler (70 pts)", "Homework 4.2: MCMC with Boolean data (30 pts)", "4. Sampling with MCMC", "BE/Bi 103 b: Statistical Inference in the Biological Sciences", "E1. To be completed after lesson 5", "E2. To be completed after lesson 6", "E3. To be completed after lesson 10", "E4. To be completed after lesson 13", "E5. To be completed after lesson 16", "E6. To be completed after lesson 18", "E7. To be completed after lesson 20", "E8. To be completed after lesson 22", "E9. To be completed after lesson 25", "AWS setup and usage", "Using Google Colab", "0. Setting up computing resources", "Configuring your machine", "Probability as the logic of science", "Bayes\u2019s theorem as a model for learning", "Notation of parts of Bayes\u2019s Theorem", "1. Probability and the logic of scientific reasoning", "Marginalization", "Probability distributions", "Bayesian modeling example: parameter estimation from repeated measurements", "Tasks of Bayesian modeling", "Choosing likelihoods", "Choosing priors", "2. Introduction to Bayesian modeling", "3. Plotting posteriors", "4. Marginalization by numerical quadrature", "5. Conjugacy", "6. Parameter estimation by optimization", "Parameter estimation by optimization case study: Normal likelihood", "Bayesian approach to parameter estimation by optimization", "Parameter estimation by optimization: A variate-covariate model", "&lt;no title&gt;", "Further reading on MCMC", "7. Introduction to Markov chain Monte Carlo", "Random number generation", "Generating a transition kernel: The Metropolis-Hastings algorithm", "Warm-up", "Why MCMC?", "8. Introduction to MCMC with Stan", "Parameter estimation with Markov chain Monte Carlo", "\u201cHello, world\u201d \u2014Stan", "9. Mixture models and label switching with MCMC", "10. Variate-covariate models with MCMC", "Display of MCMC samples", "11. Display of MCMC results", "Reporting summaries of the posterior", "12. Model building with prior predictive checks", "13. Posterior predictive checks", "14. Collector\u2019s box of distributions", "15. MCMC diagnostics", "16. A diagnostics case study: Artificial funnel of hell", "17. Model comparison", "Example model selection: regression", "18. Model comparison in practice", "Model comparison in practice", "Choosing a hierarchical prior", "Generalization of hierarchical models", "Implementation of a hierarchical model", "19. Hierarchical models", "Modeling repeated experiments", "20. Implementation of hierarchical models", "21. Principled analysis pipelines", "22: Simulation based calibration and related checks in practice", "23. Introduction to Gaussian processes", "Gaussian process hyperparameters by optimization", "Calculating derivatives from data with GPs", "Gaussian processes with non-Normal likelihoods", "24. Implementation of Gaussian processes", "MCMC with GPs with Normal likelihoods", "25. Variational Bayesian inference", "26: Wrap-up", "Meetings", "R1: Review of probability", "R2: Choosing priors and review of optimization", "R2: Choosing priors and review of optimization", "R3: Just homework help", "More details on Hamiltonian Monte Carlo", "R4. Introduction to Hamiltonian Monte Carlo", "Overview of Hamiltonian Monte Carlo", "R5: Bayesian model building", "R6: MCMC using Caltech\u2019s HPC", "R6: MCMC using Caltech\u2019s HPC", "R7: Sampling discrete parameters with Stan", "R8: Discussion of HW 10 project proposals", "R9: Just homework help", "Software", "Schedule overview"], "terms": {"collard": 0, "cowork": [0, 6, 48, 58, 66, 73, 77, 81], "did": [0, 12, 24, 25, 26, 33, 34, 36, 37, 40, 42, 51, 52, 54, 55, 58, 59, 62, 63, 64, 66, 67, 69, 71, 73, 74, 75, 76, 83, 90, 91, 95], "simpl": [0, 25, 31, 32, 36, 38, 41, 48, 52, 53, 57, 62, 63, 67, 73, 74, 75, 76, 78, 80, 81, 83, 88, 90, 92], "experi": [0, 2, 6, 9, 18, 25, 26, 30, 32, 33, 34, 36, 38, 51, 58, 60, 61, 63, 67, 68, 69, 70, 72, 73, 74, 75, 77, 81, 90, 91, 92, 94], "thei": [0, 2, 5, 25, 31, 34, 36, 38, 40, 41, 42, 51, 52, 53, 54, 55, 58, 61, 62, 63, 66, 72, 73, 75, 77, 78, 81, 83, 88, 90, 91, 92, 94], "collect": [0, 49, 51, 52, 59, 91], "sampl": [0, 8, 9, 11, 14, 16, 17, 21, 24, 30, 32, 37, 42, 46, 47, 48, 49, 56, 58, 59, 63, 64, 66, 67, 68, 69, 73, 80, 81, 88, 92, 98], "carrion": 0, "beetl": 0, "feed": [0, 94], "decai": [0, 36, 58, 74], "anim": [0, 9, 88, 94], "matter": [0, 34, 49, 68, 83], "measur": [0, 2, 5, 6, 27, 30, 32, 33, 34, 35, 36, 37, 40, 51, 52, 58, 59, 60, 61, 63, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 81, 88, 91, 94], "morpholog": 0, "featur": [0, 36, 40, 52, 60, 61, 63, 67, 68, 74, 75, 81, 84, 85, 92, 93, 95], "variou": [0, 6, 32, 46, 52, 55, 57, 75, 77, 92, 94, 97], "speci": [0, 34], "from": [0, 2, 3, 5, 6, 9, 22, 24, 25, 26, 29, 30, 32, 34, 35, 36, 38, 40, 41, 42, 44, 46, 47, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 88, 90, 91, 92, 94], "differ": [0, 2, 9, 21, 22, 25, 34, 36, 40, 41, 51, 53, 57, 58, 59, 62, 63, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 81, 83, 88, 90, 91, 92, 94], "site": [0, 3, 76, 77], "time": [0, 5, 8, 9, 21, 22, 23, 25, 31, 33, 36, 37, 41, 47, 48, 52, 53, 54, 57, 58, 60, 63, 67, 71, 73, 74, 75, 76, 77, 78, 81, 83, 91, 92, 94, 97, 98], "year": [0, 9, 21, 34, 47, 71], "imagin": [0, 5, 30, 48, 51, 60, 62, 63, 68, 71, 74, 75, 77, 88, 90], "you": [0, 2, 3, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 31, 32, 33, 34, 36, 38, 40, 41, 42, 44, 46, 47, 48, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 66, 68, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94, 97], "ar": [0, 2, 3, 5, 6, 8, 9, 11, 13, 15, 16, 17, 20, 22, 23, 24, 25, 27, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94], "cabin": 0, "main": [0, 34, 40, 41, 46, 51, 52, 55, 60, 73, 78, 90, 92, 97], "There": [0, 6, 9, 21, 22, 23, 24, 25, 31, 34, 38, 47, 48, 51, 52, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 72, 73, 75, 77, 78, 81, 83, 87, 90, 92, 94, 96, 97], "also": [0, 6, 8, 9, 11, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 46, 47, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 69, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 91, 92, 94, 97], "plenti": [0, 21, 61, 66], "area": [0, 37, 61, 74, 88, 94], "which": [0, 3, 5, 6, 8, 9, 21, 22, 23, 24, 25, 26, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94], "stai": [0, 53, 88], "so": [0, 2, 9, 18, 21, 22, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 91, 92, 94], "curiou": 0, "look": [0, 3, 6, 8, 9, 21, 34, 36, 38, 40, 41, 42, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 92, 94], "your": [0, 2, 3, 9, 10, 11, 18, 19, 22, 23, 25, 33, 34, 36, 40, 41, 42, 47, 53, 58, 59, 60, 61, 62, 63, 72, 73, 74, 75, 76, 80, 81, 83, 88, 90, 91, 92], "plan": [0, 94], "set": [0, 2, 3, 5, 6, 9, 11, 13, 18, 21, 22, 24, 25, 26, 27, 30, 32, 34, 37, 40, 41, 42, 47, 49, 52, 53, 54, 55, 59, 63, 64, 66, 67, 68, 69, 71, 73, 74, 76, 77, 78, 80, 81, 83, 91, 92, 94], "up": [0, 3, 6, 8, 11, 14, 21, 22, 24, 31, 32, 34, 36, 37, 40, 42, 45, 46, 51, 58, 59, 60, 61, 62, 64, 68, 71, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 92, 94, 98], "trap": 0, "specimen": 0, "given": [0, 6, 21, 25, 27, 30, 31, 32, 34, 36, 38, 41, 46, 49, 51, 53, 58, 61, 63, 66, 69, 71, 72, 75, 76, 77, 78, 80, 81, 82, 83, 88, 90, 91, 94], "For": [0, 2, 6, 9, 21, 22, 25, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 46, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 71, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 92, 94], "each": [0, 2, 3, 6, 8, 9, 12, 17, 21, 22, 25, 31, 36, 37, 38, 40, 41, 46, 49, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63, 66, 67, 69, 71, 72, 73, 74, 75, 78, 80, 81, 83, 88, 90, 91, 92, 94, 98], "its": [0, 5, 6, 25, 31, 34, 36, 37, 38, 40, 51, 52, 53, 54, 57, 58, 60, 62, 63, 67, 69, 74, 75, 76, 77, 81, 83, 88, 92, 94, 97], "mass": [0, 6, 30, 34, 40, 53, 57, 60, 62, 66, 73, 74, 75, 83, 88, 90], "length": [0, 8, 31, 33, 34, 36, 37, 40, 42, 51, 52, 53, 54, 55, 58, 59, 60, 61, 64, 66, 73, 75, 76, 78, 81, 88, 92], "elytra": 0, "As": [0, 2, 6, 21, 22, 24, 25, 30, 31, 32, 34, 36, 37, 38, 41, 46, 47, 51, 52, 53, 55, 58, 59, 60, 61, 62, 63, 64, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 88, 90, 92, 94], "we": [0, 2, 3, 5, 6, 8, 9, 11, 12, 13, 17, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 88, 91, 92, 94], "learn": [0, 11, 23, 25, 28, 32, 38, 40, 41, 51, 52, 53, 55, 58, 59, 61, 63, 71, 72, 73, 75, 76, 77, 92], "class": [0, 2, 11, 22, 24, 27, 37, 47, 60, 75, 81, 83, 88, 92, 94, 97, 98], "prior": [0, 4, 5, 6, 11, 12, 13, 15, 19, 26, 27, 29, 33, 35, 36, 37, 38, 40, 41, 42, 52, 53, 54, 59, 61, 63, 66, 68, 69, 70, 71, 72, 73, 77, 78, 80, 81, 83, 90, 91, 92, 94, 98], "perform": [0, 6, 13, 19, 21, 23, 32, 33, 34, 36, 37, 40, 47, 49, 51, 52, 53, 54, 57, 58, 59, 61, 63, 66, 69, 72, 73, 75, 76, 77, 78, 80, 81, 83, 88, 90, 92, 94], "an": [0, 3, 6, 9, 22, 23, 24, 25, 26, 27, 29, 31, 32, 33, 34, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 67, 69, 71, 72, 73, 76, 77, 78, 81, 83, 88, 91, 92, 94], "i": [0, 2, 3, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 41, 42, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 87, 88, 90, 91, 94, 96, 97, 98], "us": [0, 2, 3, 6, 8, 9, 13, 14, 15, 16, 17, 18, 20, 23, 24, 25, 27, 29, 30, 31, 32, 33, 36, 37, 38, 40, 42, 46, 47, 48, 49, 51, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 76, 81, 83, 90, 91, 94, 97], "think": [0, 5, 6, 25, 31, 32, 34, 40, 42, 46, 52, 53, 57, 58, 61, 63, 66, 72, 75, 76, 78, 88, 90, 94], "about": [0, 6, 8, 21, 22, 25, 26, 27, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 60, 61, 63, 66, 72, 73, 74, 75, 76, 77, 78, 81, 83, 88, 90, 91, 92, 94, 95, 97], "what": [0, 2, 5, 6, 9, 12, 13, 14, 17, 18, 19, 20, 21, 22, 27, 31, 32, 34, 36, 37, 42, 46, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 66, 72, 73, 74, 75, 76, 77, 81, 83, 90, 91, 94], "kind": [0, 25, 47, 53, 55, 58, 61, 63, 74, 75, 76, 77, 94], "data": [0, 2, 3, 5, 6, 10, 11, 18, 21, 22, 24, 25, 26, 27, 30, 31, 32, 33, 34, 37, 38, 41, 42, 48, 49, 52, 53, 54, 55, 57, 59, 60, 63, 64, 66, 67, 68, 69, 73, 74, 76, 78, 79, 80, 81, 83, 91, 92, 94, 97], "might": [0, 6, 8, 9, 21, 22, 24, 31, 32, 33, 34, 36, 38, 46, 49, 52, 53, 55, 57, 58, 60, 62, 63, 67, 73, 74, 75, 76, 80, 81, 88, 90, 91, 92, 94], "expect": [0, 5, 6, 24, 25, 31, 32, 34, 36, 38, 40, 42, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 66, 72, 73, 74, 75, 78, 81, 83, 88, 90, 94], "observ": [0, 6, 9, 25, 32, 38, 59, 60, 63, 66, 71, 75, 77, 78, 81, 91], "thi": [0, 2, 3, 5, 6, 8, 9, 11, 16, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 91, 92, 94, 97, 98], "involv": [0, 6, 9, 21, 25, 31, 32, 34, 37, 41, 51, 55, 58, 61, 63, 68, 75, 80, 90, 92], "propos": [0, 6, 8, 47, 48, 58, 61, 62, 63, 73, 88, 91], "draw": [0, 34, 46, 51, 52, 53, 57, 58, 59, 61, 62, 63, 64, 66, 69, 73, 74, 75, 76, 77, 78, 80, 81, 88, 94], "befor": [0, 22, 25, 31, 32, 34, 36, 37, 38, 42, 51, 52, 53, 58, 59, 62, 63, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 92, 94, 98], "proceed": [0, 59, 62, 77, 81], "do": [0, 2, 5, 6, 8, 9, 12, 13, 15, 19, 21, 22, 23, 24, 25, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 91, 93, 94], "want": [0, 8, 9, 12, 21, 22, 25, 30, 36, 37, 38, 40, 46, 47, 49, 51, 52, 53, 55, 58, 59, 60, 61, 63, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94], "clarifi": 0, "purpos": [0, 9, 21, 31, 51, 52, 53, 58, 60, 61, 66, 76, 88], "problem": [0, 2, 3, 5, 6, 9, 16, 22, 23, 27, 30, 32, 34, 36, 37, 40, 41, 42, 46, 47, 53, 55, 57, 58, 61, 62, 63, 68, 71, 72, 73, 74, 76, 77, 78, 81, 83, 88, 90, 91, 92, 94], "address": [0, 21, 61, 72, 73, 75, 92], "question": [0, 12, 13, 14, 15, 16, 17, 18, 19, 20, 59, 60, 61, 63, 73, 83], "mai": [0, 3, 5, 6, 8, 13, 14, 15, 16, 17, 21, 22, 23, 24, 25, 27, 30, 31, 32, 34, 40, 46, 49, 51, 52, 53, 57, 58, 59, 60, 61, 62, 63, 66, 67, 71, 72, 73, 75, 76, 78, 80, 81, 83, 90, 91, 94], "my": [0, 12, 24, 25, 30, 31, 34, 40, 47, 55, 57, 74, 81, 88, 90, 92, 94], "formal": [0, 25, 32, 58, 63, 72], "procedur": [0, 5, 8, 33, 34, 37, 42, 58, 59, 63, 73, 74, 77, 81, 94], "build": [0, 2, 11, 33, 34, 52, 54, 60, 74, 75, 77, 80, 83, 94, 98], "The": [0, 2, 3, 5, 6, 8, 9, 21, 22, 23, 24, 27, 30, 33, 40, 41, 45, 52, 53, 54, 57, 60, 62, 64, 66, 67, 68, 69, 72, 73, 76, 77, 78, 80, 82, 83, 91, 92, 94, 97, 98], "concept": [0, 30, 46, 81, 83, 88, 90, 92, 94], "though": [0, 8, 21, 22, 24, 30, 31, 32, 34, 36, 37, 40, 41, 42, 47, 48, 52, 55, 57, 58, 59, 60, 61, 63, 64, 66, 71, 72, 73, 74, 75, 76, 80, 81, 83, 90, 91, 94], "fairli": [0, 42, 53, 94], "intuit": [0, 11, 25, 34, 38, 58, 63, 74, 88, 90, 98], "At": [0, 21, 32, 34, 52, 75, 88, 94], "point": [0, 5, 6, 9, 12, 13, 25, 34, 37, 40, 42, 46, 51, 52, 53, 54, 55, 58, 59, 60, 61, 63, 64, 66, 72, 73, 76, 77, 78, 80, 81, 83, 88, 90, 94], "re": [0, 3, 31, 38, 40, 42, 46, 51, 55, 57, 61, 62, 71, 75, 76, 77, 78, 90, 94], "ask": [0, 31, 58, 63, 83, 90], "how": [0, 2, 3, 6, 8, 9, 12, 13, 16, 21, 23, 24, 25, 26, 30, 31, 32, 34, 36, 38, 41, 42, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 88, 91, 93, 94, 97], "right": [0, 21, 22, 25, 30, 31, 34, 36, 37, 41, 42, 46, 47, 49, 53, 54, 55, 58, 59, 62, 63, 64, 66, 67, 73, 75, 76, 77, 81, 83, 88, 90, 91, 94], "now": [0, 2, 5, 6, 9, 21, 25, 26, 29, 30, 31, 34, 36, 37, 38, 40, 41, 42, 46, 49, 51, 52, 53, 54, 55, 58, 59, 61, 62, 63, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 88, 90, 92, 94], "concern": [0, 21, 32, 51], "some": [0, 2, 5, 6, 8, 19, 21, 22, 23, 24, 25, 30, 31, 32, 34, 41, 49, 51, 52, 53, 54, 55, 58, 60, 61, 62, 63, 64, 66, 69, 71, 72, 73, 74, 75, 76, 78, 80, 81, 83, 88, 90, 91, 92, 94, 97], "definit": [0, 25, 30, 31, 34, 36, 40, 41, 54, 60, 63, 67, 71, 73, 75, 77, 78, 80, 81, 88, 90, 92, 94], "soon": [0, 34, 55], "like": [0, 3, 5, 8, 9, 21, 22, 25, 30, 31, 34, 36, 38, 41, 42, 48, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 67, 71, 72, 73, 74, 75, 77, 78, 81, 83, 88, 90, 91, 92, 94], "likelihood": [0, 2, 3, 5, 6, 12, 13, 17, 27, 29, 32, 34, 35, 37, 38, 39, 41, 42, 51, 53, 54, 59, 60, 61, 63, 64, 68, 69, 71, 73, 74, 76, 77, 79, 81, 91, 92, 94], "function": [0, 3, 8, 9, 22, 24, 25, 27, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 46, 49, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 72, 74, 76, 77, 78, 80, 83, 88, 90, 92, 94, 97], "last": [0, 6, 12, 24, 25, 30, 47, 51, 52, 59, 61, 69, 76, 77, 82, 88, 90, 92, 94], "term": [0, 6, 9, 13, 22, 23, 24, 25, 30, 31, 32, 34, 36, 40, 41, 47, 51, 52, 53, 58, 61, 63, 73, 75, 81, 82, 83, 88, 90, 92, 94, 97], "rather": [0, 30, 32, 36, 41, 51, 52, 58, 61, 64, 66, 75, 76, 77, 81, 88], "just": [0, 6, 8, 22, 26, 30, 31, 32, 34, 36, 37, 38, 40, 42, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 68, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 92, 94], "yourself": [0, 33, 36, 38, 40, 44, 72, 74], "when": [0, 2, 5, 9, 13, 17, 18, 19, 21, 24, 25, 31, 32, 33, 34, 36, 37, 38, 42, 46, 48, 49, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 71, 73, 74, 75, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94], "thing": [0, 22, 25, 31, 32, 36, 49, 51, 52, 55, 57, 75, 78, 88, 90, 91, 92, 94], "later": [0, 23, 34, 36, 37, 48, 49, 55, 58, 61], "suspect": [0, 34, 67, 76, 78], "see": [0, 2, 5, 6, 21, 24, 29, 32, 34, 36, 38, 40, 41, 42, 51, 52, 53, 55, 58, 59, 60, 61, 62, 63, 64, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 92, 94], "close": [0, 8, 32, 34, 36, 40, 41, 42, 54, 59, 60, 62, 72, 73, 74, 75, 76, 78, 81, 88, 90], "match": [0, 31, 33, 34, 36, 38, 58, 60, 64, 72, 74, 94], "That": [0, 2, 6, 9, 21, 22, 25, 26, 30, 31, 32, 34, 36, 38, 40, 51, 53, 58, 60, 61, 62, 63, 66, 71, 72, 73, 74, 75, 76, 81, 83, 88, 94], "said": [0, 25, 34, 38, 46, 47, 51, 52, 58, 67, 88], "most": [0, 2, 6, 21, 22, 24, 32, 34, 36, 37, 40, 41, 42, 47, 48, 49, 51, 52, 55, 57, 58, 60, 61, 63, 66, 67, 69, 72, 74, 75, 76, 81, 83, 88, 90, 92, 94], "take": [0, 2, 5, 6, 8, 11, 19, 21, 22, 23, 24, 25, 31, 32, 34, 36, 40, 42, 46, 47, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 66, 67, 72, 74, 75, 78, 81, 88, 90, 91, 92], "approach": [0, 5, 6, 11, 19, 23, 24, 25, 31, 32, 34, 36, 38, 39, 40, 46, 47, 53, 54, 57, 59, 60, 61, 62, 66, 71, 73, 74, 75, 76, 81, 83, 90, 91, 94, 97], "develop": [0, 8, 9, 11, 34, 58, 81], "cours": [0, 2, 6, 21, 22, 23, 25, 30, 31, 32, 34, 36, 41, 52, 53, 58, 61, 63, 67, 68, 74, 75, 78, 81, 88, 92, 98], "make": [0, 3, 6, 8, 12, 21, 22, 24, 25, 30, 31, 34, 36, 37, 38, 40, 41, 42, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 88, 90, 91, 92, 94], "mistak": 0, "ok": [0, 54, 59, 66, 72, 73, 75, 81, 94], "go": [0, 8, 11, 21, 23, 25, 27, 32, 34, 36, 37, 41, 47, 48, 52, 53, 55, 57, 58, 59, 60, 61, 63, 66, 67, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 94], "grade": [0, 9, 11], "detail": [0, 2, 6, 11, 38, 40, 44, 48, 53, 55, 61, 63, 66, 75, 77, 81, 83, 89, 90], "implement": [0, 11, 22, 24, 36, 37, 38, 40, 41, 42, 46, 47, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 70, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94, 98], "our": [0, 2, 5, 9, 21, 22, 24, 25, 26, 30, 31, 32, 33, 34, 36, 38, 40, 42, 46, 47, 49, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 69, 71, 72, 73, 75, 76, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94, 97], "get": [0, 6, 8, 9, 21, 22, 23, 25, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 52, 53, 55, 58, 59, 60, 61, 62, 63, 66, 71, 72, 73, 74, 75, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94], "defin": [0, 5, 6, 25, 27, 30, 31, 32, 34, 36, 40, 41, 42, 46, 47, 51, 52, 54, 57, 58, 60, 63, 68, 69, 71, 72, 73, 75, 76, 77, 78, 81, 83, 88, 90, 92, 94], "probabl": [0, 2, 6, 8, 9, 11, 14, 21, 22, 27, 29, 31, 32, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 60, 61, 62, 63, 66, 67, 69, 71, 73, 74, 75, 76, 77, 81, 88, 90, 91, 98], "distribut": [0, 2, 3, 5, 6, 8, 9, 11, 12, 13, 14, 16, 17, 25, 26, 28, 29, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 52, 53, 54, 58, 61, 62, 63, 64, 66, 68, 69, 71, 72, 73, 74, 76, 77, 78, 80, 81, 83, 88, 90, 92, 97, 98], "describ": [0, 6, 17, 18, 19, 20, 25, 26, 27, 30, 31, 32, 33, 34, 38, 40, 41, 49, 51, 52, 57, 59, 60, 63, 66, 68, 71, 73, 75, 76, 77, 81, 83, 88, 90, 91, 94], "b": [0, 2, 3, 5, 6, 8, 9, 14, 25, 30, 34, 38, 40, 41, 51, 52, 53, 58, 61, 63, 66, 73, 74, 88, 91, 92, 94], "sai": [0, 2, 5, 6, 9, 12, 13, 21, 25, 26, 30, 31, 32, 34, 36, 37, 47, 48, 49, 55, 58, 59, 61, 63, 71, 73, 75, 78, 80, 83, 88, 94], "40": [0, 36, 37, 42, 51, 53, 58, 69, 72, 78, 81, 94], "would": [0, 6, 8, 21, 27, 31, 33, 34, 36, 37, 40, 41, 42, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 66, 67, 69, 73, 74, 75, 76, 78, 80, 81, 88, 90, 91, 92, 94], "out": [0, 6, 8, 14, 15, 21, 22, 25, 31, 32, 34, 36, 37, 38, 40, 42, 44, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 61, 64, 66, 67, 68, 71, 72, 73, 74, 76, 77, 78, 80, 81, 83, 88, 90, 92, 94], "respons": [0, 9, 11, 74], "part": [0, 6, 9, 21, 28, 30, 33, 34, 36, 41, 42, 48, 52, 53, 59, 75, 77, 83, 92], "unfortun": [0, 37, 46, 81, 90], "know": [0, 25, 26, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 48, 49, 53, 54, 57, 58, 60, 62, 63, 66, 73, 75, 77, 83, 88, 90, 91, 94], "paramet": [0, 2, 3, 5, 6, 8, 11, 13, 22, 24, 25, 26, 27, 29, 30, 32, 34, 35, 37, 38, 46, 47, 48, 49, 50, 52, 53, 54, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 72, 73, 74, 76, 77, 78, 80, 81, 88, 90, 91, 92, 98], "valu": [0, 5, 6, 8, 25, 26, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 66, 69, 71, 72, 73, 74, 76, 77, 78, 80, 81, 88, 90, 91, 92], "chose": [0, 33, 34, 37, 42, 59, 67, 76, 78, 88, 91, 94], "In": [0, 2, 5, 6, 8, 9, 11, 21, 22, 23, 24, 25, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 47, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94], "fact": [0, 22, 25, 32, 34, 36, 37, 38, 40, 41, 51, 58, 61, 62, 63, 74, 78, 81, 88, 92], "ahead": [0, 26, 52, 60, 61, 63, 74, 80, 83, 98], "write": [0, 6, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 47, 49, 52, 53, 58, 60, 63, 71, 72, 75, 77, 78, 81, 83, 88, 90, 91, 94, 97], "down": [0, 6, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 27, 31, 32, 34, 36, 37, 38, 41, 42, 49, 58, 60, 62, 63, 72, 75, 88], "context": [0, 5, 18, 27, 31, 32, 34, 36, 42, 51, 58, 61, 75, 88, 92], "full": [0, 20, 21, 22, 32, 40, 41, 42, 57, 60, 76, 81, 83, 91], "specif": [0, 6, 22, 25, 31, 36, 41, 46, 52, 55, 58, 61, 63, 66, 67, 71, 72, 73, 75, 76, 77, 78, 80, 81, 83, 90, 92], "c": [0, 2, 3, 5, 6, 9, 21, 25, 31, 33, 34, 52, 60, 61, 71, 75, 81], "To": [0, 2, 6, 8, 11, 21, 22, 24, 25, 27, 29, 31, 34, 36, 37, 40, 41, 42, 44, 46, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 66, 69, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94], "one": [0, 2, 6, 9, 21, 22, 24, 25, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 51, 52, 53, 54, 57, 58, 59, 60, 61, 66, 67, 71, 73, 74, 75, 78, 80, 81, 83, 88, 90, 91, 92, 94], "follow": [0, 2, 6, 12, 21, 22, 23, 24, 25, 27, 34, 36, 37, 42, 46, 49, 51, 52, 53, 54, 55, 58, 59, 60, 61, 64, 72, 73, 74, 75, 76, 77, 78, 80, 83, 88, 90, 91, 92, 94], "construct": [0, 12, 25, 32, 36, 37, 40, 51, 53, 55, 58, 59, 72, 73, 74, 75, 76, 77, 78, 83, 90, 92, 94], "those": [0, 21, 22, 27, 31, 34, 36, 37, 48, 49, 52, 53, 58, 59, 62, 63, 72, 73, 74, 75, 76, 80, 81, 90], "parametr": [0, 31, 34, 38, 51, 57, 58, 61, 62, 63, 67, 74, 75, 76, 78, 81, 90], "can": [0, 3, 6, 8, 9, 16, 17, 18, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94, 97], "mani": [0, 2, 9, 21, 22, 24, 29, 31, 33, 34, 38, 40, 41, 42, 46, 47, 48, 49, 51, 52, 53, 57, 58, 60, 61, 62, 69, 72, 75, 76, 78, 81, 83, 88, 90, 91, 92, 94, 97], "plot": [0, 2, 3, 6, 8, 9, 11, 15, 22, 24, 32, 34, 37, 40, 41, 42, 43, 46, 49, 52, 54, 57, 58, 59, 61, 62, 63, 64, 66, 69, 72, 74, 76, 77, 78, 80, 81, 88, 90, 92, 94, 98], "them": [0, 6, 11, 25, 34, 36, 38, 46, 47, 48, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 69, 72, 73, 75, 76, 77, 83, 88, 92, 94, 97], "should": [0, 3, 5, 6, 8, 9, 21, 22, 24, 25, 30, 31, 33, 34, 36, 37, 38, 40, 42, 44, 46, 51, 52, 53, 58, 59, 60, 61, 62, 63, 64, 66, 72, 73, 74, 75, 76, 78, 81, 83, 88, 90, 92, 94], "carefulli": [0, 2, 25, 30, 54, 58, 66, 72, 76, 83], "best": [0, 5, 6, 15, 21, 22, 34, 38, 54, 57, 59, 63, 64, 66, 75, 81, 83, 88, 97], "clear": [0, 25, 37, 38, 41, 49, 53, 60, 64, 75, 77, 83, 88, 90, 91, 94, 97], "come": [0, 2, 6, 8, 9, 21, 31, 32, 34, 36, 38, 42, 46, 49, 51, 52, 53, 54, 58, 60, 62, 66, 67, 68, 72, 73, 74, 75, 76, 88, 90, 91, 94], "doe": [0, 2, 3, 8, 14, 15, 19, 21, 22, 25, 30, 31, 33, 34, 36, 40, 42, 47, 51, 52, 53, 57, 58, 61, 62, 63, 66, 72, 74, 75, 76, 78, 80, 81, 83, 84, 88, 90, 92, 93, 94], "jibe": 0, "If": [0, 6, 8, 11, 15, 16, 18, 21, 22, 24, 25, 30, 31, 32, 34, 36, 37, 38, 41, 42, 46, 47, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 67, 72, 73, 74, 75, 77, 78, 81, 83, 88, 90, 91, 92, 94], "have": [0, 2, 5, 6, 8, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94, 97], "ani": [0, 5, 6, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 25, 31, 32, 34, 36, 38, 40, 41, 42, 46, 47, 49, 51, 52, 53, 57, 58, 60, 62, 63, 67, 71, 72, 73, 74, 75, 80, 81, 83, 84, 88, 90, 92, 93, 94, 95], "idea": [0, 6, 14, 20, 25, 33, 34, 38, 45, 51, 53, 57, 58, 61, 63, 64, 66, 73, 75, 88, 90], "why": [0, 2, 3, 6, 12, 13, 14, 15, 16, 17, 18, 30, 36, 45, 53, 55, 66, 72, 74, 81, 83, 88, 90, 91, 92, 94], "d": [0, 3, 5, 6, 21, 24, 30, 31, 32, 34, 36, 37, 40, 41, 42, 46, 47, 49, 54, 55, 58, 59, 62, 63, 64, 66, 73, 75, 77, 81, 88, 90], "until": [0, 73, 88, 92], "through": [0, 11, 21, 22, 23, 31, 34, 38, 41, 42, 49, 53, 55, 63, 72, 74, 75, 76, 77, 83, 88, 90, 92], "complet": [0, 11, 21, 24, 31, 36, 37, 38, 40, 42, 49, 52, 54, 58, 61, 67, 72, 73, 74, 75, 76, 80, 81, 83, 88, 90, 92], "access": [0, 6, 21, 32, 46, 51, 52, 53, 57, 61, 83], "here": [0, 3, 6, 8, 9, 21, 25, 30, 31, 32, 34, 36, 40, 42, 46, 47, 48, 51, 52, 53, 54, 55, 57, 58, 60, 61, 62, 63, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 88, 90, 92, 94], "extract": [0, 40, 42, 52, 58, 76, 77, 81, 92], "made": [0, 5, 16, 21, 36, 51, 58, 60, 83, 88, 97], "nicrophoru": 0, "orbicolli": 0, "locat": [0, 2, 8, 16, 21, 31, 34, 38, 40, 52, 54, 60, 62, 69, 72, 76, 83, 88, 92, 94], "10": [0, 3, 8, 11, 22, 24, 31, 34, 36, 37, 38, 40, 41, 42, 46, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94, 98], "0": [0, 6, 8, 9, 11, 21, 22, 24, 34, 36, 37, 38, 40, 41, 42, 43, 46, 47, 48, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 80, 81, 88, 90, 92, 94, 98], "fall": [0, 57, 74, 75, 88, 90], "within": [0, 2, 21, 34, 48, 51, 53, 54, 58, 59, 61, 63, 74, 83, 90, 92], "homework": [1, 4, 7, 10, 21, 22, 32, 34, 60, 71, 95], "first": [1, 2, 3, 6, 8, 21, 22, 25, 26, 30, 31, 32, 34, 36, 37, 38, 40, 42, 46, 47, 48, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 88, 90, 91, 92, 94], "attempt": [1, 6, 12, 34, 57, 62, 63, 81, 83], "bayesian": [1, 5, 11, 27, 33, 34, 36, 37, 39, 40, 46, 48, 49, 51, 52, 57, 58, 61, 63, 73, 74, 88, 90, 97, 98], "70": [1, 10, 57, 59, 61, 64, 72, 81], "pt": [1, 4, 7, 10], "import": [2, 3, 6, 8, 14, 15, 18, 22, 24, 25, 30, 31, 33, 36, 37, 38, 40, 41, 42, 43, 46, 47, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 92, 94], "numpi": [2, 8, 22, 24, 36, 37, 38, 40, 41, 42, 43, 46, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 76, 77, 78, 80, 81, 88, 92, 94], "np": [2, 8, 22, 24, 36, 37, 38, 40, 41, 42, 43, 46, 51, 52, 53, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94], "continu": [2, 8, 25, 32, 34, 37, 41, 42, 46, 47, 49, 53, 55, 60, 63, 66, 73, 74, 75, 81, 88, 92, 94], "choos": [2, 21, 31, 32, 35, 36, 37, 38, 40, 42, 46, 48, 49, 51, 53, 54, 57, 58, 59, 62, 63, 70, 71, 75, 76, 77, 78, 83, 90], "gener": [2, 5, 6, 8, 11, 12, 15, 22, 25, 27, 31, 32, 33, 34, 36, 37, 40, 41, 42, 45, 48, 49, 52, 53, 55, 57, 59, 60, 61, 62, 63, 64, 66, 70, 71, 73, 75, 76, 77, 80, 81, 83, 88, 90, 91, 92, 94], "model": [2, 3, 5, 6, 11, 12, 14, 15, 18, 19, 22, 24, 25, 27, 28, 30, 33, 34, 38, 39, 41, 46, 49, 52, 57, 60, 67, 73, 75, 76, 77, 80, 83, 88, 90, 92, 94, 97, 98], "nonetheless": [2, 22, 25, 34, 40, 51, 58, 60, 61, 74, 75, 80, 81], "estim": [2, 5, 9, 11, 13, 22, 24, 25, 27, 32, 34, 35, 36, 38, 46, 47, 50, 54, 55, 58, 60, 61, 66, 69, 71, 72, 73, 74, 76, 77, 81, 90, 91, 94, 98], "where": [2, 5, 6, 8, 9, 21, 22, 25, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 46, 48, 49, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 66, 67, 72, 73, 75, 76, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94], "contribut": [2, 31, 53, 66, 81, 88, 90], "exact": [2, 36, 40, 81, 88, 90], "constraint": [2, 58, 76, 92], "less": [2, 16, 30, 34, 36, 46, 51, 58, 61, 66, 73, 74, 90, 92, 94], "explor": [2, 6, 11, 25, 32, 33, 34, 36, 38, 40, 52, 55, 58, 59, 62, 72, 75, 88, 90, 92, 94, 97], "computation": [2, 21, 41, 63, 81, 92], "work": [2, 8, 9, 18, 21, 22, 23, 24, 25, 31, 34, 36, 37, 40, 41, 44, 47, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 80, 83, 88, 90, 91, 92, 94, 98], "david": [2, 81], "prober": 2, "": [2, 3, 9, 11, 15, 21, 22, 23, 24, 28, 29, 31, 32, 34, 36, 37, 40, 41, 44, 46, 47, 48, 51, 52, 53, 54, 55, 57, 59, 61, 62, 63, 64, 66, 68, 69, 71, 72, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 94, 97, 98], "lab": [2, 11, 21, 51, 74, 91, 92, 98], "monitor": 2, "activ": [2, 9, 21, 48, 51, 74, 75, 83, 92], "zebrafish": 2, "larva": 2, "genotyp": 2, "effort": [2, 73], "understand": [2, 5, 11, 25, 31, 38, 40, 46, 49, 53, 58, 66, 72, 75, 81, 83, 88], "sleep": 2, "control": [2, 7, 9, 21, 52, 54, 58, 91], "publish": [2, 3, 51, 61, 81], "gandhi": 2, "et": [2, 6, 9, 38, 40, 42, 51, 54, 55, 58, 59, 61, 64, 73, 77, 78, 81, 97], "al": [2, 6, 9, 38, 40, 42, 51, 54, 55, 58, 59, 61, 64, 73, 77, 78, 81, 94, 97], "2015": [2, 9, 69, 71], "minut": [2, 6, 22, 24, 25, 31, 42, 51, 74, 91], "17": [2, 11, 21, 36, 42, 51, 52, 53, 58, 59, 61, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 92, 94, 98], "fish": [2, 61, 66, 74, 75, 78, 92], "had": [2, 31, 34, 42, 54, 58, 61, 62, 64, 67, 74, 80, 83, 88, 94], "over": [2, 8, 11, 25, 29, 34, 36, 37, 38, 42, 47, 48, 49, 53, 58, 63, 66, 71, 73, 74, 75, 77, 78, 81, 83, 88, 90, 92, 94], "nine": 2, "hour": [2, 21, 22, 23, 24, 51, 83, 92, 98], "third": [2, 36, 53, 59, 83], "night": 2, "result": [2, 6, 9, 11, 25, 32, 33, 34, 36, 37, 40, 41, 42, 47, 51, 52, 53, 55, 58, 59, 61, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 81, 83, 88, 90, 92, 94, 97], "easili": [2, 21, 36, 47, 51, 52, 58, 68, 75, 81, 88, 90], "load": [2, 21, 22, 24, 36, 37, 38, 40, 41, 42, 43, 46, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94], "directli": [2, 21, 25, 31, 34, 36, 40, 41, 49, 51, 52, 53, 54, 55, 58, 63, 64, 66, 71, 73, 75, 77, 81, 90], "arrai": [2, 3, 8, 31, 36, 37, 40, 42, 51, 52, 53, 54, 55, 57, 58, 59, 61, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 92, 94], "variabl": [2, 5, 8, 25, 29, 31, 34, 36, 37, 40, 47, 51, 52, 53, 54, 55, 58, 59, 61, 62, 66, 68, 71, 72, 73, 74, 75, 76, 77, 80, 81, 88, 92, 94], "call": [2, 8, 21, 24, 25, 29, 30, 31, 32, 34, 36, 46, 48, 51, 52, 53, 55, 58, 62, 63, 64, 71, 72, 75, 78, 80, 81, 88, 90, 92, 94], "y": [2, 5, 6, 22, 24, 25, 27, 29, 30, 31, 32, 34, 36, 37, 40, 41, 42, 43, 46, 49, 51, 52, 53, 54, 55, 57, 58, 60, 63, 66, 68, 72, 73, 74, 75, 76, 77, 78, 80, 81, 88, 94], "200": [2, 36, 37, 38, 40, 41, 42, 43, 51, 53, 54, 55, 57, 58, 59, 64, 74, 75, 81, 94], "190": [2, 38, 81, 94], "249": 2, "232": 2, "319": [2, 51], "104": 2, "93": [2, 53, 66], "233": 2, "287": 2, "49": [2, 36, 53, 92], "311": [2, 51], "225": 2, "243": [2, 53], "113": [2, 21, 81], "133": 2, "179": [2, 53, 81, 92], "normal": [2, 5, 6, 8, 13, 22, 24, 32, 33, 34, 37, 38, 39, 46, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 72, 74, 76, 77, 79, 81, 88, 92, 94], "drawn": [2, 51, 53, 58, 63, 73, 75, 81, 94], "mu": [2, 6, 8, 22, 24, 30, 31, 34, 36, 41, 42, 57, 58, 59, 60, 62, 64, 75, 81, 94], "scale": [2, 31, 34, 36, 40, 41, 42, 43, 51, 52, 54, 55, 58, 60, 63, 64, 66, 72, 74, 76, 77, 78, 80, 88, 90, 92], "sigma": [2, 5, 8, 22, 24, 25, 30, 31, 34, 36, 37, 40, 41, 42, 54, 55, 57, 58, 59, 60, 62, 64, 72, 75, 76, 77, 78, 80, 81, 90], "begin": [2, 5, 6, 8, 21, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 88, 90, 92, 94], "align": [2, 5, 6, 8, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 88, 90, 92, 94], "y_i": [2, 5, 30, 31, 40, 63, 66, 75, 78], "mid": [2, 8, 9, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 46, 47, 49, 51, 52, 53, 54, 55, 58, 60, 62, 63, 66, 67, 68, 71, 73, 75, 76, 77, 78, 80, 81, 88], "sim": [2, 5, 6, 31, 34, 36, 37, 38, 40, 42, 51, 53, 54, 55, 58, 59, 60, 61, 62, 64, 67, 69, 71, 72, 74, 75, 76, 77, 78, 80, 81, 90, 92, 94], "text": [2, 6, 24, 25, 30, 31, 34, 36, 37, 38, 40, 42, 48, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 67, 69, 71, 72, 74, 75, 76, 77, 78, 80, 81, 83, 88, 92, 94], "norm": [2, 5, 31, 34, 36, 40, 41, 42, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 64, 72, 74, 75, 77, 78, 81, 88], "foral": [2, 5, 6, 31, 36, 37, 40, 42, 51, 53, 54, 55, 58, 59, 61, 64, 67, 69, 74, 75, 77, 78, 81, 92, 94], "end": [2, 5, 6, 8, 24, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 46, 47, 48, 49, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 92, 94], "task": [2, 25, 34, 35, 40, 59, 64, 83, 88, 90, 92], "posterior": [2, 3, 8, 9, 11, 12, 13, 15, 17, 19, 22, 24, 26, 27, 29, 31, 34, 37, 42, 46, 47, 49, 52, 53, 54, 56, 58, 60, 61, 62, 64, 66, 67, 68, 69, 71, 72, 73, 74, 77, 78, 81, 88, 90, 92, 94, 98], "g": [2, 9, 21, 22, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 46, 49, 51, 52, 53, 58, 60, 63, 67, 68, 69, 71, 73, 74, 75, 77, 81, 83, 88, 94], "improp": [2, 34, 36, 37], "uninform": 2, "becaus": [2, 6, 8, 21, 22, 23, 25, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 42, 47, 51, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 92, 94], "veri": [2, 6, 25, 30, 31, 32, 34, 36, 38, 40, 41, 42, 47, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 72, 74, 75, 76, 77, 78, 80, 81, 88, 90, 92, 94], "broad": [2, 31, 32, 34, 36, 40, 58, 63, 74, 75, 83, 94, 98], "infinit": [2, 34, 51, 75, 90], "even": [2, 6, 25, 31, 32, 34, 36, 52, 53, 57, 58, 61, 63, 72, 74, 75, 80, 83, 88, 90, 94], "normaliz": [2, 34], "constant": [2, 5, 31, 34, 36, 37, 40, 58, 67, 75, 76, 78, 80, 81, 94], "1em": [2, 31, 34, 36, 37, 38, 40, 42, 47, 51, 53, 54, 55, 58, 59, 61, 62, 64, 66, 67, 69, 71, 72, 74, 75, 76, 77, 78, 80, 81, 90, 92, 94], "Of": [2, 6, 31, 38, 67, 75], "both": [2, 8, 25, 30, 36, 42, 51, 52, 58, 59, 61, 63, 64, 66, 74, 75, 77, 83, 88, 90, 92, 94], "assum": [2, 3, 5, 6, 9, 21, 24, 31, 34, 36, 37, 38, 40, 41, 42, 51, 52, 53, 54, 58, 60, 63, 66, 67, 68, 71, 72, 75, 77, 81, 88, 91, 94], "nonneg": [2, 34], "again": [2, 8, 22, 24, 25, 30, 31, 32, 36, 37, 40, 41, 42, 47, 49, 51, 53, 55, 58, 59, 61, 63, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 88, 94], "150": [2, 51, 53, 55, 81], "min": [2, 34, 43, 47, 58, 75, 76, 77, 78, 80, 92], "effect": [2, 9, 16, 22, 24, 25, 32, 34, 40, 46, 51, 55, 60, 62, 64, 66, 67, 69, 71, 72, 74, 75, 77, 78, 80, 81, 83, 88, 90, 94], "oppos": [2, 8, 37, 58, 83, 90, 92], "uniform": [2, 5, 36, 37, 38, 43, 46, 53, 54, 69, 73, 90], "20": [2, 7, 8, 11, 21, 22, 24, 31, 36, 40, 41, 42, 51, 52, 53, 58, 59, 61, 64, 66, 69, 74, 75, 76, 77, 78, 80, 81, 83, 94, 98], "comment": [2, 6, 20, 52, 75, 83, 92], "download": [3, 6, 21, 22, 36, 37, 40, 42, 51, 53, 54, 55, 58, 59, 61, 64, 66, 74, 75, 76, 77, 78, 80, 88, 94], "wa": [3, 6, 8, 9, 25, 34, 36, 38, 40, 42, 46, 47, 51, 52, 55, 58, 60, 61, 63, 72, 74, 75, 78, 80, 81, 88, 90, 92, 94, 95], "motiv": [3, 30, 38], "discuss": [3, 5, 6, 11, 22, 24, 25, 30, 32, 34, 36, 41, 42, 46, 48, 49, 51, 53, 55, 58, 59, 61, 66, 68, 73, 75, 76, 83, 88, 97], "section": [3, 22, 23, 24, 25, 30, 41, 52, 61, 62, 75, 83, 88, 92, 94], "holm": 3, "huber": 3, "book": [3, 25, 30, 38, 48, 97], "show": [3, 5, 21, 22, 24, 34, 36, 37, 38, 40, 41, 42, 43, 47, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 83, 88, 92, 94], "gamma": [3, 37, 38, 41, 42, 43, 46, 53, 54, 55, 58, 59, 60, 64, 67, 74, 75, 76, 77, 78, 81, 92], "updat": [3, 8, 21, 26, 32, 34, 38, 40, 53, 58, 60, 72, 73, 74, 77, 81, 88], "welcom": 3, "wikipedia": [3, 38, 61], "tabl": [3, 38, 52, 58, 91, 94], "check": [3, 6, 9, 11, 15, 17, 18, 19, 21, 22, 38, 44, 51, 52, 53, 54, 62, 64, 66, 69, 73, 75, 77, 78, 81, 83, 88, 91, 92, 94, 98], "answer": [3, 16, 52, 59, 60, 61, 63, 83, 91, 92, 94], "actual": [3, 32, 34, 36, 38, 41, 49, 51, 58, 59, 63, 66, 69, 71, 73, 74, 75, 77, 78, 80, 88, 92, 94], "proof": [3, 30, 77], "sequenc": [3, 6, 88], "chromosom": 3, "dna": [3, 34, 51], "e": [3, 6, 21, 22, 24, 25, 30, 32, 34, 36, 37, 41, 46, 51, 53, 58, 60, 62, 63, 64, 66, 67, 69, 71, 72, 74, 75, 77, 78, 80, 81, 83, 90, 92, 94], "coli": [3, 34, 72, 77], "strain": [3, 9, 71], "atcc": 3, "baa": 3, "196": [3, 81], "fasta": 3, "format": [3, 18, 24, 40, 42, 52, 58, 69, 76, 77, 88], "resist": 3, "multipl": [3, 8, 23, 41, 52, 61, 63, 80, 81, 88, 90, 92, 94], "drug": 3, "studi": [3, 9, 11, 25, 32, 39, 51, 53, 54, 58, 71, 72, 75, 78, 81, 91, 94, 97], "antibiot": 3, "paper": [3, 6, 31, 32, 38, 48, 51, 52, 53, 61, 62, 63, 66, 73, 74, 75, 77, 81, 88, 90, 91, 94], "read": [3, 6, 11, 22, 31, 33, 40, 45, 46, 48, 52, 53, 60, 61, 63, 66, 71, 72, 73, 74, 81, 88, 91, 92, 98], "singl": [3, 6, 26, 29, 30, 31, 33, 34, 38, 41, 51, 53, 55, 57, 59, 60, 61, 63, 66, 71, 72, 77, 78, 83, 91, 92, 94], "string": [3, 52, 72, 92], "below": [3, 8, 9, 11, 22, 24, 25, 30, 38, 42, 46, 52, 53, 54, 55, 57, 58, 59, 61, 62, 66, 72, 73, 75, 77, 80, 83, 88, 90, 92, 94], "1": [3, 4, 6, 7, 9, 10, 11, 22, 24, 25, 29, 30, 31, 32, 34, 36, 37, 38, 40, 41, 42, 43, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 84, 88, 90, 91, 92, 94, 98], "def": [3, 8, 36, 37, 40, 42, 51, 57, 75, 76, 77, 78, 80, 81, 88, 92], "read_fasta_single_record": 3, "filenam": [3, 52, 83], "file": [3, 6, 21, 52, 58, 77, 81, 83], "contain": [3, 8, 25, 30, 34, 37, 38, 41, 49, 51, 52, 53, 55, 57, 58, 60, 66, 67, 71, 72, 75, 78, 80, 81, 83, 88, 90, 92, 97], "line": [3, 15, 21, 24, 31, 34, 36, 37, 38, 40, 41, 43, 51, 52, 53, 54, 55, 57, 58, 74, 75, 76, 77, 78, 80, 88, 90, 92, 94], "descriptor": 3, "all": [3, 5, 6, 11, 21, 22, 25, 29, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 47, 49, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 92, 94], "subsequ": [3, 32, 60, 75, 80, 94], "open": [3, 21, 22, 24, 81, 92], "r": [3, 24, 25, 47, 48, 52, 62, 72, 81, 90, 92], "f": [3, 6, 22, 24, 26, 27, 29, 30, 31, 32, 34, 36, 38, 40, 41, 43, 46, 51, 53, 58, 60, 63, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 80, 81, 88, 90, 91, 92, 94], "readlin": 3, "rstrip": 3, "strip": [3, 72, 74, 78, 81, 83], "whitespac": 3, "seq": [3, 7], "while": [3, 9, 21, 34, 36, 37, 38, 40, 47, 48, 51, 52, 53, 55, 58, 61, 63, 73, 75, 76, 78, 81, 83, 88, 90, 92, 94], "return": [3, 8, 11, 30, 36, 37, 40, 41, 42, 46, 48, 51, 52, 53, 54, 55, 58, 59, 64, 66, 75, 76, 77, 78, 80, 81, 88, 90, 92, 94], "find": [3, 5, 6, 12, 13, 21, 22, 29, 31, 32, 33, 34, 36, 37, 40, 41, 42, 53, 57, 58, 60, 63, 66, 73, 75, 76, 77, 80, 81, 83, 88, 90, 92, 97], "index": [3, 6, 49, 51, 52, 53, 58, 59, 61, 66, 72, 78, 81], "shine": [3, 9], "delgarno": 3, "motif": 3, "initi": [3, 21, 37, 38, 40, 42, 58, 60, 66, 76, 77, 88, 90, 94], "protein": [3, 58, 91, 94], "synthesi": 3, "aggaggt": 3, "recognit": 3, "recognition_sites_with_r": 3, "recog_seq": 3, "indic": [3, 12, 40, 53, 55, 58, 60, 61, 62, 64, 66, 67, 69, 72, 73, 74, 75, 77, 78, 80, 83, 88, 94], "findit": 3, "append": [3, 51, 57, 58, 78, 92], "start": [3, 8, 9, 21, 24, 25, 32, 34, 36, 37, 40, 42, 48, 51, 52, 53, 54, 55, 57, 58, 61, 62, 66, 72, 73, 75, 76, 77, 78, 88, 90, 91, 92, 94], "store": [3, 21, 36, 37, 52, 57, 58, 59, 61, 66, 76, 94], "number": [3, 6, 8, 9, 16, 21, 22, 24, 25, 30, 31, 32, 34, 36, 38, 45, 49, 51, 52, 53, 55, 57, 58, 59, 61, 63, 66, 69, 71, 72, 73, 74, 78, 80, 81, 83, 88, 90, 91, 92, 94], "base": [3, 9, 11, 19, 21, 22, 25, 31, 32, 34, 51, 52, 53, 57, 58, 60, 61, 63, 64, 75, 76, 81, 88, 91, 92, 94, 97, 98], "between": [3, 5, 9, 25, 30, 32, 33, 34, 37, 42, 48, 51, 53, 54, 55, 58, 60, 61, 63, 64, 66, 67, 72, 73, 74, 75, 78, 81, 84, 88, 90, 91, 94, 95], "occurr": [3, 25], "distanc": [3, 34, 60, 81, 88], "explain": [3, 14, 16, 18, 77, 83, 91], "reason": [3, 6, 8, 11, 25, 31, 34, 36, 40, 41, 51, 53, 58, 59, 60, 61, 62, 63, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 92, 94, 97], "exploratori": [3, 6], "ecdf": [3, 9, 49, 52, 53, 54, 55, 58, 59, 61, 64, 69, 81, 94], "inter": 3, "comput": [3, 6, 8, 9, 11, 12, 13, 17, 21, 25, 29, 30, 31, 32, 34, 46, 47, 48, 49, 63, 68, 71, 72, 73, 90, 92], "rate": [3, 8, 30, 47, 58, 75, 76, 77, 80, 91, 94], "invers": [3, 34, 40, 41, 46, 51, 53, 60, 75, 76, 78, 88], "characterist": [3, 40, 58, 77], "overwhelm": [4, 69, 90], "45": [4, 37, 38, 53, 57, 78], "exponenti": [4, 30, 33, 36, 37, 41, 42, 46, 57, 60, 63, 75, 76, 78, 80, 88, 90, 94], "conjug": [4, 12, 75], "55": [4, 9, 51, 72, 78], "heard": [5, 25], "fit": [5, 15, 21, 25, 54, 58, 71, 75, 78, 97], "variat": [5, 11, 20, 31, 32, 36, 37, 39, 52, 55, 58, 71, 75, 78, 92, 98], "covari": [5, 8, 11, 31, 39, 40, 41, 55, 60, 76, 78, 80, 81, 88, 90, 98], "minim": [5, 36, 40, 41, 42, 52, 58, 76, 77, 81, 83, 88], "sum": [5, 9, 29, 30, 32, 36, 37, 40, 42, 46, 47, 53, 57, 58, 60, 61, 63, 69, 81, 88, 90, 94], "residu": 5, "pars": [5, 74, 75, 97], "mean": [5, 8, 13, 14, 15, 19, 20, 21, 22, 24, 25, 31, 33, 34, 36, 40, 42, 46, 48, 49, 51, 52, 53, 57, 58, 60, 61, 62, 63, 66, 67, 71, 72, 73, 74, 76, 77, 78, 80, 81, 83, 88, 90, 92, 94], "x": [5, 8, 25, 27, 30, 36, 37, 40, 41, 42, 43, 51, 52, 53, 54, 55, 57, 58, 62, 74, 75, 76, 77, 78, 80, 81, 88, 92], "independ": [5, 8, 16, 20, 31, 33, 34, 36, 37, 42, 46, 53, 54, 60, 61, 62, 63, 64, 66, 67, 69, 72, 75, 81, 88, 94], "known": [5, 8, 25, 31, 32, 33, 34, 37, 38, 41, 46, 48, 57, 58, 60, 63, 66, 73, 75, 91, 92, 94], "essenti": [5, 17, 31, 52, 61, 72, 83, 90, 92], "exactli": [5, 25, 31, 38, 53, 58, 60, 66, 75, 76, 77, 81, 88, 94], "could": [5, 23, 30, 31, 34, 36, 37, 40, 42, 47, 49, 51, 53, 54, 57, 58, 59, 60, 62, 63, 67, 71, 72, 74, 75, 78, 80, 81, 88, 90, 92, 94], "someth": [5, 8, 21, 25, 36, 38, 58, 63, 71, 73, 75, 83, 88, 90, 92], "depend": [5, 22, 31, 33, 36, 37, 38, 41, 46, 47, 51, 53, 59, 64, 68, 71, 74, 75, 81, 88, 91, 92, 94], "ha": [5, 6, 8, 9, 13, 21, 24, 25, 30, 31, 32, 33, 34, 36, 37, 38, 40, 41, 46, 47, 48, 51, 52, 53, 55, 58, 60, 61, 62, 63, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 78, 80, 81, 83, 88, 90, 91, 92, 94, 97], "stochast": [5, 58, 75, 81, 90, 94], "nois": [5, 25, 31, 77], "deriv": [5, 25, 30, 33, 34, 36, 40, 41, 46, 58, 60, 63, 73, 75, 79, 81, 88, 90], "theoret": [5, 6, 31, 32, 37, 38, 42, 51, 53, 58, 60, 74, 75, 76, 83, 90], "relat": [5, 6, 11, 19, 30, 31, 34, 40, 41, 46, 58, 62, 63, 73, 75, 83, 90, 92], "written": [5, 8, 24, 25, 27, 32, 34, 36, 37, 51, 52, 53, 58, 63, 67, 71, 78, 83, 84, 88, 92, 93, 94, 95], "f_y": [5, 30], "phi": [5, 6, 34, 36, 37, 40, 42, 54, 55, 58, 59, 64, 67, 68, 69, 71, 78, 81, 90, 94], "wish": [5, 30, 31, 32, 36, 37, 46, 51, 52, 53, 54, 57, 58, 60, 62, 63, 72, 73, 75, 81, 83, 91], "determin": [5, 6, 30, 34, 38, 53, 58, 60, 61, 63, 66, 69, 72, 75, 76, 88, 92, 94], "infer": [5, 20, 21, 23, 27, 32, 34, 36, 37, 40, 41, 52, 53, 58, 61, 63, 69, 73, 74, 76, 77, 78, 97, 98], "x_1": [5, 30, 60, 77], "y_1": [5, 26, 30, 31, 40, 63, 66], "x_2": [5, 30, 60, 77], "y_2": [5, 26, 30, 31, 40, 63, 66], "ldot": [5, 30, 31, 46, 49, 60, 63, 66, 67, 71, 72, 75, 76], "x_n": 5, "y_n": [5, 31, 63, 66], "mathrm": [5, 30, 31, 32, 34, 36, 37, 41, 46, 47, 49, 61, 62, 63, 66, 73, 75, 76, 77, 78, 80, 88, 90, 94], "x_i": [5, 36, 60, 75, 77, 94], "sigma_i": [5, 31, 58, 59, 64, 75, 81], "A": [5, 6, 8, 9, 11, 25, 27, 30, 31, 33, 34, 39, 41, 46, 52, 53, 55, 57, 59, 61, 63, 67, 74, 75, 77, 83, 91, 92, 94, 97], "r_i": 5, "frac": [5, 25, 26, 27, 29, 30, 31, 32, 34, 36, 37, 38, 41, 42, 47, 48, 49, 53, 54, 55, 58, 59, 61, 62, 63, 64, 66, 67, 68, 71, 73, 75, 77, 81, 88, 90], "sum_": [5, 29, 31, 36, 37, 49, 63, 66, 71, 81, 94], "n": [5, 9, 30, 31, 36, 37, 38, 46, 49, 51, 53, 54, 55, 58, 59, 61, 63, 64, 66, 67, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 88, 90, 91, 92, 94], "2": [5, 7, 8, 10, 11, 22, 24, 25, 30, 31, 34, 36, 37, 38, 40, 41, 42, 43, 46, 49, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 83, 85, 88, 90, 91, 92, 94, 95, 98], "equival": [5, 25, 30, 34, 36, 53, 58, 60, 62, 78, 81, 90, 94], "map": [5, 7, 13, 42, 53, 57, 69, 75, 77, 80, 90, 92], "abov": [5, 6, 8, 9, 21, 22, 26, 31, 34, 36, 37, 46, 51, 53, 55, 58, 59, 62, 66, 71, 72, 73, 75, 77, 80, 81, 88, 90, 92, 94], "note": [5, 6, 8, 9, 21, 24, 25, 27, 30, 32, 34, 36, 37, 38, 40, 41, 42, 47, 49, 51, 52, 53, 54, 58, 59, 60, 61, 62, 63, 64, 66, 67, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 90, 91, 92, 94], "taken": [5, 8, 21, 32, 46, 49, 52, 61, 62, 88], "homoscedast": [5, 42, 54, 75, 76, 77], "error": [5, 31, 36, 51, 53, 58, 60, 66, 71, 74, 75, 76, 77, 83, 88, 90, 92], "further": [5, 15, 25, 36, 45, 58, 63, 72, 74, 75, 81], "whose": [5, 25, 46], "still": [5, 17, 31, 34, 41, 47, 51, 55, 57, 58, 59, 60, 62, 63, 66, 72, 74, 75, 81, 88, 92, 94], "need": [5, 6, 8, 16, 21, 22, 23, 24, 25, 30, 31, 32, 33, 36, 37, 40, 42, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63, 66, 67, 71, 72, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94], "consid": [5, 6, 25, 31, 32, 34, 36, 37, 40, 41, 42, 47, 51, 53, 55, 57, 58, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 90, 94], "assumpt": [5, 63, 66, 71], "often": [5, 6, 22, 25, 30, 31, 32, 34, 36, 41, 46, 49, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 71, 74, 75, 77, 83, 92, 94], "done": [5, 9, 21, 25, 31, 32, 40, 51, 52, 53, 55, 58, 63, 66, 71, 72, 75, 78, 80, 88, 90, 92, 94], "issu": [5, 6, 30, 31, 32, 34, 36, 55, 57, 58, 62, 72, 74, 75, 92], "inspir": 6, "valentin": 6, "svensson": 6, "blog": [6, 53, 75, 83, 94], "post": [6, 36, 37, 53, 73, 75, 77, 80, 83, 94], "viewabl": 6, "cell": [6, 22, 31, 34, 42, 51, 53, 54, 58, 61, 66, 72, 74, 75, 77, 78, 83, 88, 91, 92], "rna": [6, 51, 66, 74, 75, 92], "scrna": 6, "technologi": 6, "more": [6, 9, 21, 22, 25, 26, 30, 31, 32, 34, 36, 37, 38, 40, 42, 44, 47, 48, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 63, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 89, 90, 92, 94], "common": [6, 25, 34, 55, 63, 67, 75], "It": [6, 8, 21, 22, 24, 25, 30, 31, 33, 34, 36, 37, 38, 40, 41, 42, 46, 47, 49, 51, 52, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 72, 73, 74, 75, 76, 77, 78, 80, 83, 84, 88, 90, 94, 95], "enabl": [6, 8, 22, 38, 41, 51, 52, 54, 55, 58, 59, 61, 76, 78, 92], "research": [6, 22, 25, 31, 32, 34, 42, 57, 83, 92, 97], "count": [6, 53, 60, 61, 66, 75, 78, 91, 94], "mrna": [6, 53, 61, 66, 78], "transcript": [6, 51, 53, 61, 66, 74, 75, 78], "gene": [6, 53, 60, 61, 66, 72, 74, 75, 78, 92], "techniqu": [6, 11, 34, 46, 51, 52, 55, 61, 63, 66, 73, 77, 81, 90], "usual": [6, 16, 22, 25, 36, 42, 52, 54, 58, 60, 61, 63, 66, 69, 73, 75, 76, 77, 78, 88, 92, 94], "individu": [6, 9, 33, 37, 58, 66, 69, 72, 90, 94], "encas": [6, 80], "droplet": [6, 36, 37, 40, 42, 54, 55, 59, 64, 81], "microfluid": 6, "devic": 6, "importantli": [6, 22, 30, 31, 32, 38, 42, 46, 47, 49, 51, 53, 58, 61, 63, 66, 72, 73, 74, 75, 78, 81], "cdna": 6, "barcod": 6, "molecul": [6, 33, 51, 58, 60, 61, 78], "identif": 6, "output": [6, 8, 21, 42, 51, 58, 63, 66, 72, 76, 81, 92], "matrix": [6, 8, 30, 31, 34, 40, 41, 42, 53, 60, 66, 76, 77, 78, 80, 88, 90, 92], "row": [6, 51, 52, 57, 58, 59, 72, 75, 81, 88], "correspond": [6, 21, 25, 30, 51, 53, 72, 75, 77, 78, 81, 88, 94], "column": [6, 8, 51, 52, 53, 55, 57, 58, 59, 61, 72, 74, 81, 92], "entri": [6, 31, 34, 41, 53, 60, 72, 75, 76, 78, 81, 83, 92], "integ": [6, 8, 30, 46, 51, 53, 60, 92], "process": [6, 8, 11, 21, 22, 25, 29, 31, 32, 33, 46, 51, 52, 58, 59, 60, 62, 63, 73, 77, 80, 90, 91, 94], "worth": [6, 33, 75, 77, 88, 92], "analysi": [6, 11, 19, 25, 32, 34, 36, 42, 48, 49, 52, 53, 54, 58, 74, 75, 77, 78, 81, 83, 91, 92, 97], "tool": [6, 11, 24, 25, 40, 42, 63, 83, 91, 97], "kalisto": 6, "fulli": [6, 25, 31, 32, 59, 75, 81, 91, 94], "saw": [6, 30, 32, 53, 55, 74, 77, 81], "smfish": [6, 51, 53, 61], "abund": 6, "neg": [6, 31, 34, 36, 40, 41, 42, 51, 53, 58, 60, 61, 66, 74, 76, 81, 88, 92, 94], "binomi": [6, 34, 51, 53, 61, 66, 69, 71, 74, 88, 92, 94], "under": [6, 21, 25, 34, 36, 37, 41, 53, 58, 59, 61, 69, 71, 73, 83, 90, 92, 94], "bursti": [6, 51, 53, 61, 75, 78], "express": [6, 9, 25, 26, 29, 31, 37, 38, 40, 41, 49, 51, 53, 54, 58, 60, 61, 62, 63, 67, 71, 72, 73, 75, 78, 81, 92, 94], "absenc": [6, 46, 61, 75], "zheng": 6, "inject": [6, 25, 62], "ercc": 6, "extern": [6, 32], "consortium": 6, "spike": 6, "solut": [6, 11, 75, 80, 81, 83, 88, 90, 92], "thu": [6, 25, 26, 30, 34, 38, 40, 47, 54, 58, 60, 62, 63, 66, 71, 72, 74, 75, 76, 78, 81, 83, 90], "confound": [6, 31], "absent": 6, "poisson": [6, 33, 60, 75, 94], "turn": [6, 25, 31, 36, 51, 52, 53, 62, 63, 64, 68, 69, 74, 83, 88, 90], "hi": [6, 34, 38, 44, 48, 55], "link": [6, 30, 55, 78, 92, 97], "caus": [6, 9, 21, 53, 62, 72], "constern": 6, "among": [6, 21, 29, 34, 58, 81, 83], "commun": [6, 11, 22, 51, 94], "explan": [6, 61, 88, 94, 97], "unknown": [6, 32, 58, 63, 75], "captur": [6, 31, 34, 36, 59, 60, 64, 71, 72, 73, 74, 75, 76, 78, 81, 94], "flexibl": [6, 63, 64, 66, 73, 81], "than": [6, 16, 21, 25, 30, 31, 32, 34, 36, 38, 40, 41, 42, 46, 48, 51, 52, 53, 57, 58, 60, 61, 63, 66, 67, 69, 71, 73, 74, 75, 77, 81, 83, 88, 90, 92, 94], "limit": [6, 22, 25, 31, 33, 34, 46, 47, 48, 52, 60, 61, 64, 73, 75, 77, 90, 92, 94], "understood": [6, 32, 58, 63], "formul": [6, 25, 88, 94], "http": [6, 21, 22, 36, 40, 51, 61, 83, 88, 94], "s3": [6, 22, 36, 40, 51, 83, 92, 94], "amazonaw": [6, 22, 36, 40, 51, 83, 94], "com": [6, 21, 22, 36, 40, 51, 83, 88, 92, 94], "bebi103": [6, 8, 21, 22, 24, 36, 37, 40, 41, 42, 51, 52, 53, 54, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 83, 92, 94, 97], "caltech": [6, 9, 11, 21, 22, 23, 36, 40, 51, 83, 94], "edu": [6, 11, 22, 36, 40, 51, 83, 92, 94], "zheng_gemcode_control": 6, "csv": [6, 21, 36, 37, 40, 42, 51, 52, 53, 54, 55, 58, 59, 61, 64, 66, 74, 75, 76, 77, 78, 80, 81, 83, 92], "presum": [6, 91], "raw": 6, "deposit": [6, 52], "short": [6, 62, 77, 92], "archiv": 6, "srp073767": 6, "avail": [6, 21, 22, 34, 36, 51, 52, 57, 58, 59, 61, 64, 74, 80, 83, 92, 97], "figshar": 6, "licens": 6, "cc": 6, "BY": 6, "4": [6, 11, 22, 24, 30, 34, 36, 38, 40, 41, 42, 47, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 91, 92, 94, 98], "addition": [6, 8, 73, 83], "inform": [6, 9, 13, 21, 22, 25, 26, 30, 36, 37, 38, 40, 42, 52, 54, 57, 58, 59, 61, 64, 66, 67, 72, 73, 74, 81, 88, 90, 92, 94, 98], "concentr": [6, 67, 73, 75, 88, 90], "mix": [6, 61, 62, 66, 72, 77, 94], "obtain": [6, 25, 32, 36, 37, 51, 52, 55, 57, 61, 63, 73, 77, 80, 81, 88], "thermo": 6, "fisher": [6, 34], "were": [6, 25, 27, 34, 37, 41, 46, 51, 52, 55, 58, 59, 60, 61, 63, 66, 69, 72, 73, 74, 75, 78, 81, 92, 94], "dilut": 6, "50": [6, 31, 34, 36, 37, 40, 41, 42, 43, 46, 54, 55, 57, 58, 59, 64, 69, 72, 74, 78, 81, 83, 94], "fold": [6, 25, 40], "eas": [6, 32, 34, 75, 81], "although": [6, 63, 88, 90, 94], "strictli": [6, 34, 58, 60, 80, 92], "refer": [6, 21, 25, 31, 34, 41, 52, 53, 54, 57, 61, 63, 75, 77, 81, 83, 90, 94, 97], "obviou": [6, 30, 31, 32, 58, 64, 66, 72, 73, 88], "deviat": [6, 8, 31, 57, 58, 60, 61, 72, 73, 74, 75, 76, 77, 88], "being": [6, 14, 19, 22, 34, 36, 38, 51, 52, 54, 58, 60, 61, 63, 72, 75, 78, 80, 81, 83, 90], "sure": [6, 8, 21, 24, 31, 34, 36, 40, 46, 51, 55, 58, 59, 60, 61, 63, 66, 72, 73, 74, 76, 80, 81, 83, 88, 91, 92, 94], "strang": [6, 38, 49, 58, 75, 94], "specul": 6, "hint": 6, "obvious": [6, 8, 58], "inconsist": [6, 34], "onli": [6, 9, 21, 22, 25, 31, 32, 34, 36, 38, 40, 42, 46, 47, 49, 53, 55, 58, 60, 61, 63, 71, 72, 74, 75, 77, 80, 81, 83, 88, 91, 92, 94], "behavior": [6, 9, 61, 62, 64, 66, 69, 72, 74, 75, 77, 78, 80, 94], "calcul": [6, 21, 23, 25, 31, 32, 34, 37, 38, 40, 42, 51, 52, 57, 58, 60, 61, 63, 64, 73, 74, 75, 79, 80, 81, 83, 90, 92, 93, 94], "quick": [6, 21, 22, 36, 40, 42, 51, 54, 55, 58, 59, 61, 62, 63, 66, 74, 75, 78, 81, 94, 97], "graphic": [6, 11, 15, 17, 41, 46, 58, 62, 72, 73, 83, 92], "verif": [6, 58], "inde": [6, 17, 30, 31, 32, 51, 52, 53, 58, 75, 80], "principl": [6, 11, 19, 34, 58, 60, 63, 74, 75, 90, 91, 98], "wai": [6, 24, 25, 26, 32, 34, 36, 37, 47, 48, 51, 53, 55, 57, 58, 60, 61, 62, 63, 64, 66, 67, 71, 72, 75, 77, 78, 81, 83, 88, 90, 92, 94], "week": [6, 9, 42, 59, 83, 98], "dirti": 6, "credibl": [6, 13, 42, 54, 55, 57, 69, 75, 76, 77, 80], "interv": [6, 13, 34, 38, 42, 46, 52, 53, 54, 55, 57, 60, 68, 69, 73, 74, 75, 76, 77, 80, 88, 91], "local": [6, 13, 22, 24, 32, 37, 40, 41, 75, 92], "notic": [6, 21, 34, 42, 51, 52, 53, 81, 92, 94], "sourc": [6, 21, 36, 37, 40, 42, 54, 55, 58, 74, 75, 76, 78, 81, 83, 92], "commonli": [6, 32, 34, 48, 52, 55, 57, 61, 77, 80, 92], "occur": 6, "typic": [6, 22, 31, 32, 34, 38, 42, 51, 53, 54, 58, 60, 61, 67, 72, 73, 74, 75], "nonzero": [6, 30, 31, 40], "let": [6, 21, 25, 26, 29, 31, 34, 36, 37, 40, 41, 48, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 69, 71, 72, 74, 75, 77, 78, 80, 81, 83, 88, 90, 94], "p": [6, 8, 22, 24, 25, 27, 30, 36, 37, 38, 40, 41, 42, 43, 46, 47, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94], "case": [6, 11, 21, 29, 30, 31, 32, 33, 34, 36, 37, 39, 41, 42, 46, 47, 49, 51, 52, 53, 54, 57, 58, 59, 60, 61, 63, 66, 67, 68, 71, 72, 73, 74, 75, 76, 77, 81, 83, 88, 90, 92, 94, 97], "detect": [6, 61], "due": [6, 11, 22, 25, 34, 58, 63, 77, 83, 88, 92, 94], "unspecifi": 6, "includ": [6, 9, 11, 21, 22, 23, 24, 25, 30, 32, 34, 40, 41, 46, 49, 51, 52, 53, 55, 57, 58, 59, 61, 63, 64, 66, 72, 73, 74, 75, 77, 81, 83, 88, 90, 91, 92, 94], "Then": [6, 25, 26, 29, 31, 34, 36, 47, 49, 52, 54, 62, 63, 73, 75, 88, 92, 94], "accord": [6, 24, 37, 41, 48, 53, 54, 55, 61, 71, 77, 78], "version": [6, 21, 22, 24, 36, 37, 38, 40, 41, 42, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94], "mixtur": [6, 11, 57, 98], "delta_": [6, 9, 75, 77], "0y": 6, "otherwis": [6, 8, 47, 48, 52, 73, 81, 90], "investig": [6, 26, 37, 38, 47, 51, 58, 61, 62, 63, 69, 71], "whether": [6, 9, 61, 74, 76, 78, 83], "rel": [6, 21, 22, 25, 31, 63, 66, 73, 90], "similar": [6, 30, 36, 38, 52, 53, 54, 58, 59, 63, 64, 72, 83, 91, 92, 94], "versu": [6, 36, 40, 55, 58, 59, 64, 72, 74, 75], "fraction": [6, 36, 58, 61, 90], "stand": [6, 88], "technic": [6, 32, 88, 92], "quantifi": [6, 9, 25, 63, 76, 81, 90, 94], "well": [6, 21, 22, 24, 31, 32, 33, 34, 36, 40, 41, 42, 49, 52, 53, 55, 59, 63, 66, 67, 71, 74, 75, 76, 77, 88, 90, 94], "other": [6, 8, 23, 24, 25, 27, 30, 31, 32, 34, 36, 37, 40, 41, 46, 49, 51, 52, 53, 54, 55, 58, 61, 63, 67, 69, 71, 72, 73, 75, 80, 81, 83, 88, 91, 92, 94, 97], "With": [6, 31, 34, 51, 52, 54, 58, 59, 66, 67, 74, 77, 90, 94], "mind": [6, 25, 30, 31, 52, 61, 72, 75, 76, 92], "new": [6, 21, 25, 30, 32, 34, 36, 51, 52, 53, 58, 59, 60, 63, 75, 76, 88, 90, 92, 97], "wherein": 6, "mu_i": [6, 31, 42, 54, 55, 58, 59, 60, 64, 75, 77, 81], "share": [6, 11, 21, 34], "j": [6, 22, 24, 29, 34, 36, 37, 40, 42, 63, 81, 92, 94], "y_": [6, 63], "ij": [6, 31, 34, 41, 75, 77], "negbinom": [6, 51, 53, 61, 74, 92], "trickier": [6, 57, 76], "optim": [6, 8, 11, 13, 32, 36, 37, 47, 51, 52, 66, 78, 79, 80, 81, 88, 92, 98], "solv": [6, 41, 58, 75, 88, 90], "big": [6, 34, 42, 51, 57, 58, 72, 81], "report": [6, 40, 41, 42, 51, 53, 56, 61, 63, 71, 72, 73, 91], "hessian": [6, 34, 40, 41, 42], "sever": [6, 22, 23, 24, 34, 36, 37, 40, 42, 48, 57, 62, 74], "smooth": [6, 36, 59, 63, 66, 75, 77], "curv": [6, 36, 37, 42, 54, 58, 59, 75, 77, 88], "overlai": [6, 40, 43, 59, 62, 76, 78], "light": [6, 9, 31, 32, 34, 58, 60, 71], "least": [7, 25, 37, 40, 41, 61, 74, 75, 81, 83, 90, 92, 94], "squar": [7, 31, 34, 75, 76, 78, 80, 88, 92], "zero": [7, 30, 31, 34, 36, 37, 40, 41, 42, 46, 51, 52, 53, 54, 58, 60, 62, 71, 72, 73, 74, 75, 76, 78, 81, 88, 94], "inflat": 7, "drop": [7, 54, 58, 75], "80": [7, 58, 69, 81], "numba": [8, 94], "emploi": [8, 80, 81, 91, 94], "metropoli": [8, 9, 45, 90], "hast": [8, 9, 45, 90], "algorithm": [8, 40, 45, 46, 48, 52, 61, 63, 75], "handl": [8, 37, 47, 53, 73, 76, 90, 92], "discret": [8, 30, 32, 34, 46, 47, 53, 60, 66, 75, 88, 90], "sinc": [8, 21, 25, 31, 34, 36, 37, 40, 41, 42, 46, 47, 51, 52, 53, 54, 57, 58, 59, 61, 62, 63, 64, 66, 67, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 94], "multi": [8, 31, 57, 80, 94], "dimension": [8, 12, 31, 32, 34, 36, 52, 53, 55, 59, 66, 75, 80, 88], "diagon": [8, 31, 40, 41, 53, 74, 75, 76, 78, 80, 81], "word": [8, 14, 17, 20, 25, 32, 46, 51, 54, 58, 63, 71, 73, 75, 92], "target": [8, 46, 47, 53, 61, 62, 66, 90, 92, 94], "organ": [8, 11, 51, 66, 72], "code": [8, 11, 21, 22, 24, 31, 36, 37, 40, 42, 51, 54, 55, 57, 58, 59, 61, 62, 64, 66, 74, 75, 76, 77, 78, 80, 81, 94], "suggest": [8, 34, 48, 53, 63], "step": [8, 16, 21, 24, 25, 32, 36, 40, 42, 46, 47, 48, 52, 55, 58, 59, 61, 62, 63, 68, 72, 73, 75, 78, 81, 88, 90, 92, 94], "instead": [8, 21, 24, 30, 34, 36, 37, 40, 41, 42, 46, 53, 55, 57, 58, 59, 60, 62, 63, 66, 71, 74, 75, 76, 77, 78, 81, 83, 88, 90, 92, 94], "pass": [8, 9, 36, 40, 42, 51, 52, 53, 58, 59, 61, 64, 74, 81, 83, 92], "ing": [8, 21], "mh_step": 8, "logtarget": 8, "logtarget_curr": 8, "arg": [8, 36, 37, 40, 42, 58, 76, 77, 92], "ndarrai": 8, "shape": [8, 36, 38, 42, 51, 53, 55, 57, 58, 59, 61, 62, 72, 74, 78, 81, 94], "n_variabl": 8, "present": [8, 22, 25, 36, 40, 52, 53, 55, 58, 62, 64, 72, 73, 76, 77, 80, 83, 90, 93], "walker": [8, 46, 47, 48, 55, 61, 66, 90, 94], "space": [8, 30, 34, 36, 46, 47, 48, 54, 55, 57, 59, 61, 72, 73, 88, 92, 94], "log": [8, 17, 21, 22, 34, 37, 40, 41, 42, 51, 53, 57, 58, 59, 60, 62, 64, 72, 74, 76, 77, 81, 88, 90], "signatur": 8, "float": [8, 46, 53, 58, 63, 66], "current": [8, 31, 34, 36, 47, 55, 63, 90, 94], "standard": [8, 31, 32, 52, 57, 58, 66, 72, 73, 74, 75, 76, 77, 83, 90], "tupl": 8, "addit": [8, 18, 19, 20, 22, 32, 36, 53, 63, 69, 81, 90, 92, 94], "argument": [8, 21, 34, 36, 40, 42, 53, 54, 76, 80, 92], "new_x": 8, "posit": [8, 31, 34, 36, 37, 40, 41, 46, 47, 48, 51, 58, 66, 67, 72, 75, 76, 77, 78, 80, 81, 88, 90], "after": [8, 11, 24, 25, 31, 32, 37, 38, 42, 46, 51, 52, 58, 59, 61, 63, 73, 74, 78, 80, 81, 83, 88, 90, 91, 94], "input": [8, 37, 51, 52, 58, 59, 66, 77, 78, 80, 92, 94], "new_logtarget": 8, "densiti": [8, 27, 30, 31, 34, 36, 37, 40, 41, 47, 49, 51, 54, 55, 57, 58, 62, 66, 75, 77, 81, 88, 90], "accept": [8, 47, 58, 73, 83, 90, 92], "bool": [8, 52, 53], "true": [8, 9, 13, 24, 25, 34, 36, 51, 52, 53, 54, 55, 57, 58, 62, 63, 64, 66, 69, 72, 73, 74, 75, 80, 81, 88, 92, 94], "fals": [8, 9, 22, 24, 42, 51, 52, 53, 55, 57, 58, 61, 64, 66, 72, 74, 75, 76, 77, 81, 88, 92, 94], "anoth": [8, 9, 21, 26, 37, 38, 46, 52, 53, 55, 58, 60, 61, 62, 63, 66, 67, 72, 75, 88, 94, 97], "am": [8, 31, 40, 49, 53, 60, 63, 66, 69, 83, 92, 94, 98], "n_burn": 8, "n_warmup": 8, "burn": [8, 48], "contrast": 8, "stan": [8, 9, 11, 21, 22, 34, 44, 47, 48, 53, 55, 59, 60, 61, 62, 64, 66, 68, 69, 73, 74, 83, 90, 97, 98], "tune": [8, 47, 48, 72, 75, 90], "dure": [8, 23, 48, 51, 58, 83], "warm": [8, 14, 45, 51, 61, 88, 90], "phase": [8, 48, 51, 77, 88, 90], "3": [8, 11, 22, 24, 25, 30, 34, 37, 38, 40, 41, 42, 49, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 66, 69, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 87, 88, 90, 91, 92, 94, 98], "mh_sampl": 8, "x0": 8, "1000": [8, 46, 51, 52, 53, 54, 55, 58, 59, 61, 66, 67, 69, 73, 74, 75, 76, 78, 80, 81, 88, 92, 94], "n_step": [8, 52, 53], "variable_nam": 8, "none": [8, 31, 33, 43, 51, 58, 60, 64, 74, 92], "int": [8, 22, 24, 30, 31, 32, 34, 36, 46, 47, 49, 51, 53, 54, 55, 58, 59, 61, 62, 63, 64, 66, 69, 72, 73, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94], "default": [8, 21, 22, 32, 52, 53, 55, 61, 62, 66, 75, 81, 92], "list": [8, 21, 53, 57, 60, 67, 74, 75, 83, 91, 92, 94], "name": [8, 21, 25, 31, 33, 34, 46, 51, 52, 53, 54, 55, 57, 58, 60, 61, 62, 63, 64, 66, 83, 92, 94], "sequenti": [8, 47, 60, 92], "datafram": [8, 53, 57, 74, 78, 94], "lnprob": 8, "test": [8, 22, 25, 59, 63, 73, 74, 81, 92, 94], "bivari": [8, 60], "boldsymbol": [8, 31, 75, 76, 77, 78, 80, 81], "mathsf": [8, 31, 34, 40, 41, 60, 75, 76, 77, 78, 80, 81, 88], "pmatrix": [8, 30, 34, 38, 75, 88], "6": [8, 9, 11, 30, 36, 37, 40, 41, 42, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 92, 93, 94, 98], "pdf": [8, 31, 33, 34, 36, 37, 38, 40, 41, 42, 49, 51, 55, 57, 58, 74, 76, 83, 90], "unnorm": [8, 36, 37, 53, 94], "jit": 8, "speed": [8, 34, 41, 57, 60, 78, 81, 88, 92], "confus": [8, 12, 13, 74, 75, 83], "mathbf": [8, 30, 51, 75, 76, 77, 78, 80, 88], "rememb": [8, 21, 31, 32, 34, 36, 51, 52, 54, 58, 63, 66, 75, 76, 81], "arbitrari": [8, 46, 47, 49, 53, 61, 72, 75, 78, 90], "furthermor": [8, 36, 40, 42, 49, 57, 59, 60, 72, 73, 75, 92], "log_test_distribut": 8, "cov": [8, 40, 42, 75], "inv_cov": 8, "linalg": [8, 40, 42], "inv": [8, 40, 42, 60, 80], "njit": 8, "multivari": [8, 13, 31, 32, 34, 41, 42, 60, 75, 78, 88, 90], "gaussian": [8, 11, 20, 31, 37, 68, 77, 80, 81, 90], "dot": [8, 11, 53, 88, 91], "viz": [8, 36, 37, 40, 41, 42, 51, 53, 54, 55, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 94], "corner": [8, 21, 53, 54, 57, 59, 62, 64, 66, 69, 72, 74, 75, 77, 78, 80, 81, 88, 94], "everyth": [8, 21, 25, 52, 55, 58, 61, 64, 66, 72, 74, 75, 78, 80], "sens": [8, 12, 25, 30, 31, 34, 36, 37, 38, 41, 42, 58, 63, 71, 73, 74, 75, 90, 91, 94], "add": [8, 21, 25, 42, 52, 53, 57, 59, 62, 63, 64, 67, 75, 76, 77, 78, 80, 83, 88, 91, 92, 94], "logic": [8, 11, 30, 55, 63, 75, 92, 97, 98], "automat": [8, 32, 36, 53, 58, 61, 62, 88, 92], "adjust": [8, 37, 52, 55, 58, 59, 64, 73, 77, 81], "desir": [8, 25, 48, 63, 75, 92], "good": [8, 9, 15, 31, 36, 37, 41, 42, 48, 51, 52, 53, 54, 55, 58, 59, 60, 61, 62, 63, 64, 66, 67, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 92, 94, 97], "pymc": 8, "scheme": [8, 57], "adapt": [8, 25, 51, 52, 74, 81], "001": [8, 61, 92], "05": [8, 53, 72, 75, 76, 78, 80, 88, 98], "5": [8, 11, 22, 24, 30, 31, 34, 36, 37, 40, 41, 42, 43, 46, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 66, 69, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 91, 92, 94, 98], "9": [8, 9, 11, 22, 24, 36, 37, 40, 42, 51, 52, 58, 59, 61, 62, 64, 66, 69, 71, 72, 74, 75, 76, 77, 78, 80, 81, 83, 88, 92, 94, 96, 98], "75": [8, 53, 54, 55, 58, 59, 61, 64, 72, 81, 83, 88], "95": [8, 34, 40, 41, 55, 57, 58, 60, 61, 75, 78, 83], "Be": [8, 21, 32, 72], "demonstr": [8, 24, 31, 34, 38, 52, 53, 57, 58, 66, 69, 75, 78, 80, 83, 90, 92], "type": [9, 21, 34, 51, 52, 53, 54, 55, 74, 77, 88, 90, 92, 94], "lot": [9, 21, 25, 36, 51, 52, 55, 59, 60, 63, 64, 72, 75, 78, 94], "biolog": [9, 63, 71], "scienc": [9, 28, 30, 40, 42, 54, 55, 58, 64, 75, 97], "exampl": [9, 21, 25, 27, 32, 33, 35, 36, 37, 38, 40, 41, 46, 48, 49, 51, 53, 55, 57, 58, 60, 61, 63, 65, 67, 68, 71, 72, 74, 77, 78, 80, 83, 88, 92, 94], "certain": [9, 75, 88, 92], "mutat": 9, "drosophila": [9, 38], "affect": [9, 22, 34, 38, 41, 74, 75], "egg": [9, 31, 33, 34, 38, 40, 54, 60], "hatch": [9, 38], "past": [9, 21, 61, 80], "bi": [9, 24, 55, 71, 82], "1x": [9, 71], "meaghan": 9, "sullivan": 9, "help": [9, 19, 21, 26, 27, 36, 55, 58, 59, 60, 61, 62, 64, 73, 75, 83, 90, 92, 94, 98], "ravi": 9, "nath": 9, "jimmi": 9, "hamilton": [9, 88, 90], "sophi": 9, "walton": 9, "improv": [9, 47, 72, 74, 75], "neural": 9, "circuit": 9, "elegan": [9, 31, 33, 34, 60, 71], "optogenet": 9, "seri": [9, 25, 37, 38, 57, 73, 75, 91, 94, 97], "interconnect": 9, "neuron": [9, 71], "creat": [9, 74, 77, 92], "pathwai": [9, 91, 94], "transmit": 9, "signal": [9, 74, 91, 94], "receiv": [9, 83, 88, 92], "revers": [9, 67, 68, 69, 92], "consist": [9, 25, 30, 34, 38, 49, 52, 61, 73, 74, 76, 83, 88], "three": [9, 22, 31, 36, 42, 53, 54, 55, 57, 59, 60, 61, 63, 66, 68, 69, 71, 73, 83, 92], "sensori": [9, 71], "stimuli": 9, "environ": [9, 21, 92], "command": [9, 21, 24, 52, 88, 92], "interneuron": 9, "integr": [9, 31, 32, 34, 36, 37, 38, 42, 46, 47, 49, 62, 63, 73, 81, 94, 98], "motor": [9, 34, 58, 60], "worm": [9, 67, 68, 69, 71], "six": [9, 83], "non": [9, 27, 51, 53, 60, 62, 75, 79], "act": [9, 88], "respond": 9, "environment": [9, 51, 92], "cue": 9, "trigger": 9, "shown": [9, 30, 34, 37, 40, 46, 47, 58, 63, 73, 75, 88], "figur": [9, 22, 24, 25, 30, 36, 37, 38, 40, 41, 42, 43, 51, 54, 55, 58, 62, 72, 74, 75, 76, 77, 78, 81, 88, 90, 94], "schulthei": 9, "2011": 9, "These": [9, 21, 22, 25, 36, 47, 51, 52, 53, 55, 58, 61, 69, 72, 74, 75, 80, 83, 88, 92, 94], "four": [9, 21, 34, 51, 52, 55, 58, 59, 61, 68, 72, 73, 90], "alm": 9, "avm": 9, "ash": [9, 71], "plm": 9, "two": [9, 22, 23, 24, 25, 31, 32, 34, 36, 37, 38, 40, 42, 47, 51, 52, 53, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 71, 72, 73, 74, 75, 80, 81, 82, 88, 90, 91, 92], "avd": 9, "ava": 9, "sensit": [9, 73, 74], "stimulu": 9, "chemosensori": 9, "toxin": 9, "mechan": [9, 41, 88, 94], "touch": [9, 92], "bodi": 9, "send": [9, 51, 91], "provid": [9, 22, 30, 31, 36, 40, 41, 42, 46, 51, 52, 53, 61, 63, 66, 72, 73, 75, 76, 77, 83, 92, 97], "impuls": 9, "order": [9, 21, 22, 25, 32, 34, 36, 37, 41, 46, 51, 52, 57, 58, 59, 60, 61, 63, 66, 72, 73, 74, 75, 77, 83, 88, 92, 94], "fire": [9, 21, 22], "must": [9, 22, 25, 30, 31, 36, 38, 40, 41, 51, 52, 54, 66, 73, 75, 78, 81, 83, 90, 92, 94, 98], "exce": [9, 22], "threshold": [9, 58], "onc": [9, 21, 22, 48, 52, 59, 75, 88, 90, 92, 94], "induc": [9, 63, 90], "action": 9, "potenti": [9, 16, 55, 88, 90, 94], "modul": [9, 22, 40, 46, 51, 55, 58, 75, 83, 92, 94], "dissect": 9, "channelrhodopsin": [9, 71], "chr2": 9, "repres": [9, 25, 51, 55, 69, 73, 75, 90, 94], "red": [9, 53, 94], "barrel": 9, "blue": [9, 53, 58, 71], "allow": [9, 21, 22, 41, 46, 47, 49, 51, 53, 54, 58, 59, 61, 62, 64, 66, 69, 75, 77, 78, 80, 81, 83, 88, 90, 92, 94], "sodium": 9, "calcium": 9, "cation": 9, "flow": [9, 73, 91], "simul": [9, 11, 19, 21, 58, 92, 94, 98], "robustli": 9, "stimul": 9, "exhibit": 9, "avers": 9, "goal": [9, 25, 32, 36, 38, 40, 41, 46, 49, 63, 78, 81], "compar": [9, 34, 36, 41, 42, 55, 59, 62, 63, 64, 66, 72, 73, 77, 78, 80, 81, 92, 94], "wild": [9, 77], "undergo": 9, "student": [9, 22, 36, 60, 71, 83, 84, 95, 97], "trial": [9, 34, 38, 69, 71, 73, 74, 88], "wt": 9, "2017": [9, 32, 69, 71, 81, 88], "7": [9, 11, 22, 24, 34, 36, 37, 40, 42, 43, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 92, 94, 98], "54": [9, 21, 53, 61, 69, 71, 72, 81], "18": [9, 11, 22, 24, 36, 51, 52, 53, 54, 57, 58, 59, 61, 64, 66, 69, 71, 72, 74, 75, 77, 78, 81, 88, 94, 98], "52": [9, 42, 61], "28": [9, 22, 24, 53, 58, 74, 78, 81, 94, 98], "2016": [9, 69, 71], "36": [9, 24, 36, 37, 40, 53, 64, 76, 77, 78, 80, 81, 94], "35": [9, 36, 40, 42, 51, 52, 53, 54, 58, 59, 61, 62, 64, 66, 69, 71, 72, 74, 75, 81, 94], "12": [9, 11, 22, 24, 36, 37, 40, 42, 51, 52, 53, 54, 55, 57, 59, 60, 61, 62, 64, 66, 69, 71, 72, 74, 75, 76, 77, 78, 80, 81, 92, 94, 98], "33": [9, 36, 40, 51, 53, 57, 62, 94], "pool": [9, 69, 72, 81], "13": [9, 11, 36, 37, 40, 42, 51, 52, 53, 54, 55, 57, 58, 61, 62, 64, 66, 72, 74, 75, 76, 77, 78, 81, 92, 94, 98], "126": [9, 66], "39": [9, 42, 51, 52, 53, 55, 66, 72, 76, 81, 92, 94], "124": 9, "91": [9, 42, 92], "theta": [9, 22, 24, 25, 26, 27, 29, 30, 32, 34, 36, 38, 40, 41, 46, 47, 49, 52, 53, 58, 60, 62, 63, 66, 67, 68, 69, 71, 72, 73, 78, 81, 88, 94], "upon": [9, 38, 58, 63, 72], "exposur": [9, 71], "sampler": [9, 10, 14, 16, 44, 47, 48, 51, 52, 53, 55, 59, 62, 64, 72, 73, 88, 94], "previou": [9, 32, 33, 40, 41, 42, 53, 54, 55, 59, 61, 64, 66, 72, 73, 74, 76, 78, 80, 83, 90, 94], "same": [9, 21, 22, 25, 26, 30, 31, 34, 37, 38, 40, 42, 47, 51, 52, 53, 55, 59, 61, 62, 63, 66, 67, 72, 73, 74, 75, 76, 77, 78, 81, 88, 90, 91, 94], "either": [9, 21, 22, 24, 36, 37, 51, 55, 58, 60, 61, 90, 92], "histogram": [9, 49, 51, 55, 57], "illumin": 9, "suppos": [9, 34, 94], "n_1": [9, 71], "n_2": [9, 71], "equiv": [9, 31, 34, 58, 63, 72, 75], "theta_2": [9, 32, 34, 40, 67, 71, 72, 81], "theta_1": [9, 32, 34, 40, 67, 71, 72, 81], "hand": [9, 25, 30, 36, 40, 51, 54, 57, 59, 71, 73, 77, 83, 88, 90, 94], "possibl": [9, 19, 24, 25, 29, 31, 33, 34, 46, 52, 53, 54, 55, 57, 58, 63, 72, 73, 74, 75, 81, 88, 90, 92, 94], "quit": [9, 34, 53, 58, 60, 63, 66, 73, 75, 80, 83, 88, 90, 92, 94], "difficult": [9, 34, 36, 41, 58, 61, 62, 81], "Not": [9, 25, 52, 58, 72, 74], "practic": [9, 11, 25, 31, 34, 46, 53, 60, 61, 63, 75, 83, 88, 90, 92, 98], "repeat": [9, 21, 25, 30, 33, 35, 51, 55, 58, 59, 60, 70, 75, 78], "own": [10, 18, 21, 22, 23, 24, 25, 52, 75, 77, 81, 83, 90, 92], "boolean": 10, "30": [10, 21, 36, 37, 43, 58, 59, 64, 81, 83, 92, 94, 98], "prequel": [11, 36], "pipelin": [11, 58, 74], "preserv": [11, 60, 90], "displai": [11, 53, 58, 61, 62, 75, 77, 81, 83, 98], "quantit": [11, 25, 58, 59], "basic": [11, 14, 20, 45, 51, 55, 81, 88, 90, 92, 94], "resampl": [11, 52, 90], "method": [11, 22, 25, 32, 33, 36, 37, 40, 41, 42, 48, 51, 52, 53, 54, 55, 58, 59, 61, 63, 66, 72, 73, 76, 77, 81, 88, 92], "frequentist": [11, 34, 41, 52], "deeper": [11, 72], "mostli": [11, 34, 42, 73, 74, 90], "comparison": [11, 58, 59, 62, 64, 78, 81, 94, 98], "hierarch": [11, 18, 24, 32, 34, 58, 60, 75, 78, 98], "markov": [11, 14, 32, 34, 37, 41, 44, 46, 49, 50, 52, 58, 59, 61, 73, 80, 98], "chain": [11, 14, 16, 32, 34, 37, 41, 44, 46, 47, 48, 49, 50, 52, 53, 54, 55, 58, 59, 61, 62, 64, 66, 68, 71, 72, 73, 74, 75, 77, 78, 80, 88, 90, 92, 94, 98], "mont": [11, 14, 32, 34, 37, 41, 44, 47, 49, 50, 52, 58, 59, 73, 80, 94, 98], "carlo": [11, 14, 32, 34, 37, 41, 44, 47, 49, 50, 52, 58, 59, 73, 80, 94, 98], "workflow": [11, 32, 58, 83, 92, 98], "topic": [11, 34, 44, 61, 67, 75, 88, 92], "real": [11, 22, 24, 25, 30, 34, 41, 51, 52, 53, 54, 55, 58, 59, 61, 62, 64, 66, 67, 69, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 92, 94], "enrol": 11, "pleas": [11, 18, 34, 38, 73, 75, 83], "ed": [11, 83, 97], "canva": [11, 83], "assign": [11, 25, 30, 34, 52, 53, 58, 90, 92], "submiss": [11, 92], "password": [11, 92], "protect": [11, 66, 76, 77], "instructor": [11, 83, 98], "justin": [11, 92], "boi": [11, 52, 76, 77, 92], "ta": [11, 83, 84, 90, 95, 98], "kayla": 11, "jackson": 11, "scientif": [11, 22, 92, 97, 98], "introduct": [11, 44, 52, 61, 88, 94, 98], "margin": [11, 12, 25, 28, 30, 31, 32, 40, 41, 42, 47, 49, 53, 54, 57, 60, 69, 73, 75, 76, 78, 80, 81, 90, 98], "numer": [11, 32, 40, 41, 42, 53, 63, 71, 75, 76, 80, 90, 92, 94], "quadratur": [11, 42], "conjugaci": [11, 37, 75, 98], "e1": 11, "e2": 11, "8": [11, 22, 24, 36, 37, 38, 40, 41, 42, 43, 51, 52, 53, 54, 57, 58, 59, 61, 62, 64, 66, 69, 72, 73, 74, 75, 76, 77, 78, 80, 81, 83, 88, 92, 94, 95, 98], "mcmc": [11, 16, 18, 21, 32, 34, 45, 47, 48, 52, 58, 59, 62, 63, 66, 69, 73, 74, 75, 79, 81, 88, 90, 94, 97, 98], "label": [11, 63, 66, 67, 72, 88, 91, 94, 98], "switch": [11, 66, 67, 98], "e3": 11, "11": [11, 22, 24, 36, 37, 38, 40, 41, 42, 51, 52, 53, 55, 58, 59, 60, 61, 62, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94, 98], "predict": [11, 15, 17, 19, 25, 42, 51, 52, 54, 60, 64, 66, 69, 73, 74, 77, 81, 91, 92, 94, 98], "e4": 11, "14": [11, 36, 37, 40, 42, 51, 52, 53, 55, 58, 59, 61, 62, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 92, 94, 98], "collector": [11, 98], "box": [11, 25, 46, 90, 98], "15": [11, 22, 24, 36, 37, 38, 40, 41, 42, 51, 52, 53, 57, 58, 59, 62, 66, 69, 72, 74, 75, 76, 77, 78, 81, 88, 92, 94, 98], "diagnost": [11, 16, 18, 48, 53, 55, 64, 66, 69, 74, 75, 77, 78, 80, 90, 94, 98], "16": [11, 22, 24, 36, 42, 51, 52, 53, 55, 58, 59, 61, 66, 72, 74, 75, 76, 77, 78, 81, 88, 92, 94, 98], "artifici": [11, 57], "funnel": [11, 72, 78, 81, 90, 98], "hell": [11, 98], "e5": 11, "e6": 11, "19": [11, 36, 41, 51, 52, 53, 58, 61, 66, 74, 75, 77, 78, 81, 94, 98], "e7": 11, "21": [11, 36, 37, 40, 42, 51, 52, 53, 54, 57, 58, 59, 60, 61, 62, 64, 66, 72, 74, 75, 81, 94, 98], "22": [11, 58, 60, 66, 72, 75, 78, 81, 92, 94, 98], "calibr": [11, 19, 21, 58, 92, 98], "e8": 11, "23": [11, 53, 55, 58, 72, 74, 81, 94], "24": [11, 53, 55, 58, 74, 80, 81, 83, 94, 98], "25": [11, 22, 24, 36, 37, 40, 42, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 72, 74, 75, 76, 77, 78, 80, 92, 94, 98], "e9": 11, "26": [11, 22, 24, 36, 37, 38, 40, 41, 42, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 94, 98], "wrap": [11, 98], "analyt": [11, 32, 34, 38, 41, 42, 49, 54, 62, 78, 81, 90], "maximum": [11, 34, 36, 40, 55, 60, 61, 62, 64, 66, 69, 72, 74, 75, 77, 78, 80, 91, 92, 94], "posteriori": [11, 38, 41, 76], "overview": [11, 89, 92], "date": [11, 83], "exercis": [11, 21, 36, 57, 58, 66], "weekli": [11, 83], "meet": 11, "session": [11, 21, 22, 52, 87, 96], "collabor": [11, 22], "honor": 11, "ediquett": 11, "softwar": [11, 21, 47], "tutori": [11, 62, 66, 92], "winter": 11, "2024": [11, 22, 51, 52, 53, 66], "2022": 11, "2021": [11, 61], "2020": [11, 48], "statement": [12, 53, 54, 58, 75, 80], "curs": [12, 32, 36], "appear": [12, 21, 22, 36, 58, 81, 91], "few": [12, 23, 32, 34, 36, 38, 42, 48, 51, 52, 53, 54, 57, 58, 61, 63, 64, 66, 72, 73, 74, 75, 78, 81, 92, 94], "approxim": [13, 31, 32, 37, 46, 49, 51, 55, 57, 58, 60, 61, 62, 63, 66, 68, 72, 75, 77, 81, 88, 91, 94], "possibli": [13, 49, 55, 72, 73, 75, 94], "stori": [13, 31, 33, 34, 38, 53, 60, 88, 94], "meant": [13, 21, 53, 73, 90], "weakli": [13, 40, 54, 58, 67, 71, 72], "off": [13, 31, 36, 40, 52, 54, 60, 62, 71, 74, 75, 77, 88, 90], "abl": [14, 37, 42, 46, 49, 51, 55, 58, 61, 63, 72, 74, 75, 83, 90, 91, 92, 94], "behind": [14, 20, 31, 38, 45, 51, 63, 66, 81, 83], "nonidentifi": [14, 53], "contend": 15, "suffici": [15, 31, 36, 46, 47, 76], "assess": [15, 34, 40, 51, 53, 58, 60, 66, 73], "better": [15, 34, 46, 53, 55, 59, 63, 64, 66, 72, 74, 75, 78, 81, 83], "agre": [15, 25, 34, 61, 63], "total": [16, 21, 40, 42, 57, 59, 61, 63, 64, 71, 72, 74, 75, 81, 83, 88, 90, 92, 94], "diverg": [16, 34, 52, 53, 62, 64, 66, 69, 72, 74, 75, 77, 78, 80, 81, 90, 94], "diagnos": [16, 55, 62, 72, 73, 74], "ever": [16, 21, 62, 81, 88], "guarante": [16, 24, 34, 40, 41, 53, 61, 81], "properli": [16, 36, 51, 52, 54, 55, 61, 62, 72, 73, 74, 77, 83, 94], "finit": [16, 46, 51, 77, 90], "ye": [16, 52, 59], "stop": [16, 58, 66, 73, 81, 90], "underscor": [16, 53, 63], "extens": [16, 53, 88, 92], "pointwis": [17, 64, 94], "necessari": [17, 21, 22, 36, 47, 48, 49, 53, 57, 60, 61, 72, 78, 83], "waic": [17, 63], "loo": [17, 63, 64], "tidi": [18, 55, 72], "encount": [18, 30, 34, 36, 41, 52, 61, 74, 75, 76, 77, 78, 88, 91, 94], "structur": [18, 25, 37, 52, 53, 60, 78, 81, 83, 90, 92], "briefli": [18, 52, 55, 88], "situat": [18, 34, 66, 67, 94], "exchang": 18, "thoroughli": [18, 81], "especi": [18, 38, 40, 53, 57, 66, 83, 88, 92, 97], "z": [19, 25, 74, 75, 77, 80], "score": [19, 74], "verifi": [19, 22, 24, 52, 59, 73, 76, 83], "shrinkag": [19, 74], "rank": [19, 20, 57, 61, 62, 64, 66, 72, 74, 81, 88, 94], "statist": [19, 21, 23, 24, 31, 48, 49, 52, 53, 57, 58, 60, 63, 72, 74, 75, 81, 88, 94, 97], "pitfal": 19, "By": [19, 26, 31, 34, 49, 55, 61, 66, 73, 75, 88], "cautiou": 19, "sbc": [19, 21, 58, 73, 92], "analys": [19, 22, 32, 73, 92], "elbo": [20, 81], "advantag": [20, 23, 24, 34, 38, 57, 58, 63, 71, 75, 90, 94], "disadvantag": [20, 23, 38], "field": [20, 81, 88, 90, 91], "famili": [20, 32, 75, 81, 90], "run": [21, 22, 23, 24, 25, 36, 42, 51, 52, 53, 58, 61, 62, 72, 73, 74, 78, 81, 83, 90, 94], "power": [21, 24, 49, 51, 52, 53, 61, 63, 73, 75, 88, 92], "instal": [21, 22, 51, 52, 92, 94], "suffic": [21, 40, 58], "serv": [21, 25, 26, 38, 51, 58, 69, 75, 76, 88], "expans": [21, 41], "resourc": [21, 22, 24, 41, 83, 92], "option": [21, 36, 40, 55, 58, 83, 90, 92], "googl": [21, 23, 24, 51, 52, 83, 94], "cloud": [21, 22, 23, 24], "platform": [21, 22], "microsoft": [21, 22, 23], "azur": [21, 23], "high": [21, 23, 31, 34, 41, 48, 55, 61, 62, 75, 76, 77, 88, 92], "center": [21, 34, 41, 53, 57, 58, 62, 72, 76, 77, 78, 80, 88, 94], "lesson": [21, 23, 24, 32, 34, 36, 37, 40, 41, 51, 52, 53, 54, 55, 58, 59, 61, 62, 64, 66, 68, 71, 72, 73, 74, 75, 76, 77, 78, 80, 81, 92], "much": [21, 22, 24, 25, 30, 31, 32, 36, 37, 40, 41, 42, 47, 49, 52, 53, 57, 58, 59, 60, 61, 62, 63, 64, 66, 72, 73, 74, 75, 76, 77, 78, 81, 83, 88, 90, 94], "next": [21, 22, 25, 26, 34, 36, 37, 40, 41, 42, 46, 47, 52, 58, 59, 60, 69, 71, 75, 76, 81, 88, 90, 94], "spin": [21, 94], "outlin": [21, 48, 66, 77, 83, 90], "alreadi": [21, 22, 24, 26, 30, 32, 40, 41, 42, 46, 51, 53, 55, 58, 63, 75, 77, 78, 81, 90, 92], "cost": [21, 73], "100": [21, 25, 34, 36, 40, 41, 42, 51, 58, 62, 66, 72, 74, 75, 81, 83, 88, 92, 94, 98], "core": [21, 22, 23, 52, 74, 92], "entir": [21, 34, 40, 58, 60, 72, 77, 83, 87, 88, 91, 92, 96], "consol": [21, 92], "click": [21, 22, 62], "button": 21, "upper": [21, 34, 41, 53, 54, 57, 58, 59, 61, 64, 66, 69, 75, 76, 77, 81, 94], "page": [21, 22, 38, 49, 83, 92, 98], "imag": [21, 36, 37, 52, 58, 60, 62, 78, 88, 91, 94], "ami": 21, "pre": [21, 22, 75, 83, 92], "oregon": [21, 52], "u": [21, 25, 26, 27, 29, 32, 36, 37, 40, 41, 42, 43, 49, 51, 52, 58, 59, 62, 63, 64, 66, 69, 72, 74, 75, 77, 83, 88, 92, 94], "west": 21, "select": [21, 24, 37, 53, 55, 60, 65, 72, 81, 83, 94], "region": [21, 36, 41, 42, 48, 52, 55, 57, 58, 61, 62, 75, 88, 90], "top": [21, 22, 58, 69, 83], "throughout": [21, 24, 31, 41, 58, 83, 94, 97], "physic": [21, 25, 32, 36, 37, 42, 54, 58, 75, 88, 90, 97], "live": [21, 74, 92], "ec2": 21, "pulldown": [21, 83], "menu": [21, 83], "left": [21, 25, 30, 31, 34, 36, 37, 41, 42, 47, 49, 51, 53, 54, 55, 58, 59, 62, 63, 64, 66, 67, 71, 73, 75, 77, 81, 83, 88, 90, 92, 94], "screen": [21, 51, 55, 83], "pane": 21, "me": [21, 25, 32, 34, 57, 58, 63, 92], "public": 21, "search": [21, 80, 83], "doubl": [21, 46, 53, 78, 90], "request": [21, 22, 51, 91, 92, 94], "spot": 21, "save": [21, 58, 92, 94], "monei": [21, 25], "lose": [21, 67, 81, 94], "whatev": [21, 75, 92], "tag": [21, 94], "give": [21, 26, 29, 32, 34, 36, 37, 40, 42, 47, 51, 52, 53, 55, 57, 58, 61, 63, 66, 68, 72, 73, 74, 75, 76, 77, 81, 83, 88, 90, 91, 92, 94, 97], "recommend": [21, 22, 44, 61, 81, 88, 92], "back": [21, 71, 73, 74, 75, 81, 83, 88, 90, 92, 94], "simpli": [21, 22, 32, 34, 38, 42, 48, 49, 51, 53, 55, 59, 60, 63, 69, 88, 90, 92, 94], "mine": 21, "skip": [21, 24, 61, 75, 90], "applic": [21, 31, 34, 47, 63, 75, 76, 88, 94], "o": [21, 22, 36, 37, 40, 42, 51, 52, 53, 54, 55, 58, 59, 61, 64, 66, 74, 75, 76, 77, 78, 80, 81, 83, 92, 94], "choic": [21, 34, 38, 42, 55, 57, 59, 60, 71, 75, 76, 81, 83, 88, 94], "c5": 21, "xlarg": 21, "intens": [21, 31, 41, 72, 92], "2xlarg": 21, "larger": [21, 58, 60, 62, 72, 75, 78, 88, 90, 92, 94], "kei": [21, 51, 58, 66, 75, 88], "pair": [21, 25, 32, 36, 37, 53, 58, 75, 81], "login": [21, 92], "pop": 21, "window": [21, 83], "enter": [21, 88], "bebi103_aws_keypair": 21, "fine": [21, 22, 55, 59, 64, 80, 83], "leav": [21, 23, 34, 52, 55, 66, 75, 76, 94], "radio": 21, "NOT": 21, "git": [21, 52], "repositori": 21, "anyth": [21, 22, 25, 34, 63, 72, 73, 88, 90, 94], "dropbox": [21, 52], "never": [21, 31, 36, 46, 47, 48, 52, 61, 66, 75, 81], "internet": [21, 23, 92], "reus": 21, "forward": [21, 25, 27, 37, 58, 63, 75, 80, 88, 90], "network": 21, "ssh": [21, 92], "traffic": 21, "anywher": [21, 51, 74, 83, 97], "els": [21, 22, 51, 52, 66, 83, 94], "secur": 21, "ip": 21, "prove": [21, 29, 31, 36, 75, 92], "inconveni": 21, "home": [21, 80, 92], "campu": [21, 92], "configur": [21, 23, 92], "storag": [21, 22, 94], "gib": 21, "gp2": 21, "root": [21, 34, 72, 92], "volum": [21, 36, 58, 88, 90, 92], "enough": [21, 22, 34, 36, 42, 46, 53, 58, 61, 75, 90], "rest": [21, 22, 31, 32, 51, 61, 74, 88, 92], "bottom": [21, 62, 72], "summari": [21, 34, 36, 56, 61, 74, 75], "view": [21, 32, 53, 74, 88, 92], "dashboard": [21, 58], "state": [21, 25, 30, 32, 34, 46, 47, 51, 53, 57, 61, 64, 75, 77, 81, 90, 94], "statu": 21, "readi": [21, 40, 61, 76, 77, 78, 94], "protocol": 21, "instruct": [21, 23, 24, 25, 37, 52, 58, 72, 83], "maco": 21, "linux": [21, 92], "bash": [21, 92], "zsh": 21, "accomplish": [21, 42, 49, 52, 53, 57, 61, 66, 75, 76, 78, 90, 94], "gitbash": 21, "identifi": [21, 32, 36, 37, 38, 41, 51, 53, 58, 61, 63, 73, 74, 75, 83, 88, 90], "put": [21, 34, 52, 54, 55, 58, 60, 61, 67, 73, 74, 75, 77, 88, 91, 92], "keypair": 21, "directori": [21, 22, 52, 80, 83, 92], "key_pair": 21, "pem": 21, "chang": [21, 22, 34, 51, 53, 58, 61, 62, 63, 71, 73, 77, 78, 81, 83, 88, 90, 92, 94, 98], "permiss": 21, "chmod": 21, "400": [21, 38, 41, 43, 61, 62, 72, 81, 88, 94], "clink": 21, "webpag": 21, "ipv4": 21, "92": [21, 66, 81], "67": 21, "user": [21, 52, 76, 77, 90, 92], "avoid": [21, 22, 31, 36, 37, 40, 51, 72, 74, 75, 78, 83, 88], "profil": [21, 81, 92], "echo": [21, 92], "k": [21, 42, 46, 47, 57, 66, 67, 69, 71, 72, 75, 76, 77, 78, 80, 81, 88], "zshrc": 21, "world": [21, 50], "oyster": 21, "clone": 21, "keep": [21, 25, 27, 36, 48, 52, 58, 60, 61, 62, 66, 72, 76, 78, 81, 90, 92], "github": [21, 22, 51, 92, 94], "my_user_nam": 21, "my_favorite_repositori": 21, "folder": [21, 52, 81, 88], "appropri": [21, 25, 51, 53, 57, 58, 61, 72, 75, 83, 88], "path": [21, 22, 36, 37, 40, 42, 51, 53, 54, 55, 58, 59, 61, 64, 66, 74, 75, 76, 77, 78, 80, 81, 83, 88, 92], "ipynb": [21, 83], "whenev": 21, "ad": [21, 32, 53, 55, 66, 75, 76, 80, 92], "bebi103_upd": 21, "document": [21, 24, 40, 51, 52, 73, 80, 81, 83, 92, 97], "edit": [21, 22, 83, 92], "manag": [21, 51, 52, 62, 92], "push": [21, 74, 76, 78, 90], "pull": [21, 36, 37, 40, 42, 54, 55, 58, 61, 74, 81, 90, 94], "execut": [21, 22, 52, 54, 92], "jupyt": [21, 22, 24, 52, 58, 83, 88, 92], "browser": [21, 22, 74, 92], "server": [21, 92], "runtim": 21, "jpserver": 21, "30060": 21, "html": [21, 22, 58, 83], "Or": [21, 60, 75], "url": 21, "localhost": 21, "8888": 21, "token": 21, "e52184f06c9fb0f9ceea176b1d51d9cb36c72a019e688f": 21, "127": 21, "socket": 21, "l": [21, 36, 37, 40, 42, 54, 58, 73, 75, 78, 81, 83], "8000": 21, "port": [21, 92], "got": [21, 26, 36, 51, 57, 61, 62, 63, 75, 76, 81, 88, 92, 94], "8889": 21, "substitut": [21, 32, 36, 63, 71, 75, 81], "8001": 21, "90": [21, 31, 58, 69, 72, 81], "direct": [21, 38, 75, 90], "specifi": [21, 31, 32, 36, 37, 40, 51, 52, 53, 54, 55, 58, 59, 60, 66, 67, 72, 75, 76, 81, 90, 92], "8890": 21, "notebook": [21, 22, 24, 51, 52, 58, 74, 83, 88, 90, 92, 94], "move": [21, 34, 47, 58, 61, 62, 74, 90, 92], "commit": 21, "intermedi": [21, 42, 58, 94], "scp": [21, 92], "yet": [21, 24, 34, 59, 75, 78, 83, 94], "my_fil": 21, "transfer": [21, 94], "colon": 21, "second": [21, 24, 32, 34, 36, 37, 40, 41, 42, 51, 52, 55, 58, 59, 60, 66, 71, 73, 74, 75, 77, 81, 83, 92, 94], "similarli": [21, 25, 30, 42, 63, 75, 94], "upload": 21, "txt": [21, 52], "finish": [21, 52, 92, 94], "shut": 21, "shutdown": 21, "prompt": [21, 24, 90, 92], "hard": [21, 31, 40, 58, 72, 77, 78], "press": [21, 30, 42], "ctrl": 21, "unless": [21, 48, 52, 57, 81], "realli": [21, 25, 31, 32, 34, 36, 37, 40, 58, 60, 62, 63, 66, 73, 74, 75, 77, 78, 81, 83, 90, 94], "rid": 21, "charg": 21, "rack": 21, "massiv": 21, "bill": 21, "idl": [21, 22], "minor": [21, 58], "pain": 21, "wait": [21, 25, 31, 38, 75, 92], "forget": [21, 92], "pocketbook": 21, "easier": [21, 25, 31, 32, 36, 40, 53, 57, 63, 75, 76, 90], "navig": [21, 22], "via": [21, 22, 33, 38, 51, 52, 72, 75, 83], "spun": 21, "per": [21, 34, 36, 51, 58, 60, 62, 66, 72, 74, 75, 81, 88, 92, 94], "eb": 21, "etc": [21, 22, 25, 31, 32, 52, 68, 71, 75, 80, 81, 83, 92], "intact": 21, "free": [21, 22, 23, 59, 63, 72, 76, 81, 83, 88], "tier": [21, 22], "expir": 21, "promo": 21, "wipe": 21, "conveni": [22, 31, 34, 36, 40, 41, 42, 46, 49, 51, 52, 53, 55, 57, 58, 59, 61, 63, 66, 68, 72, 75, 77, 78, 80, 88, 90], "account": [22, 51, 61, 83, 92, 94], "employe": 22, "suit": 22, "person": [22, 57, 92], "gmail": 22, "youtub": [22, 97], "facilit": [22, 33, 80, 92], "teammat": [22, 83], "staff": [22, 83], "machin": [22, 23, 52, 63, 74, 75, 92], "annoi": [22, 23, 52], "trick": [22, 32, 36, 47, 53, 72, 88, 94], "safari": 22, "edg": [22, 88], "web": 22, "brows": 22, "chrome": 22, "firefox": 22, "jupyterlab": [22, 24, 36, 37, 38, 40, 41, 42, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 94], "support": [22, 81], "launch": [22, 53], "altern": [22, 40, 51, 60, 62, 63, 71, 88, 90, 92], "badg": 22, "content": [22, 33, 52, 53, 58, 60, 75, 77, 80, 81], "virtual": [22, 92], "cpu": [22, 92], "gb": 22, "vari": [22, 24, 25, 31, 40, 55, 58, 71, 72, 75, 76, 78, 81, 88, 90], "ram": [22, 52], "gpu": [22, 92], "tpu": 22, "tensor": 22, "unit": [22, 31, 34, 40, 51, 52, 54, 58, 63, 72, 75, 78, 90], "too": [22, 25, 31, 34, 36, 37, 47, 57, 60, 61, 62, 73, 74, 75, 76, 78, 81, 83, 88, 90], "long": [22, 25, 34, 47, 48, 52, 57, 60, 61, 67, 77, 78, 88, 90, 91, 94], "disconnect": [22, 23], "timeout": 22, "almost": [22, 30, 31, 32, 34, 36, 40, 42, 46, 48, 49, 51, 53, 60, 66, 74, 75, 76, 83], "alwai": [22, 24, 25, 31, 34, 36, 40, 42, 46, 49, 51, 53, 57, 58, 60, 66, 67, 75, 81, 83, 88, 94], "effici": [22, 58, 61, 80, 90, 92], "place": [22, 40, 57, 58, 77, 78, 83, 90], "offer": [22, 36, 40, 47, 55, 61, 63, 66, 92, 94], "longer": [22, 34, 37, 51, 53, 58, 67, 76, 80, 88, 90], "pro": [22, 23], "howev": [22, 34, 36, 38, 41, 42, 49, 51, 53, 58, 59, 60, 61, 62, 63, 66, 73, 75, 76, 77, 83, 88, 90, 91, 92, 94], "encourag": [22, 72, 73, 75, 83], "bokeh": [22, 24, 36, 37, 38, 40, 41, 42, 43, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94], "app": [22, 88], "python": [22, 36, 37, 38, 40, 41, 42, 51, 52, 53, 54, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 83, 88, 94, 97], "callback": [22, 58], "instanc": [22, 23, 36, 51, 52, 58], "major": [22, 34, 36, 40, 42, 58, 73], "burden": 22, "circumv": 22, "upgrad": [22, 23, 51, 94], "faq": 22, "latest": 22, "januari": [22, 98], "wherea": [22, 41, 90], "anaconda": 22, "preinstal": 22, "variant": [22, 66], "thereof": [22, 63, 66, 83], "cmdstanpi": [22, 51, 52, 53, 54, 55, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 92, 94, 97], "install_cmdstan": [22, 24, 51, 94], "setup": [22, 23, 51, 60, 77, 94], "sy": [22, 51, 83, 94], "subprocess": [22, 31, 51, 94], "cmd": [22, 51, 94], "pip": [22, 51, 92, 94], "polar": [22, 36, 37, 40, 42, 51, 53, 54, 55, 57, 58, 59, 61, 64, 66, 72, 74, 75, 76, 77, 78, 80, 81], "iqplot": [22, 51, 52, 53, 54, 57, 58, 61, 69, 72, 74, 78, 81, 94], "colorcet": [22, 51, 52, 94], "datashad": [22, 51], "arviz": [22, 24, 51, 53, 54, 57, 58, 59, 61, 62, 63, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 92, 94, 97], "watermark": [22, 24, 36, 37, 38, 40, 41, 42, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 94], "popen": [22, 51, 94], "split": [22, 25, 32, 51, 53, 58, 63, 92, 94], "stdout": [22, 51, 52, 92, 94], "pipe": [22, 51, 94], "stderr": [22, 51, 92, 94], "data_path": [22, 36, 37, 40, 42, 51, 53, 54, 55, 58, 59, 61, 64, 66, 74, 75, 76, 77, 78, 80, 81, 83, 94], "ensur": [22, 31, 48, 53, 61, 62, 73, 78, 80, 83, 90, 94], "recent": [22, 72, 83, 92], "cmdstan": [22, 24, 51, 52, 53, 54, 55, 58, 59, 61, 62, 64, 66, 72, 74, 75, 76, 77, 78, 80, 81, 94], "drawback": [22, 41, 55, 57], "built": [22, 36, 40, 46, 52, 53, 58, 61, 66, 69, 72, 75, 80, 94], "binari": 22, "shutil": [22, 51, 94], "urllib": [22, 51, 94], "latest_vers": [22, 51, 94], "cmdstan_vers": [22, 24, 51, 52, 53, 54, 55, 58, 59, 61, 62, 64, 66, 72, 74, 75, 76, 77, 78, 80, 81, 94], "cmdstan_url": [22, 51, 94], "dev": [22, 36, 51, 94], "releas": [22, 51, 55, 94], "v": [22, 24, 36, 37, 38, 40, 41, 42, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 90, 94], "fname": [22, 51, 81, 94], "tgz": [22, 51, 94], "urlretriev": [22, 51, 94], "unpack_arch": [22, 51, 94], "faster": [22, 34, 36, 41, 51, 58, 60, 74, 83, 92], "mode": [22, 41, 52, 53, 57, 90], "fetch": [22, 80], "aw": [22, 23, 52], "hidden": 22, "render": [22, 43, 55, 58, 83, 88], "clutter": [22, 31, 51, 52], "collab": 22, "az": [22, 24, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 92, 94], "io": [22, 24, 36, 37, 38, 40, 41, 42, 43, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94], "output_notebook": [22, 24, 36, 37, 38, 40, 41, 42, 43, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94], "schools_data": [22, 24], "schools_cod": [22, 24], "lower": [22, 24, 25, 34, 41, 51, 53, 54, 55, 57, 58, 59, 61, 62, 63, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 90, 92, 94], "school": [22, 24], "vector": [22, 24, 53, 58, 66, 72, 75, 76, 77, 78, 80, 81, 88, 90], "treatment": [22, 24, 41, 42, 54, 73], "tau": [22, 24, 34, 72, 81], "eta": [22, 24, 81], "transform": [22, 24, 25, 30, 34, 46, 51, 52, 53, 54, 55, 59, 60, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94], "w": [22, 24, 32, 53, 58, 66, 72, 81, 90, 92, 98], "disable_log": [22, 24, 51, 53, 54, 55, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 92, 94], "sm": [22, 24, 51, 52, 53, 54, 55, 59, 61, 62, 66, 69, 74, 76, 77, 78, 80, 81, 83, 92, 94], "cmdstanmodel": [22, 24, 51, 52, 53, 54, 55, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 83, 92, 94], "stan_fil": [22, 24, 51, 52, 53, 54, 55, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 92, 94], "output_dir": [22, 24, 92], "show_progress": [22, 24, 51, 52, 58, 81, 92, 94], "from_cmdstanpi": [22, 24, 51, 52, 53, 54, 55, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 77, 78, 80, 81, 92, 94], "clean_cmdstan": [22, 24, 51, 52, 53, 54, 55, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 94], "frame_height": [22, 24, 36, 37, 38, 40, 41, 42, 43, 51, 53, 54, 55, 57, 58, 74, 75, 76, 77, 78, 81, 88, 94], "250": [22, 24, 36, 37, 40, 42, 51, 54, 55, 57, 58, 59, 64, 74, 75, 76, 77, 78, 80, 81], "frame_width": [22, 24, 36, 37, 38, 40, 41, 42, 43, 51, 53, 54, 55, 57, 58, 69, 74, 75, 76, 77, 78, 81, 88, 94], "x_axis_label": [22, 24, 36, 37, 38, 40, 41, 42, 43, 51, 53, 54, 55, 57, 58, 59, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 81, 88, 94], "\u03bc": [22, 24, 36], "y_axis_label": [22, 24, 36, 37, 38, 40, 41, 42, 43, 51, 54, 55, 57, 58, 59, 62, 64, 69, 72, 74, 75, 76, 77, 78, 81, 88, 94], "\u03c4": [22, 24, 72, 81], "scatter": [22, 24, 36, 37, 40, 42, 51, 53, 54, 55, 57, 58, 62, 72, 74, 75, 76, 77, 78, 81, 88], "ravel": [22, 24, 51, 52, 94], "alpha": [22, 24, 36, 37, 38, 40, 41, 42, 43, 46, 47, 51, 53, 54, 55, 58, 60, 61, 62, 66, 67, 69, 72, 73, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94], "bokehj": [22, 24, 36, 37, 38, 40, 41, 42, 43, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 94], "load_ext": [22, 24, 36, 37, 38, 40, 41, 42, 43, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 94], "cpython": [22, 24, 36, 37, 38, 40, 41, 42, 51, 52, 53, 54, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 94], "ipython": [22, 24, 36, 37, 38, 40, 41, 42, 51, 52, 53, 54, 57, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 88, 94], "27": [22, 24, 51, 53, 55, 58, 72, 74, 76, 77, 78, 80, 81, 94, 98], "requir": [23, 25, 32, 46, 49, 51, 58, 61, 63, 74, 81, 83, 88, 90, 91, 92], "signific": [23, 47, 58, 75, 92], "prefer": [23, 25, 34, 54, 55, 58, 63, 66, 92, 94], "connect": [23, 25, 63, 64, 88, 92], "larg": [23, 25, 31, 34, 36, 37, 49, 51, 54, 58, 61, 62, 63, 72, 74, 75, 76, 78, 81, 83, 88, 92, 94], "loud": 23, "hot": 23, "unavail": [23, 36], "colab": [23, 24, 51, 52, 83, 94], "pretti": [23, 34, 38, 46, 49, 53, 55, 58, 63, 74, 75, 90, 92, 94], "fast": [23, 40, 58, 63, 72], "biggest": [23, 92], "interact": [23, 52, 58, 60, 91, 92], "babysit": 23, "commerci": 23, "servic": [23, 32, 92], "hpc": 23, "oper": [24, 34, 51, 53, 75, 77, 90, 92, 94], "BE": [24, 82], "103": [24, 82], "probabilist": [24, 25, 30, 31, 34, 51, 52, 90], "program": [24, 31, 51, 54, 80, 92], "languag": [24, 31, 51, 52, 83, 94], "translat": [24, 52, 90], "parser": 24, "compil": [24, 51, 52, 53, 58, 59, 61, 62, 64, 66, 69, 74, 75, 76, 77, 78, 80, 81, 83, 92, 94], "interfac": [24, 51, 52, 81, 97], "wide": [24, 31, 34, 36, 47, 48, 63, 74, 75, 77, 92], "rstan": 24, "pystan": [24, 52], "respect": [24, 31, 34, 36, 42, 52, 53, 55, 57, 62, 63, 66, 67, 69, 72, 75, 77, 80, 81, 83], "simpler": [24, 58, 60, 76, 94], "becom": [24, 25, 26, 32, 34, 36, 37, 42, 49, 53, 58, 60, 63, 88, 90, 91, 94], "appar": [24, 72, 77, 94], "whichev": 24, "tricki": [24, 36, 66, 75], "system": [24, 31, 52, 63, 71, 75, 88, 90, 92], "troubleshoot": 24, "worri": [24, 46, 57, 94], "troubl": [24, 58, 61, 62, 83], "On": [24, 60, 71, 88, 94], "xcode": 24, "previous": [24, 55, 61, 81, 92], "One": [24, 30, 31, 32, 36, 46, 57, 58, 72, 81, 88, 90, 92, 94], "mingw": 24, "conda": [24, 92], "libpython": 24, "m2w64": 24, "msys2": 24, "util": [24, 30, 34, 38, 90, 92, 97], "raspberri": 24, "pi": [24, 27, 29, 30, 31, 32, 34, 36, 41, 55, 58, 59, 62, 64, 66, 69, 73, 75, 78, 81, 88, 90, 92, 94], "took": [24, 36, 38, 42, 47, 61, 63, 71, 81], "appreci": 24, "nifti": [24, 94], "trivial": [24, 25, 49, 52, 59, 88, 92], "feat": 24, "warn": [24, 41, 51, 62, 64, 66, 74], "print": [24, 36, 40, 42, 51, 52, 53, 54, 55, 58, 59, 61, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 81, 83, 88, 92, 94], "thought": [25, 38, 40, 83], "inquiri": 25, "visit": [25, 36, 48], "refresh": [25, 63, 74, 81, 88], "sketch": [25, 31, 34], "cycl": 25, "itself": [25, 58, 63, 66, 72, 76, 90], "natur": [25, 31, 51, 58, 60, 63, 66, 94], "mileston": 25, "along": [25, 34, 48, 51, 52, 55, 60, 61, 64, 88, 90, 92], "arrow": 25, "orang": [25, 36, 38, 40, 42, 51, 53, 62, 72, 74, 75, 76, 77, 78, 80, 81, 88], "fig": [25, 73], "gregori": [25, 97], "cambridg": [25, 30], "2005": 25, "hypothesi": [25, 26, 29, 32], "invent": 25, "refin": [25, 31], "stage": [25, 31, 58], "hypothes": [25, 27, 29, 30], "theori": [25, 41, 51, 66], "pursu": 25, "innov": 25, "sometim": [25, 40, 53, 58, 60, 63, 81, 91, 92], "geniu": 25, "deduct": [25, 83], "deduc": 25, "experiment": [25, 58, 71, 72, 81, 94], "strong": [25, 51, 53, 61, 75, 78, 81, 94], "syllog": 25, "therefor": [25, 29, 31, 33, 34, 36, 37, 38, 40, 41, 42, 51, 52, 54, 58, 60, 61, 63, 66, 74, 75, 77, 78, 81, 83, 88, 91], "plausibl": [25, 31, 32], "perhap": [25, 32, 34, 38, 58, 60, 61, 66, 71, 75, 90], "familiar": [25, 33, 52, 53, 58, 60, 74, 75, 88, 94], "talk": [25, 30, 31, 34, 38, 46, 55, 61, 73], "bullet": 25, "But": [25, 31, 34, 37, 40, 41, 46, 47, 49, 51, 52, 54, 57, 60, 61, 63, 74, 75, 76, 81], "knowledg": [25, 26, 31, 32, 34, 38, 47, 54, 58, 60, 63, 73, 76, 88], "design": [25, 58, 72, 91, 94], "necessarili": [25, 34, 40, 51, 57, 58, 61, 63, 94], "weak": [25, 34, 90], "wastewat": 25, "hydraul": 25, "fractur": 25, "frack": 25, "lead": [25, 32, 34, 41, 51, 53, 58, 62, 66, 78, 88], "greater": [25, 58, 60, 61], "earthquak": 25, "frequenc": [25, 51, 53, 58, 61, 74], "oklahoma": 25, "increas": [25, 36, 58, 72, 74, 75, 88, 90, 92, 94], "2010": 25, "becam": 25, "busi": [25, 94], "obeserv": 25, "role": 25, "crucial": [25, 53, 61, 62, 63, 88], "t": [25, 30, 31, 34, 36, 40, 41, 46, 47, 52, 57, 58, 60, 61, 62, 63, 66, 72, 73, 74, 75, 76, 77, 78, 80, 81, 88, 90, 91, 92, 94], "jayn": [25, 30], "domin": [25, 36, 66, 69, 74], "interpret": [25, 26, 30, 32, 41, 57, 59, 63, 75, 92], "ident": [25, 30, 31, 40, 51, 61, 66, 94], "repetit": 25, "hypothet": [25, 94], "event": [25, 30, 33, 34, 47, 60, 61, 63], "restrict": [25, 38, 75, 81], "proposit": [25, 32], "random": [25, 30, 43, 45, 52, 53, 57, 58, 60, 61, 62, 74, 75, 76, 77, 78, 81, 88, 90, 92, 94], "quantiti": [25, 27, 30, 31, 32, 34, 36, 52, 58, 59, 60, 63, 64, 66, 74, 75, 77, 78, 80, 81, 90, 92, 94], "meaningfulli": 25, "degre": [25, 51], "belief": [25, 51], "fight": 25, "peopl": 25, "who": [25, 83], "appli": [25, 26, 29, 30, 32, 51, 61, 62, 63, 67, 72, 75, 77, 81, 83, 88, 90, 92, 94], "valid": [25, 63, 66, 80], "exclus": 25, "great": [25, 33, 34, 48, 77, 92, 94, 97], "opinion": [25, 47, 55, 94], "proce": [25, 36, 37, 41, 42, 66, 73, 76, 78, 80, 81], "conceptu": [25, 27, 34, 38, 44, 88], "cleaner": 25, "certainti": 25, "convers": [25, 30, 58, 63, 83], "fix": [25, 36, 51, 52, 53, 55, 61, 75, 76, 88, 94], "convert": [25, 34, 46, 51, 52, 53, 55, 58, 59, 60, 61, 63, 66, 72, 75, 77, 80, 81, 88], "1946": 25, "cox": 25, "laid": [25, 32, 38, 48, 52, 55, 61, 74, 80], "properti": [25, 32, 46, 48, 49, 75, 78, 81, 90], "expand": [25, 53, 90, 92], "1970": [25, 94], "ration": 25, "suppli": 25, "rise": [25, 91], "monoton": [25, 40, 63], "manner": 25, "proprieti": 25, "relev": [25, 34, 36, 40, 41, 42, 57], "satisfi": [25, 46, 47, 48, 49, 61, 62, 63, 73, 90], "paus": [25, 31, 32, 36, 53, 54, 63, 90], "without": [25, 30, 32, 33, 34, 38, 42, 48, 52, 62, 63, 75, 77, 83, 88, 92, 94], "chapter": 25, "uniti": [25, 47, 61, 73, 74, 75], "except": [25, 51, 52, 58, 78, 83, 90, 94], "complement": 25, "interest": [25, 31, 33, 36, 38, 42, 47, 49, 51, 52, 53, 55, 60, 61, 63, 69, 72, 75, 88, 91, 94], "happen": [25, 31, 41, 58, 59, 61, 62, 63, 75, 83, 92], "denot": [25, 27, 30, 32, 34, 41, 61, 63, 75, 88, 90], "notion": [25, 34, 63, 90], "bit": [25, 27, 30, 31, 34, 36, 38, 40, 46, 48, 53, 57, 58, 62, 63, 72, 73, 76, 77, 90, 92, 94], "abstract": 25, "bring": [25, 34, 60, 63, 75, 94], "realm": [25, 63, 94], "ll": [25, 37, 42, 51, 52, 57, 59, 60, 61, 62, 64, 66, 73, 74, 77, 78, 81, 88, 92], "been": [25, 30, 32, 42, 58, 63, 76, 78, 81, 92], "rewrit": [25, 58, 71], "explicitli": [25, 31, 36, 47, 52, 53, 63, 67, 75, 78, 83, 94], "henceforth": [25, 75], "vacuum": 25, "ahoi": 25, "pictur": [25, 36, 37, 54, 55, 61, 75, 92], "cannot": [25, 30, 34, 36, 37, 38, 42, 47, 49, 51, 53, 55, 58, 59, 60, 62, 63, 64, 72, 75, 77, 78, 81, 88], "perspect": [25, 88, 90], "analyz": [25, 32, 51, 64, 72, 73, 83, 91], "commut": 25, "side": [25, 30, 36, 42, 73, 75, 91, 94], "seemingli": [25, 51], "equal": [25, 34, 41, 47, 63, 73, 81, 91], "rearrang": [25, 81, 94], "far": [25, 30, 32, 40, 41, 46, 51, 58, 62, 66, 73, 76, 78, 83, 92], "item": [25, 53, 57, 88, 92, 94], "believ": [25, 34, 40, 67, 92], "acquir": [25, 26, 38, 51, 52, 76, 78], "instrument": [25, 67], "constitut": [25, 63], "bulk": [25, 37, 58], "algebra": [25, 36, 75, 80], "outcom": [25, 30, 33, 34, 63, 71, 72, 88], "cute": 25, "acronym": 25, "feel": [25, 34, 38, 51, 54, 83, 88], "try": [25, 31, 32, 34, 38, 53, 58, 60, 61, 62, 66, 71, 72, 78, 81, 83, 90, 92, 94], "head": [25, 37, 53, 55, 72, 74, 81, 88], "around": [25, 36, 37, 40, 47, 53, 55, 58, 60, 63, 72, 73, 78, 88, 90, 94], "plug": [26, 31, 63], "product": [26, 31, 32, 34, 36, 53, 58, 71, 75, 81, 83, 90, 94], "rule": [26, 29, 34, 37, 47, 48, 59, 61, 64, 73, 83], "denomin": 26, "insert": [26, 38, 58, 73], "equat": [26, 31, 46, 63, 71, 73, 83, 88, 90, 94], "yield": [26, 53, 73, 75, 94], "gave": [26, 52, 74], "combin": [26, 53, 58, 66, 92, 94], "acquisit": [26, 60], "constantli": 26, "symbol": [27, 31, 75, 90], "overload": 27, "aid": 27, "convent": [27, 80], "evid": [27, 29, 31, 32, 53, 60, 81, 88, 94], "joint": [27, 29, 32, 36, 47, 58, 62, 73, 75, 81, 88, 90, 94], "speak": [27, 32, 60, 61, 75, 90], "track": [27, 48, 61, 72, 81], "notat": [28, 30, 31, 36, 46, 63, 75, 77], "bay": [28, 29, 31, 32, 38, 61, 63, 68, 71, 75, 81, 94], "theorem": [28, 29, 31, 32, 33, 38, 63, 68, 71, 73, 75, 88, 90, 94], "mention": [29, 34, 51, 62, 66, 71, 92], "theta_i": [29, 34, 41, 46, 47, 49, 67, 69, 71, 73, 81], "particular": [29, 34, 37, 49, 51, 52, 53, 55, 57, 59, 61, 62, 69, 75, 76, 90, 94], "theta_j": [29, 34, 40, 41, 81], "c_j": [29, 75], "nonumb": [29, 31, 47, 63], "ne": [29, 63, 75, 78], "sum_i": [29, 30, 40, 63, 75, 88], "elimin": [29, 90], "lectur": [30, 32, 34, 44, 48, 51, 55, 63, 66, 73, 82, 83, 98], "verbatim": 30, "introduc": [30, 34, 52, 53, 58, 75, 76, 81, 88, 90], "deal": [30, 34, 47, 53, 61, 72, 74, 90, 94], "notation": 30, "le": [30, 36, 37, 42, 58, 75], "cumul": [30, 41], "cdf": [30, 40, 41, 43, 46, 49, 51, 53, 55, 60, 69], "panel": 30, "height": [30, 36, 62, 72, 88], "men": 30, "centimet": 30, "countri": 30, "ly": [30, 76, 77, 80], "y_0": 30, "int_": [30, 88], "satisfact": 30, "axiom": [30, 88], "infti": [30, 31, 34, 36, 37, 40, 60, 75], "necessit": [30, 67], "pmf": [30, 33, 38, 53, 92, 94], "unlik": [30, 31, 42, 53, 58, 60, 62, 66, 72, 88, 94], "roll": 30, "fair": 30, "die": [30, 77], "seen": [30, 32, 36, 38, 46, 51, 53, 57, 59, 61, 64, 68, 75, 77, 80, 88], "hold": [30, 46, 47, 53, 58, 73, 75], "immedi": [30, 38, 49, 52, 58, 62, 72, 74], "consequ": 30, "conjectur": [30, 75], "final": [30, 37, 42, 49, 51, 63, 66, 72, 73, 74, 75, 76, 78, 81, 83, 90, 98], "f_x": 30, "subscript": [30, 49, 63, 72], "enforc": [30, 53], "partial": [30, 34, 41, 77, 88, 90], "factor": [30, 31, 36, 67, 68, 75, 81, 92], "jacobian": 30, "absolut": [30, 62, 88], "jacobi": [30, 34], "cdot": [30, 31, 34, 40, 41, 49, 60, 71, 75, 77, 78, 88, 90, 94], "vdot": [30, 34], "ddot": [30, 34], "beta": [30, 41, 42, 43, 46, 51, 53, 54, 55, 58, 59, 60, 61, 64, 66, 67, 68, 69, 71, 74, 75, 77, 81, 90, 92, 94], "rescal": [30, 88], "accordingli": [30, 81], "sqrt": [30, 31, 34, 36, 40, 41, 42, 62, 75, 76, 77, 88, 90, 92], "ln": [30, 34, 36, 40, 41, 46, 53, 58, 59, 63, 64, 66, 75, 76, 78, 80, 81, 94], "subtl": [30, 34], "univers": [30, 71], "2003": 30, "subtleti": [30, 63], "simplest": [31, 37, 49, 55, 92], "beak": [31, 66], "depth": [31, 36, 62, 64, 66, 69, 72, 74, 75, 77, 78, 80, 94], "finch": [31, 66], "fluoresc": [31, 51, 72, 91, 94], "abound": 31, "concret": [31, 32, 34, 63, 72, 75, 94], "ambigu": [31, 63], "sharpen": 31, "low": [31, 34, 42, 48, 53, 55, 72, 75, 76, 77, 90, 94], "codifi": [31, 32, 34, 54, 63], "everi": [31, 34, 37, 40, 41, 47, 53, 54, 58, 59, 76, 78, 83, 88, 90, 92, 94], "prod_": [31, 36, 63, 67, 94], "delta": [31, 32, 63, 77, 78, 80], "dirac": [31, 32, 63], "shall": [31, 36, 75], "heavi": [31, 57, 60, 76, 90, 92, 94], "univari": [31, 55, 59, 60, 78, 80], "exp": [31, 36, 37, 40, 41, 42, 53, 62, 63, 66, 75, 76, 77, 78, 80, 88, 94], "varianc": [31, 33, 40, 48, 52, 58, 60, 61, 62, 63, 72, 73, 74, 75, 77, 90], "confusingli": 31, "literatur": [31, 83], "central": [31, 33, 41, 55, 57, 90, 92], "emerg": 31, "tend": [31, 34, 40, 53, 61, 62, 63, 66, 69, 73, 75, 77], "broadli": 31, "det": [31, 34, 88], "mu_1": 31, "mu_2": [31, 57], "mu_n": 31, "symmetr": [31, 41, 73, 75, 81], "sigma_": [31, 34, 41, 73, 75], "y_j": 31, "correl": [31, 51, 53, 61, 75, 88, 90], "anticorrel": [31, 55], "reduc": [31, 64, 92], "2_i": 31, "decid": [31, 34, 58, 78, 83, 91, 94], "spread": [31, 74, 78, 92], "sought": 31, "beyond": [31, 34, 36, 63, 74, 77, 83], "int_0": [31, 34, 36, 37], "guess": [31, 34, 37, 40, 42, 76, 77, 88], "\u00b5m": [31, 34, 36, 37, 40, 42, 54, 55, 58, 59, 60, 64, 81], "mu_": [31, 34], "tini": [31, 41, 62], "five": [31, 68, 73, 74], "ten": [31, 34, 60, 91], "micron": [31, 34, 40, 54], "size": [31, 34, 37, 42, 43, 52, 53, 54, 55, 57, 62, 64, 66, 69, 72, 74, 75, 76, 77, 78, 80, 88, 90, 92, 94], "unphys": [31, 58, 74], "mathemat": [31, 34, 36, 37, 38, 40, 58, 60, 63, 75, 81, 83, 90, 92], "disallow": 31, "roughli": [31, 32, 73, 91, 94], "piec": [31, 40], "cover": [31, 34, 47, 64, 92], "exclud": 31, "unreason": [31, 75], "brace": [31, 52, 53, 54, 58], "oh": [31, 94], "mess": [31, 63], "challeng": [31, 32, 33, 34, 38, 53, 72, 75, 92], "easi": [31, 32, 38, 41, 53, 57, 58, 62, 81, 88, 92, 94], "shorthand": [31, 46], "omit": [31, 63], "english": [31, 73], "self": [31, 73, 74], "nasti": [31, 38, 49], "nor": [31, 34, 40, 57, 66, 75, 76, 92], "maintain": [31, 34], "focu": [31, 32, 36, 46, 51, 53, 58, 75], "loos": [32, 61, 63, 90], "explicit": [32, 58, 75], "unambigu": [32, 53, 58], "descript": [32, 51, 61, 73, 74, 90, 94], "prescrib": [32, 58, 60], "asid": [32, 61], "philosoph": 32, "gelman": [32, 46, 48, 63, 66, 97], "simpson": [32, 55], "betancourt": [32, 44, 53, 59, 61, 62, 73, 88, 90, 97], "clearli": [32, 36, 38, 51, 53, 59, 62, 66, 69, 72, 74, 81, 83, 91, 94], "dilemma": 32, "apt": [32, 51], "titl": [32, 51, 57, 58, 88, 94], "emphasi": [32, 57, 76], "sort": [32, 38, 58, 64, 92], "liter": 32, "social": 32, "intervent": 32, "he": [32, 34, 40, 42, 63, 94], "she": 32, "pattern": [32, 72], "gather": 32, "form": [32, 34, 38, 41, 53, 55, 58, 63, 67, 75, 78, 81, 83, 88, 90, 91, 94], "latter": [32, 53, 63, 73, 92], "destin": 32, "complic": [32, 34, 52, 88, 90], "grow": [32, 34, 36, 58, 72, 75, 90], "manifest": [32, 53], "heart": [32, 75], "langl": [32, 49, 73, 88], "xi": [32, 60, 68, 75, 80], "rangl": [32, 49, 88], "replac": [32, 46, 47, 72, 75, 77, 80, 81, 88, 94], "conjagaci": 32, "maxim": [32, 34, 36, 40, 41, 57, 76, 81, 94], "earlier": [32, 34, 53, 88], "resort": [32, 90], "candid": [32, 47], "nice": [32, 46, 51, 55, 57, 59, 73, 75, 77, 80, 94, 97], "therebi": [32, 34, 38], "enorm": 33, "amount": [33, 34, 40, 58, 60, 63, 64, 92], "bind": [33, 91, 94], "ligand": [33, 91, 94], "receptor": [33, 91, 94], "record": 33, "memori": [33, 46, 92], "arriv": [33, 46, 48, 81, 94], "exist": [33, 41, 46, 58, 90], "invest": 33, "greatli": [33, 75, 90, 92], "felt": 34, "heat": 34, "framework": [34, 90], "invalid": [34, 51, 76, 77, 88], "bia": [34, 51, 73, 75], "entropi": [34, 81], "bernardo": 34, "eventu": [34, 46, 90, 94], "advoc": 34, "insuffici": 34, "old": [34, 38, 94], "flat": [34, 42, 63], "summar": [34, 40, 55], "Such": [34, 53, 73], "encod": [34, 54, 81], "machineri": [34, 51], "remedi": 34, "bound": [34, 36, 37, 40, 41, 51, 53, 54, 55, 57, 58, 61, 75, 76, 77, 81, 92], "outsid": [34, 52, 58, 63, 64, 73, 83, 88, 90], "small": [34, 36, 53, 58, 60, 61, 62, 72, 74, 75, 76, 77, 78, 80, 81, 83, 88, 90, 94], "epsilon": [34, 90], "kinesin": [34, 60], "noth": [34, 52, 58, 74], "goe": [34, 42, 46, 58, 77, 90, 94], "absurd": 34, "primari": [34, 36, 57, 97], "critic": [34, 38, 58], "contemporari": 34, "illustr": [34, 46, 53, 57, 66, 75, 88, 94], "resolut": 34, "earli": [34, 76, 77], "patholog": [34, 61, 62, 64, 66, 69, 72, 73, 74, 75, 77, 78, 80, 90, 94], "bad": [34, 51, 58, 59, 64, 66, 78, 94], "subject": [34, 61, 63, 81, 92, 98], "debat": 34, "complain": 34, "chosen": [34, 53, 57, 58, 59, 72, 75, 88], "recal": [34, 36, 41, 42, 52, 61, 63, 66, 74, 77, 94], "formula": [34, 62], "invari": [34, 46, 47, 67], "harold": 34, "discov": [34, 53, 60, 62, 74], "coordin": [34, 51, 52, 53, 61, 62, 66, 72], "mathcal": [34, 81, 88, 90], "_": [34, 37, 41, 57, 63, 66, 75, 76, 77, 78, 80, 90, 94], "succinctli": 34, "sharp": [34, 58, 67, 94], "peak": [34, 36, 37, 40, 41, 58, 63, 67, 94], "propto": [34, 36, 37, 41, 90, 94], "reparametr": [34, 62, 72, 90], "phi_1": 34, "phi_2": 34, "matric": [34, 75, 77, 80], "recogn": [34, 90, 91], "intract": [34, 42, 81], "against": [34, 42, 58, 59, 63, 64, 66, 73, 76, 77], "tediou": 34, "bernoulli": [34, 38, 71, 88], "success": [34, 36, 38, 71, 81, 88, 94], "proper": [34, 36], "highli": [34, 47, 54, 58, 71, 77], "priori": [34, 38, 58, 60], "regardless": [34, 61, 90], "littl": [34, 36, 40, 49, 57, 60, 61, 63, 78, 88], "influenc": [34, 75], "lack": [34, 46, 63], "imposs": [34, 47, 49, 53, 58, 60, 94], "nefari": 34, "care": [34, 36, 37, 51, 58, 63, 75, 81, 83], "anywai": [34, 36, 77], "travel": 34, "somewhat": [34, 94], "breadth": [34, 36, 90], "broader": [34, 41], "opt": [34, 88], "wiki": [34, 61], "loss": [34, 63], "precis": [34, 60, 61, 77, 90], "popul": [34, 51, 53, 94], "expert": 34, "seriou": [34, 53, 81, 83], "gain": [34, 63], "robust": [34, 57, 66, 90], "separ": [34, 51, 52, 58, 60, 69, 71, 80, 83, 94], "sublim": 34, "ridicul": 34, "consider": [34, 36, 53, 58, 75], "difficulti": [34, 57, 68, 74, 83], "rare": [34, 41, 47, 58, 63], "complex": [34, 38, 52, 53, 58, 60, 75, 81, 88, 90, 91, 92, 94], "certainli": [34, 37, 41, 53, 58, 61, 92], "hierarchi": [34, 68, 72, 81], "parametriz": 34, "greatest": 34, "unbound": 34, "idiomat": 34, "giant": [34, 60], "wager": 34, "salari": 34, "pig": [34, 63], "fly": [34, 63], "comfort": 34, "wage": 34, "don": [34, 40, 61, 72, 75, 88, 90, 92, 94], "hope": [34, 53, 73, 92], "lo": 34, "angel": 34, "footbal": 34, "club": 34, "win": 34, "ml": 34, "cup": 34, "someon": [34, 38, 88], "tell": [34, 37, 38, 40, 41, 48, 51, 52, 58, 63, 72, 73, 74, 80, 88, 90], "bacterium": 34, "absurdli": 34, "bigger": [34, 40, 58, 66, 67, 78, 94], "nanomet": [34, 60], "diamet": [34, 36, 37, 40, 42, 54, 55, 58, 59, 64, 81], "strand": 34, "nm": [34, 40, 72, 81], "flinch": 34, "m": [34, 53, 58, 63, 72, 75, 76, 77, 78, 80, 81, 88, 90, 92, 94, 98], "bacteria": [34, 77], "smaller": [34, 40, 58, 62, 63, 66, 72, 88, 94], "uneasi": 34, "won": [34, 62, 72, 73, 88], "meter": [34, 60], "cm": 34, "gigant": 34, "mm": [34, 40], "huge": [34, 88, 94], "tremend": 34, "divers": 34, "eukaryot": [34, 58], "xenopu": [34, 40, 54, 58], "strongli": [34, 52, 58, 88, 94], "wouldn": [34, 94], "magnitud": [34, 36, 55, 58, 60, 73, 74, 75, 88, 90], "geometr": 34, "boundari": 34, "surprisingli": [34, 72], "bacteri": [34, 51, 77], "logarithm": [34, 36, 40, 41, 51, 53, 60, 62, 63, 66, 72, 75, 78, 81, 90], "ignor": [34, 41, 42, 49, 51, 54, 55, 58, 59, 63, 67, 90], "li": [34, 62], "width": [34, 58, 62, 72, 73, 88], "rang": [34, 36, 37, 40, 42, 46, 51, 53, 58, 59, 63, 69, 73, 74, 75, 76, 78, 81, 88, 92, 94], "ell": [34, 36, 37, 40, 42, 54, 55, 58, 59, 64, 81], "log_": [34, 40, 51, 53, 54, 55, 60, 61, 74, 75, 81], "approx": [34, 41, 48, 49, 58, 63, 66, 77, 88], "lognorm": [34, 40, 42, 58, 59, 61, 64, 66, 81, 83], "hesit": [34, 61], "theta_": [34, 46, 47, 81], "max": [34, 36, 37, 40, 42, 43, 53, 75, 76, 77, 78, 80, 88, 92, 94], "divid": [34, 37, 46, 74, 77], "conceiv": [34, 73, 78], "came": [34, 63, 83, 90], "firm": 34, "countless": 34, "pl": [36, 37, 40, 42, 51, 53, 54, 55, 57, 58, 59, 61, 64, 66, 72, 74, 75, 76, 77, 78, 80, 81], "scipi": [36, 37, 38, 40, 41, 42, 43, 51, 52, 53, 58, 74, 77, 78, 80, 88, 92, 94], "stat": [36, 37, 38, 40, 41, 42, 43, 51, 52, 53, 57, 58, 74, 76, 77, 80, 88, 92], "st": [36, 37, 38, 40, 41, 42, 43, 51, 52, 53, 58, 74, 76, 77, 80, 88, 92], "ve": [36, 92, 94], "whole": [36, 40, 62, 72, 94], "bread": 36, "butter": 36, "inaccess": 36, "viabl": 36, "mitot": [36, 58, 64], "encapsul": [36, 54], "matt": [36, 81], "refamiliar": [36, 40], "remind": [36, 37, 55, 61, 63, 69, 78, 80, 81], "good_invitro_droplet_data": [36, 37, 40, 42, 54, 55, 58, 59, 64, 81], "frame": [36, 37, 40, 42, 52, 53, 54, 55, 57, 58, 61, 64, 72, 74, 76, 81], "df": [36, 37, 40, 42, 51, 53, 54, 55, 58, 59, 61, 64, 66, 72, 74, 75, 76, 77, 78, 80, 81, 92], "read_csv": [36, 37, 40, 42, 51, 53, 54, 55, 58, 59, 61, 64, 66, 72, 74, 75, 76, 77, 78, 80, 81, 92], "join": [36, 37, 40, 42, 51, 53, 54, 55, 58, 59, 61, 64, 66, 72, 74, 75, 76, 77, 78, 80, 81, 83, 91, 92, 94], "comment_prefix": [36, 37, 40, 42, 51, 53, 54, 55, 58, 59, 61, 64, 66, 74, 77, 81], "um": [36, 37, 40, 42, 54, 55, 58, 59, 64, 81], "to_numpi": [36, 37, 40, 42, 51, 53, 54, 55, 57, 58, 59, 61, 64, 66, 74, 75, 76, 77, 78, 80, 81], "300": [36, 37, 38, 40, 42, 43, 52, 54, 55, 58, 74, 81, 88, 94], "x_rang": [36, 37, 38, 40, 41, 42, 43, 51, 54, 55, 58, 59, 62, 64, 74, 75, 81], "y_rang": [36, 37, 40, 41, 42, 43, 54, 55, 58, 74, 81, 88], "to_dict": [36, 37, 40, 42, 54, 55, 58, 74, 75, 76, 78, 81], "object": [36, 38, 40, 52, 53, 61, 66, 76, 81, 83, 88, 90, 92], "treat": [36, 58, 75], "jeffrei": [36, 37, 40, 54], "l_i": [36, 37, 40, 42, 54, 55, 58, 59, 64, 81], "implicit": [36, 63], "somedistribut": 36, "vanilla": 36, "tubulin": [36, 40, 54, 55, 64], "conserv": [36, 40, 54, 55, 58, 64, 66, 88, 90], "proport": [36, 46, 49, 51, 63, 94], "evalu": [36, 37, 38, 41, 42, 75, 76, 77, 78, 81, 88, 90, 94], "handi": [36, 55], "progress": [36, 52, 75], "postpon": 36, "secondli": [36, 92], "hit": [36, 61, 72, 76, 88], "underflow": [36, 37, 40, 53, 94], "circumst": 36, "insid": [36, 90, 94], "behav": [36, 41, 53, 67, 75, 88, 94], "risk": 36, "logsumexp": 36, "log_marginalized_posterior": [36, 37], "inf": [36, 40, 42, 51, 66, 76, 77], "len": [36, 37, 40, 51, 53, 54, 55, 58, 59, 61, 64, 66, 69, 74, 75, 76, 77, 78, 80, 81, 88, 92, 94], "grung": [36, 75], "linspac": [36, 37, 38, 40, 41, 42, 43, 58, 59, 62, 64, 74, 75, 76, 77, 78, 80, 81, 88], "log_marg_post": 36, "phi_val": [36, 37], "\u03c6": [36, 37, 40, 42, 55, 81], "l\u1d62": [36, 37], "line_width": [36, 37, 38, 40, 41, 42, 43, 51, 53, 57, 58, 61, 62, 74, 75, 76, 77, 78, 88], "awai": [36, 40, 41, 42, 58, 60, 62, 66, 73, 74, 75, 76, 88, 90], "subtract": [36, 63, 94], "marg": 36, "log_marg_post_max": 36, "marg_post": 36, "visual": [36, 37, 40, 41, 51, 53, 54, 57, 58, 74, 75, 90], "axi": [36, 42, 46, 51, 55, 58, 60, 73, 74, 94], "g_": 36, "proportion": [36, 58], "clever": [36, 46, 81], "momentarili": [36, 61, 72, 75], "quad": [36, 37], "marginalized_posterior": [36, 37], "integrand": [36, 37], "resolv": [36, 58], "domain": [36, 54, 60, 76], "kwarg": [36, 40, 51, 52, 53, 55, 58, 59, 66, 78, 80, 81], "err": 36, "46386461926837497": 36, "981239131261995e": 36, "review": [36, 81, 82, 88], "unorm": 36, "found": [36, 40, 41, 42, 49, 71, 75, 80, 81, 92, 94], "straightforwardli": 36, "grungi": 36, "bar": [36, 52, 53, 71, 75], "hat": [36, 48, 62, 63, 90], "nu": [36, 60, 75, 77], "std": [36, 57, 75, 76, 77, 78, 80], "exact_pdf": 36, "color": [36, 38, 41, 42, 43, 51, 53, 55, 57, 62, 69, 72, 74, 75, 76, 77, 78, 80, 88, 94], "line_dash": 36, "dash": 36, "perfect": [36, 88], "efficaci": 36, "tough": 36, "contour": [36, 37, 40, 42, 62, 90], "clean": [36, 90], "log_prior_indep_s": 36, "param": [36, 37, 40, 42, 51, 53, 55, 58, 75, 76, 77, 80], "log_likelihood_indep_s": 36, "logpdf": [36, 40, 42, 76, 77], "loc": [36, 40, 41, 42, 43, 53, 58, 74, 76, 77], "log_posterior_indep_s": 36, "lp": [36, 40, 42, 52, 53, 76, 77, 94], "prevent": [36, 58, 92], "bug": [36, 61, 83, 92], "trade": 36, "overhead": 36, "log_likelihood_indep_size_numpy_onli": 36, "timeit": 36, "ntime": 36, "136": 36, "452": 36, "loop": [36, 53, 58, 92], "000": [36, 42, 61, 74, 81, 92], "nearli": [36, 58, 72, 83, 88, 94], "slow": [36, 40, 75, 77], "increasingli": 36, "nonneglig": 36, "shrink": [36, 69], "rapidli": [36, 38, 75, 90], "dimens": [36, 41, 51, 52, 53, 59, 61, 66, 88, 90], "log_post": [36, 37, 42], "enumer": [36, 37], "sigma_v": 36, "overflow": [36, 37, 61], "packag": [36, 52, 55, 63, 66, 76, 77, 80, 83, 92, 97], "overlaid": [36, 37, 42, 62, 63], "\u03c3": [36, 40, 42, 54, 55, 58, 76, 77, 80, 81], "harder": [36, 42, 52, 61], "zoom": [36, 37, 72, 77, 94], "31": [36, 43, 53, 57, 61, 62, 64, 81, 94, 98], "spindl": [37, 40, 42, 54, 55, 59, 64], "d_i": [37, 42, 54, 55, 58, 59, 64, 81], "trivari": 37, "tri": [37, 58], "theor_spindle_length": 37, "cbrt": [37, 42, 54, 55, 58, 59, 64, 81], "eyebal": 37, "somewher": [37, 40, 58], "37": [37, 42, 53, 64, 72, 81, 94], "asymptot": [37, 58, 63, 81], "slope": 37, "gamma_v": 37, "\u03d5": [37, 40, 42, 54, 55, 58, 69], "\u03b3": [37, 42, 54, 55, 58, 81], "log_post_max": 37, "calc": 37, "varphi": 37, "infin": [37, 75, 88], "unnormalized_marg_post_phi": 37, "empty_lik": [37, 42], "d\u1d62": 37, "trapezoid": 37, "trapz": [37, 42, 94], "normalization_const": 37, "wrinkl": 37, "lambda": [37, 62, 75, 78, 88], "swap": 37, "unnormalized_marg_post_gamma": 37, "norm_const": 37, "valuabl": [37, 60, 97], "rear": 37, "doom": 37, "spend": [37, 83, 92], "sophist": [37, 66], "seem": [38, 47, 51, 58, 64, 72, 73, 74, 75, 81, 90, 92, 94], "mossman": 38, "2019": 38, "author": [38, 51, 92, 97], "ag": 38, "parent": 38, "viabil": 38, "offspr": 38, "vial": 38, "mate": 38, "young": 38, "dai": [38, 47, 72, 81, 83, 92, 98], "male": 38, "femal": 38, "176": [38, 81], "period": [38, 46, 75], "94": [38, 55, 78], "remaind": 38, "fail": [38, 59, 66, 73, 74, 92], "154": 38, "failur": 38, "binom": [38, 66, 67, 69, 88], "seek": [38, 41, 51, 63, 66], "Its": 38, "mother": 38, "n_old": 38, "n_young": 38, "instanti": [38, 57, 58, 92], "\u03b8": [38, 62, 69, 72, 88], "legend_label": [38, 41, 57, 62, 69, 72, 75, 81, 88, 94], "legend": [38, 57, 62, 69, 72, 88, 94], "top_left": [38, 88], "disavantag": 38, "tractabl": [38, 41, 54], "paltri": 38, "hopeless": 38, "coin": 38, "slightli": [38, 76], "bias": [38, 90], "bimod": [38, 51, 53, 57, 66], "sivia": 38, "bear": [38, 46, 57, 61], "conduct": [38, 74, 91, 92], "statsmodel": [40, 42], "numdiff": [40, 42], "smnd": [40, 42], "tqdm": [40, 42], "342": [40, 42, 54, 55, 58, 64], "856": [40, 42, 54, 55, 58, 61, 64], "860": [40, 42, 54, 55, 58, 64], "2013": [40, 42, 54, 55, 58, 64], "abandon": 40, "bet": [40, 51, 54, 60], "farm": [40, 51, 54, 60], "breviti": 40, "logspac": 40, "1e": [40, 58, 75, 76, 77, 78, 80], "1e5": 40, "x_axis_typ": [40, 74], "half": [40, 54, 58, 60, 67, 72, 76, 91], "halfnorm": [40, 42, 54, 55, 58, 67, 69, 72, 75, 76, 77, 78, 80, 81, 94], "albeit": 40, "themselv": [40, 52, 61], "y_3": 40, "sum_j": [40, 63], "fortun": [40, 42, 48, 53, 63, 66, 80, 94], "log_prior": [40, 42, 76, 77], "log_likelihood": [40, 42, 64, 66, 76, 77, 94], "log_posterior": [40, 42, 76, 77], "indpend": [40, 42], "powel": [40, 42, 76, 77], "reli": [40, 57, 90, 94], "discontinu": 40, "hurt": 40, "particularli": [40, 55, 61, 81, 90, 92], "constrain": [40, 53, 81, 90], "bfg": 40, "cobyla": 40, "neg_log_posterior": [40, 42, 76, 77], "routin": 40, "converg": [40, 61, 81], "params_0": [40, 42, 76, 77], "minimz": 40, "optimzi": 40, "attribut": [40, 51, 52, 53, 61, 66], "extra": [40, 75, 77, 81, 83, 88], "popt": [40, 42], "phi_map": [40, 42], "sigma_map": [40, 42], "2f": [40, 42], "3f": [40, 42, 58, 69], "32": [40, 53, 66, 72, 81, 92, 94], "86": [40, 61, 66], "784": 40, "successfulli": 40, "invert": [40, 42, 75], "element": [40, 41, 53, 54, 72, 90], "approx_hess": [40, 42], "shove": 40, "41668904e": 40, "02": [40, 52, 53, 74, 98], "09388085e": 40, "06": [40, 53, 72, 81, 98], "70799615e": 40, "multipli": [40, 63, 75, 76, 77, 94], "96": [40, 41, 42, 57, 72, 74, 75, 76, 77, 81], "256": 40, "multivariate_norm": [40, 42, 75, 76, 77], "neighborhood": [40, 90], "post_norm": [40, 42], "empti": [40, 92], "log_post_exact": 40, "00": [40, 42, 51, 52, 53, 66, 74, 92, 98], "lt": [40, 42, 51, 52, 53, 61, 66, 74, 94], "50it": 40, "post_exact": [40, 42], "line_kwarg": [40, 41, 42, 57, 58, 61, 62, 69, 81], "dict": [40, 41, 42, 51, 53, 54, 55, 58, 61, 62, 64, 69, 72, 74, 75, 76, 77, 78, 80, 81, 92, 94], "line_color": [40, 42, 43, 57, 69, 77, 78, 80, 81], "danger": [40, 42], "66": [40, 42, 57], "catch_warn": 41, "simplefilt": 41, "abbrevi": [41, 52], "paramount": 41, "dwell": 41, "seldom": [41, 57, 83], "Near": 41, "taylor": 41, "truncat": [41, 55, 58], "b_": 41, "y_gamma": 41, "y_norm": 41, "tomato": [41, 75, 76], "percent": [41, 46], "confid": [41, 52, 73, 74], "erron": 41, "025": [41, 81], "975": 41, "benefit": [41, 73, 75, 81, 92], "afford": [41, 75], "ii": 41, "pm": [41, 57, 58, 83, 98], "asymmetr": [41, 57], "extrem": [41, 58, 60, 61, 66, 71, 72, 75, 76, 90], "flaw": [41, 48], "median": [41, 49, 57, 58, 59, 69, 81], "34": [41, 51, 53, 61, 69, 72, 81, 94], "ppf": [41, 43, 88], "99": [41, 51, 58, 59, 62, 64, 69, 72, 74, 75, 78, 81], "perc_cred_int": 41, "gamma_low": 41, "gamma_high": 41, "norm_low": 41, "norm_high": 41, "fill_between": [41, 75, 76, 77], "patch_kwarg": [41, 75, 76, 77], "shift": [41, 94], "rightward": 41, "notabl": [41, 61, 69, 94], "miss": [41, 60, 61, 64, 73, 74, 88, 90], "despit": [41, 80, 90], "character": [41, 53, 58, 60, 74, 90], "throughput": [41, 91], "attract": 41, "pathologi": [41, 62, 66, 90], "breakdown": [41, 52, 75, 83], "p_data": [42, 55], "relationship": [42, 63, 72], "toward": [42, 60, 69, 72, 73, 75, 81, 90, 94], "embark": 42, "solver": [42, 75, 90], "differenti": [42, 51, 53, 75, 77, 80], "theoretical_spindle_length": 42, "And": [42, 51, 58, 59, 61, 64, 66, 73, 74, 88], "gamma_map": 42, "38": [42, 46, 62, 74, 81, 94], "77": [42, 53, 66], "859": 42, "034": 42, "754": 42, "201": [42, 69], "grid": [42, 53, 57], "sigma_0": [42, 58, 59, 64, 81], "million": [42, 88], "brute": [42, 54, 58, 94], "forc": [42, 54, 58, 88, 94], "style": [42, 52, 69, 88], "tight": [42, 59], "sea": 42, "needl": [42, 62], "haystack": 42, "meshgrid": [42, 62, 88], "51": [42, 52, 72, 81], "post_margin": 42, "narrow": [42, 62, 73], "cut": 42, "instantan": 42, "dstack": 42, "discourag": 42, "d_theor": 42, "ell_theor": [42, 54, 55, 58, 59, 64, 81], "linear": [42, 53, 58, 60, 75, 76, 77, 80], "regim": [42, 58], "caught": [42, 74], "dynam": [42, 51, 90], "blackcellmag": 43, "rng": [43, 52, 57, 58, 76, 78, 94], "default_rng": [43, 52, 57, 58, 75, 76, 78, 94], "seed": [43, 53, 57, 61, 62, 66, 72, 81, 94], "12341234": 43, "udraw": 43, "04": [43, 52, 74, 98], "xgrid": 43, "grid_line_color": 43, "ygrid": 43, "x_val": 43, "y_val": [43, 57], "grai": [43, 57, 88], "zeros_lik": [43, 75, 76, 77], "black": [43, 69, 78, 94], "circl": [43, 55, 88, 90, 94], "fill_color": [43, 77, 78, 80], "level": [43, 51, 53, 63, 68, 72, 75, 81, 88, 90], "educ": 44, "vignett": 44, "michael": [44, 53, 59, 61, 73, 88, 97], "hmc": [44, 47, 52, 72, 94], "hamiltonian": [44, 47, 61, 94], "transit": [45, 46, 48, 49, 81], "kernel": [45, 46, 48, 49, 55, 76, 78, 80, 88], "capabl": [46, 51, 66, 91, 92], "pcg64": 46, "128": [46, 66], "nonuniform": 46, "muller": 46, "quantil": [46, 49, 57, 61], "mark": [46, 94], "vertic": [46, 72, 75], "horizont": [46, 75], "correct": [46, 63, 83, 88], "simplic": [46, 75, 92], "walk": [46, 48, 60, 90], "bold": [46, 59], "sentenc": [46, 61], "achiev": [46, 47, 48, 61, 74, 88], "condit": [46, 47, 53, 58, 63, 68, 71, 72, 73, 75, 78, 81, 88, 90, 92], "stationari": [46, 48, 77], "uniqu": [46, 53, 75, 81], "ergod": [46, 47, 90], "aperiod": 46, "2k": 46, "3k": 46, "irreduc": 46, "recurr": [46, 90], "revisit": 46, "checklist": 46, "moment": [46, 48, 51, 58, 63, 72, 75, 88, 90, 94], "preced": [46, 53, 54, 60, 88], "margossian": 46, "randomli": 47, "ratio": [47, 61, 77, 90, 94], "ge": 47, "nut": [47, 88], "earth": 47, "bracket": 47, "art": [47, 51, 59, 61], "origin": [47, 52, 62, 67, 72, 73, 74, 75, 88], "1953": 47, "thumb": [47, 48, 61, 73], "wander": [47, 60], "reject": [47, 62, 90], "gibb": 47, "modern": 47, "popular": [47, 52, 94], "special": [47, 53, 60, 72, 73, 75, 77, 88, 90, 92, 94], "subclass": 47, "overemphas": 47, "naiv": 47, "anyhow": 47, "devis": [48, 62, 91], "theta_0": 48, "travers": 48, "incredibli": [48, 75, 88, 90], "began": 48, "weight": [48, 51, 64, 77], "reach": [48, 61, 77], "heurist": 48, "coauthor": 48, "rubin": 48, "metric": [48, 61, 73, 88, 90], "stationar": [48, 61], "famou": 48, "defer": [48, 54], "vehtari": [48, 61, 63, 66], "stringent": 48, "01": [48, 52, 57, 61, 62, 66, 72, 75, 81, 90, 92, 94, 98], "regular": [48, 94], "neglect": [48, 60, 81], "bunch": [48, 94], "strategi": [48, 53, 62, 73, 90, 94], "h": [49, 63, 88, 90], "averag": [49, 63, 66, 73, 88, 90, 91, 94], "th": [49, 58, 63], "abundantli": 49, "abil": [49, 61, 63, 73, 75, 92, 94], "superscript": [49, 72], "parenthet": 49, "hello": 50, "drew": 51, "reconstruct": 51, "miracul": 51, "elowitz": [51, 74, 91, 92], "singer": [51, 61, 66], "heterogen": 51, "methyl": 51, "embryon": 51, "stem": 51, "molec": 51, "331": 51, "2014": 51, "paragraph": [51, 83], "eda": 51, "situ": 51, "hybrid": 51, "focus": [51, 92], "pluripot": 51, "associ": [51, 52, 53, 60, 74, 90, 98], "regul": [51, 71], "hallmark": 51, "tempor": 51, "laps": [51, 91, 94], "movi": 51, "insight": [51, 90], "279": [51, 66, 94], "rex1": [51, 53, 66], "nanog": 51, "prdm14": 51, "singer_transcript_count": [51, 53, 61, 66, 74, 92], "q": [51, 55, 61, 63, 72, 74, 78, 88, 92, 94], "layout": [51, 55, 57, 58, 81, 88, 94], "fewer": [51, 58, 62, 94], "copi": [51, 66, 74, 78, 80, 92], "presenc": 51, "inflect": [51, 60], "edcf": 51, "impli": [51, 58, 72], "n_i": [51, 53, 61, 66, 67, 69, 71, 74, 75, 78, 92], "higher": [51, 53, 63, 88, 90, 91, 92], "frequent": 51, "assembl": 51, "shorter": [51, 92], "lifetim": [51, 74], "promot": [51, 74, 77], "strength": [51, 74, 88], "thousand": [51, 73, 74, 92], "syntax": [51, 52, 53, 55, 58, 80, 97], "log10_alpha": [51, 53, 61, 66, 74], "log10_b": [51, 53, 61, 66, 74], "beta_": [51, 53, 61, 66, 69, 74, 92, 94], "neg_binomi": [51, 61, 66, 74, 92], "rais": 51, "block": [51, 52, 54, 58, 59, 60, 75, 76, 77, 78, 80, 90, 92, 94], "declar": [51, 52, 53, 54], "dictionari": [51, 53, 64, 66, 72, 75, 76, 77, 80], "iter_sampl": [51, 52, 53, 54, 55, 58, 59, 61, 69, 74, 75, 92, 94], "inferencedata": [51, 52, 53, 58, 61, 66], "info": [51, 52, 92], "fatal": 51, "neg_binomial_lpmf": [51, 66, 92], "show_consol": 51, "unclear": 51, "fed": 51, "aris": [51, 53, 92, 94], "silenc": 51, "throw": [51, 73], "pedagog": [51, 97], "disabl": 51, "xarrai": [51, 52, 53, 59, 61, 66], "dataset": [51, 52, 53, 59, 61, 66, 92, 94], "gt": [51, 52, 53, 61, 66, 92, 94], "168kb": 51, "int64": [51, 52, 53, 61, 66], "32b": [51, 52, 53, 61, 66], "8kb": [51, 52, 53, 61, 66], "993": [51, 52, 53, 61, 66], "994": [51, 52, 53, 61, 66], "995": [51, 52, 53, 61, 66], "996": [51, 52, 53, 61, 66], "997": [51, 52, 53, 61, 66], "998": [51, 52, 53, 61, 66], "999": [51, 52, 53, 58, 61, 66], "float64": [51, 52, 53, 61, 66], "32kb": [51, 52, 53, 61], "722": [51, 61], "814": 51, "808": 51, "155": 51, "271": [51, 61, 66], "48": 51, "64": [51, 53], "07": [51, 52, 53, 66, 72, 81, 98], "05002": 51, "04916": 51, "0567": 51, "05535": 51, "5707": 51, "5814": 51, "6186": 51, "6305": 51, "301": [51, 81], "308": [51, 94], "246": 51, "257": 51, "created_at": [51, 52, 53, 66], "19t23": [51, 52], "29": [51, 53, 61, 74, 81, 94, 98], "089569": 51, "arviz_vers": [51, 52, 53, 66], "inference_librari": [51, 52, 53, 66], "inference_library_vers": [51, 52, 53, 66], "4xarrai": [51, 52, 53, 66], "datasetdimens": [51, 52, 53, 61, 66], "4draw": [51, 52, 53, 61, 66], "1000coordin": [51, 52, 53], "int640": [51, 52, 53, 61, 66], "3arrai": [51, 52, 53, 61, 66], "999arrai": [51, 52, 53, 61, 66], "float643": 51, "271arrai": 51, "72176": 51, "81412": 51, "8077": 51, "02461": 51, "95251": 51, "49689": 51, "82657": 51, "61593": 51, "68701": 51, "36608": 51, "37078": 51, "37826": 51, "87778": 51, "33051": 51, "30581": 51, "38294": 51, "52823": 51, "08891": 51, "80512": 51, "22812": 51, "36809": 51, "38976": 51, "15537": 51, "27078": 51, "float6419": 51, "07arrai": 51, "9922": 51, "3422": 51, "4787": 51, "5616": 51, "3612": 51, "3301": 51, "2128": 51, "9165": 51, "9441": 51, "5362": 51, "5644": 51, "7573": 51, "2453": 51, "2903": 51, "8039": 51, "0338": 51, "6761": 51, "7705": 51, "1302": 51, "1052": 51, "1311": 51, "5695": 51, "6351": 51, "0655": 51, "float640": [51, 52, 53], "05535arrai": 51, "0500194": 51, "049159": 51, "0488312": 51, "0686739": 51, "0650993": 51, "0612367": 51, "0616795": 51, "0591138": 51, "0590177": 51, "0570248": 51, "0569334": 51, "0563149": 51, "065594": 51, "0578358": 51, "05951": 51, "0587069": 51, "059966": 51, "0532751": 51, "0619955": 51, "0584618": 51, "0551539": 51, "0569168": 51, "056705": 51, "0553542": 51, "6305arrai": 51, "570748": 51, "581394": 51, "580663": 51, "701103": 51, "694826": 51, "652913": 51, "683638": 51, "664259": 51, "670896": 51, "640091": 51, "640559": 51, "641301": 51, "688222": 51, "636539": 51, "634055": 51, "641766": 51, "655928": 51, "611608": 51, "681705": 51, "626147": 51, "640292": 51, "642441": 51, "61861": 51, "630507": 51, "float641": [51, 52, 53, 61], "257arrai": 51, "30086": 51, "3084": 51, "3113": 51, "16321": 51, "18642": 51, "21299": 51, "20986": 51, "22831": 51, "22902": 51, "24394": 51, "24463": 51, "24938": 51, "18314": 51, "2378": 51, "22541": 51, "23131": 51, "2221": 51, "27348": 51, "20764": 51, "23313": 51, "25842": 51, "24476": 51, "24638": 51, "25685": 51, "chainpandasindexpandasindex": [51, 52, 53, 61, 66], "dtype": [51, 52, 53, 61, 66], "x27": [51, 52, 53, 61, 66], "drawpandasindexpandasindex": [51, 52, 53, 61, 66], "990": [51, 52, 53, 61, 66], "991": [51, 52, 53, 61, 66], "992": [51, 52, 53, 61, 66], "00arviz_vers": [51, 52, 53, 66], "0inference_librari": [51, 52, 53, 66], "cmdstanpyinference_library_vers": [51, 52, 53, 66], "puls": 51, "plot_scatt": 51, "\u03b1": [51, 58, 69, 74, 75, 76, 77], "bin": [51, 55, 57, 92], "rug": [51, 55, 57], "foolishli": 51, "grab": [51, 77], "arang": [51, 53, 57, 78, 88], "251": [51, 81], "flatten": [51, 52, 53, 57, 62, 69, 72, 75, 76, 81, 94], "zip": [51, 53, 57, 58, 74, 78, 83, 88], "nbinom": [51, 53], "x_plot": [51, 53], "y_plot": [51, 53], "cdf_to_staircas": [51, 53], "underlai": [51, 53], "425": 51, "426": 51, "amazon": [52, 92], "julia": 52, "matlab": [52, 92], "stata": 52, "across": [52, 66, 92, 94], "dive": 52, "disk": 52, "seven": [52, 61], "intend": 52, "ventur": 52, "friend": [52, 94], "guid": [52, 97], "manual": [52, 53, 61, 94], "static": [52, 54], "semicolon": 52, "curli": 52, "prepar": [52, 72, 88, 90, 92, 94, 98], "favorit": [52, 57], "editor": [52, 92], "groundwork": 52, "hello_world": 52, "bebi103_cours": 52, "2025": 52, "08": [52, 72, 74, 81, 98], "ex": 52, "43": [52, 53], "iter": [52, 53, 55, 61, 62, 64, 66, 69, 72, 73, 74, 75, 77, 78, 80, 81, 88, 90, 92, 94], "44": [52, 53, 74, 81], "job": [52, 78, 88, 92], "cmdstanmcmc": 52, "num_sampl": 52, "engag": [52, 81], "csv_file": 52, "var": [52, 74, 81, 88, 90], "j_": [52, 81], "c5r9ch0913v3h1w4bdwzm0lh0000gn": [52, 81], "tmpvzktutt3": 52, "hello_worldg4sdgzab": 52, "20240719161944_1": 52, "20240719161944_2": 52, "20240719161944_3": 52, "20240719161944_4": 52, "output_fil": 52, "20240719161944_0": 52, "pronounc": 52, "rv": 52, "recreat": 52, "vehicl": 52, "40kb": 52, "6374": 52, "5841": 52, "5403": 52, "6269": 52, "542659": 52, "6269arrai": 52, "637411": 52, "58407": 52, "302226": 52, "474132": 52, "962219": 52, "03972": 52, "75933": 52, "254514": 52, "365888": 52, "96866": 52, "20111": 52, "82037": 52, "477287": 52, "556766": 52, "32425": 52, "55547": 52, "494835": 52, "364278": 52, "015963": 52, "141604": 52, "35541": 52, "39819": 52, "540314": 52, "626918": 52, "sample_stat": [52, 53, 61], "204kb": [52, 53], "acceptance_r": [52, 53], "9468": 52, "8258": 52, "9861": 52, "9895": 52, "4kb": [52, 53, 61], "energi": [52, 53, 61, 75, 81], "5121": 52, "564": [52, 61], "1502": 52, "215": 52, "2031": 52, "1706": 52, "1965": 52, "step_siz": [52, 53], "015": 52, "tree_depth": [52, 53, 61], "549548": 52, "9895arrai": 52, "946755": 52, "82582": 52, "998086": 52, "91481": 52, "689701": 52, "794211": 52, "991144": 52, "725178": 52, "979043": 52, "928644": 52, "989108": 52, "945146": 52, "757333": 52, "998694": 52, "864913": 52, "978766": 52, "99792": 52, "791233": 52, "982238": 52, "986148": 52, "989484": 52, "boolfals": [52, 53], "falsearrai": [52, 53, 61], "139": [52, 72], "215arrai": 52, "512115": 52, "56356": 52, "138952": 52, "137244": 52, "462933": 52, "42688": 52, "55296": 52, "33155": 52, "0698188": 52, "39816": 52, "793701": 52, "70602": 52, "858483": 52, "6095": 52, "70213": 52, "43293": 52, "44248": 52, "113932": 52, "07941": 52, "0126613": 52, "4355": 52, "107657": 52, "150176": 52, "214951": 52, "146": 52, "1965arrai": 52, "03146e": 52, "70569e": 52, "56703e": 52, "12401e": 52, "62933e": 52, "40512e": 52, "54763e": 52, "23887e": 52, "69369e": 52, "69151e": 52, "21337e": 52, "65687e": 52, "13902e": 52, "54994e": 52, "70108e": 52, "20974e": 52, "22431e": 52, "63494e": 52, "27409e": 52, "00259e": 52, "18573e": 52, "92776e": 52, "45970e": 52, "96513e": 52, "int643": 52, "1arrai": [52, 53, 61], "0arrai": 52, "01508": 52, "07811": 52, "841159": 52, "00025": 52, "int641": 52, "group": [52, 53, 63, 72, 92], "dataarrai": [52, 53, 59, 61], "panda": [52, 53, 61, 76, 81, 92, 94], "interestingli": [52, 55], "arbitrarili": 52, "multidimension": [52, 55, 66, 75, 77], "999xarrai": [52, 61], "3022": 52, "2444": 52, "01371": 52, "3982": 52, "togeth": [52, 67, 69, 71, 72, 75, 76, 90, 91, 92, 94], "np_sampl": 52, "sp_sampl": 52, "staircas": [52, 69], "palett": [52, 57, 69, 88], "b_glasbey_category10": 52, "normal_rng": [52, 58, 59, 64, 74, 75, 77, 78, 80, 81], "sm_rng": 52, "norm_rng": 52, "mote": 52, "fixed_param": [52, 58, 74, 75, 92, 94], "stan_sampl": 52, "novel": 52, "occasion": [52, 58], "visibl": [52, 57, 69], "netcdf": 52, "to_netcdf": 52, "stan_hello_world": 52, "nc": 52, "from_netcdf": 52, "hpp": 52, "exit": 52, "delet": [52, 78], "outpur_dir": 52, "unimod": 53, "alpha_1": 53, "alpha_2": 53, "beta_1": 53, "beta_2": 53, "burst": [53, 60, 61, 74], "concis": 53, "retain": [53, 60, 81], "alpha_i": [53, 94], "b_i": 53, "beta_i": 53, "hood": [53, 90, 92], "summand": [53, 63], "a_1": [53, 78], "a_2": 53, "a_i": 53, "stabl": [53, 63, 75, 76, 80, 90], "log_mix": [53, 66], "keyword": [53, 80], "n_val": [53, 66], "neg_binomial_lupmf": 53, "negative_binomial_lpmf": 53, "_lpmf": [53, 66], "_lpdf": [53, 66], "_lupmf": 53, "_lupdf": 53, "signifi": 53, "wise": [53, 76, 92], "vvector": 53, "log10_beta": 53, "front": [53, 90, 92], "slash": 53, "elementwis": 53, "smart": 53, "enclos": [53, 58], "inclus": [53, 75], "3252": [53, 57, 61, 62, 66, 72, 81], "360kb": 53, "alpha_dim_0": [53, 66], "b_dim_0": [53, 66], "beta__dim_0": 53, "log10_alpha_dim_0": 53, "log10_b_dim_0": 53, "16b": 53, "64kb": 53, "867": 53, "379": 53, "235": 53, "691": 53, "191": [53, 81], "2132": 53, "4575": 53, "7189": 53, "159": 53, "8032": 53, "8652": 53, "20t01": 53, "493203": 53, "1000alpha_dim_0": 53, "2b_dim_0": 53, "2beta__dim_0": 53, "2log10_alpha_dim_0": 53, "2log10_b_dim_0": 53, "2coordin": 53, "float642": 53, "773": 53, "745": 53, "842": 53, "379arrai": 53, "86735": 53, "77317": 53, "74531": 53, "08933": 53, "06105": 53, "65147": 53, "56703": 53, "75107": 53, "16542": 53, "79654": 53, "77347": 53, "10867": 53, "63497": 53, "5682": 53, "16957": 53, "98005": 53, "53614": 53, "5058": 53, "88295": 53, "46085": 53, "9517": 53, "19794": 53, "67976": 53, "08075": 53, "55802": 53, "94599": 53, "01463": 53, "48093": 53, "25886": 53, "19726": 53, "78945": 53, "78982": 53, "45851": 53, "7594": 53, "09546": 53, "03334": 53, "60415": 53, "37894": 53, "04128": 53, "18814": 53, "3936": 53, "73299": 53, "86744": 53, "82427": 53, "84191": 53, "37865": 53, "float645": 53, "406": 53, "691arrai": 53, "2351": 53, "3362": 53, "40603": 53, "9016": 53, "64434": 53, "5218": 53, "6283": 53, "2829": 53, "59981": 53, "1368": 53, "85139": 53, "3799": 53, "4836": 53, "88547": 53, "2705": 53, "66373": 53, "2696": 53, "29264": 53, "7265": 53, "78734": 53, "3232": 53, "54503": 53, "02042": 53, "726": 53, "6697": 53, "1807": 53, "61744": 53, "0982": 53, "98924": 53, "8056": 53, "25143": 53, "1896": 53, "27248": 53, "2288": 53, "2259": 53, "96834": 53, "481": 53, "33478": 53, "0416": 53, "76565": 53, "2165": 53, "88078": 53, "172": [53, 81], "65381": 53, "3025": 53, "69076": 53, "02912": 53, "02915": 53, "2132arrai": 53, "191018": 53, "0291238": 53, "184979": 53, "0303937": 53, "274398": 53, "0289672": 53, "150868": 53, "0341496": 53, "277793": 53, "0292939": 53, "350706": 53, "0308834": 53, "028182": 53, "101159": 53, "0366697": 53, "176562": 53, "0341652": 53, "188942": 53, "0296503": 53, "208884": 53, "0309375": 53, "132538": 53, "24873": 53, "0315199": 53, "0731546": 53, "0354853": 53, "276439": 53, "0355895": 53, "334533": 53, "0271698": 53, "444163": 53, "0292486": 53, "440048": 53, "0276023": 53, "030097": 53, "201274": 53, "0339201": 53, "157859": 53, "0302649": 53, "173441": 53, "0342272": 53, "25768": 53, "0301459": 53, "176872": 53, "0291524": 53, "213185": 53, "6788": 53, "685": 53, "5287arrai": 53, "457481": 53, "678807": 53, "438592": 53, "706661": 53, "608639": 53, "66759": 53, "409431": 53, "759749": 53, "619659": 53, "680928": 53, "761437": 53, "708308": 53, "666047": 53, "1954": 53, "790255": 53, "474224": 53, "743207": 53, "398946": 53, "688683": 53, "539182": 53, "694754": 53, "342016": 53, "565819": 53, "705928": 53, "192574": 53, "774224": 53, "603645": 53, "738854": 53, "629294": 53, "622966": 53, "762637": 53, "680319": 53, "737074": 53, "677552": 53, "707183": 53, "481921": 53, "74851": 53, "376383": 53, "70254": 53, "503538": 53, "731878": 53, "572057": 53, "687301": 53, "450906": 53, "685017": 53, "528744": 53, "536": 53, "535": 53, "6712arrai": 53, "718925": 53, "53575": 53, "732878": 53, "51722": 53, "561619": 53, "53809": 53, "821402": 53, "46661": 53, "556279": 53, "53322": 53, "455057": 53, "51028": 53, "55003": 53, "994998": 53, "43569": 53, "753102": 53, "46642": 53, "723672": 53, "52797": 53, "680094": 53, "50951": 53, "877661": 53, "604271": 53, "50141": 53, "13576": 53, "44995": 53, "558401": 53, "44868": 53, "475561": 53, "56591": 53, "352458": 53, "53389": 53, "3565": 53, "55905": 53, "52148": 53, "696211": 53, "46954": 53, "801731": 53, "51906": 53, "760848": 53, "46563": 53, "58892": 53, "52077": 53, "752341": 53, "53533": 53, "671243": 53, "8652arrai": 53, "179038": 53, "159009": 53, "133145": 53, "194928": 53, "146822": 53, "152438": 53, "806095": 53, "846002": 53, "835965": 53, "872181": 53, "858328": 53, "136364": 53, "213688": 53, "164984": 53, "133647": 53, "125085": 53, "12076": 53, "793301": 53, "801544": 53, "807659": 53, "822806": 53, "803243": 53, "865222": 53, "alpha_dim_0pandasindexpandasindex": 53, "b_dim_0pandasindexpandasindex": 53, "beta__dim_0pandasindexpandasindex": 53, "log10_alpha_dim_0pandasindexpandasindex": 53, "log10_b_dim_0pandasindexpandasindex": 53, "9871": 53, "9415": 53, "9976": 53, "9587": 53, "597e": 53, "03": [53, 61, 66, 81, 98], "598e": 53, "595e": 53, "1227": 53, "1186": 53, "501268": 53, "9587arrai": 53, "987143": 53, "941549": 53, "977411": 53, "99892": 53, "976145": 53, "732715": 53, "910988": 53, "992787": 53, "951251": 53, "9523": 53, "919331": 53, "63308": 53, "997946": 53, "999491": 53, "932981": 53, "886662": 53, "992565": 53, "839946": 53, "972186": 53, "989851": 53, "943136": 53, "999211": 53, "997595": 53, "958723": 53, "03arrai": [53, 61], "1596": 53, "84": [53, 78], "1597": 53, "82": 53, "1599": 53, "1600": [53, 81], "58": [53, 61, 72, 81, 94], "1598": 53, "47": [53, 72, 74], "1601": 53, "73": [53, 72, 81], "87": [53, 61], "53": [53, 61, 72, 78, 81], "69": [53, 61, 72, 81], "1602": 53, "68": [53, 58, 61, 72, 81], "1595": 53, "59": 53, "78": [53, 61, 66], "65": [53, 72, 81], "int6423": 53, "31arrai": 53, "63": [53, 72, 81], "1186arrai": 53, "122749": 53, "119707": 53, "102969": 53, "11862": 53, "int644": 53, "5arrai": 53, "futur": [53, 55, 61, 62], "doc": 53, "478": 53, "184b": 53, "8b": [53, 61], "642": 53, "802": [53, 81], "2082": 53, "02532": 53, "422": 53, "6277": 53, "6815": 53, "597": 53, "1674": 53, "int642arrai": 53, "int64478arrai": 53, "243arrai": 53, "64227": 53, "24292": 53, "float644": 53, "80233": 53, "4987": 53, "02532arrai": 53, "208232": 53, "0253173": 53, "6277arrai": 53, "421977": 53, "627665": 53, "597arrai": 53, "681452": 53, "59658": 53, "1674arrai": 53, "167433": 53, "1xarrai": 53, "int641arrai": 53, "scalar": [53, 76, 77], "to_datafram": 53, "from_panda": [53, 81], "include_index": 53, "chaindrawalpha_dim_0b_dim_0beta__dim_0log10_alpha_dim_0log10_b_dim_0alphabbeta_log10_alphalog10_bwi64i64i64i64i64i64i64f64f64f64f64f64f6400000002": 53, "867355": 53, "23510": 53, "1910180": 53, "4574810": 53, "7189250": 53, "17903800000012": 53, "4574811": 53, "535750": 53, "17903800000102": 53, "6788070": 53, "17903800000112": 53, "6788071": 53, "17903800001002": 53, "02912380": 53, "cumbersom": [53, 63, 77], "arviz_to_datafram": [53, 55], "df_mcmc": [53, 55], "wchain__draw__diverging__f64f64f64f64f64f64f64f64f64f64f64i64i64bool2": 53, "867354": 53, "773175": 53, "235134": 53, "33620": 53, "7189251": 53, "17903800false2": 53, "745315": 53, "089335": 53, "4060332": 53, "90160": 53, "1849790": 53, "03039370": 53, "4385920": 53, "7066610": 53, "7328781": 53, "517220": 53, "15900901false4": 53, "061054": 53, "651473": 53, "6443434": 53, "52180": 53, "2743980": 53, "02896720": 53, "6086390": 53, "667590": 53, "5616191": 53, "538090": 53, "13314502false5": 53, "017854": 53, "427832": 53, "7704935": 53, "84410": 53, "3609480": 53, "02789860": 53, "7005180": 53, "6461910": 53, "4425561": 53, "554420": 53, "14577403false2": 53, "309674": 53, "870747": 53, "4160534": 53, "1050": 53, "1348430": 53, "02932120": 53, "3635510": 53, "6875950": 53, "8701731": 53, "532820": 53, "19200404fals": 53, "chain__": 53, "draw__": 53, "diverging__": 53, "par": 53, "\u03b1\u2081": 53, "\u03b1\u2082": 53, "b\u2081": 53, "b\u2082": 53, "peculiar": 53, "reveal": 53, "glyph": [53, 55], "id": [53, 81, 92], "color_by_chain": [53, 94], "green": 53, "uncov": [53, 73, 74], "observation": 53, "emphas": [53, 61, 75], "devilish": 53, "vigil": 53, "b_1": 53, "b_2": 53, "overlap": [53, 63, 76, 94], "filter": [53, 57, 77], "col": [53, 57, 74, 75, 76, 77, 78, 80], "renam": 53, "with_column": [53, 57, 74, 75, 76, 78, 80], "alia": [53, 57, 74, 75, 76, 78, 80], "df_switch": 53, "concat": [53, 94], "alon": [53, 58], "param_mean": 53, "wf64f64f64f64f645": 53, "2096973": 53, "16429831": 53, "9572976": 53, "2381460": 53, "831563": 53, "init": [53, 66, 81], "unconstrain": 53, "warmup": 53, "advis": 53, "hoc": [53, 60], "alpha0": 53, "alpha1": 53, "beta0": 53, "beta1": 53, "fragil": 53, "closer": [53, 58, 63, 64, 66, 81], "microtubul": [54, 58, 81, 94], "departur": [54, 81], "sacrific": 54, "largest": 54, "smallest": 54, "uncomfort": 54, "millimet": 54, "gamma_": [54, 55, 58, 59, 64, 81], "denom_ratio": [54, 55, 58, 59, 64, 81], "log10_phi": [54, 55], "syntact": 54, "parenthes": 54, "plane": 54, "plot_ecdf": [54, 55], "depict": [54, 72], "eschew": 54, "promis": 55, "quickli": [55, 57, 83, 88, 92], "aesthet": 55, "trajectori": [55, 61, 88, 90], "trace_plot": 55, "plot_": 55, "backend": 55, "plot_trac": 55, "kde": 55, "bandwidth": 55, "dan": 55, "minimum": [55, 60], "plot_parallel": 55, "var_nam": [55, 74, 92], "norm_method": 55, "minmax": [55, 72], "parcoord": [55, 62, 72], "neck": 55, "vice": [55, 88], "versa": [55, 88], "plot_dens": 55, "highest": [55, 57], "hpd": [55, 57], "shortest": [55, 57], "backend_kwarg": 55, "bokehdeprecationwarn": 55, "deprec": 55, "remov": [55, 62, 63, 72, 78, 92], "gamma_log10_phiphisigmachain__draw__diverging__f64f64f64f64i64i64bool0": 55, "8760751": 55, "5813638": 55, "13823": 55, "7229800false0": 55, "8695911": 55, "5794137": 55, "96693": 55, "7328201false0": 55, "8521091": 55, "5858338": 55, "53243": 55, "803702false0": 55, "8800941": 55, "5797237": 55, "99453": 55, "7278603false0": 55, "8934751": 55, "5709837": 55, "23743": 55, "7522504fals": 55, "hist": 55, "transpar": 55, "plot_pair": 55, "scatter_kwarg": 55, "fill_alpha": [55, 74], "radius_unit": 55, "represent": [55, 90, 92], "uni": 55, "hex": 55, "hexbin": 55, "xtick_label_orient": [55, 59, 64, 66, 69, 72, 94], "beauti": [57, 63, 67, 88], "lie": [57, 58, 59, 64], "plu": [57, 75, 80, 88], "5th": [57, 61], "percentil": [57, 58, 59, 61, 64, 69], "97": [57, 72, 81], "hdi": 57, "tail": [57, 58, 60, 61, 62, 66, 72, 76, 90, 94], "sigma_2": [57, 60], "x_expon": 57, "15000": 57, "x_norm": 57, "which_norm": 57, "x_2norm": 57, "pareto": [57, 63, 66], "x_heavytail": 57, "readili": [57, 76], "trace": [57, 61, 62, 94], "df_summari": 57, "hpd_low": 57, "hpd_high": 57, "schema": 57, "dist": 57, "concaten": [57, 78], "hdi_prob": 57, "statisticexponentialnormaltwo": 57, "normalsheavi": 57, "tailstrf64f64f64f64": 57, "quot": [57, 72, 74], "0078431": 57, "0014472": 57, "0040054": 57, "134071": 57, "0053510": 57, "249141": 57, "0738544": 57, "580247": 57, "0248750": 57, "5115520": 57, "5904380": 57, "02307": 57, "7010921": 57, "0006981": 57, "7679750": 57, "79814": 57, "6495411": 57, "492053": 57, "80497720": 57, "613608": 57, "0000880": 57, "5318630": 57, "5613620": 57, "000057": 57, "9965491": 57, "5073143": 57, "75565311": 57, "296449": 57, "y_valu": 57, "category10": [57, 69], "plot_interv": 57, "barx": 57, "is_in": 57, "asymmetri": 57, "finder": 57, "uniniti": 57, "suffer": [57, 90], "interquantil": 57, "modal": [57, 94], "mislead": 57, "futil": 57, "deceiv": 57, "chanc": [57, 61, 88, 94], "reeeealli": 57, "71": 57, "struggl": [58, 90], "symptom": [58, 72], "produc": [58, 59, 63, 73, 76, 91, 92, 94], "obei": 58, "cytoplasm": 58, "embryogenesi": 58, "colleagu": 58, "regress": [58, 59, 65, 75], "hone": 58, "670": [58, 59, 64], "uniformli": [58, 73, 74], "inher": [58, 61, 75], "resid": 58, "depolymer": 58, "e_i": 58, "compon": [58, 88, 91, 94], "datum": [58, 63], "establish": 58, "sound": 58, "varieti": [58, 66, 92], "uncertain": [58, 63], "irrelev": [58, 76], "ey": [58, 59, 66, 76, 77, 92], "nonposit": 58, "vanish": 58, "unrealist": 58, "ultim": [58, 60, 72, 74], "jettison": 58, "halfnorm_pdf": 58, "350": [58, 75, 76, 77, 78], "lognorm_pdf": 58, "n_ppc_sampl": 58, "ab": [58, 62, 74, 82], "ph": [58, 75], "sig": 58, "thin": [58, 69, 94], "20th": 58, "ell_val": 58, "line_alpha": [58, 62, 74], "predictive_ecdf": [58, 59, 64, 66, 74, 94], "n_": [58, 61, 78], "middl": [58, 59, 64, 81], "darker": 58, "fill": [58, 92], "extent": 58, "willing": 58, "toler": [58, 76], "tug": 58, "substanti": [58, 62, 73, 81], "059903": 58, "linearli": [58, 88, 91], "gamma_pdf": 58, "\u03c3\u2080": 58, "settl": 58, "clearer": [58, 74, 81], "_rng": 58, "lognormal_rng": 58, "gamma_rng": [58, 74, 92, 94], "tweak": 58, "recompil": 58, "phi_mu": 58, "phi_sigma": 58, "sigma_0_alpha": 58, "sigma_0_beta": 58, "sm_prior_pr": [58, 74], "indep_size_model_prior_predict": 58, "alert": [58, 83], "parallel": [58, 61, 62, 72, 90, 92], "prior_predict": [58, 74, 75, 92], "reshap": [58, 59], "2d": [58, 90], "verbos": 58, "hing": 58, "polymer": 58, "assembli": 58, "balanc": [58, 90], "catastroph": [58, 88, 94], "t_0": [58, 88], "t_1": 58, "t_": [58, 76, 90], "gg": [58, 64], "l_": 58, "mt": 58, "unimport": 58, "geometri": [58, 90], "nmol": 58, "ccl": 58, "assur": 58, "prolat": 58, "spheroid": 58, "spheric": 58, "microscop": [58, 60, 72, 94], "growth": [58, 77], "spectroscop": 58, "vitro": 58, "assai": 58, "2t_": 58, "distinguish": [58, 67, 88], "ones": [58, 61, 74, 76, 77, 81, 88, 94], "lest": [58, 61], "unidentifi": 58, "dire": 58, "commensur": [58, 59, 60, 63], "enhanc": [58, 92], "strive": [58, 83], "didn": [58, 74, 75], "slight": [58, 71], "baselin": 58, "continuum": 58, "basi": [58, 75, 90], "gamma_alpha": 58, "gamma_beta": 58, "beta_rng": 58, "cons_tubulin_model_prior_predict": 58, "span": [58, 66], "predictive_regress": [58, 59, 64, 75, 76, 77, 78, 80, 81], "30th": 58, "60th": 58, "90th": 58, "99th": [58, 59, 64], "samples_x": [58, 59, 64, 75], "60": [58, 74, 77, 81], "javascript": 58, "slider": [58, 72], "draw_slid": 58, "data_dict": 58, "str": 58, "sel": [58, 66, 69], "cd": 58, "columndatasourc": 58, "params_dict": 58, "squeez": [58, 74], "cds_param": 58, "div": 58, "js_code": 58, "cb_obj": 58, "tostr": 58, "toprecis": 58, "emit": 58, "customj": 58, "js_on_chang": 58, "spacer": 58, "encompass": [58, 73, 74, 75, 76], "replot": 58, "heavili": [58, 73, 81, 88, 90, 94], "coupl": [58, 59, 75, 94], "examin": 58, "mayb": [58, 60, 75], "relax": 58, "spindle_volum": 58, "vol_ratio": 58, "ul": 58, "v0": 58, "nonconst": 58, "highlight": [58, 59, 81], "ell_ppc": [59, 64, 81], "indep_size_model": 59, "posterior_predict": [59, 64, 66, 74, 75, 77, 78, 80, 94], "n_sampl": 59, "stack": [59, 61, 64, 66, 74, 75, 76, 77, 78, 80, 94], "collaps": 59, "transpos": [59, 64, 66, 74, 75, 76, 77, 78, 80, 94], "ell_ppc_dim_0": [59, 64], "diff": [59, 64, 74, 94], "vstack": [59, 75], "trend": 59, "envelop": [59, 73, 74, 75, 76], "n_ppc": [59, 64, 66, 74, 75, 81, 92, 94], "d_ppc": [59, 64, 81], "mu_ppc": [59, 64, 81], "cons_tubulin_model": 59, "lost": 59, "former": [59, 90], "shelf": 60, "oftentim": 60, "pare": 60, "pixel": 60, "interpixel": 60, "optic": [60, 77], "digit": 60, "camera": 60, "simplifi": 60, "fourth": 60, "symmetri": 60, "s_": [60, 75], "sigma_1": 60, "c_": 60, "rho": [60, 75, 76, 77, 78, 80], "lkj": 60, "rethink": [60, 97], "underpin": [60, 90], "inappropri": 60, "underli": [60, 63, 73, 75, 78, 94], "inclin": 60, "depart": 60, "inadequ": 60, "adequ": [60, 74], "lightest": 60, "heaviest": 60, "cauchi": 60, "distirbut": 60, "heavier": [60, 90], "opposit": [60, 72], "slower": [60, 94], "log10_v": 60, "reproduc": [61, 83], "rhat": [61, 62, 64, 66, 69, 72, 74, 75, 77, 78, 80, 94], "40b": 61, "007": 61, "007xarrai": 61, "007arrai": 61, "00714323": 61, "00676445": 61, "00684101": 61, "00707471": 61, "00687351": 61, "sd": 61, "hdi_3": 61, "hdi_97": 61, "mcse_mean": 61, "mcse_sd": 61, "ess_bulk": 61, "ess_tail": 61, "r_hat": 61, "521": 61, "398": [61, 81], "769": 61, "266": 61, "014": [61, 81], "010": 61, "797": 61, "679": 61, "706": 61, "056": 61, "040": [61, 81], "763": 61, "709": 61, "060": 61, "006": [61, 66, 81], "049": 61, "070": 61, "654": 61, "038": [61, 81], "576": 61, "221": 61, "142": 61, "295": 61, "samples_limited_warmup": 61, "iter_warmup": [61, 74, 75], "018": [61, 81], "876": 61, "119": [61, 72], "151": 61, "729": 61, "798": 61, "644": 61, "31633592": 61, "252": 61, "091": 61, "299": 61, "683": 61, "486": 61, "734": 61, "293": 61, "149": 61, "241": 61, "114": 61, "714": 61, "841": 61, "059": 61, "419": 61, "321": 61, "868": 61, "327": 61, "925": 61, "181": [61, 81], "661": 61, "506": [61, 78], "272": [61, 66], "395": 61, "314": 61, "866": [61, 81], "695": 61, "532": 61, "poor": [61, 62, 74, 94], "rejec": 61, "caveat": [61, 94], "ideal": [61, 74, 94], "ess": [61, 62, 66, 72, 74, 90, 94], "eff": 61, "prescript": [61, 75], "4000": [61, 62, 64, 66, 69, 72, 74, 75, 77, 78, 80, 81, 94], "500": [61, 81, 88, 94], "ess_mean": 61, "ess_sd": 61, "land": [61, 92], "mcse": 61, "msce_mean": 61, "accur": [61, 88], "wonder": 61, "curvatur": [61, 62, 88, 90], "veer": 61, "sharpli": [61, 63, 67], "regist": 61, "1000fals": 61, "improperli": 61, "3002": 61, "yike": 61, "endem": 61, "sciencei": 61, "unfamiliar": 61, "recurs": 61, "en": 61, "org": [61, 92], "recursion_": 61, "computer_sci": 61, "deep": [61, 62, 92], "cap": 61, "wrong": 61, "10003": 61, "decreas": [61, 62, 75, 88, 90, 92], "ineffici": [61, 90], "1379": 61, "1378": 61, "09": [61, 98], "1377": 61, "98": 61, "1381": 61, "76": [61, 72, 81], "62": 61, "1380": 61, "1383": 61, "1382": 61, "72": [61, 66, 72, 81], "10001": 61, "379e": 61, "38e": 61, "nope": 61, "wrote": [61, 63, 83, 94], "submodul": 61, "check_all_diagnost": [61, 62, 64, 66, 69, 72, 74, 75, 77, 78, 80, 94], "satur": [61, 62, 64, 66, 69, 72, 74, 75, 77, 78, 80, 94], "forthcom": 62, "hack": 62, "probabilti": 62, "thoma": 62, "wiecki": 62, "microinject": 62, "tip": [62, 83], "radford": 62, "neal": 62, "girolami": 62, "450": [62, 72, 75, 88], "66c2a5": 62, "indep": 62, "bottom_left": 62, "2509935801914": 62, "17582178946987": 62, "061082354895177": 62, "103015323352217": 62, "483": 62, "075": 62, "tree": [62, 64, 66, 69, 72, 74, 75, 77, 78, 80, 94], "bfmi": [62, 64, 66, 69, 72, 74, 75, 77, 78, 80, 90, 94], "trust": 62, "hide": [62, 72], "fc8d62": 62, "click_polici": [62, 72], "penetr": 62, "correctli": 62, "awar": [62, 74], "clue": 62, "stuck": [62, 94], "log10": 62, "divergence_kwarg": 62, "advic": [62, 81], "messag": [62, 81, 83], "crank": 62, "8da0cb": 62, "335": 62, "8697624482687": 62, "188": [62, 81], "9130440674577": 62, "123": 62, "79148039281294": 62, "109": 62, "7300569471941": 62, "0225440084677622": 62, "028248959476883": 62, "825": 62, "5103845064002706": 62, "3791047493010087": 62, "6261488838631215": 62, "28202314605045126": 62, "shy": [62, 66], "tild": [62, 63, 66, 72, 73, 76, 78], "uncent": [62, 72, 73, 75, 76, 77, 78, 80, 98], "henc": [62, 72, 88, 90, 94], "theta_tild": 62, "bother": [62, 63, 74], "funnel_noncent": 62, "excel": [62, 73, 74, 76], "No": [62, 83, 88, 90, 92, 98], "e78ac3": 62, "spent": [63, 83], "theta_m": [63, 75], "g_m": 63, "f_m": 63, "eq": 63, "model_bay": 63, "f_t": [63, 66], "digest": 63, "overli": 63, "reduct": 63, "p_i": [63, 90], "haven": 63, "pope": 63, "cathol": 63, "improb": 63, "garner": 63, "p_ip_j": 63, "p_j": 63, "addabl": 63, "tradit": 63, "ensembl": 63, "surpris": [63, 78, 94], "shannon": [63, 81], "thermodynam": 63, "delv": 63, "rich": [63, 92], "knew": 63, "unbias": 63, "shortcut": 63, "1948": 63, "claud": [63, 83], "desiderata": 63, "composit": 63, "law": [63, 75], "extend": [63, 83, 90], "cross": [63, 66, 94], "q_i": [63, 81, 88, 90], "govern": [63, 71, 72, 94], "kl": [63, 81], "d_": [63, 81], "sum_ip_i": 63, "f_": 63, "m_a": 63, "m_b": 63, "awkward": 63, "_i": [63, 66, 73, 75, 77, 78], "nf_m": 63, "elppd": 63, "lpd": 63, "lppd": 63, "_j": [63, 66, 75], "_t": 63, "overestim": [63, 73, 81], "discrep": [63, 73], "p_": [63, 66], "gabri": [63, 66], "arxiv": [63, 66, 88], "therein": 63, "incred": 63, "histor": [63, 66], "held": 63, "remain": [63, 76, 81, 83], "pleasant": 63, "expens": [63, 73, 81], "pacakg": 63, "criteria": [63, 64, 66, 90], "m_i": 63, "m_j": 63, "w_i": [63, 66], "plai": 63, "immens": [63, 92], "invis": 63, "log_lik": [64, 66, 94], "normal_lpdf": [64, 94], "sm_indep": 64, "indep_s": 64, "sm_con": 64, "cons_tubulin": 64, "samples_indep": 64, "samples_con": 64, "ic": [64, 66], "devianc": [64, 66, 75], "elpd_loo": [64, 66], "p_loo": [64, 66], "elpd_diff": [64, 66], "se": [64, 66, 75, 76, 77, 78, 80, 90], "dse": [64, 66], "3662": 64, "643494": 64, "260725": 64, "000000": [64, 66], "354190": 64, "00000": 64, "4003": 64, "001053": 64, "950445": 64, "340": 64, "357559": 64, "379594": 64, "52863": 64, "elpd": 66, "kullback": [66, 81], "leibler": [66, 81], "watanab": 66, "akaik": 66, "criterion": 66, "terribli": 66, "prospect": 66, "straightforward": [66, 67, 72], "easiest": [66, 72, 76], "scientist": [66, 83], "aim": [66, 75, 90], "yao": 66, "pure": [66, 75, 77], "academ": 66, "spectacularli": 66, "neg_binomial_rng": [66, 74, 92], "neg_binom": 66, "doesn": [66, 90, 94], "n_ppc_dim_0": [66, 74], "9mb": 66, "log_lik_dim_0": 66, "2kb": 66, "274": 66, "275": 66, "276": 66, "277": 66, "278": 66, "24t05": 66, "208975": 66, "1000log_lik_dim_0": 66, "279coordin": 66, "278arrai": 66, "871": 66, "571": 66, "006arrai": 66, "9195": 66, "87102": 66, "68695": 66, "26063": 66, "48547": 66, "87587": 66, "86585": 66, "88487": 66, "24419": 66, "48612": 66, "91271": 66, "66727": 66, "93771": 66, "63568": 66, "34274": 66, "58902": 66, "79424": 66, "68369": 66, "92896": 66, "68832": 66, "29315": 66, "55258": 66, "86131": 66, "83427": 66, "8913": 66, "70419": 66, "25863": 66, "50083": 66, "89138": 66, "72091": 66, "92151": 66, "6401": 66, "32705": 66, "56721": 66, "8041": 66, "69304": 66, "9281": 66, "75358": 66, "24444": 66, "5209": 66, "94195": 66, "63444": 66, "94668": 66, "80166": 66, "22269": 66, "52082": 66, "99609": 66, "90389": 66, "8773": 66, "59252": 66, "33818": 66, "53827": 66, "75795": 66, "83866": 66, "892": 66, "73364": 66, "23837": 66, "48808": 66, "92752": 66, "44289": 66, "99838": 66, "74154": 66, "30305": 66, "61111": 66, "90777": 66, "69926": 66, "9251": 66, "67632": 66, "29999": 66, "55376": 66, "84761": 66, "72413": 66, "91933": 66, "65612": 66, "3123": 66, "5567": 66, "82437": 66, "47554": 66, "99033": 66, "81682": 66, "24099": 66, "56584": 66, "0027": 66, "65642": 66, "93676": 66, "68018": 66, "30494": 66, "56586": 66, "84914": 66, "7639": 66, "90806": 66, "69262": 66, "2766": 66, "52578": 66, "87242": 66, "91387": 66, "87357": 66, "60488": 66, "32544": 66, "52772": 66, "77417": 66, "45548": 66, "99638": 66, "82115": 66, "2423": 66, "57115": 66, "00638": 66, "log_lik_dim_0pandasindexpandasindex": 66, "269": 66, "270": 66, "273": 66, "tradition": 66, "deviance_wa": 66, "3281": 66, "p_waic": 66, "single_loo": 66, "deviance_loo": 66, "pct": 66, "wider": 66, "_logpmf": 66, "uniform_rng": 66, "sm_mix": 66, "neg_binom_mix": 66, "samples_mix": 66, "004040383981042": 66, "318": 66, "7069921736581": 66, "836302265033044": 66, "2393686900295": 66, "432640073574931": 66, "12692598049735": 66, "210628341260978": 66, "183": [66, 81], "7239430399982": 66, "432641423716465": 66, "12692598048358": 66, "210629331032064": 66, "72394304000517": 66, "1460975400222795": 66, "170": [66, 81], "8943375375399": 66, "3240338139575638": 66, "3286803456589167": 66, "6654700530731357": 66, "72055885067414": 66, "665470122994841": 66, "7205589366050218": 66, "7356984105623074": 66, "oof": [66, 74, 78, 81], "2774578420000005": 66, "23979613": 66, "64700481": 66, "16986432480000002": 66, "nicer": 66, "3191": 66, "mix_loo": 66, "88": 66, "89": 66, "33459299576725": 66, "d_loo": 66, "w_singl": 66, "w_mix": 66, "99245113565338e": 66, "agreement": 66, "884444": 66, "778852": 66, "983497": 66, "718306": 66, "219037": 66, "927518": 66, "334593": 66, "016503": 66, "315398": 66, "565504": 66, "hyperprior": [67, 69, 71, 72, 75, 80], "theta_k": [67, 71, 75, 76, 77, 80], "permut": 67, "permuat": 67, "nuanc": 67, "advanc": 67, "recov": [67, 73, 90], "nonhierarch": 67, "kappa": [67, 69], "hyperparamet": [68, 69, 71, 72, 75, 77, 78, 79, 81], "portion": [68, 78, 83, 88, 90], "d3": 69, "synthet": [69, 78], "110": 69, "660": 69, "worm_hier": 69, "adapt_delta": [69, 72, 75, 78, 81, 88, 90], "2000": [69, 74, 81], "global": [69, 71, 81, 92], "diamond": [69, 94], "650": 69, "theta_dim_0": 69, "\u03b2": [69, 94], "theta_map": 69, "bottom_right": [69, 72, 94], "significantli": [69, 81, 92], "240": 69, "292": 69, "disfavor": 71, "indirectli": 71, "compris": 71, "dig": 72, "mondai": [72, 81, 83, 98], "batch": [72, 81, 92], "plate": 72, "coloni": [72, 81, 94], "mount": 72, "slide": [72, 82], "microscopi": [72, 91, 94], "wednesdai": [72, 81, 83, 98], "thursdai": [72, 81, 83, 98], "diagram": 72, "phantom": 72, "theta_3": [72, 81], "condition": 72, "j_1": [72, 81], "j_2": [72, 81], "j_k": 72, "j_3": [72, 81], "straight": 72, "clariti": 72, "index_1": [72, 81], "index_2": [72, 81], "index_3": [72, 81], "fabric": [72, 83], "weird": [72, 92], "compact": 72, "data_str": [72, 81], "41": [72, 81], "74": [72, 81], "nw": [72, 81], "42": [72, 81], "nr": [72, 81], "stringio": [72, 81], "daybatchcolonyystri64i64f64": 72, "1111": 72, "1110": 72, "1112": 72, "metadata": 72, "cat": [72, 74, 78, 81, 94], "color_column": [72, 74, 81], "marker_kwarg": [72, 74, 78, 81], "adher": 72, "categor": [72, 74, 94], "df_to_datadict_hi": [72, 81], "convei": 72, "level_col": [72, 81], "data_col": [72, 81], "hellip": [72, 81], "129": [72, 81], "1210": 72, "1310": 72, "1412": 72, "sm_center": 72, "samples_cent": 72, "hopefulli": [72, 74, 81, 90], "dianost": 72, "120": 72, "6206946627826": 72, "193": [72, 81], "46855809117585": 72, "0181667967555237": 72, "0104461055496787": 72, "17398128059170156": 72, "09851564271989993": 72, "12373822952024313": 72, "07573497349280298": 72, "whew": 72, "strikingli": [72, 74], "theta_1_dim_0": 72, "theta_2_dim_0": 72, "theta_3_dim_0": 72, "allevi": 72, "_1": [72, 75, 76, 77], "_2": [72, 76, 77], "_3": 72, "theta_1_tild": 72, "theta_2_tild": 72, "theta_3_tild": 72, "sm_noncent": 72, "samples_noncent": 72, "gone": 72, "y_axis_typ": [72, 74, 77], "articl": 73, "unsatisfi": [73, 94], "reliabl": [73, 74], "ground": [73, 74], "truth": [73, 74], "talt": 73, "umbrella": 73, "abus": [73, 75, 88], "forgiv": 73, "ant": [73, 94], "experimentum": 73, "hundr": 73, "uncertainti": [73, 75], "z_i": 73, "rangle_": 73, "sign": [73, 88], "overfit": [73, 74], "s_i": 73, "drift": [73, 90], "permit": 73, "coverag": [73, 74], "surround": 73, "diagnosi": 73, "empir": [74, 90], "justif": 74, "prior_pr": [74, 92], "choke": 74, "samples_prior_pr": [74, 92], "range1d": 74, "3e5": 74, "nanmax": 74, "poissonian": 74, "dispers": 74, "upward": 74, "mammalian": 74, "ingredi": 74, "requisit": [74, 83], "df_sbc": [74, 92], "prior_predictive_model": [74, 92], "posterior_model": [74, 92], "prior_predictive_model_data": [74, 92], "posterior_model_data": [74, 92], "measured_data": [74, 92], "measured_data_dtyp": [74, 92], "progress_bar": [74, 92], "07it": 74, "ground_truthrank_statisticmeansdshrinkagez_scorerhatessess_per_itertail_esstail_ess_per_itern_divergencesn_bad_ebfmin_max_treedepthwarning_codeltrialerrorparameterf64i64f64f64f64f64f64f64f64f64f64i64i64i64i64i64i64strstr0": 74, "002862101": 74, "0053340": 74, "0052541": 74, "0190": 74, "8112971": 74, "0023851662": 74, "3330420": 74, "4155831245": 74, "9198970": 74, "31148000040000": 74, "592778483": 74, "8443910": 74, "3097990": 74, "9999590": 74, "8122061": 74, "004025732": 74, "4173080": 74, "183104694": 74, "8219580": 74, "173705000040001": 74, "2772539031": 74, "1166130": 74, "0717330": 74, "999998": 74, "2393821": 74, "004734780": 74, "7275920": 74, "1951821050": 74, "450650": 74, "262613200440002": 74, "62861396101": 74, "20665711": 74, "1994990": 74, "9459420": 74, "4087731": 74, "005957512": 74, "1181450": 74, "12803548": 74, "8116860": 74, "137203000040003": 74, "91851601": 74, "0684490": 74, "0510140": 74, "9999992": 74, "9390361": 74, "001264807": 74, "4313030": 74, "201858936": 74, "5215790": 74, "23413100440004": 74, "warning_cod": 74, "succinct": 74, "parse_warning_cod": 74, "treedepth": 74, "tooltip": 74, "sub_df": 74, "1f77b4": 74, "group_bi": 74, "z_score": 74, "evidenc": 74, "good_z": 74, "ground_truth": 74, "jitter": [74, 78], "expos": 74, "abort": 74, "002": [74, 92], "5000": 74, "problemat": [74, 90], "sm_prior_pred_2": [74, 92], "prior_pred_2": 74, "1e6": 74, "sm_2": [74, 92], "model_2": 74, "posterior_predictive_var_nam": [74, 92], "48it": 74, "warning_codeleni64u32087721073818": 74, "sampling_kwarg": [74, 92], "93it": 74, "warning_codeleni64u32210999": 74, "decent": 74, "sbc_rank_ecdf": 74, "hadn": 75, "untest": 75, "amplitud": [75, 76, 78], "methylglucopyranosid": 75, "hydrolysi": 75, "cellulos": 75, "wolfenden": [75, 76, 78, 80], "snider": [75, 76, 80], "enzym": 75, "catalyst": 75, "glucosid": 75, "temperatur": [75, 76, 78, 80], "wolfenden_arrheniu": [75, 76, 78, 80], "chemic": [75, 78, 80], "arrheniu": 75, "e_a": 75, "k_bt": 75, "k_b": 75, "t_i": [75, 77, 78, 94], "k_i": 75, "fun": 75, "t_ppc": [75, 94], "log10_ea": 75, "log10_a": 75, "ea": 75, "k_ppc": [75, 76, 80], "uncatalyz": 75, "reaction": 75, "530": 75, "sm_parametr": 75, "max_treedepth": [75, 78], "16000": 75, "k_ppc_dim_0": 75, "sec": 75, "meaning": 75, "kinet": [75, 78], "capit": 75, "epsilon_i": 75, "primarili": 75, "_n": 75, "latent": [75, 80, 81, 94], "semi": 75, "hugo": 75, "bown": 75, "anderson": 75, "arithmet": 75, "k_": [75, 77, 78], "gram": 75, "sigma_b": 75, "polynomi": 75, "sigma_p": 75, "vert": 75, "vert_2": 75, "mat\u00e9rn": 75, "sin": [75, 78], "modifi": [75, 77, 81, 88, 90, 92], "bessel": [75, 77], "quadrat": 75, "radial": 75, "spirit": 75, "realiz": 75, "rough": [75, 77], "farther": [75, 88], "apart": 75, "unrel": 75, "tunabl": 75, "multinorm": [75, 76, 77, 78, 80, 81], "nstar": [75, 76, 77, 78, 80], "xstar": [75, 76, 77, 78, 80], "gp_exp_quad_cov": [75, 76, 77, 78, 80], "diag_matrix": [75, 76, 77, 78, 80], "rep_vector": [75, 76, 77, 78, 80], "choleski": [75, 76, 78, 80], "decomposit": [75, 76, 78, 80], "cholesky_decompos": [75, 76, 77, 78, 80], "multi_normal_cholesky_rng": [75, 77, 80], "gp_cov_exp_quad": 75, "stabil": [75, 94], "sm_prior": 75, "gp_prior_fixed_rho_alpha": 75, "\u03c1": [75, 76, 77], "rougher": [75, 77], "cov_matern": [75, 77], "rg": 75, "spaghetti": 75, "cov_exp_quad": [75, 76, 77, 80], "multi_lin": 75, "mult_kern": 75, "x1": 75, "x2": 75, "rho_s": 75, "rho_per": 75, "periodic_kernel": 75, "se_kernel": 75, "cov_from_kernel": 75, "add_kern": 75, "linear_kernel": 75, "c_1": 75, "c_2": 75, "iptg": 75, "poi": 75, "c_i": 75, "heteroscedast": 75, "lll": 75, "diag": [75, 76, 77], "unmeasur": 75, "5em": [75, 90], "triangular": 75, "stabli": 75, "shade": 75, "k_scale": [75, 76, 78, 80], "t_scale": [75, 76, 77, 78, 80], "t_rang": [75, 76, 78, 80], "manipul": [75, 80, 81, 92], "posterior_mean_cov": [75, 76, 77], "mstar": [75, 76, 77, 80], "sigmastar": [75, 76, 77, 80], "unscal": [75, 76, 77, 78, 80], "tstar": [75, 76, 77, 78, 80], "kstar": [75, 76, 77, 80], "show_lin": [75, 76, 77], "exent": 75, "muster": 75, "dampen": 75, "favor": [75, 77, 94], "flatter": 75, "simplif": 75, "gp": [76, 79], "stipul": 76, "wiggli": 76, "outlier": 76, "contort": 76, "invgamma": [76, 77, 78, 80], "singular": [76, 77, 90, 92], "diag_to_add": [76, 77], "ky": [76, 77, 80], "4f": [76, 77], "5887": 76, "5791": 76, "0886": 76, "miniconda3": [76, 77, 92], "env": [76, 77], "bebi103_build": [76, 77], "lib": [76, 77, 92], "python3": [76, 77, 92], "_optim": [76, 77], "py": [76, 77, 88, 92], "2472": [76, 77], "runtimewarn": [76, 77, 88], "tmp2": [76, 77], "fx": [76, 77], "fw": [76, 77], "nonparametr": [76, 77, 78, 80], "draw_gp_ppc": 76, "y_mean": 76, "y_std": 76, "nonparameter": 76, "inv_gamma": [76, 77, 78, 80], "multi_normal_choleski": [76, 77, 80], "gp_kinetics_no_ppc": [76, 80], "optimized_params_dict": 76, "ordereddict": 76, "lp__": [76, 81], "79106": 76, "40338": 76, "25657": 76, "0893158": 76, "optimized_params_pd": 76, "od": [77, 90], "remark": 77, "peter": 77, "swain": 77, "tom": [77, 88, 90], "r\u00f6schinger": [77, 88], "roeschinger_growth_rate_data": 77, "tetracycline_conc_\u00b5g_per_ml": 77, "mg1655": 77, "a01": 77, "time_min": 77, "od600": 77, "hr": 77, "extrapol": 77, "od600_scal": 77, "solak": 77, "ourselv": 77, "2_x": 77, "z_j": 77, "partial_1": 77, "partial_2": 77, "pertin": 77, "matern": 77, "1420": 77, "5917": 77, "0118": 77, "augment": 77, "posterior_mean_cov_deriv": 77, "exp_quad_kernel": 77, "gstar": 77, "sigma_g_star": 77, "od600star": 77, "deriv_high": 77, "deriv_low": 77, "deriv_star": 77, "dt": [77, 88], "2_z": 77, "mu_z": 77, "mu_x": 77, "2_y": 77, "shortli": 77, "growth_rat": 77, "sigma_growth_r": 77, "gr_high": 77, "gr_low": 77, "redefin": 77, "matern_kernel": 77, "wiggl": 77, "gp_one_dimension": [77, 80], "stanfunct": 77, "fstar": [77, 78, 80], "dfstar": 77, "y_ppc": [77, 78, 80], "kstarstar": [77, 80], "d1_kstar": 77, "d1_cov_exp_quad": 77, "d1_d2_kstarstar": 77, "d1_d2_cov_exp_quad": 77, "gp_posterior_mstar": [77, 80], "lstar": [77, 80], "gp_posterior_sigmastar_choleski": [77, 80], "sigmag": 77, "l_g_star": 77, "gp_growth_curv": 77, "stanc_opt": [77, 80], "include_path": [77, 80], "y_ppc_dim_0": [77, 80], "od600_ppc": 77, "dfstar_scal": 77, "dfstar_dim_0": 77, "fstar_scal": [77, 78, 80], "fstar_dim_0": [77, 80], "experienc": 77, "unmargin": 78, "f_i": 78, "layer": 78, "hyperparamat": 78, "preprocess": 78, "xstar_ind": 78, "f_tild": 78, "append_sort_index": 78, "index_origin": 78, "duplic": 78, "indici": 78, "73988004": 78, "67222743": 78, "60457482": 78, "58919923": 78, "53692222": 78, "46926961": 78, "401617": 78, "3339644": 78, "26631179": 78, "22693001": 78, "19865918": 78, "13100658": 78, "06335397": 78, "99570136": 78, "96124699": 78, "92804876": 78, "86039615": 78, "79274354": 78, "72509093": 78, "65743833": 78, "58978572": 78, "52324311": 78, "52213311": 78, "45448051": 78, "3868279": 78, "31917529": 78, "25152269": 78, "18459205": 78, "18387008": 78, "11621747": 78, "04856487": 78, "01908774": 78, "08674035": 78, "15439295": 78, "22204556": 78, "28969817": 78, "35735077": 78, "42500338": 78, "49265599": 78, "50367757": 78, "56030859": 78, "6279612": 78, "69561381": 78, "76326641": 78, "81156517": 78, "83091902": 78, "89857163": 78, "96622423": 78, "03387684": 78, "10152945": 78, "16918205": 78, "23683466": 78, "2418742": 78, "30448727": 78, "37213987": 78, "42441689": 78, "43979248": 78, "50744509": 78, "57509769": 78, "56": [78, 92], "526": 78, "97268063": 78, "522": 78, "8398459": 78, "513": 78, "09748852": 78, "12679808": 78, "490": 78, "5441167": 78, "482": 78, "87692992": 78, "472": [78, 81], "96035845": 78, "466": 78, "94519538": 78, "458": 78, "74328484": 78, "leapfrog": [78, 81, 90], "gp_kinetics_no_marg": 78, "dial": 78, "475": 78, "f_dim_0": 78, "data_kwarg": [78, 80], "1f78b4": [78, 80], "contriv": [78, 81], "scenario": [78, 92, 94], "a_0": 78, "varying_funct": 78, "a0": 78, "a1": 78, "\u03bb": 78, "time_point": 78, "n_cell": 78, "astyp": 78, "plop": 78, "fram": 78, "q_axi": 78, "600": [78, 81], "t_ind": 78, "log_f_tild": 78, "log_f": 78, "poisson_log": 78, "poisson_log_rng": 78, "gp_transcript_count": 78, "184": [78, 81], "3782": 78, "log_fstar": 78, "log_f_dim_0": 78, "mdivide_left_tri_low": 80, "mdivide_right_tri_low": 80, "sigma_star": 80, "po": 80, "wherev": 80, "suffix": 80, "stan_includ": 80, "comma": 80, "gp_kinet": 80, "pathto": 80, "force_compil": 80, "k_ppc_scale": 80, "heidi": [81, 91], "klump": [81, 91], "selector": 81, "adopt": 81, "interchang": 81, "blei": 81, "dissimilar": 81, "leiber": 81, "resembl": [81, 88, 90], "poorli": 81, "prod_i": 81, "phi_i": 81, "partit": [81, 90], "neq": 81, "q_j": 81, "hurdl": 81, "q_": 81, "randon": 81, "advi": 81, "alp": 81, "kucukelbir": 81, "zeta": 81, "zeta_i": 81, "meanfield": 81, "optimum": 81, "samples_vi": 81, "pertain": 81, "stdout_fil": 81, "runset": 81, "_stdout_fil": 81, "10000": 81, "grad_sampl": 81, "elbo_sampl": 81, "tol_rel_obj": 81, "eval_elbo": 81, "output_sampl": 81, "tmpcshdblkp": 81, "01ufoem2": 81, "json": 81, "spindlezaxcnbxg": 81, "20240727161414": 81, "diagnostic_fil": 81, "sig_fig": 81, "profile_fil": 81, "save_cmdstan_config": 81, "num_thread": 81, "unstabl": 81, "buggi": 81, "gradient": [81, 88, 90], "000392": 81, "ascent": 81, "delta_elbo_mean": 81, "delta_elbo_m": 81, "6093": 81, "3580": 81, "851": 81, "3473": 81, "163": 81, "578": 81, "702": 81, "3406": 81, "187": 81, "438": 81, "3310": 81, "589": 81, "356": 81, "031": 81, "3197": 81, "393": 81, "303": 81, "035": 81, "700": 81, "3119": 81, "716": 81, "263": 81, "800": 81, "3118": 81, "230": 81, "900": 81, "3055": 81, "396": 81, "207": 81, "029": 81, "3007": 81, "033": 81, "1100": 81, "2958": 81, "594": 81, "090": 81, "1200": 81, "2882": 81, "045": 81, "022": 81, "1300": 81, "2825": 81, "021": 81, "1400": 81, "2755": 81, "1500": 81, "2656": 81, "2549": 81, "177": 81, "023": 81, "1700": 81, "2429": 81, "026": 81, "1800": 81, "2310": 81, "505": 81, "027": 81, "1900": 81, "2205": 81, "968": 81, "037": 81, "2103": 81, "036": 81, "042": 81, "2100": 81, "2027": 81, "055": 81, "039": 81, "2200": 81, "1952": 81, "219": 81, "2300": 81, "1908": 81, "2400": 81, "1881": 81, "840": [81, 92], "2500": 81, "1870": 81, "947": 81, "2600": 81, "1869": 81, "602": 81, "032": 81, "2700": 81, "1859": 81, "828": 81, "2800": 81, "1852": 81, "081": 81, "2900": 81, "1855": 81, "085": 81, "3000": [81, 94], "1848": 81, "013": 81, "variational_sample_pd": 81, "df_vi": 81, "1_546": 81, "lp__log_p__log_g__phigamma_sigma_0mu": 81, "164": 81, "165": 81, "166": 81, "167": 81, "168": 81, "169": 81, "171": 81, "173": 81, "174": 81, "175": 81, "178": 81, "180": 81, "182": 81, "185": 81, "186": [81, 94], "189": 81, "192": 81, "194": 81, "195": 81, "197": 81, "198": 81, "199": 81, "f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64": 81, "f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f640": 81, "1835": 81, "33121238": 81, "2270": 81, "8426290": 81, "11378121": 81, "410822": 81, "116822": 81, "863123": 81, "818223": 81, "818224": 81, "107224": 81, "221524": 81, "391524": 81, "5625": 81, "109525": 81, "217225": 81, "377425": 81, "483325": 81, "640725": 81, "796425": 81, "899425": 81, "899426": 81, "052426": 81, "153526": 81, "303726": 81, "40326": 81, "403": 81, "248343": 81, "154236": 81, "822544": 81, "668738": 81, "665544": 81, "02741": 81, "527232": 81, "699924": 81, "670637": 81, "833836": 81, "934941": 81, "205144": 81, "229931": 81, "700542": 81, "786742": 81, "284843": 81, "183633": 81, "922841": 81, "924440": 81, "99631": 81, "870935": 81, "84937": 81, "39738": 81, "296335": 81, "662538": 81, "725243": 81, "700342": 81, "188434": 81, "516936": 81, "389942": 81, "901239": 81, "483443": 81, "509634": 81, "06443": 81, "242134": 81, "12140": 81, "64320": 81, "1840": 81, "78530839": 81, "15010": 81, "8652280": 81, "11209321": 81, "974922": 81, "698523": 81, "463224": 81, "441524": 81, "737524": 81, "854625": 81, "028725": 81, "201225": 81, "763925": 81, "874125": 81, "874126": 81, "038126": 81, "146526": 81, "307626": 81, "46726": 81, "572426": 81, "72926": 81, "832426": 81, "986227": 81, "087827": 81, "0878": 81, "852838": 81, "859240": 81, "255547": 81, "723140": 81, "816530": 81, "954534": 81, "280637": 81, "754237": 81, "441734": 81, "807737": 81, "139236": 81, "539429": 81, "180541": 81, "470439": 81, "744540": 81, "545239": 81, "189340": 81, "0141": 81, "243634": 81, "44339": 81, "726140": 81, "452141": 81, "051329": 81, "214242": 81, "083739": 81, "000348": 81, "029239": 81, "175628": 81, "694240": 81, "588942": 81, "45241": 81, "212443": 81, "891929": 81, "079348": 81, "109934": 81, "261135": 81, "85890": 81, "1858": 81, "3135140": 81, "27760": 81, "8440270": 81, "12307621": 81, "626222": 81, "358723": 81, "135824": 81, "134924": 81, "438324": 81, "558524": 81, "914925": 81, "49525": 81, "608925": 81, "778525": 81, "890726": 81, "057726": 81, "223126": 81, "332526": 81, "495326": 81, "60326": 81, "763126": 81, "86926": 81, "869": 81, "305746": 81, "086545": 81, "675337": 81, "458641": 81, "120538": 81, "046242": 81, "214834": 81, "958247": 81, "576935": 81, "842340": 81, "759945": 81, "705848": 81, "77944": 81, "312848": 81, "809835": 81, "705734": 81, "544637": 81, "255641": 81, "519542": 81, "743345": 81, "759829": 81, "798840": 81, "612251": 81, "127443": 81, "244447": 81, "42946": 81, "350742": 81, "102934": 81, "758235": 81, "285637": 81, "087235": 81, "45129": 81, "324637": 81, "891744": 81, "517646": 81, "607338": 81, "60070": 81, "57": 81, "2506237": 81, "61070": 81, "8235380": 81, "12039920": 81, "9521": 81, "643522": 81, "376723": 81, "315823": 81, "600123": 81, "712623": 81, "879923": 81, "879924": 81, "045724": 81, "586724": 81, "692824": 81, "850524": 81, "954825": 81, "109825": 81, "263325": 81, "364725": 81, "515525": 81, "615225": 81, "763325": 81, "861125": 81, "8611": 81, "700133": 81, "765741": 81, "01630": 81, "692931": 81, "122833": 81, "522642": 81, "145236": 81, "1543": 81, "160140": 81, "126942": 81, "508540": 81, "00243": 81, "993937": 81, "575338": 81, "000436": 81, "304840": 81, "071936": 81, "101739": 81, "003932": 81, "224645": 81, "635435": 81, "53938": 81, "868137": 81, "839935": 81, "145742": 81, "555744": 81, "950539": 81, "690740": 81, "796237": 81, "734439": 81, "588133": 81, "151932": 81, "761429": 81, "640840": 81, "012242": 81, "179343": 81, "35860": 81, "1837": 81, "70917538": 81, "33510": 81, "8371120": 81, "11236821": 81, "305322": 81, "011622": 81, "758623": 81, "715523": 81, "715524": 81, "005224": 81, "119824": 81, "290424": 81, "459425": 81, "01125": 81, "119125": 81, "279925": 81, "386325": 81, "544425": 81, "700925": 81, "804325": 81, "958125": 81, "958126": 81, "059826": 81, "210826": 81, "310726": 81, "3107": 81, "389538": 81, "487935": 81, "552138": 81, "478339": 81, "257242": 81, "376948": 81, "535439": 81, "861436": 81, "31238": 81, "527838": 81, "715338": 81, "726839": 81, "719838": 81, "526837": 81, "728746": 81, "05735": 81, "144146": 81, "713130": 81, "492937": 81, "246445": 81, "322936": 81, "658942": 81, "086337": 81, "391944": 81, "149438": 81, "827439": 81, "504842": 81, "60740": 81, "123337": 81, "005437": 81, "151228": 81, "840532": 81, "462543": 81, "715541": 81, "509742": 81, "00435": 81, "4243": 81, "legaci": 81, "log_p__": 81, "log_g__": 81, "variational_params_pd": 81, "4521": 81, "853254": 81, "116228": 81, "6552": 81, "3666": 81, "1182": 81, "0794": 81, "4477": 81, "673": 81, "7122": 81, "1776": 81, "381": 81, "9442": 81, "6642": 81, "46": 81, "0142": 81, "2081": 81, "4419": 81, "1546": 81, "plot_marginal_ecdf": 81, "p_phi": 81, "p_gamma": 81, "fullrank": 81, "3251": 81, "88812": 81, "noncent": [81, 90], "hier_lognorm": 81, "32520": 81, "require_converg": 81, "tendenc": 81, "underestim": 81, "p_theta": 81, "p_sigma": 81, "p_tau": 81, "gridplot": [81, 94], "ncol": [81, 94], "custom": 81, "ranganath": 81, "morn": 83, "noon": [83, 98], "kerckhoff": [83, 98], "b123": [83, 98], "attend": 83, "recit": [83, 84, 85, 87, 88, 90, 91, 92, 93, 94, 95, 96, 98], "offic": [83, 98], "tuesdai": [83, 98], "dilig": 83, "golden": 83, "opportun": 83, "submit": [83, 92, 98], "schedul": [83, 92], "skill": 83, "_lastname_firstnam": 83, "pacif": 83, "sundai": 83, "perfectli": 83, "aspect": 83, "fridai": 83, "hw": 83, "restart": 83, "runnabl": 83, "submitt": 83, "credit": [83, 88], "name_of_datafil": 83, "embed": 83, "mathjax": 83, "latex": 83, "inversegamma": 83, "justifi": 83, "guidelin": 83, "adjac": [83, 90], "explanatori": 83, "markdown": 83, "header": 83, "delin": 83, "late": 83, "grace": 83, "penalti": 83, "saturdai": 83, "ill": 83, "health": 83, "cass": 83, "accommod": 83, "coursework": 83, "exam": 83, "announc": 83, "offici": 83, "passag": 83, "nullifi": 83, "violat": 83, "publicli": 83, "unpublish": 83, "institut": 83, "faith": 83, "imper": 83, "dissemin": 83, "classmat": 83, "whom": 83, "consult": 83, "websit": 83, "materi": [83, 84, 93, 94, 95], "cite": 83, "llm": 83, "chatgpt": 83, "gpt": 83, "llama": 83, "gemini": 83, "cursor": 83, "copilot": 83, "ai": 83, "engin": [83, 97], "deni": 83, "contrari": 83, "basal": 83, "compet": 83, "reiter": 83, "chatbot": 83, "privat": 83, "email": [83, 92], "shot": 83, "anonym": 83, "spur": 83, "dialog": [84, 95], "factori": 88, "curdoc": 88, "ticker": 88, "fixedtick": 88, "holoview": 88, "hv": 88, "pallete1": 88, "9faeb2": 88, "ab6e7d": 88, "1c2630": 88, "autohid": 88, "text_font": 88, "helvetica": 88, "text_font_s": 88, "16px": 88, "xaxi": 88, "axis_label_text_font": 88, "yaxi": 88, "axis_label_text_font_s": 88, "13px": 88, "axis_label_text_font_styl": 88, "background_fill_alpha": 88, "toolbar": 88, "anyon": 88, "background": [88, 91, 92], "break": [88, 92], "subset": 88, "bob": 88, "carpent": 88, "weigh": 88, "coeffici": 88, "375": 88, "326": 88, "420": 88, "binomial_coeff": 88, "prob": 88, "patch": 88, "eaeaea": 88, "degeneraci": 88, "999999": 88, "1000000": 88, "imbal": 88, "classic": [88, 90, 94], "quantum": 88, "harmon": 88, "oscil": [88, 90], "attach": [88, 91], "spring": 88, "kx": 88, "movement": 88, "mv": 88, "2m": 88, "momentum": [88, 90], "fiat": 88, "brick": 88, "wall": 88, "wreck": 88, "train": 88, "consum": [88, 92], "ellipsoid": 88, "simple_oscil": 88, "bupu": 88, "x_arr": 88, "p_plu": 88, "p_minu": 88, "add_layout": 88, "major_label_text_font_s": 88, "0pt": 88, "evolut": 88, "motion": [88, 90], "qquad": 88, "angl": 88, "mag": 88, "arctan2": 88, "vectorfield": 88, "cmap": 88, "viridi": 88, "xlabel": 88, "ylabel": 88, "interrupt": 88, "therm": 88, "preprint": 88, "1701": 88, "02434": 88, "momenta": 88, "scatter1": 88, "scatter2": 88, "arrow1": 88, "arrow1_1": 88, "arrow1_2": 88, "arrow2": 88, "arrow2_1": 88, "arrow2_2": 88, "partial_h": 88, "xlim": 88, "ylim": 88, "show_grid": 88, "distinct": 88, "h1": 88, "h2": 88, "h3": 88, "x_arr1": 88, "x_arr2": 88, "x_arr3": 88, "p_plus1": 88, "p_minus1": 88, "p_plus2": 88, "p_minus2": 88, "p_plus3": 88, "p_minus3": 88, "scatter12": 88, "79": 88, "scatter22": 88, "arrow12": 88, "arrow1_12": 88, "arrow1_22": 88, "arrow22": 88, "arrow2_12": 88, "arrow2_22": 88, "partial_h2": 88, "l3": 88, "n6j3jk1n1p94lc552kcbzq280000gn": 88, "ipykernel_5666": 88, "985606356": 88, "prime": 88, "prime_i": 88, "rotat": 88, "parameter": 88, "disrupt": 88, "regard": 88, "const": [88, 90], "lap": 88, "unexplor": 88, "backward": [88, 90], "met": 88, "euler": 88, "inaccuraci": [88, 90], "drastic": 88, "stackoverflow": 88, "33601089": 88, "n0": 88, "dn": 88, "dx_dt": 88, "liouvil": 88, "symplect": [88, 90], "detriment": 88, "shoot": 88, "bridg": 88, "rail": 88, "fought": 88, "rosita": 90, "fu": 90, "linger": 90, "r\u00f6esching": 90, "alongsid": 90, "math": [90, 92], "int_q": 90, "hspace": 90, "mathbb": 90, "entireti": 90, "ordinari": 90, "dq": 90, "1d": 90, "3d": 90, "cube": [90, 92], "denisti": 90, "predomin": 90, "sit": 90, "x_": 90, "sole": 90, "creativ": 90, "allud": 90, "determinist": [90, 94], "dictat": 90, "f_n": 90, "btw": 90, "habit": 90, "hover": 90, "overcompens": 90, "usag": 90, "diffus": 90, "irredeem": 90, "incapacit": 90, "jump": [90, 94], "sluggish": 90, "increment": 90, "overal": [90, 94], "q_1": 90, "q_2": 90, "q_3": 90, "cast": 90, "hearken": 90, "metaphor": 90, "planet": 90, "gravit": 90, "orbit": 90, "satellit": 90, "crash": [90, 92], "eject": 90, "auxiliari": 90, "2xd": 90, "q_n": 90, "rightarrow": 90, "p_n": 90, "canon": 90, "nbsphinx": 90, "8em": 90, "9em": 90, "interepret": 90, "lift": [90, 94], "omega": 90, "omega_": 90, "microcanon": 90, "ring": 90, "jointli": 90, "cfrac": 90, "2em": 90, "3em": 90, "phi_t": 90, "altogeth": 90, "somehow": 90, "unlock": 90, "expon": 90, "decoupl": 90, "retriev": [90, 92], "repeatedli": 90, "project": [90, 91, 92], "swiftli": 90, "euclidean": 90, "riemannian": 90, "pi_": 90, "pi_e": 90, "e_bfmi": 90, "proven": 90, "ke": 90, "pick": 90, "convolut": 90, "distribtuion": 90, "de": 90, "distribuion": 90, "Their": 90, "smoothen": 90, "persist": [90, 94], "stronger": 90, "suspicion": 90, "distribt": 90, "termin": [90, 92], "mysteri": 90, "impress": 90, "takeawai": 90, "life": 90, "exploit": 90, "glean": 90, "face": [90, 94], "cellular": 91, "architectur": 91, "extracellular": 91, "surfac": 91, "confoc": 91, "membran": [91, 94], "autom": 91, "cytometri": 91, "fluorophor": 91, "cytomet": 91, "bead": 91, "subunit": 91, "spontan": 91, "weren": 91, "multimer": [91, 94], "intracellular": [91, 94], "fusion": [91, 94], "zachari": 92, "martinez": 92, "tailor": 92, "cluster": 92, "terabyt": 92, "petabyt": 92, "facillit": 92, "acceler": 92, "node": 92, "cento": 92, "admin": 92, "grant": 92, "authent": 92, "duo": 92, "wifi": 92, "vpn": 92, "zmartin": 92, "host": 92, "refus": 92, "ondemand": 92, "studio": 92, "desktop": 92, "compos": 92, "script": 92, "alloc": 92, "queue": 92, "princeton": 92, "my_slurm_script": 92, "sbatch": 92, "walltim": 92, "ntask": 92, "processor": 92, "mem": 92, "16g": 92, "my_first_job": 92, "mail": 92, "purg": 92, "export": 92, "ld_library_path": 92, "mthomson": 92, "zam": 92, "miniconda": 92, "librari": 92, "example_env": 92, "highly_parallelized_script": 92, "my_first_job_xxxxxx": 92, "cheatsheet": 92, "flag": 92, "gre": 92, "qo": 92, "debug": 92, "prioriti": 92, "forev": 92, "cascadelak": 92, "squeue": 92, "pend": 92, "scancel": 92, "12345678": 92, "kill": [92, 94], "jobid": 92, "srun": 92, "pty": 92, "xx": 92, "lastli": 92, "programat": 92, "slurm_ntask": 92, "n_task": 92, "gui": 92, "winscp": 92, "filezilla": 92, "cyberduck": 92, "awscli": 92, "forth": 92, "remote_script": 92, "local_script": 92, "local_filenam": 92, "currect": 92, "remote_filenam": 92, "3ish": 92, "50gb": 92, "10tb": 92, "thomson": 92, "80tb": 92, "scratch": 92, "20tb": 92, "scratchio": 92, "2tb": 92, "quota": 92, "mmlsquota": 92, "auto": 92, "ticket": 92, "vscode": 92, "plugin": 92, "vim": 92, "friendli": 92, "isn": [92, 94], "geeksforgeek": 92, "realpython": 92, "superfastpython": 92, "prematur": 92, "evil": 92, "donald": 92, "knuth": 92, "multiprocess": 92, "exhaust": 92, "unexpect": 92, "silent": 92, "multithread": 92, "lock": 92, "gil": 92, "thread": 92, "cpu_count": 92, "mp": 92, "laptop": 92, "squareroot": 92, "benchmark": 92, "square_list": 92, "input_list": 92, "num": [92, 94], "squareroot_list": 92, "mylist": 92, "100_000_001": 92, "100_000_000": 92, "ran": 92, "elaps": 92, "94840407371521": 92, "ascend": 92, "overcom": 92, "__name__": 92, "__main__": 92, "p1": [92, 94], "p2": [92, 94], "p3": 92, "30126214027405": 92, "demo": 92, "10_000_001": 92, "10_000_000": 92, "8647820949554443": 92, "teardown": 92, "3583669662475586": 92, "precari": 92, "race": 92, "cube_and_revers": 92, "val": 92, "arr": 92, "125": 92, "random_word": 92, "randomword": 92, "flush": 92, "get_random_word": 92, "consumer_process": 92, "producer_process": 92, "modulenotfounderror": 92, "traceback": 92, "firstli": 92, "dramat": 92, "bebi103b": 92, "thirdli": 92, "capac": 92, "infeas": 92, "simultan": 92, "benefici": 92, "timefram": 92, "paralleliz": 92, "pd": [92, 94], "prep": [92, 94], "prior_predictive_check": 92, "stan_model_cod": 92, "example_model": 92, "_perform_sbc": 92, "_get_output_dir": 92, "samples_dir": 92, "prior_sample_cmdstanpi": 92, "posterior_samples_cmdstanpi": 92, "parallel_chain": 92, "arg_input_gener": 92, "stan_sbc": 92, "my_job": 92, "thefilenam": 92, "6g": 92, "stan_sbc_test": 92, "chunk": 92, "cpp_option": 92, "stan_thread": 92, "rewritten": 92, "reduce_sum": 92, "piecewis": 92, "partial_sum_neg_binom": 92, "slice_n": 92, "mere": 92, "iceberg": 92, "taught": 92, "foot": 92, "door": 92, "luck": 92, "zach": 93, "julian": 94, "wagner": 94, "bespok": 94, "ecolog": 94, "recaptur": 94, "afterward": 94, "worst": 94, "dread": 94, "nan": 94, "datatyp": 94, "explod": 94, "ecologi": 94, "leg": 94, "band": 94, "bird": 94, "fin": 94, "shark": 94, "stradl": 94, "radioact": 94, "phosphor": 94, "32p": 94, "tissu": 94, "worker": 94, "myrmica": 94, "rubra": 94, "gari": 94, "alpert": 94, "hypergeometr": 94, "white": 94, "ball": 94, "unlabel": 94, "stickler": 94, "todai": 94, "insist": 94, "stick": 94, "negative_binomi": 94, "log_sum_exp": 94, "game": 94, "mark_recapture_hypergeometr": 94, "max_pop": 94, "min_pop": 94, "neg_binomial_2_lpmf": 94, "hypergeometric_lpmf": 94, "simplex": 94, "pstate": 94, "funni": 94, "346": 94, "sample_it": 94, "aren": 94, "distibut": 94, "0000000284678414": 94, "yai": 94, "gotten": 94, "sake": 94, "ra": 94, "a_min": 94, "a_max": 94, "mt_gamma": 94, "20000": 94, "ndiagnost": 94, "t_ppc_dim_0": 94, "alpha_": 94, "t_j": 94, "a_": 94, "hei": 94, "sm2": 94, "mt_gamma_integer_alpha": 94, "beta2": 94, "binomial_lpmf": 94, "gamma_lpdf": 94, "log_p_norm": 94, "categorical_logit_rng": 94, "round": 94, "logit": 94, "samples_discret": 94, "odd": 94, "funki": 94, "intermediari": 94, "df_sample_compar": 94, "peaki": 94, "confirm": 94, "87136123": 94, "170593759154506": 94, "76135737638342": 94, "5281784828052738": 94, "mt_gamma_integer_alpha_jb": 94, "log_alpha_prior": 94, "un": 94, "log_q": 94, "samp": 94, "log_norm_const": 94, "log_g": 94, "net": 94, "monstrou": 94, "3rd": 97, "freeli": 97, "channel": 97, "video": 97, "2nd": 97, "richard": 97, "mcelreath": 97, "ben": 97, "lambert": 97, "beginn": 97, "press\u00e9": 97, "sgourali": 97, "exposit": 97, "phil": 97, "supplement": 97, "kerkchoff": 98, "februari": 98, "march": 98, "martin": 98, "luther": 98, "king": 98, "presid": 98}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"homework": [0, 2, 3, 5, 6, 8, 9, 11, 83, 87, 96, 98], "1": [0, 1, 2, 5, 8, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 28, 58, 81], "first": 0, "attempt": 0, "bayesian": [0, 25, 31, 32, 35, 41, 75, 81, 91], "gener": [0, 1, 30, 46, 47, 51, 54, 58, 68, 72, 74, 78], "model": [0, 1, 26, 31, 32, 35, 36, 37, 40, 42, 51, 53, 54, 55, 58, 59, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 72, 74, 78, 81, 91], "70": [0, 8], "pt": [0, 2, 3, 5, 6, 8, 9], "intuit": 1, "2": [2, 3, 4, 6, 9, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 35, 58, 81], "overwhelm": 2, "prior": [2, 3, 25, 31, 32, 34, 51, 58, 60, 67, 74, 75, 76, 85, 86], "45": 2, "exponenti": [3, 77], "conjug": [3, 34, 38], "55": 3, "analyt": [4, 36, 37, 75], "graphic": 4, "method": [4, 34, 57, 90], "analysi": [4, 40, 51, 73], "posterior": [4, 25, 32, 36, 38, 40, 41, 51, 55, 57, 59, 63, 75, 76, 80], "3": [5, 6, 7, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 36, 58], "least": 5, "squar": [5, 77], "20": [5, 18, 72], "map": [6, 40, 41, 76], "estim": [6, 7, 31, 39, 40, 41, 42, 51, 63, 75, 80], "zero": 6, "inflat": 6, "drop": 6, "seq": 6, "control": 6, "80": 6, "maximum": [7, 41], "posteriori": 7, "paramet": [7, 31, 36, 39, 40, 41, 42, 51, 55, 58, 71, 75, 94], "4": [8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 37], "write": [8, 92], "your": [8, 21, 24, 52], "own": 8, "mcmc": [8, 9, 10, 44, 46, 49, 50, 51, 53, 54, 55, 56, 57, 61, 78, 80, 92, 93], "sampler": [8, 61], "boolean": 9, "data": [9, 36, 40, 51, 58, 61, 71, 72, 75, 77], "30": 9, "sampl": [10, 22, 51, 52, 53, 54, 55, 57, 61, 62, 72, 74, 75, 76, 77, 78, 90, 94], "BE": 11, "bi": 11, "103": 11, "b": [11, 90], "statist": [11, 25, 59, 61, 73], "infer": [11, 25, 75, 81], "biolog": 11, "scienc": [11, 25], "us": [11, 21, 22, 34, 41, 52, 54, 75, 77, 78, 80, 88, 92, 93], "link": 11, "peopl": 11, "lesson": [11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 83, 98], "schedul": [11, 98], "polici": [11, 83], "resourc": [11, 23], "previou": 11, "edit": 11, "cours": [11, 83], "e1": 12, "To": [12, 13, 14, 15, 16, 17, 18, 19, 20], "complet": [12, 13, 14, 15, 16, 17, 18, 19, 20], "after": [12, 13, 14, 15, 16, 17, 18, 19, 20, 21], "5": [12, 13, 16, 18, 21, 38], "exercis": [12, 13, 14, 15, 16, 17, 18, 19, 20, 83, 98], "e2": 13, "6": [13, 17, 21, 39], "e3": 14, "10": [14, 54, 95], "e4": 15, "13": [15, 59], "e5": 16, "16": [16, 62], "e6": 17, "18": [17, 65], "e7": 18, "7": [18, 21, 45], "e8": 19, "22": [19, 74], "8": [19, 21, 50], "e9": 20, "25": [20, 81], "9": [20, 21, 53], "aw": 21, "setup": 21, "usag": 21, "creat": 21, "an": [21, 30, 36, 66, 74, 75, 90], "amazon": 21, "web": 21, "servic": 21, "account": 21, "launch": 21, "instanc": 21, "connect": 21, "jupyterlab": 21, "copi": 21, "result": [21, 56, 57], "from": [21, 31, 77], "local": 21, "machin": [21, 24], "exit": 21, "serious": 21, "stop": 21, "you": 21, "ar": [21, 52], "them": 21, "again": 21, "termin": 21, "class": 21, "i": [21, 25, 40, 58, 92], "over": 21, "googl": 22, "colab": 22, "watchout": 22, "when": 22, "softwar": [22, 92, 97], "A": [22, 36, 42, 62, 71, 72, 73, 78, 81, 88, 90], "calcul": [22, 36, 66, 77], "comput": [22, 23, 24, 36, 37, 38, 40, 41, 42, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 74, 75, 76, 77, 78, 80, 81, 88, 94], "environ": [22, 24, 36, 37, 38, 40, 41, 42, 51, 52, 53, 54, 55, 57, 58, 59, 61, 62, 64, 66, 69, 74, 75, 76, 77, 78, 80, 81, 88, 94], "0": 23, "set": [23, 36, 51, 58, 60, 61, 72, 75, 88, 90], "up": [23, 48, 52, 53, 72, 82], "configur": 24, "instal": 24, "python": [24, 92], "packag": 24, "stan": [24, 50, 51, 52, 54, 58, 72, 75, 76, 77, 78, 80, 81, 92, 94], "c": [24, 90], "toolchain": 24, "maco": 24, "window": 24, "linux": 24, "cmdstanpi": 24, "check": [24, 42, 58, 59, 60, 61, 63, 72, 74, 80], "probabl": [25, 28, 30, 84, 94], "logic": [25, 28], "what": [25, 88, 92], "The": [25, 31, 32, 34, 36, 37, 38, 42, 46, 47, 51, 55, 58, 59, 61, 63, 71, 74, 75, 81, 88, 90], "problem": 25, "frequentist": 25, "desiderata": 25, "sum": 25, "rule": 25, "product": 25, "condit": [25, 30, 67], "applic": 25, "scientif": [25, 28], "measur": [25, 31], "bay": [25, 26, 27, 30], "": [25, 26, 27, 30, 58, 60, 92, 93], "theorem": [25, 26, 27, 30], "likelihood": [25, 31, 33, 36, 40, 58, 66, 75, 78, 80], "evid": 25, "learn": 26, "notat": [27, 90], "part": 27, "reason": 28, "margin": [29, 36, 37, 51, 55, 94], "distribut": [30, 31, 55, 57, 60, 67, 75, 94], "joint": 30, "pdf": 30, "chang": 30, "variabl": [30, 60, 78], "formula": 30, "continu": 30, "multipl": 30, "dimens": 30, "exampl": [30, 31, 34, 64, 66, 75, 81], "anoth": [30, 31], "log": [30, 36, 63, 66, 92, 94], "normal": [30, 31, 36, 40, 41, 42, 75, 78, 80], "repeat": [31, 71], "revisit": 31, "choic": [31, 67, 90], "succinctli": 31, "state": [31, 92], "task": 32, "build": [32, 51, 58, 73, 91], "role": 32, "make": 32, "sens": 32, "choos": [33, 34, 47, 60, 67, 81, 85, 86, 88], "uniform": 34, "jeffrei": 34, "why": [34, 41, 49, 52], "weakli": 34, "inform": [34, 63], "bet": 34, "farm": 34, "specifi": 34, "introduct": [35, 45, 50, 75, 89], "plot": [36, 38, 51, 53, 55, 73, 75], "spindl": [36, 58, 81], "size": [36, 40, 51, 58, 59, 61, 81], "singl": 36, "numer": [36, 37, 88], "quadratur": [36, 37], "prescript": 36, "1d": 36, "express": [36, 77], "2d": 36, "asid": [36, 72, 80], "speed": 36, "tubulin": [37, 42, 58, 59], "conserv": [37, 42, 59], "curs": 37, "dimension": [37, 90], "overcom": 37, "conjugaci": 38, "beta": 38, "binomi": 38, "pair": [38, 55], "find": 38, "comment": 38, "optim": [39, 40, 41, 42, 76, 77, 85, 86, 90], "case": [40, 62], "studi": [40, 62], "exploratori": 40, "independ": [40, 58, 59, 71, 92], "approxim": [40, 41, 42], "credibl": [40, 41], "interv": [40, 41], "how": [40, 57, 90, 92], "good": 40, "approach": 41, "summar": [41, 57], "its": 41, "demonstr": 41, "mai": 41, "skew": 41, "variat": [42, 54, 81], "covari": [42, 54, 75, 77], "displai": [42, 51, 52, 55, 56, 57], "best": [42, 51, 71], "fit": [42, 51], "line": 42, "further": 44, "read": [44, 97], "markov": [45, 51, 90], "chain": [45, 51], "mont": [45, 51, 61, 88, 89, 90], "carlo": [45, 51, 61, 88, 89, 90], "random": 46, "number": [46, 60, 75], "basic": [46, 52], "idea": [46, 81], "behind": 46, "transit": [47, 88, 90], "kernel": [47, 75, 77], "metropoli": 47, "hast": 47, "algorithm": [47, 81, 90], "detail": [47, 88], "balanc": 47, "warm": 48, "our": [51, 74], "engin": 51, "ecdf": [51, 73, 74], "mrna": [51, 74], "count": [51, 74], "burst": 51, "inter": 51, "time": [51, 88, 90], "all": [51, 58, 90], "gene": 51, "hello": 52, "world": [52, 71], "program": 52, "sai": 52, "hi": 52, "pars": [52, 53], "output": [52, 53], "arviz": [52, 55], "direct": 52, "we": [52, 90], "code": [52, 53, 72, 83, 92], "save": 52, "clean": 52, "shrapnel": 52, "mixtur": [53, 66], "label": 53, "switch": 53, "initi": 53, "walker": 53, "conclus": [53, 72, 74, 75], "updat": 54, "visual": 55, "examin": 55, "trace": 55, "bebi103": 55, "interpet": 55, "parallel": 55, "coordin": 55, "intepret": 55, "one": [55, 63], "iqplot": 55, "two": [55, 94], "corner": 55, "11": 56, "report": 57, "summari": [57, 59, 81], "some": 57, "error": [57, 61], "bar": 57, "rel": 57, "merit": 57, "each": 57, "text": 57, "12": 58, "predict": [58, 59, 63, 75, 76, 80], "droplet": 58, "take": [58, 94], "depend": 58, "total": 58, "concentr": 58, "indentifi": 58, "limit": 58, "behavior": 58, "assumpt": 58, "v_": 58, "mathrm": 58, "v_0": 58, "ll": 58, "do": [58, 90], "have": 58, "same": 58, "aspect": 58, "ratio": 58, "k": [58, 90], "bewar": 59, "14": 60, "collector": 60, "box": 60, "out": [60, 62, 63, 75], "explor": 60, "start": 60, "simpl": 60, "ad": 60, "flexibl": 60, "support": [60, 92], "posit": 60, "real": 60, "15": 61, "diagnost": [61, 62, 72, 73], "ani": 61, "gelman": 61, "rubin": 61, "r": 61, "hat": 61, "effect": 61, "standard": 61, "hmc": [61, 88], "diverg": [61, 63, 88], "tree": 61, "depth": 61, "e": 61, "bfmi": 61, "quickli": 61, "artifici": 62, "funnel": 62, "hell": 62, "conquer": 62, "adjust": [62, 74], "adapt_delta": 62, "noncent": [62, 72, 78], "hierarch": [62, 67, 68, 69, 70, 71, 72, 81], "featur": [62, 90], "17": 63, "comparison": [63, 65, 66], "metric": 63, "assess": 63, "close": 63, "entropi": 63, "kullback": 63, "leibler": 63, "expect": 63, "pointwis": [63, 66], "densiti": 63, "watanab": 63, "akaik": 63, "criterion": 63, "leav": 63, "elpd": 63, "weight": [63, 66], "select": 64, "regress": 64, "practic": [65, 66, 74, 77], "waic": 66, "loo": 66, "exchang": 67, "implement": [69, 72, 79, 90], "19": 70, "experi": 71, "revers": 71, "pool": [71, 92], "ident": 71, "both": 71, "structur": 72, "quick": 72, "input": 72, "draw": 72, "parametr": 72, "21": 73, "principl": 73, "pipelin": 73, "workflow": 73, "refer": 73, "terminologi": 73, "simul": [73, 74], "base": [73, 74], "calibr": [73, 74], "z": 73, "score": 73, "shrinkag": 73, "v": 73, "rank": 73, "histogram": 73, "full": 73, "relat": 74, "perform": 74, "sbc": 74, "new": 74, "23": 75, "gaussian": [75, 76, 78, 79, 88], "process": [75, 76, 78, 79, 92], "nonparametr": 75, "finit": 75, "point": 75, "mean": 75, "function": [75, 81], "center": 75, "scale": 75, "matrix": 75, "gp": [75, 77, 78, 80], "numpi": 75, "compos": 75, "valu": [75, 94], "hyperparamet": [76, 80], "scipi": 76, "obtain": [76, 92], "hyperprior": 76, "deriv": 77, "mat\u00e9rn": 77, "gradient": 77, "non": 78, "latent": 78, "poisson": 78, "24": 79, "includ": 80, "file": [80, 92], "main": 81, "q": [81, 90], "\u03b8": 81, "vi": 81, "automat": 81, "differenti": 81, "volum": 81, "multilevel": 81, "26": 82, "wrap": 82, "meet": 83, "lab": 83, "session": 83, "submiss": 83, "assign": 83, "grade": 83, "collabor": 83, "honor": 83, "commun": [83, 92], "ediquett": 83, "r1": 84, "review": [84, 85, 86, 94], "r2": [85, 86], "r3": 87, "just": [87, 96], "help": [87, 96], "more": 88, "hamiltonian": [88, 89, 90], "typic": [88, 90], "kinet": [88, 90], "energi": [88, 90], "euclidean": 88, "short": 88, "note": 88, "integr": [88, 90], "happen": 88, "r4": 89, "overview": [90, 98], "motiv": 90, "interest": 90, "high": 90, "space": 90, "But": 90, "question": 90, "remain": 90, "design": 90, "so": 90, "thi": 90, "lead": 90, "u": 90, "ideal": 90, "actual": 90, "consider": 90, "p": 90, "conclud": 90, "thought": 90, "r5": 91, "r6": [92, 93], "caltech": [92, 93], "hpc": [92, 93], "even": 92, "supercomput": 92, "hpcc": 92, "access": 92, "slurm": 92, "transfer": 92, "storag": 92, "pro": 92, "tip": 92, "concurr": 92, "between": 92, "share": 92, "run": 92, "foreword": 92, "r7": 94, "discret": 94, "logsumexp": 94, "cornerston": 94, "stabl": 94, "handl": 94, "vector": 94, "paremet": 94, "integ": 94, "\u03b1": 94, "gamma": 94, "via": 94, "r8": 95, "discuss": 95, "hw": 95, "project": 95, "propos": 95, "r9": 96, "tutori": 97, "due": 98, "date": 98, "weekli": 98}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"Homework 1.1: First attempts at Bayesian generative modeling (70 pts)": [[0, "Homework-1.1:-First-attempts-at-Bayesian-generative-modeling-(70-pts)"]], "1. Intuitive generative modeling": [[1, "intuitive-generative-modeling"]], "Homework 2.1: Overwhelming a prior (45 pts)": [[2, "Homework-2.1:-Overwhelming-a-prior-(45-pts)"]], "Homework 2.2: Exponential conjugate prior (55 pts)": [[3, "Homework-2.2:-Exponential-conjugate-prior-(55-pts)"]], "2. Analytical and graphical methods for analysis of the posterior": [[4, "analytical-and-graphical-methods-for-analysis-of-the-posterior"]], "Homework 3.1: Least squares (20 pts)": [[5, "Homework-3.1:-Least-squares-(20-pts)"]], "Homework 3.2: MAP estimates and zero-inflation for Drop-Seq controls (80 pts)": [[6, "Homework-3.2:-MAP-estimates-and-zero-inflation-for-Drop-Seq-controls-(80-pts)"]], "3. Maximum a posteriori parameter estimation": [[7, "maximum-a-posteriori-parameter-estimation"]], "Homework 4.1: Writing your own MCMC sampler (70 pts)": [[8, "Homework-4.1:-Writing-your-own-MCMC-sampler-(70-pts)"]], "Homework 4.2: MCMC with Boolean data (30 pts)": [[9, "Homework-4.2:-MCMC-with-Boolean-data-(30-pts)"]], "4. Sampling with MCMC": [[10, "sampling-with-mcmc"]], "BE/Bi 103 b: Statistical Inference in the Biological Sciences": [[11, "be-bi-103-b-statistical-inference-in-the-biological-sciences"]], "Useful links": [[11, "useful-links"]], "People": [[11, "people"]], "Lessons": [[11, null]], "Homework": [[11, null], [83, "homework"]], "Schedule": [[11, null]], "Policies": [[11, null]], "Resources": [[11, null]], "Previous editions of the course": [[11, "previous-editions-of-the-course"]], "E1. To be completed after lesson 5": [[12, "E1.-To-be-completed-after-lesson-5"]], "Exercise 1.1": [[12, "Exercise-1.1"]], "Exercise 1.2": [[12, "Exercise-1.2"]], "Exercise 1.3": [[12, "Exercise-1.3"]], "Exercise 1.4": [[12, "Exercise-1.4"]], "E2. To be completed after lesson 6": [[13, "E2.-To-be-completed-after-lesson-6"]], "Exercise 2.1": [[13, "Exercise-2.1"]], "Exercise 2.2": [[13, "Exercise-2.2"]], "Exercise 2.3": [[13, "Exercise-2.3"]], "Exercise 2.4": [[13, "Exercise-2.4"]], "Exercise 2.5": [[13, "Exercise-2.5"]], "E3. To be completed after lesson 10": [[14, "E3.-To-be-completed-after-lesson-10"]], "Exercise 3.1": [[14, "Exercise-3.1"]], "Exercise 3.2": [[14, "Exercise-3.2"]], "Exercise 3.3": [[14, "Exercise-3.3"]], "Exercise 3.4": [[14, "Exercise-3.4"]], "E4. To be completed after lesson 13": [[15, "E4.-To-be-completed-after-lesson-13"]], "Exercise 4.1": [[15, "Exercise-4.1"]], "Exercise 4.2": [[15, "Exercise-4.2"]], "Exercise 4.3": [[15, "Exercise-4.3"]], "Exercise 4.4": [[15, "Exercise-4.4"]], "E5. To be completed after lesson 16": [[16, "E5.-To-be-completed-after-lesson-16"]], "Exercise 5.1": [[16, "Exercise-5.1"]], "Exercise 5.2": [[16, "Exercise-5.2"]], "Exercise 5.3": [[16, "Exercise-5.3"]], "Exercise 5.4": [[16, "Exercise-5.4"]], "E6. To be completed after lesson 18": [[17, "E6.-To-be-completed-after-lesson-18"]], "Exercise 6.1": [[17, "Exercise-6.1"]], "Exercise 6.2": [[17, "Exercise-6.2"]], "Exercise 6.3": [[17, "Exercise-6.3"]], "Exercise 6.4": [[17, "Exercise-6.4"]], "E7. To be completed after lesson 20": [[18, "E7.-To-be-completed-after-lesson-20"]], "Exercise 7.1": [[18, "Exercise-7.1"]], "Exercise 7.2": [[18, "Exercise-7.2"]], "Exercise 7.3": [[18, "Exercise-7.3"]], "Exercise 7.4": [[18, "Exercise-7.4"]], "Exercise 7.5": [[18, "Exercise-7.5"]], "E8. To be completed after lesson 22": [[19, "E8.-To-be-completed-after-lesson-22"]], "Exercise 8.1": [[19, "Exercise-8.1"]], "Exercise 8.2": [[19, "Exercise-8.2"]], "Exercise 8.3": [[19, "Exercise-8.3"]], "E9. To be completed after lesson 25": [[20, "E9.-To-be-completed-after-lesson-25"]], "Exercise 9.1": [[20, "Exercise-9.1"]], "Exercise 9.2": [[20, "Exercise-9.2"]], "Exercise 9.3": [[20, "Exercise-9.3"]], "Exercise 9.4": [[20, "Exercise-9.4"]], "AWS setup and usage": [[21, "AWS-setup-and-usage"]], "1. Create an Amazon Web Services account": [[21, "1.-Create-an-Amazon-Web-Services-account"]], "2. Launch your instance": [[21, "2.-Launch-your-instance"]], "3. Connect to your instance": [[21, "3.-Connect-to-your-instance"]], "4. Launch JupyterLab": [[21, "4.-Launch-JupyterLab"]], "5. Copying results to and from AWS to your local machine": [[21, "5.-Copying-results-to-and-from-AWS-to-your-local-machine"]], "6. Exiting": [[21, "6.-Exiting"]], "7. Seriously. Stop your instances if you are not using them.": [[21, "7.-Seriously.-Stop-your-instances-if-you-are-not-using-them."]], "8. Using your instance again": [[21, "8.-Using-your-instance-again"]], "9. Terminate your instances after the class is over": [[21, "9.-Terminate-your-instances-after-the-class-is-over"]], "Using Google Colab": [[22, "Using-Google-Colab"]], "Watchouts when using Colab": [[22, "Watchouts-when-using-Colab"]], "Software in Colab": [[22, "Software-in-Colab"]], "A sample calculation": [[22, "A-sample-calculation"]], "Computing environment": [[22, "Computing-environment"], [24, "Computing-environment"], [36, "Computing-environment"], [37, "Computing-environment"], [38, "Computing-environment"], [40, "Computing-environment"], [41, "Computing-environment"], [42, "Computing-environment"], [51, "Computing-environment"], [52, "Computing-environment"], [53, "Computing-environment"], [54, "Computing-environment"], [55, "Computing-environment"], [57, "Computing-environment"], [58, "Computing-environment"], [59, "Computing-environment"], [61, "Computing-environment"], [62, "Computing-environment"], [64, "Computing-environment"], [66, "Computing-environment"], [69, "Computing-environment"], [74, "Computing-environment"], [75, "Computing-environment"], [76, "Computing-environment"], [77, "Computing-environment"], [78, "Computing-environment"], [80, "Computing-environment"], [81, "Computing-environment"], [94, "Computing-environment"]], "0. Setting up computing resources": [[23, "setting-up-computing-resources"]], "Configuring your machine": [[24, "Configuring-your-machine"]], "Installing Python packages": [[24, "Installing-Python-packages"]], "Stan installation": [[24, "Stan-installation"]], "Configuring a C++ toolchain for MacOS": [[24, "Configuring-a-C++-toolchain-for-MacOS"]], "Configuring a C++ toolchain for Windows": [[24, "Configuring-a-C++-toolchain-for-Windows"]], "Configuring a C++ toolchain for Linux": [[24, "Configuring-a-C++-toolchain-for-Linux"]], "Installing Stan with CmdStanPy": [[24, "Installing-Stan-with-CmdStanPy"]], "Checking your Stan installation": [[24, "Checking-your-Stan-installation"]], "Probability as the logic of science": [[25, "probability-as-the-logic-of-science"]], "What is statistical inference?": [[25, "what-is-statistical-inference"]], "The problem of probability": [[25, "the-problem-of-probability"]], "Frequentist probability.": [[25, "frequentist-probability"]], "Bayesian probability.": [[25, "bayesian-probability"]], "Desiderata for Bayesian probability": [[25, "desiderata-for-bayesian-probability"]], "The sum rule, the product rule, and conditional probability": [[25, "the-sum-rule-the-product-rule-and-conditional-probability"]], "Application to scientific measurement": [[25, "application-to-scientific-measurement"]], "Bayes\u2019s Theorem": [[25, "bayess-theorem"]], "The prior probability.": [[25, "the-prior-probability"]], "The likelihood.": [[25, "the-likelihood"]], "The evidence.": [[25, "the-evidence"]], "The posterior probability.": [[25, "the-posterior-probability"]], "Bayes\u2019s theorem as a model for learning": [[26, "bayes-s-theorem-as-a-model-for-learning"]], "Notation of parts of Bayes\u2019s Theorem": [[27, "notation-of-parts-of-bayess-theorem"]], "1. Probability and the logic of scientific reasoning": [[28, "probability-and-the-logic-of-scientific-reasoning"]], "Marginalization": [[29, "marginalization"]], "Probability distributions": [[30, "probability-distributions"]], "Joint and conditional distributions and Bayes\u2019s theorem for PDFs": [[30, "joint-and-conditional-distributions-and-bayess-theorem-for-pdfs"]], "Change of variables formula for continuous distributions": [[30, "change-of-variables-formula-for-continuous-distributions"]], "Generalization to multiple dimensions": [[30, "generalization-to-multiple-dimensions"]], "An example of change of variables": [[30, "an-example-of-change-of-variables"]], "Another example of change of variables: the Log-Normal distribution": [[30, "another-example-of-change-of-variables-the-log-normal-distribution"]], "Bayesian modeling example: parameter estimation from repeated measurements": [[31, "bayesian-modeling-example-parameter-estimation-from-repeated-measurements"]], "The likelihood": [[31, "the-likelihood"], [58, "The-likelihood"]], "The Normal distribution": [[31, "the-normal-distribution"]], "The likelihood revisited: and another parameter": [[31, "the-likelihood-revisited-and-another-parameter"]], "Choice of prior": [[31, "choice-of-prior"]], "Succinctly stating the model": [[31, "succinctly-stating-the-model"]], "Tasks of Bayesian modeling": [[32, "tasks-of-bayesian-modeling"]], "Model building": [[32, "model-building"]], "The role of the prior": [[32, "the-role-of-the-prior"]], "Making sense of the posterior": [[32, "making-sense-of-the-posterior"]], "Choosing likelihoods": [[33, "choosing-likelihoods"]], "Choosing priors": [[34, "choosing-priors"]], "Uniform priors": [[34, "uniform-priors"]], "Jeffreys priors": [[34, "jeffreys-priors"]], "Example Jeffreys priors": [[34, "example-jeffreys-priors"]], "Why not use Jeffreys priors?": [[34, "why-not-use-jeffreys-priors"]], "Weakly informative priors": [[34, "weakly-informative-priors"]], "Conjugate priors": [[34, "conjugate-priors"]], "The bet-the-farm method of specifying weakly informative priors": [[34, "the-bet-the-farm-method-of-specifying-weakly-informative-priors"]], "2. Introduction to Bayesian modeling": [[35, "introduction-to-bayesian-modeling"]], "3. Plotting posteriors": [[36, "3.-Plotting-posteriors"]], "The data set": [[36, "The-data-set"], [51, "The-data-set"], [58, "The-data-set"], [61, "The-data-set"]], "Models for spindle size": [[36, "Models-for-spindle-size"]], "Plotting the posterior for a single parameter": [[36, "Plotting-the-posterior-for-a-single-parameter"]], "Analytically marginalizing": [[36, "Analytically-marginalizing"]], "Computing and plotting the marginalized posterior": [[36, "Computing-and-plotting-the-marginalized-posterior"]], "Normalizing by numerical quadrature": [[36, "Normalizing-by-numerical-quadrature"]], "A prescription for plotting 1D posteriors": [[36, "A-prescription-for-plotting-1D-posteriors"]], "An analytical expression for the marginal posterior": [[36, "An-analytical-expression-for-the-marginal-posterior"]], "Plotting a 2D posterior": [[36, "Plotting-a-2D-posterior"]], "Aside: Speed of likelihood calculation": [[36, "Aside:-Speed-of-likelihood-calculation"]], "Computing the log of a 2D posterior": [[36, "Computing-the-log-of-a-2D-posterior"]], "4. Marginalization by numerical quadrature": [[37, "4.-Marginalization-by-numerical-quadrature"]], "The tubulin conservation model": [[37, "The-tubulin-conservation-model"], [42, "The-tubulin-conservation-model"], [59, "The-tubulin-conservation-model"]], "Analytical marginalization": [[37, "Analytical-marginalization"]], "Numerical marginalization": [[37, "Numerical-marginalization"]], "The curse of dimensionality and overcoming it": [[37, "The-curse-of-dimensionality-and-overcoming-it"]], "5. Conjugacy": [[38, "5.-Conjugacy"]], "The Beta-Binomial conjugate pair": [[38, "The-Beta-Binomial-conjugate-pair"]], "Finding the conjugate": [[38, "Finding-the-conjugate"]], "Plots of the posteriors": [[38, "Plots-of-the-posteriors"]], "Comments on conjugates": [[38, "Comments-on-conjugates"]], "6. Parameter estimation by optimization": [[39, "parameter-estimation-by-optimization"]], "Parameter estimation by optimization case study: Normal likelihood": [[40, "Parameter-estimation-by-optimization-case-study:-Normal-likelihood"]], "Exploratory data analysis": [[40, "Exploratory-data-analysis"]], "Independent size model": [[40, "Independent-size-model"]], "Estimation of the MAP parameters": [[40, "Estimation-of-the-MAP-parameters"]], "Normal approximation of the posterior": [[40, "Normal-approximation-of-the-posterior"]], "Credible intervals": [[40, "Credible-intervals"], [41, "Credible-intervals"]], "How good is the approximation?": [[40, "How-good-is-the-approximation?"]], "Bayesian approach to parameter estimation by optimization": [[41, "Bayesian-approach-to-parameter-estimation-by-optimization"]], "Summarizing the posterior near its maximum": [[41, "Summarizing-the-posterior-near-its-maximum"]], "Demonstration of the Normal approximation": [[41, "Demonstration-of-the-Normal-approximation"]], "Credible intervals may be skewed": [[41, "Credible-intervals-may-be-skewed"]], "Why use the MAP for parameter estimation?": [[41, "Why-use-the-MAP-for-parameter-estimation?"]], "Parameter estimation by optimization: A variate-covariate model": [[42, "Parameter-estimation-by-optimization:-A-variate-covariate-model"]], "Parameter estimation": [[42, "Parameter-estimation"]], "Checking the Normal approximation": [[42, "Checking-the-Normal-approximation"]], "Displaying the best fit line": [[42, "Displaying-the-best-fit-line"]], "Further reading on MCMC": [[44, "further-reading-on-mcmc"]], "7. Introduction to Markov chain Monte Carlo": [[45, "introduction-to-markov-chain-monte-carlo"]], "Random number generation": [[46, "random-number-generation"]], "The basic idea behind MCMC": [[46, "the-basic-idea-behind-mcmc"]], "Generating a transition kernel: The Metropolis-Hastings algorithm": [[47, "generating-a-transition-kernel-the-metropolis-hastings-algorithm"]], "The algorithm/kernel": [[47, "the-algorithm-kernel"]], "Detailed balance": [[47, "detailed-balance"]], "Choosing the transition kernel": [[47, "choosing-the-transition-kernel"]], "Warm-up": [[48, "warm-up"]], "Why MCMC?": [[49, "why-mcmc"]], "8. Introduction to MCMC with Stan": [[50, "introduction-to-mcmc-with-stan"]], "Parameter estimation with Markov chain Monte Carlo": [[51, "Parameter-estimation-with-Markov-chain-Monte-Carlo"]], "Stan: Our MCMC engine": [[51, "Stan:-Our-MCMC-engine"]], "ECDFs of mRNA counts": [[51, "ECDFs-of-mRNA-counts"], [74, "ECDFs-of-mRNA-counts"]], "Building a generative model": [[51, "Building-a-generative-model"], [58, "Building-a-generative-model"]], "Priors for burst size and inter-burst time": [[51, "Priors-for-burst-size-and-inter-burst-time"]], "Sampling the posterior": [[51, "Sampling-the-posterior"]], "Plots of the samples": [[51, "Plots-of-the-samples"]], "Marginalizing the posterior": [[51, "Marginalizing-the-posterior"]], "Analysis for all genes": [[51, "Analysis-for-all-genes"]], "Display of \u201cbest fit\u201d": [[51, "Display-of-%22best-fit%22"]], "\u201cHello, world\u201d \u2014Stan": [[52, "%22Hello,-world%22-\u2014Stan"]], "Basics of Stan programs": [[52, "Basics-of-Stan-programs"]], "Say hi, Stan": [[52, "Say-hi,-Stan"]], "Parsing output with ArviZ": [[52, "Parsing-output-with-ArviZ"]], "Direct sampling": [[52, "Direct-sampling"]], "Why are we using that?": [[52, "Why-are-we-using-that?"]], "Displaying your Stan code": [[52, "Displaying-your-Stan-code"]], "Saving samples": [[52, "Saving-samples"]], "Cleaning up the shrapnel": [[52, "Cleaning-up-the-shrapnel"]], "9. Mixture models and label switching with MCMC": [[53, "9.-Mixture-models-and-label-switching-with-MCMC"]], "Mixture models": [[53, "Mixture-models"]], "Coding up a mixture model": [[53, "Coding-up-a-mixture-model"]], "Parsing the output": [[53, "Parsing-the-output"]], "Plotting the samples": [[53, "Plotting-the-samples"]], "Label switching": [[53, "Label-switching"]], "Initializing walkers": [[53, "Initializing-walkers"]], "Conclusions": [[53, "Conclusions"], [72, "Conclusions"], [74, "Conclusions"], [75, "Conclusions"]], "10. Variate-covariate models with MCMC": [[54, "10.-Variate-covariate-models-with-MCMC"]], "Updated generative model": [[54, "Updated-generative-model"]], "Using Stan to sample": [[54, "Using-Stan-to-sample"]], "Display of MCMC samples": [[55, "Display-of-MCMC-samples"]], "Visualization with ArviZ": [[55, "Visualization-with-ArviZ"]], "The model and samples": [[55, "The-model-and-samples"]], "Examining traces": [[55, "Examining-traces"]], "Trace plots": [[55, "Trace-plots"]], "Trace plots with ArviZ": [[55, "Trace-plots-with-ArviZ"]], "Trace plots with bebi103": [[55, "Trace-plots-with-bebi103"]], "Interpetation of trace plots": [[55, "Interpetation-of-trace-plots"]], "Parallel coordinate plots": [[55, "Parallel-coordinate-plots"]], "Parallel coordinate plots with ArviZ": [[55, "Parallel-coordinate-plots-with-ArviZ"]], "Parallel coordinate plots with bebi103": [[55, "Parallel-coordinate-plots-with-bebi103"]], "Intepretation of parallel coordinate plots": [[55, "Intepretation-of-parallel-coordinate-plots"]], "Plots of marginalized distributions": [[55, "Plots-of-marginalized-distributions"]], "Plotting marginalized distributions of one parameter": [[55, "Plotting-marginalized-distributions-of-one-parameter"]], "Plotting marginalized distributions with ArviZ": [[55, "Plotting-marginalized-distributions-with-ArviZ"]], "Plotting marginalized distributions with iqplot": [[55, "Plotting-marginalized-distributions-with-iqplot"]], "Marginal posteriors of two parameters and corner plots": [[55, "Marginal-posteriors-of-two-parameters-and-corner-plots"]], "Pair plots with ArviZ": [[55, "Pair-plots-with-ArviZ"]], "Corner plots with bebi103": [[55, "Corner-plots-with-bebi103"]], "11. Display of MCMC results": [[56, "display-of-mcmc-results"]], "Reporting summaries of the posterior": [[57, "Reporting-summaries-of-the-posterior"]], "Reporting summaries of MCMC samples": [[57, "Reporting-summaries-of-MCMC-samples"]], "Some distributions to sample": [[57, "Some-distributions-to-sample"]], "Summarizing the \u201cMCMC\u201d results with error bars": [[57, "Summarizing-the-%22MCMC%22-results-with-error-bars"]], "Relative merits of each method": [[57, "Relative-merits-of-each-method"]], "How to display the summary in text.": [[57, "How-to-display-the-summary-in-text."]], "12. Model building with prior predictive checks": [[58, "12.-Model-building-with-prior-predictive-checks"]], "Model 1: Spindle size is independent of droplet size": [[58, "Model-1:-Spindle-size-is-independent-of-droplet-size"]], "The prior": [[58, "The-prior"]], "The prior, take 2": [[58, "The-prior,-take-2"]], "Prior predictive checks": [[58, "Prior-predictive-checks"], [58, "id1"]], "The prior, take 3": [[58, "The-prior,-take-3"]], "Prior predictive checks, take 2": [[58, "Prior-predictive-checks,-take-2"]], "Prior predictive checks with Stan": [[58, "Prior-predictive-checks-with-Stan"]], "Model 2: Spindle size dependent on total tubulin concentration": [[58, "Model-2:-Spindle-size-dependent-on-total-tubulin-concentration"]], "Indentifiability of parameters": [[58, "Indentifiability-of-parameters"]], "Limiting behavior": [[58, "Limiting-behavior"]], "Generative model": [[58, "Generative-model"]], "Checking model assumptions": [[58, "Checking-model-assumptions"]], "Is V_\\mathrm{s} / V_0 \\ll 1?": [[58, "Is-V_\\mathrm{s}-/-V_0-\\ll-1?"]], "Do all spindles have the same aspect ratio k?": [[58, "Do-all-spindles-have-the-same-aspect-ratio-k?"]], "13. Posterior predictive checks": [[59, "13.-Posterior-predictive-checks"]], "The independent size model": [[59, "The-independent-size-model"]], "Beware the summary statistic": [[59, "Beware-the-summary-statistic"]], "14. Collector\u2019s box of distributions": [[60, "collector-s-box-of-distributions"]], "Check out the Distribution Explorer": [[60, "check-out-the-distribution-explorer"]], "Choosing distributions": [[60, "choosing-distributions"]], "Starting simple and adding flexibility": [[60, "starting-simple-and-adding-flexibility"]], "Priors for variables with support on the set of positive real numbers": [[60, "priors-for-variables-with-support-on-the-set-of-positive-real-numbers"]], "15. MCMC diagnostics": [[61, "15.-MCMC-diagnostics"]], "The model": [[61, "The-model"]], "Diagnostics for any MCMC sampler": [[61, "Diagnostics-for-any-MCMC-sampler"]], "The Gelman-Rubin R-hat statistic": [[61, "The-Gelman-Rubin-R-hat-statistic"]], "Effective samples size": [[61, "Effective-samples-size"]], "Monte Carlo standard error": [[61, "Monte-Carlo-standard-error"]], "Diagnostics for HMC": [[61, "Diagnostics-for-HMC"]], "Divergences": [[61, "Divergences"]], "Tree depth": [[61, "Tree-depth"]], "E-BFMI": [[61, "E-BFMI"]], "Quickly checking the diagnostics": [[61, "Quickly-checking-the-diagnostics"]], "16. A diagnostics case study: Artificial funnel of hell": [[62, "16.-A-diagnostics-case-study:-Artificial-funnel-of-hell"]], "Sampling out of the funnel": [[62, "Sampling-out-of-the-funnel"]], "Conquering the Funnel of Hell": [[62, "Conquering-the-Funnel-of-Hell"]], "Adjusting adapt_delta": [[62, "Adjusting-adapt_delta"]], "Noncentering": [[62, "Noncentering"], [78, "Noncentering"]], "Hierarchical models feature a Funnel of Hell": [[62, "Hierarchical-models-feature-a-Funnel-of-Hell"]], "17. Model comparison": [[63, "model-comparison"]], "Metrics for model assessment": [[63, "metrics-for-model-assessment"]], "Posterior predictive checks": [[63, "posterior-predictive-checks"]], "Closeness metrics": [[63, "closeness-metrics"]], "Entropy and the Kullback-Leibler divergence": [[63, "entropy-and-the-kullback-leibler-divergence"]], "The expected log pointwise predictive density": [[63, "the-expected-log-pointwise-predictive-density"]], "The Watanabe-Akaike information criterion": [[63, "the-watanabe-akaike-information-criterion"]], "Leave-one-out estimates of elpd": [[63, "leave-one-out-estimates-of-elpd"]], "The Akaike weights": [[63, "the-akaike-weights"]], "Example model selection: regression": [[64, "Example-model-selection:-regression"]], "18. Model comparison in practice": [[65, "model-comparison-in-practice"]], "Model comparison in practice": [[66, "Model-comparison-in-practice"]], "An example model comparison": [[66, "An-example-model-comparison"]], "Computing the pointwise log likelihood": [[66, "Computing-the-pointwise-log-likelihood"]], "Computing the WAIC and LOO": [[66, "Computing-the-WAIC-and-LOO"]], "Calculations with the mixture model": [[66, "Calculations-with-the-mixture-model"]], "Computing the weights": [[66, "Computing-the-weights"]], "Choosing a hierarchical prior": [[67, "Choosing-a-hierarchical-prior"]], "Exchangeability": [[67, "Exchangeability"]], "Choice of the conditional distribution": [[67, "Choice-of-the-conditional-distribution"]], "Generalization of hierarchical models": [[68, "Generalization-of-hierarchical-models"]], "Implementation of a hierarchical model": [[69, "Implementation-of-a-hierarchical-model"]], "19. Hierarchical models": [[70, "hierarchical-models"]], "Modeling repeated experiments": [[71, "Modeling-repeated-experiments"]], "A model for reversals": [[71, "A-model-for-reversals"]], "Pooled data: identical parameters": [[71, "Pooled-data:-identical-parameters"]], "Independent parameters": [[71, "Independent-parameters"]], "The best of both worlds: A hierarchical model": [[71, "The-best-of-both-worlds:-A-hierarchical-model"]], "20. Implementation of hierarchical models": [[72, "20.-Implementation-of-hierarchical-models"]], "Hierarchical model structure": [[72, "Hierarchical-model-structure"]], "Coding up the hierarchical model in Stan": [[72, "Coding-up-the-hierarchical-model-in-Stan"]], "A quick aside: generating a data set": [[72, "A-quick-aside:-generating-a-data-set"]], "Generating input data for Stan": [[72, "Generating-input-data-for-Stan"]], "Drawing samples and checking diagnostics": [[72, "Drawing-samples-and-checking-diagnostics"]], "A noncentered parametrization": [[72, "A-noncentered-parametrization"]], "21. Principled analysis pipelines": [[73, "21.-Principled-analysis-pipelines"]], "Building a workflow": [[73, "Building-a-workflow"]], "References and terminology": [[73, "References-and-terminology"]], "Simulation-based calibration": [[73, "Simulation-based-calibration"]], "Diagnostics": [[73, "Diagnostics"]], "z-score": [[73, "z-score"]], "Shrinkage": [[73, "Shrinkage"]], "Shrinkage vs. z-score plot": [[73, "Shrinkage-vs.-z-score-plot"]], "Rank statistics": [[73, "Rank-statistics"]], "A rank statistic ECDF plot": [[73, "A-rank-statistic-ECDF-plot"]], "Rank statistic histograms": [[73, "Rank-statistic-histograms"]], "A full principled pipeline": [[73, "A-full-principled-pipeline"]], "22: Simulation based calibration and related checks in practice": [[74, "22:-Simulation-based-calibration-and-related-checks-in-practice"]], "The generative model": [[74, "The-generative-model"]], "Performing SBC": [[74, "Performing-SBC"]], "An adjusted prior": [[74, "An-adjusted-prior"]], "Sampling with our new model": [[74, "Sampling-with-our-new-model"]], "23. Introduction to Gaussian processes": [[75, "23.-Introduction-to-Gaussian-processes"]], "Predicting using posterior estimates": [[75, "Predicting-using-posterior-estimates"]], "An example data set": [[75, "An-example-data-set"]], "Processes and nonparametric Bayesian inference": [[75, "Processes-and-nonparametric-Bayesian-inference"]], "Gaussian processes with a finite number of points": [[75, "Gaussian-processes-with-a-finite-number-of-points"]], "The mean function and centering and scaling": [[75, "The-mean-function-and-centering-and-scaling"]], "The kernel and covariance matrix": [[75, "The-kernel-and-covariance-matrix"]], "Sampling out of a Gaussian process prior": [[75, "Sampling-out-of-a-Gaussian-process-prior"]], "Sampling out of a GP prior using Stan": [[75, "Sampling-out-of-a-GP-prior-using-Stan"]], "Sampling out of a GP prior using Numpy": [[75, "Sampling-out-of-a-GP-prior-using-Numpy"]], "Composing kernels": [[75, "Composing-kernels"]], "Inference with GPs": [[75, "Inference-with-GPs"]], "Normal likelihoods with Gaussian process priors": [[75, "Normal-likelihoods-with-Gaussian-process-priors"]], "The posterior predictive distribution of function values": [[75, "The-posterior-predictive-distribution-of-function-values"]], "Computing the parameters of the posterior predictive distribution": [[75, "Computing-the-parameters-of-the-posterior-predictive-distribution"]], "Plotting an analytical posterior": [[75, "Plotting-an-analytical-posterior"]], "Gaussian process hyperparameters by optimization": [[76, "Gaussian-process-hyperparameters-by-optimization"]], "Priors for hyperparameters": [[76, "Priors-for-hyperparameters"]], "Computing the MAP with SciPy": [[76, "Computing-the-MAP-with-SciPy"]], "Posterior predictive samples": [[76, "Posterior-predictive-samples"]], "Obtaining hyperpriors by optimizing with Stan": [[76, "Obtaining-hyperpriors-by-optimizing-with-Stan"]], "Calculating derivatives from data with GPs": [[77, "Calculating-derivatives-from-data-with-GPs"]], "Derivatives of GPs": [[77, "Derivatives-of-GPs"]], "Derivative of the squared exponential kernel": [[77, "Derivative-of-the-squared-exponential-kernel"]], "Derivatives of the Mat\u00e9rn kernel": [[77, "Derivatives-of-the-Mat\u00e9rn-kernel"]], "Expressions for the gradient and covariance of the gradient": [[77, "Expressions-for-the-gradient-and-covariance-of-the-gradient"]], "Derivatives of GPs in practice using optimization": [[77, "Derivatives-of-GPs-in-practice-using-optimization"]], "Derivatives with a Mat\u00e9rn kernel": [[77, "Derivatives-with-a-Mat\u00e9rn-kernel"]], "Sampling derivatives with Stan": [[77, "Sampling-derivatives-with-Stan"]], "Gaussian processes with non-Normal likelihoods": [[78, "Gaussian-processes-with-non-Normal-likelihoods"]], "Generating samples of latent variables using MCMC": [[78, "Generating-samples-of-latent-variables-using-MCMC"]], "A GP generative model": [[78, "A-GP-generative-model"]], "Sampling latent variables with Stan": [[78, "Sampling-latent-variables-with-Stan"]], "Sampling with a Poisson likelihood": [[78, "Sampling-with-a-Poisson-likelihood"]], "24. Implementation of Gaussian processes": [[79, "implementation-of-gaussian-processes"]], "MCMC with GPs with Normal likelihoods": [[80, "MCMC-with-GPs-with-Normal-likelihoods"]], "Hyperparameter estimation using MCMC": [[80, "Hyperparameter-estimation-using-MCMC"]], "Posterior predictive checks with GPs": [[80, "Posterior-predictive-checks-with-GPs"]], "Aside: Stan include files": [[80, "Aside:-Stan-include-files"]], "25. Variational Bayesian inference": [[81, "25.-Variational-Bayesian-inference"]], "The main ideas of variational inference": [[81, "The-main-ideas-of-variational-inference"]], "Choosing Q(\u03b8)": [[81, "Choosing-Q(\u03b8)"]], "Summary of VI algorithm": [[81, "Summary-of-VI-algorithm"]], "Automatic Differentiation Variational Inference and Stan": [[81, "Automatic-Differentiation-Variational-Inference-and-Stan"]], "Examples": [[81, "Examples"]], "Example 1: Spindle size as a function of volume": [[81, "Example-1:-Spindle-size-as-a-function-of-volume"]], "Example 2: A multilevel hierarchical model": [[81, "Example-2:-A-multilevel-hierarchical-model"]], "26: Wrap-up": [[82, "wrap-up"]], "Meetings": [[83, "meetings"]], "Lab sessions": [[83, "lab-sessions"]], "Submission of assignments": [[83, "submission-of-assignments"]], "Lessons and lesson exercises": [[83, "lessons-and-lesson-exercises"]], "Grading": [[83, "grading"]], "Collaboration policy and Honor Code": [[83, "collaboration-policy-and-honor-code"]], "Course communications": [[83, "course-communications"]], "\u201cEdiquette\u201d": [[83, "ediquette"]], "R1: Review of probability": [[84, "r1-review-of-probability"]], "R2: Choosing priors and review of optimization": [[85, "r2-choosing-priors-and-review-of-optimization"], [86, "r2-choosing-priors-and-review-of-optimization"]], "R3: Just homework help": [[87, "r3-just-homework-help"]], "More details on Hamiltonian Monte Carlo": [[88, "More-details-on-Hamiltonian-Monte-Carlo"]], "The typical set": [[88, "The-typical-set"]], "Hamiltonians": [[88, "Hamiltonians"]], "Hamiltonian Monte Carlo": [[88, "Hamiltonian-Monte-Carlo"]], "Transition using HMC": [[88, "Transition-using-HMC"]], "Choosing Kinetic Energy (Euclidean-Gaussian)": [[88, "Choosing-Kinetic-Energy-(Euclidean-Gaussian)"]], "A short note on integration times": [[88, "A-short-note-on-integration-times"]], "Numerical integration and what happens in divergences": [[88, "Numerical-integration-and-what-happens-in-divergences"]], "Computing Environment": [[88, "Computing-Environment"]], "R4. Introduction to Hamiltonian Monte Carlo": [[89, "r4-introduction-to-hamiltonian-monte-carlo"]], "Overview of Hamiltonian Monte Carlo": [[90, "Overview-of-Hamiltonian-Monte-Carlo"]], "Notation": [[90, "Notation"]], "Motivating interest:": [[90, "Motivating-interest:"]], "Features of a high-dimensional space Q:": [[90, "Features-of-a-high-dimensional-space-Q:"]], "But the question then remains: how do we design an algorithm to sample the typical set?": [[90, "But-the-question-then-remains:-how-do-we-design-an-algorithm-to-sample-the-typical-set?"]], "So this all leads us to \u2026 \ud83c\udf89 Hamiltonian Monte Carlo! \ud83c\udf89": [[90, "So-this-all-leads-us-to-...-\ud83c\udf89-Hamiltonian-Monte-Carlo!-\ud83c\udf89"]], "The Ideal Hamiltonian Markov Transition": [[90, "The-Ideal-Hamiltonian-Markov-Transition"]], "Actual Implementation of Hamiltonian Markov Transition Considerations": [[90, "Actual-Implementation-of-Hamiltonian-Markov-Transition-Considerations"]], "(A) Optimizing Choice of Kinetic Energy K(q, p)": [[90, "(A)-Optimizing-Choice-of-Kinetic-Energy-K(q,-p)"]], "(B) Integration method": [[90, "(B)-Integration-method"]], "(C) Integration time": [[90, "(C)-Integration-time"]], "Concluding thoughts": [[90, "Concluding-thoughts"]], "R5: Bayesian model building": [[91, "R5:-Bayesian-model-building"]], "R6: MCMC using Caltech\u2019s HPC": [[92, "R6:-MCMC-using-Caltech's-HPC"], [93, "r6-mcmc-using-caltech-s-hpc"]], "What even is a supercomputer?": [[92, "What-even-is-a-supercomputer?"]], "How to use the Caltech HPCC?": [[92, "How-to-use-the-Caltech-HPCC?"]], "Obtaining access": [[92, "Obtaining-access"]], "Logging on": [[92, "Logging-on"]], "SLURM": [[92, "SLURM"]], "Transferring files": [[92, "Transferring-files"]], "Storage": [[92, "Storage"]], "Software": [[92, "Software"], [97, "software"]], "Support": [[92, "Support"]], "Pro-Tip for writing code on the HPCC": [[92, "Pro-Tip-for-writing-code-on-the-HPCC"]], "Concurrency with Python": [[92, "Concurrency-with-Python"]], "Independent processes": [[92, "Independent-processes"]], "Pooling between processes": [[92, "Pooling-between-processes"]], "Sharing state between processes": [[92, "Sharing-state-between-processes"]], "Communicating between processes": [[92, "Communicating-between-processes"]], "Running Stan on the HPCC": [[92, "Running-Stan-on-the-HPCC"]], "Foreword": [[92, "Foreword"]], "R7: Sampling discrete parameters with Stan": [[94, "R7:-Sampling-discrete-parameters-with-Stan"]], "Review of LogSumExp, the cornerstone of stable marginalization with discrete parameters": [[94, "Review-of-LogSumExp,-the-cornerstone-of-stable-marginalization-with-discrete-parameters"]], "Handling log probabilities of discrete valued vectors in Stan": [[94, "Handling-log-probabilities-of-discrete-valued-vectors-in-Stan"]], "Discrete paremeters in Stan: integer \u03b1 for gamma distribution": [[94, "Discrete-paremeters-in-Stan:-integer-\u03b1-for-gamma-distribution"]], "Take two: handling discrete parameters via marginalization": [[94, "Take-two:-handling-discrete-parameters-via-marginalization"]], "R8: Discussion of HW 10 project proposals": [[95, "r8-discussion-of-hw-10-project-proposals"]], "R9: Just homework help": [[96, "r9-just-homework-help"]], "Reading/tutorials": [[97, "reading-tutorials"]], "Schedule overview": [[98, "schedule-overview"]], "Homework due dates": [[98, "homework-due-dates"]], "Lesson exercise due dates": [[98, "lesson-exercise-due-dates"]], "Weekly schedule": [[98, "weekly-schedule"]]}, "indexentries": {}})