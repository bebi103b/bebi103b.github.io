Search.setIndex({"docnames": ["homework/01/hw1.1", "homework/01/index", "homework/02/hw2.1", "homework/02/hw2.2", "homework/02/index", "index", "lesson_exercises/exercise_01", "lesson_exercises/exercise_02", "lesson_exercises/exercise_03", "lesson_exercises/exercise_04", "lesson_exercises/exercise_05", "lesson_exercises/exercise_06", "lesson_exercises/exercise_07", "lesson_exercises/exercise_08", "lesson_exercises/exercise_09", "lessons/00/aws_setup", "lessons/00/colab", "lessons/00/index", "lessons/00/setup", "lessons/01/bayes_logic", "lessons/01/bayes_model_for_learning", "lessons/01/bayes_notation", "lessons/01/index", "lessons/01/marginalization", "lessons/01/probability_distributions", "lessons/02/bayesian_modeling_example", "lessons/02/bayesian_modeling_tasks", "lessons/02/choice_of_likelihood", "lessons/02/choice_of_prior", "lessons/02/index", "lessons/03/plotting_posteriors", "lessons/04/marginalization_by_numerical_quadrature", "lessons/05/conjugacy", "lessons/06/index", "lessons/06/normal_optimization", "lessons/06/optimization_basics", "lessons/06/variate_covariate_optimization", "lessons/07/Untitled", "lessons/07/further_reading", "lessons/07/index", "lessons/07/mcmc_idea", "lessons/07/metropolis_hastings", "lessons/07/warm_up", "lessons/07/why_mcmc", "lessons/08/index", "lessons/08/parameter_estimation_with_mcmc", "lessons/08/stan_hello_world", "lessons/09/mixture_model_stan", "lessons/10/variate_covariate_with_stan", "lessons/11/display_of_mcmc_samples", "lessons/11/index", "lessons/11/posterior_summaries", "lessons/12/prior_predictive_checks", "lessons/13/posterior_predictive_checks", "lessons/14/box_of_distributions", "lessons/15/mcmc_diagnostics", "lessons/16/funnel_of_hell", "lessons/17/model_comparison", "lessons/18/comparing_regressions", "lessons/18/index", "lessons/18/model_comparison", "lessons/19/choosing_a_hierarchical_prior", "lessons/19/generalization", "lessons/19/implementation", "lessons/19/index", "lessons/19/modeling_repeated_experiments", "lessons/20/hierarchical_implementation", "lessons/21/sbc", "lessons/22/sbc_in_practice", "lessons/23/intro_to_gps", "lessons/24/gp_hyperparams_by_optimization", "lessons/24/gps_and_derivatives", "lessons/24/gps_without_marginalization", "lessons/24/index", "lessons/24/mcmc_with_gps", "lessons/25/variational_inference", "lessons/26/wrapup", "policies", "recitations/01/probability_review", "recitations/02/choosing_priors", "recitations/02/index", "recitations/03/just_hw_help", "recitations/04/hmc", "recitations/04/index", "recitations/04/overview", "recitations/05/practice_model_building", "recitations/06/HPC", "recitations/06/intro_to_hpc", "recitations/07/sampling_discrete_parameters", "recitations/08/project_proposals", "recitations/09/just_hw_help", "resources", "schedule"], "filenames": ["homework/01/hw1.1.ipynb", "homework/01/index.rst", "homework/02/hw2.1.ipynb", "homework/02/hw2.2.ipynb", "homework/02/index.rst", "index.rst", "lesson_exercises/exercise_01.ipynb", "lesson_exercises/exercise_02.ipynb", "lesson_exercises/exercise_03.ipynb", "lesson_exercises/exercise_04.ipynb", "lesson_exercises/exercise_05.ipynb", "lesson_exercises/exercise_06.ipynb", "lesson_exercises/exercise_07.ipynb", "lesson_exercises/exercise_08.ipynb", "lesson_exercises/exercise_09.ipynb", "lessons/00/aws_setup.ipynb", "lessons/00/colab.ipynb", "lessons/00/index.rst", "lessons/00/setup.ipynb", "lessons/01/bayes_logic.rst", "lessons/01/bayes_model_for_learning.rst", "lessons/01/bayes_notation.rst", "lessons/01/index.rst", "lessons/01/marginalization.rst", "lessons/01/probability_distributions.rst", "lessons/02/bayesian_modeling_example.rst", "lessons/02/bayesian_modeling_tasks.rst", "lessons/02/choice_of_likelihood.rst", "lessons/02/choice_of_prior.rst", "lessons/02/index.rst", "lessons/03/plotting_posteriors.ipynb", "lessons/04/marginalization_by_numerical_quadrature.ipynb", "lessons/05/conjugacy.ipynb", "lessons/06/index.rst", "lessons/06/normal_optimization.ipynb", "lessons/06/optimization_basics.ipynb", "lessons/06/variate_covariate_optimization.ipynb", "lessons/07/Untitled.ipynb", "lessons/07/further_reading.rst", "lessons/07/index.rst", "lessons/07/mcmc_idea.rst", "lessons/07/metropolis_hastings.rst", "lessons/07/warm_up.rst", "lessons/07/why_mcmc.rst", "lessons/08/index.rst", "lessons/08/parameter_estimation_with_mcmc.ipynb", "lessons/08/stan_hello_world.ipynb", "lessons/09/mixture_model_stan.ipynb", "lessons/10/variate_covariate_with_stan.ipynb", "lessons/11/display_of_mcmc_samples.ipynb", "lessons/11/index.rst", "lessons/11/posterior_summaries.ipynb", "lessons/12/prior_predictive_checks.ipynb", "lessons/13/posterior_predictive_checks.ipynb", "lessons/14/box_of_distributions.rst", "lessons/15/mcmc_diagnostics.ipynb", "lessons/16/funnel_of_hell.ipynb", "lessons/17/model_comparison.rst", "lessons/18/comparing_regressions.ipynb", "lessons/18/index.rst", "lessons/18/model_comparison.ipynb", "lessons/19/choosing_a_hierarchical_prior.ipynb", "lessons/19/generalization.ipynb", "lessons/19/implementation.ipynb", "lessons/19/index.rst", "lessons/19/modeling_repeated_experiments.ipynb", "lessons/20/hierarchical_implementation.ipynb", "lessons/21/sbc.ipynb", "lessons/22/sbc_in_practice.ipynb", "lessons/23/intro_to_gps.ipynb", "lessons/24/gp_hyperparams_by_optimization.ipynb", "lessons/24/gps_and_derivatives.ipynb", "lessons/24/gps_without_marginalization.ipynb", "lessons/24/index.rst", "lessons/24/mcmc_with_gps.ipynb", "lessons/25/variational_inference.ipynb", "lessons/26/wrapup.rst", "policies.rst", "recitations/01/probability_review.rst", "recitations/02/choosing_priors.rst", "recitations/02/index.rst", "recitations/03/just_hw_help.rst", "recitations/04/hmc.ipynb", "recitations/04/index.rst", "recitations/04/overview.ipynb", "recitations/05/practice_model_building.ipynb", "recitations/06/HPC.ipynb", "recitations/06/intro_to_hpc.rst", "recitations/07/sampling_discrete_parameters.ipynb", "recitations/08/project_proposals.rst", "recitations/09/just_hw_help.rst", "resources.rst", "schedule.rst"], "titles": ["Homework 1.1: First attempts at Bayesian generative modeling (70 pts)", "1. Intuitive generative modeling", "Homework 2.1: Overwhelming a prior (45 pts)", "Homework 2.2: Exponential conjugate prior (55 pts)", "2. Analytical and graphical methods for analysis of the posterior", "BE/Bi 103 b: Statistical Inference in the Biological Sciences", "E1. To be completed after lesson 5", "E2. To be completed after lesson 6", "E3. To be completed after lesson 10", "E4. To be completed after lesson 13", "E5. To be completed after lesson 16", "E6. To be completed after lesson 18", "E7. To be completed after lesson 20", "E8. To be completed after lesson 22", "E9. To be completed after lesson 25", "AWS setup and usage", "Using Google Colab", "0. Setting up computing resources", "Configuring your machine", "Probability as the logic of science", "Bayes\u2019s theorem as a model for learning", "Notation of parts of Bayes\u2019s Theorem", "1. Probability and the logic of scientific reasoning", "Marginalization", "Probability distributions", "Bayesian modeling example: parameter estimation from repeated measurements", "Tasks of Bayesian modeling", "Choosing likelihoods", "Choosing priors", "2. Introduction to Bayesian modeling", "3. Plotting posteriors", "4. Marginalization by numerical quadrature", "5. Conjugacy", "6. Parameter estimation by optimization", "Parameter estimation by optimization case study: Normal likelihood", "Bayesian approach to parameter estimation by optimization", "Parameter estimation by optimization: A variate-covariate model", "&lt;no title&gt;", "Further reading on MCMC", "7. Introduction to Markov chain Monte Carlo", "Random number generation", "Generating a transition kernel: The Metropolis-Hastings algorithm", "Warm-up", "Why MCMC?", "8. Introduction to MCMC with Stan", "Parameter estimation with Markov chain Monte Carlo", "\u201cHello, world\u201d \u2014Stan", "9. Mixture models and label switching with MCMC", "10. Variate-covariate models with MCMC", "Display of MCMC samples", "11. Display of MCMC results", "Reporting summaries of the posterior", "12. Model building with prior predictive checks", "13. Posterior predictive checks", "14. Collector\u2019s box of distributions", "15. MCMC diagnostics", "16. A diagnostics case study: Artificial funnel of hell", "17. Model comparison", "Example model selection: regression", "18. Model comparison in practice", "Model comparison in practice", "Choosing a hierarchical prior", "Generalization of hierarchical models", "Implementation of a hierarchical model", "19. Hierarchical models", "Modeling repeated experiments", "20. Implementation of hierarchical models", "21. Principled analysis pipelines", "22: Simulation based calibration and related checks in practice", "23. Introduction to Gaussian processes", "Gaussian process hyperparameters by optimization", "Calculating derivatives from data with GPs", "Gaussian processes with non-Normal likelihoods", "24. Implementation of Gaussian processes", "MCMC with GPs with Normal likelihoods", "25. Variational Bayesian inference", "26: Wrap-up", "Meetings", "R1: Review of probability", "R2: Choosing priors and review of optimization", "R2: Choosing priors and review of optimization", "R3: Just homework help", "More details on Hamiltonian Monte Carlo", "R4. Introduction to Hamiltonian Monte Carlo", "Overview of Hamiltonian Monte Carlo", "R5: Bayesian model building", "R6: MCMC using Caltech\u2019s HPC", "R6: MCMC using Caltech\u2019s HPC", "R7: Sampling discrete parameters with Stan", "R8: Discussion of HW 10 project proposals", "R9: Just homework help", "Software", "Schedule overview"], "terms": {"collard": 0, "cowork": [0, 42, 52, 60, 67, 71, 75], "did": [0, 6, 18, 19, 20, 27, 28, 30, 31, 34, 36, 45, 46, 48, 49, 52, 53, 56, 57, 58, 60, 61, 63, 65, 67, 68, 69, 70, 77, 84, 85, 89], "simpl": [0, 19, 25, 26, 30, 32, 35, 42, 46, 47, 51, 56, 57, 61, 67, 68, 69, 70, 72, 74, 75, 77, 82, 84, 86], "experi": [0, 2, 12, 19, 20, 24, 26, 27, 28, 30, 32, 45, 52, 54, 55, 57, 61, 62, 63, 64, 66, 67, 68, 69, 71, 75, 84, 85, 86, 88], "thei": [0, 2, 19, 25, 28, 30, 32, 34, 35, 36, 45, 46, 47, 48, 49, 52, 55, 56, 57, 60, 66, 67, 69, 71, 72, 75, 77, 82, 84, 85, 86, 88], "collect": [0, 43, 45, 46, 53, 85], "sampl": [0, 8, 10, 11, 15, 18, 24, 26, 31, 36, 40, 41, 42, 43, 50, 52, 53, 57, 58, 60, 61, 62, 63, 67, 74, 75, 82, 86, 92], "carrion": 0, "beetl": 0, "feed": [0, 88], "decai": [0, 30, 52, 68], "anim": [0, 82, 88], "matter": [0, 28, 43, 62, 77], "measur": [0, 2, 21, 24, 26, 27, 28, 29, 30, 31, 34, 45, 46, 52, 53, 54, 55, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 82, 85, 88], "morpholog": 0, "featur": [0, 30, 34, 46, 54, 55, 57, 61, 62, 68, 69, 75, 78, 79, 86, 87, 89], "variou": [0, 26, 40, 46, 49, 51, 69, 71, 86, 88, 91], "speci": [0, 28], "from": [0, 2, 3, 16, 18, 19, 20, 23, 24, 26, 28, 29, 30, 32, 34, 35, 36, 38, 40, 41, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 82, 84, 85, 86, 88], "differ": [0, 2, 15, 16, 19, 28, 30, 34, 35, 45, 47, 51, 52, 53, 56, 57, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 75, 77, 82, 84, 85, 86, 88], "site": [0, 3, 70, 71], "time": [0, 15, 16, 17, 19, 25, 27, 30, 31, 35, 41, 42, 46, 47, 48, 51, 52, 54, 57, 61, 65, 67, 68, 69, 70, 71, 72, 75, 77, 85, 86, 88, 91, 92], "year": [0, 15, 28, 41, 65], "imagin": [0, 24, 42, 45, 54, 56, 57, 62, 65, 68, 69, 71, 82, 84], "you": [0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 25, 26, 27, 28, 30, 32, 34, 35, 36, 38, 40, 41, 42, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 60, 62, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88, 91], "ar": [0, 2, 3, 5, 7, 9, 10, 11, 14, 16, 17, 18, 19, 21, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88], "cabin": 0, "main": [0, 28, 34, 35, 40, 45, 46, 49, 54, 67, 72, 84, 86, 91], "There": [0, 15, 16, 17, 18, 19, 25, 28, 32, 41, 42, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 66, 67, 69, 71, 72, 75, 77, 81, 84, 86, 88, 90, 91], "also": [0, 5, 15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 34, 35, 40, 41, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 85, 86, 88, 91], "plenti": [0, 15, 55, 60], "area": [0, 31, 55, 68, 82, 88], "which": [0, 3, 15, 16, 17, 18, 19, 20, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88], "stai": [0, 47, 82], "so": [0, 2, 12, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 85, 86, 88], "curiou": 0, "look": [0, 3, 15, 28, 30, 32, 34, 35, 36, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 86, 88], "your": [0, 2, 3, 5, 12, 13, 16, 17, 19, 27, 28, 30, 34, 35, 36, 41, 47, 52, 53, 54, 55, 56, 57, 66, 67, 68, 69, 70, 74, 75, 77, 82, 84, 85, 86], "plan": [0, 88], "set": [0, 2, 3, 5, 7, 12, 15, 16, 18, 19, 20, 21, 24, 26, 28, 31, 34, 35, 36, 41, 43, 46, 47, 48, 49, 53, 57, 58, 60, 61, 62, 63, 65, 67, 68, 70, 71, 72, 74, 75, 77, 85, 86, 88], "up": [0, 3, 5, 8, 15, 16, 18, 25, 26, 28, 30, 31, 34, 36, 39, 40, 45, 52, 53, 54, 55, 56, 58, 62, 65, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 86, 88, 92], "trap": 0, "specimen": 0, "given": [0, 15, 19, 21, 24, 25, 26, 28, 30, 32, 35, 40, 43, 45, 47, 52, 55, 57, 60, 63, 65, 66, 69, 70, 71, 72, 74, 75, 76, 77, 82, 84, 85, 88], "For": [0, 2, 15, 16, 19, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 38, 40, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 60, 61, 62, 65, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 86, 88], "each": [0, 2, 3, 6, 11, 15, 16, 19, 25, 30, 31, 32, 34, 35, 40, 43, 45, 46, 47, 48, 49, 52, 53, 54, 55, 57, 60, 61, 63, 65, 66, 67, 68, 69, 72, 74, 75, 77, 82, 84, 85, 86, 88, 92], "its": [0, 19, 25, 28, 30, 31, 32, 34, 45, 46, 47, 48, 51, 52, 54, 56, 57, 61, 63, 68, 69, 70, 71, 75, 77, 82, 86, 88, 91], "mass": [0, 24, 28, 34, 47, 51, 54, 56, 60, 67, 68, 69, 77, 82, 84], "length": [0, 25, 27, 28, 30, 31, 34, 36, 45, 46, 47, 48, 49, 52, 53, 54, 55, 58, 60, 67, 69, 70, 72, 75, 82, 86], "elytra": 0, "As": [0, 2, 15, 16, 18, 19, 24, 25, 26, 28, 30, 31, 32, 35, 40, 41, 45, 46, 47, 49, 52, 53, 54, 55, 56, 57, 58, 60, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 77, 82, 84, 86, 88], "we": [0, 2, 3, 5, 6, 7, 11, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 82, 85, 86, 88], "learn": [0, 5, 17, 19, 22, 26, 32, 34, 35, 45, 46, 47, 49, 52, 53, 55, 57, 65, 66, 67, 69, 70, 71, 86], "class": [0, 2, 5, 16, 18, 21, 31, 41, 54, 69, 75, 77, 82, 86, 88, 91, 92], "prior": [0, 4, 5, 6, 7, 9, 13, 20, 21, 23, 27, 29, 30, 31, 32, 34, 35, 36, 46, 47, 48, 53, 55, 57, 60, 62, 63, 64, 65, 66, 67, 71, 72, 74, 75, 77, 84, 85, 86, 88, 92], "perform": [0, 7, 13, 15, 17, 26, 27, 28, 30, 31, 34, 41, 43, 45, 46, 47, 48, 51, 52, 53, 55, 57, 60, 63, 66, 67, 69, 70, 71, 72, 74, 75, 77, 82, 84, 86, 88], "an": [0, 3, 16, 17, 18, 19, 20, 21, 23, 25, 26, 27, 28, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 61, 63, 65, 66, 67, 70, 71, 72, 75, 77, 82, 85, 86, 88], "i": [0, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 35, 36, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 81, 82, 84, 85, 88, 90, 91, 92], "us": [0, 2, 3, 7, 8, 9, 10, 11, 12, 14, 17, 18, 19, 21, 23, 24, 25, 26, 27, 30, 31, 32, 34, 36, 40, 41, 42, 43, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 70, 75, 77, 84, 85, 88, 91], "think": [0, 19, 25, 26, 28, 34, 36, 40, 46, 47, 51, 52, 55, 57, 60, 66, 69, 70, 72, 82, 84, 88], "about": [0, 15, 16, 19, 20, 21, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 54, 55, 57, 60, 66, 67, 68, 69, 70, 71, 72, 75, 77, 82, 84, 85, 86, 88, 89, 91], "what": [0, 2, 6, 7, 8, 11, 12, 13, 14, 15, 16, 21, 25, 26, 28, 30, 31, 36, 40, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 60, 66, 67, 68, 69, 70, 71, 75, 77, 84, 85, 88], "kind": [0, 19, 41, 47, 49, 52, 55, 57, 68, 69, 70, 71, 88], "data": [0, 2, 3, 5, 12, 15, 16, 18, 19, 20, 21, 24, 25, 26, 27, 28, 31, 32, 35, 36, 42, 43, 46, 47, 48, 49, 51, 53, 54, 57, 58, 60, 61, 62, 63, 67, 68, 70, 72, 73, 74, 75, 77, 85, 86, 88, 91], "might": [0, 15, 16, 18, 25, 26, 27, 28, 30, 32, 40, 43, 46, 47, 49, 51, 52, 54, 56, 57, 61, 67, 68, 69, 70, 74, 75, 82, 84, 85, 86, 88], "expect": [0, 18, 19, 25, 26, 28, 30, 32, 34, 36, 43, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 60, 66, 67, 68, 69, 72, 75, 77, 82, 84, 88], "observ": [0, 19, 26, 32, 53, 54, 57, 60, 65, 69, 71, 72, 75, 85], "thi": [0, 2, 3, 5, 10, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 85, 86, 88, 91, 92], "involv": [0, 15, 19, 25, 26, 28, 31, 35, 45, 49, 52, 55, 57, 62, 69, 74, 84, 86], "propos": [0, 41, 42, 52, 55, 56, 57, 67, 82, 85], "draw": [0, 28, 40, 45, 46, 47, 51, 52, 53, 55, 56, 57, 58, 60, 63, 67, 68, 69, 70, 71, 72, 74, 75, 82, 88], "befor": [0, 16, 19, 25, 26, 28, 30, 31, 32, 36, 45, 46, 47, 52, 53, 56, 57, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 86, 88, 92], "proceed": [0, 53, 56, 71, 75], "do": [0, 2, 6, 7, 9, 13, 15, 16, 17, 18, 19, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 85, 87, 88], "want": [0, 6, 15, 16, 19, 24, 30, 31, 32, 34, 40, 41, 43, 45, 46, 47, 49, 52, 53, 54, 55, 57, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88], "clarifi": 0, "purpos": [0, 15, 25, 45, 46, 47, 52, 54, 55, 60, 70, 82], "problem": [0, 2, 3, 10, 16, 17, 21, 24, 26, 28, 30, 31, 34, 35, 36, 40, 41, 47, 49, 51, 52, 55, 56, 57, 62, 65, 66, 67, 68, 70, 71, 72, 75, 77, 82, 84, 85, 86, 88], "address": [0, 15, 55, 66, 67, 69, 86], "question": [0, 6, 7, 8, 9, 10, 11, 12, 13, 14, 53, 54, 55, 57, 67, 77], "mai": [0, 3, 7, 8, 9, 10, 11, 15, 16, 17, 18, 19, 21, 24, 25, 26, 28, 34, 40, 43, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 60, 61, 65, 66, 67, 69, 70, 72, 74, 75, 77, 84, 85, 88], "my": [0, 6, 18, 19, 24, 25, 28, 34, 41, 49, 51, 68, 75, 82, 84, 86, 88], "formal": [0, 19, 26, 52, 57, 66], "procedur": [0, 27, 28, 31, 36, 52, 53, 57, 67, 68, 71, 75, 88], "build": [0, 2, 5, 27, 28, 46, 48, 54, 68, 69, 71, 74, 77, 88, 92], "The": [0, 2, 3, 15, 16, 17, 18, 21, 24, 27, 34, 35, 39, 46, 47, 48, 51, 54, 56, 58, 60, 61, 62, 63, 66, 67, 70, 71, 72, 74, 76, 77, 85, 86, 88, 91, 92], "concept": [0, 24, 40, 75, 77, 82, 84, 86, 88], "though": [0, 15, 16, 18, 24, 25, 26, 28, 30, 31, 34, 35, 36, 41, 42, 46, 49, 51, 52, 53, 54, 55, 57, 58, 60, 65, 66, 67, 68, 69, 70, 74, 75, 77, 84, 85, 88], "fairli": [0, 36, 47, 88], "intuit": [0, 5, 19, 28, 32, 52, 57, 68, 82, 84, 92], "At": [0, 15, 26, 28, 46, 69, 82, 88], "point": [0, 6, 7, 19, 28, 31, 34, 36, 40, 45, 46, 47, 48, 49, 52, 53, 54, 55, 57, 58, 60, 66, 67, 70, 71, 72, 74, 75, 77, 82, 84, 88], "re": [0, 3, 25, 32, 34, 36, 40, 45, 49, 51, 55, 56, 65, 69, 70, 71, 72, 84, 88], "ask": [0, 25, 52, 57, 77, 84], "how": [0, 2, 3, 6, 7, 10, 15, 17, 18, 19, 20, 24, 25, 26, 28, 30, 32, 35, 36, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 82, 85, 87, 88, 91], "right": [0, 15, 16, 19, 24, 25, 28, 30, 31, 35, 36, 40, 41, 43, 47, 48, 49, 52, 53, 56, 57, 58, 60, 61, 67, 69, 70, 71, 75, 77, 82, 84, 85, 88], "now": [0, 2, 15, 19, 20, 23, 24, 25, 28, 30, 31, 32, 34, 35, 36, 40, 43, 45, 46, 47, 48, 49, 52, 53, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 82, 84, 86, 88], "concern": [0, 15, 26, 45], "some": [0, 2, 13, 15, 16, 17, 18, 19, 24, 25, 26, 28, 35, 43, 45, 46, 47, 48, 49, 52, 54, 55, 56, 57, 58, 60, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 82, 84, 85, 86, 88, 91], "definit": [0, 19, 24, 25, 28, 30, 34, 35, 48, 54, 57, 61, 65, 67, 69, 71, 72, 74, 75, 82, 84, 86, 88], "soon": [0, 28, 49], "like": [0, 3, 15, 16, 19, 24, 25, 28, 30, 32, 35, 36, 42, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 61, 65, 66, 67, 68, 69, 71, 72, 75, 77, 82, 84, 85, 86, 88], "likelihood": [0, 2, 3, 6, 7, 11, 21, 23, 26, 28, 29, 31, 32, 33, 35, 36, 45, 47, 48, 53, 54, 55, 57, 58, 62, 63, 65, 67, 68, 70, 71, 73, 75, 85, 86, 88], "function": [0, 3, 16, 18, 19, 21, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 40, 43, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 66, 68, 70, 71, 72, 74, 77, 82, 84, 86, 88, 91], "last": [0, 6, 18, 19, 24, 41, 45, 46, 53, 55, 63, 70, 71, 76, 82, 84, 86, 88], "term": [0, 7, 16, 17, 18, 19, 24, 25, 26, 28, 30, 34, 35, 41, 45, 46, 47, 52, 55, 57, 67, 69, 75, 76, 77, 82, 84, 86, 88, 91], "rather": [0, 24, 26, 30, 35, 45, 46, 52, 55, 58, 60, 69, 70, 71, 75, 82], "just": [0, 16, 20, 24, 25, 26, 28, 30, 31, 32, 34, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 62, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 86, 88], "yourself": [0, 27, 30, 32, 34, 38, 66, 68], "when": [0, 2, 7, 11, 12, 13, 15, 18, 19, 25, 26, 27, 28, 30, 31, 32, 36, 40, 42, 43, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 60, 65, 67, 68, 69, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88], "thing": [0, 16, 19, 25, 26, 30, 43, 45, 46, 49, 51, 69, 72, 82, 84, 85, 86, 88], "later": [0, 17, 28, 30, 31, 42, 43, 49, 52, 55], "suspect": [0, 28, 61, 70, 72], "see": [0, 2, 15, 18, 23, 26, 28, 30, 32, 34, 35, 36, 45, 46, 47, 49, 52, 53, 54, 55, 56, 57, 58, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 86, 88], "close": [0, 26, 28, 30, 34, 35, 36, 48, 53, 54, 56, 66, 67, 68, 69, 70, 72, 75, 82, 84], "match": [0, 25, 27, 28, 30, 32, 52, 54, 58, 66, 68, 88], "That": [0, 2, 15, 16, 19, 20, 24, 25, 26, 28, 30, 32, 34, 45, 47, 52, 54, 55, 56, 57, 60, 65, 66, 67, 68, 69, 70, 75, 77, 82, 88], "said": [0, 19, 28, 32, 40, 41, 45, 46, 52, 61, 82], "most": [0, 2, 15, 16, 18, 26, 28, 30, 31, 34, 35, 36, 41, 42, 43, 45, 46, 49, 51, 52, 54, 55, 57, 60, 61, 63, 66, 68, 69, 70, 75, 77, 82, 84, 86, 88], "take": [0, 2, 5, 13, 15, 16, 17, 18, 19, 25, 26, 28, 30, 34, 36, 40, 41, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 60, 61, 66, 68, 69, 72, 75, 82, 84, 85, 86], "approach": [0, 5, 13, 17, 18, 19, 25, 26, 28, 30, 32, 33, 34, 40, 41, 47, 48, 51, 53, 54, 55, 56, 60, 65, 67, 68, 69, 70, 75, 77, 84, 85, 88, 91], "develop": [0, 5, 28, 52, 75], "cours": [0, 2, 15, 16, 17, 19, 24, 25, 26, 28, 30, 35, 46, 47, 52, 55, 57, 61, 62, 68, 69, 72, 75, 82, 86, 92], "make": [0, 3, 6, 15, 16, 18, 19, 24, 25, 28, 30, 31, 32, 34, 35, 36, 43, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 82, 84, 85, 86, 88], "mistak": 0, "ok": [0, 48, 53, 60, 66, 67, 69, 75, 88], "go": [0, 5, 15, 17, 19, 21, 26, 28, 30, 31, 35, 41, 42, 46, 47, 49, 51, 52, 53, 54, 55, 57, 60, 61, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 88], "grade": [0, 5], "detail": [0, 2, 5, 32, 34, 38, 42, 47, 49, 55, 57, 60, 69, 71, 75, 77, 83, 84], "implement": [0, 5, 16, 18, 30, 31, 32, 34, 35, 36, 40, 41, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 64, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88, 92], "our": [0, 2, 15, 16, 18, 19, 20, 24, 25, 26, 27, 28, 30, 32, 34, 36, 40, 41, 43, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 69, 70, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88, 91], "get": [0, 15, 16, 17, 19, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 49, 52, 53, 54, 55, 56, 57, 60, 65, 66, 67, 68, 69, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88], "defin": [0, 19, 21, 24, 25, 26, 28, 30, 34, 35, 36, 40, 41, 45, 46, 48, 51, 52, 54, 57, 62, 63, 65, 66, 67, 69, 70, 71, 72, 75, 77, 82, 84, 86, 88], "probabl": [0, 2, 5, 8, 15, 16, 21, 23, 25, 26, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 61, 63, 65, 67, 68, 69, 70, 71, 75, 82, 84, 85, 92], "distribut": [0, 2, 3, 5, 6, 7, 8, 10, 11, 19, 20, 22, 23, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 52, 55, 56, 57, 58, 60, 62, 63, 65, 66, 67, 68, 70, 71, 72, 74, 75, 77, 82, 84, 86, 91, 92], "describ": [0, 11, 12, 13, 14, 19, 20, 21, 24, 25, 26, 27, 28, 32, 34, 35, 43, 45, 46, 51, 53, 54, 57, 60, 62, 65, 67, 69, 70, 71, 75, 77, 82, 84, 85, 88], "b": [0, 2, 3, 8, 19, 24, 28, 32, 34, 35, 45, 46, 47, 52, 55, 57, 60, 67, 68, 82, 85, 86, 88], "sai": [0, 2, 6, 7, 15, 19, 20, 24, 25, 26, 28, 30, 31, 41, 42, 43, 49, 52, 53, 55, 57, 65, 67, 69, 72, 74, 77, 82, 88], "40": [0, 30, 31, 36, 45, 47, 52, 63, 66, 72, 75, 88], "would": [0, 15, 21, 25, 27, 28, 30, 31, 34, 35, 36, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 60, 61, 63, 67, 68, 69, 70, 72, 74, 75, 82, 84, 85, 86, 88], "out": [0, 8, 9, 15, 16, 19, 25, 26, 28, 30, 31, 32, 34, 36, 38, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 55, 58, 60, 61, 62, 65, 66, 67, 68, 70, 71, 72, 74, 75, 77, 82, 84, 86, 88], "respons": [0, 5, 68], "part": [0, 15, 22, 24, 27, 28, 30, 35, 36, 42, 46, 47, 53, 69, 71, 77, 86], "unfortun": [0, 31, 40, 75, 84], "know": [0, 19, 20, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 42, 43, 47, 48, 51, 52, 54, 56, 57, 60, 67, 69, 71, 77, 82, 84, 85, 88], "paramet": [0, 2, 3, 5, 7, 16, 18, 19, 20, 21, 23, 24, 26, 28, 29, 31, 32, 40, 41, 42, 43, 44, 46, 47, 48, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 66, 67, 68, 70, 71, 72, 74, 75, 82, 84, 85, 86, 92], "valu": [0, 19, 20, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 60, 63, 65, 66, 67, 68, 70, 71, 72, 74, 75, 82, 84, 85, 86], "chose": [0, 27, 28, 31, 36, 53, 61, 70, 72, 82, 85, 88], "In": [0, 2, 5, 15, 16, 17, 18, 19, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 41, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88], "fact": [0, 16, 19, 26, 28, 30, 31, 32, 34, 35, 45, 52, 55, 56, 57, 68, 72, 75, 82, 86], "ahead": [0, 20, 46, 54, 55, 57, 68, 74, 77, 92], "write": [0, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 19, 21, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 41, 43, 46, 47, 52, 54, 57, 65, 66, 69, 71, 72, 75, 77, 82, 84, 85, 88, 91], "down": [0, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 21, 25, 26, 28, 30, 31, 32, 35, 36, 43, 52, 54, 56, 57, 66, 69, 82], "context": [0, 12, 21, 25, 26, 28, 30, 36, 45, 52, 55, 69, 82, 86], "full": [0, 14, 15, 16, 26, 34, 35, 36, 51, 54, 70, 75, 77, 85], "specif": [0, 16, 19, 25, 30, 35, 40, 46, 49, 52, 55, 57, 60, 61, 65, 66, 67, 69, 70, 71, 72, 74, 75, 77, 84, 86], "c": [0, 2, 3, 15, 19, 25, 27, 28, 46, 54, 55, 65, 69, 75], "To": [0, 2, 5, 15, 16, 18, 19, 21, 23, 25, 28, 30, 31, 34, 35, 36, 38, 40, 41, 43, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 60, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88], "one": [0, 2, 15, 16, 18, 19, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 45, 46, 47, 48, 51, 52, 53, 54, 55, 60, 61, 65, 67, 68, 69, 72, 74, 75, 77, 82, 84, 85, 86, 88], "follow": [0, 2, 6, 15, 16, 17, 18, 19, 21, 28, 30, 31, 36, 40, 43, 45, 46, 47, 48, 49, 52, 53, 54, 55, 58, 66, 67, 68, 69, 70, 71, 72, 74, 77, 82, 84, 85, 86, 88], "construct": [0, 6, 19, 26, 30, 31, 34, 45, 47, 49, 52, 53, 66, 67, 68, 69, 70, 71, 72, 77, 84, 86, 88], "those": [0, 15, 16, 21, 25, 28, 30, 31, 42, 43, 46, 47, 52, 53, 56, 57, 66, 67, 68, 69, 70, 74, 75, 84], "parametr": [0, 25, 28, 32, 45, 51, 52, 55, 56, 57, 61, 68, 69, 70, 72, 75, 84], "can": [0, 3, 10, 11, 12, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88, 91], "mani": [0, 2, 15, 16, 18, 23, 25, 27, 28, 32, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 51, 52, 54, 55, 56, 63, 66, 69, 70, 72, 75, 77, 82, 84, 85, 86, 88, 91], "plot": [0, 2, 3, 5, 9, 16, 18, 26, 28, 31, 34, 35, 36, 37, 40, 43, 46, 48, 51, 52, 53, 55, 56, 57, 58, 60, 63, 66, 68, 70, 71, 72, 74, 75, 82, 84, 86, 88, 92], "them": [0, 5, 19, 28, 30, 32, 40, 41, 42, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 63, 66, 67, 69, 70, 71, 77, 82, 86, 88, 91], "should": [0, 3, 15, 16, 18, 19, 24, 25, 27, 28, 30, 31, 32, 34, 36, 38, 40, 45, 46, 47, 52, 53, 54, 55, 56, 57, 58, 60, 66, 67, 68, 69, 70, 72, 75, 77, 82, 84, 86, 88], "carefulli": [0, 2, 19, 24, 48, 52, 60, 66, 70, 77], "best": [0, 9, 15, 16, 28, 32, 48, 51, 53, 57, 58, 60, 69, 75, 77, 82, 91], "clear": [0, 19, 31, 32, 35, 43, 47, 54, 58, 69, 71, 77, 82, 84, 85, 88, 91], "come": [0, 2, 15, 25, 26, 28, 30, 32, 36, 40, 43, 45, 46, 47, 48, 52, 54, 56, 60, 61, 62, 66, 67, 68, 69, 70, 82, 84, 85, 88], "doe": [0, 2, 3, 8, 9, 13, 15, 16, 19, 24, 25, 27, 28, 30, 34, 36, 41, 45, 46, 47, 51, 52, 55, 56, 57, 60, 66, 68, 69, 70, 72, 74, 75, 77, 78, 82, 84, 86, 87, 88], "jibe": 0, "If": [0, 5, 9, 10, 12, 15, 16, 18, 19, 24, 25, 26, 28, 30, 31, 32, 35, 36, 40, 41, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 61, 66, 67, 68, 69, 71, 72, 75, 77, 82, 84, 85, 86, 88], "have": [0, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88, 91], "ani": [0, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 19, 25, 26, 28, 30, 32, 34, 35, 36, 40, 41, 43, 45, 46, 47, 51, 52, 54, 56, 57, 61, 65, 66, 67, 68, 69, 74, 75, 77, 78, 82, 84, 86, 87, 88, 89], "idea": [0, 8, 14, 19, 27, 28, 32, 39, 45, 47, 51, 52, 55, 57, 58, 60, 67, 69, 82, 84], "why": [0, 2, 3, 6, 7, 8, 9, 10, 11, 12, 24, 30, 39, 47, 49, 60, 66, 68, 75, 77, 82, 84, 85, 86, 88], "d": [0, 3, 15, 18, 24, 25, 26, 28, 30, 31, 34, 35, 36, 40, 41, 43, 48, 49, 52, 53, 56, 57, 58, 60, 67, 69, 71, 75, 82, 84], "until": [0, 67, 82, 86], "through": [0, 5, 15, 16, 17, 25, 28, 32, 35, 36, 43, 47, 49, 57, 66, 68, 69, 70, 71, 77, 82, 84, 86], "complet": [0, 5, 15, 18, 25, 30, 31, 32, 34, 36, 43, 46, 48, 52, 55, 61, 66, 67, 68, 69, 70, 74, 75, 77, 82, 84, 86], "access": [0, 15, 26, 40, 45, 46, 47, 51, 55, 77], "here": [0, 3, 15, 19, 24, 25, 26, 28, 30, 34, 36, 40, 41, 42, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 82, 84, 86, 88], "extract": [0, 34, 36, 46, 52, 70, 71, 75, 86], "made": [0, 10, 15, 30, 45, 52, 54, 77, 82, 91], "nicrophoru": 0, "orbicolli": 0, "locat": [0, 2, 10, 15, 25, 28, 32, 34, 46, 48, 54, 56, 63, 66, 70, 77, 82, 86, 88], "10": [0, 3, 5, 16, 18, 25, 28, 30, 31, 32, 34, 35, 36, 40, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88, 92], "0": [0, 5, 15, 16, 18, 28, 30, 31, 32, 34, 35, 36, 37, 40, 41, 42, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 82, 84, 86, 88, 92], "fall": [0, 51, 68, 69, 82, 84], "within": [0, 2, 15, 28, 42, 45, 47, 48, 52, 53, 55, 57, 68, 77, 84, 86], "homework": [1, 4, 15, 16, 26, 28, 54, 65, 89], "first": [1, 2, 3, 15, 16, 19, 20, 24, 25, 26, 28, 30, 31, 32, 34, 36, 40, 41, 42, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 60, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 82, 84, 85, 86, 88], "attempt": [1, 6, 28, 51, 56, 57, 75, 77], "bayesian": [1, 5, 21, 27, 28, 30, 31, 33, 34, 40, 42, 43, 45, 46, 51, 52, 55, 57, 67, 68, 82, 84, 91, 92], "70": [1, 51, 53, 55, 58, 66, 75], "pt": [1, 4], "import": [2, 3, 8, 9, 12, 16, 18, 19, 24, 25, 27, 30, 31, 32, 34, 35, 36, 37, 40, 41, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 86, 88], "numpi": [2, 16, 18, 30, 31, 32, 34, 35, 36, 37, 40, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 70, 71, 72, 74, 75, 82, 86, 88], "np": [2, 16, 18, 30, 31, 32, 34, 35, 36, 37, 40, 45, 46, 47, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88], "continu": [2, 19, 26, 28, 31, 35, 36, 40, 41, 43, 47, 49, 54, 57, 60, 67, 68, 69, 75, 82, 86, 88], "choos": [2, 15, 25, 26, 29, 30, 31, 32, 34, 36, 40, 42, 43, 45, 47, 48, 51, 52, 53, 56, 57, 64, 65, 69, 70, 71, 72, 77, 84], "gener": [2, 5, 6, 9, 16, 19, 21, 25, 26, 27, 28, 30, 31, 34, 35, 36, 39, 42, 43, 46, 47, 49, 51, 53, 54, 55, 56, 57, 58, 60, 64, 65, 67, 69, 70, 71, 74, 75, 77, 82, 84, 85, 86, 88], "model": [2, 3, 5, 6, 8, 9, 12, 13, 16, 18, 19, 21, 22, 24, 27, 28, 32, 33, 35, 40, 43, 46, 51, 54, 61, 67, 69, 70, 71, 74, 77, 82, 84, 86, 88, 91, 92], "nonetheless": [2, 16, 19, 28, 34, 45, 52, 54, 55, 68, 69, 74, 75], "estim": [2, 5, 7, 16, 18, 19, 21, 26, 28, 29, 30, 32, 40, 41, 44, 48, 49, 52, 54, 55, 60, 63, 65, 66, 67, 68, 70, 71, 75, 84, 85, 88, 92], "where": [2, 15, 16, 19, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 40, 42, 43, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 60, 61, 66, 67, 69, 70, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88], "contribut": [2, 25, 47, 60, 75, 82, 84], "exact": [2, 30, 34, 75, 82, 84], "constraint": [2, 52, 70, 86], "less": [2, 10, 24, 28, 30, 40, 45, 52, 55, 60, 67, 68, 84, 86, 88], "explor": [2, 5, 19, 26, 27, 28, 30, 32, 34, 46, 49, 52, 53, 56, 66, 69, 82, 84, 86, 88, 91], "computation": [2, 15, 35, 57, 75, 86], "work": [2, 12, 15, 16, 17, 18, 19, 25, 28, 30, 31, 34, 35, 38, 41, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 74, 77, 82, 84, 85, 86, 88, 92], "david": [2, 75], "prober": 2, "": [2, 3, 5, 9, 15, 16, 17, 18, 22, 23, 25, 26, 28, 30, 31, 34, 35, 38, 40, 41, 42, 45, 46, 47, 48, 49, 51, 53, 55, 56, 57, 58, 60, 62, 63, 65, 66, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 88, 91, 92], "lab": [2, 5, 15, 45, 68, 85, 86, 92], "monitor": 2, "activ": [2, 15, 42, 45, 68, 69, 77, 86], "zebrafish": 2, "larva": 2, "genotyp": 2, "effort": [2, 67], "understand": [2, 5, 19, 25, 32, 34, 40, 43, 47, 52, 60, 66, 69, 75, 77, 82], "sleep": 2, "control": [2, 15, 46, 48, 52, 85], "publish": [2, 3, 45, 55, 75], "gandhi": 2, "et": [2, 32, 34, 36, 45, 48, 49, 52, 53, 55, 58, 67, 71, 72, 75, 91], "al": [2, 32, 34, 36, 45, 48, 49, 52, 53, 55, 58, 67, 71, 72, 75, 88, 91], "2015": [2, 63, 65], "minut": [2, 16, 18, 19, 25, 36, 45, 68, 85], "17": [2, 5, 15, 30, 36, 45, 46, 47, 52, 53, 55, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 86, 88, 92], "fish": [2, 55, 60, 68, 69, 72, 86], "had": [2, 25, 28, 36, 48, 52, 55, 56, 58, 61, 68, 74, 77, 82, 88], "over": [2, 5, 19, 23, 28, 30, 31, 32, 36, 41, 42, 43, 47, 52, 57, 60, 65, 67, 68, 69, 71, 72, 75, 77, 82, 84, 86, 88], "nine": 2, "hour": [2, 15, 16, 17, 18, 45, 77, 86, 92], "third": [2, 30, 47, 53, 77], "night": 2, "result": [2, 5, 19, 26, 27, 28, 30, 31, 34, 35, 36, 41, 45, 46, 47, 49, 52, 53, 55, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 75, 77, 82, 84, 86, 88, 91], "easili": [2, 15, 30, 41, 45, 46, 52, 62, 69, 75, 82, 84], "load": [2, 15, 16, 18, 30, 31, 32, 34, 35, 36, 37, 40, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88], "directli": [2, 15, 19, 25, 28, 30, 34, 35, 43, 45, 46, 47, 48, 49, 52, 57, 58, 60, 65, 67, 69, 71, 75, 84], "arrai": [2, 3, 25, 30, 31, 34, 36, 45, 46, 47, 48, 49, 51, 52, 53, 55, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 86, 88], "variabl": [2, 19, 23, 25, 28, 30, 31, 34, 41, 45, 46, 47, 48, 49, 52, 53, 55, 56, 60, 62, 65, 66, 67, 68, 69, 70, 71, 74, 75, 82, 86, 88], "call": [2, 15, 18, 19, 23, 24, 25, 26, 28, 30, 40, 42, 45, 46, 47, 49, 52, 56, 57, 58, 65, 66, 69, 72, 74, 75, 82, 84, 86, 88], "y": [2, 16, 18, 19, 21, 23, 24, 25, 26, 28, 30, 31, 34, 35, 36, 37, 40, 43, 45, 46, 47, 48, 49, 51, 52, 54, 57, 60, 62, 66, 67, 68, 69, 70, 71, 72, 74, 75, 82, 88], "200": [2, 30, 31, 32, 34, 35, 36, 37, 45, 47, 48, 49, 51, 52, 53, 58, 68, 69, 75, 77, 88, 92], "190": [2, 32, 75, 88], "249": 2, "232": 2, "319": [2, 45], "104": 2, "93": [2, 47, 60], "233": 2, "287": 2, "49": [2, 30, 47, 86], "311": [2, 45], "225": 2, "243": [2, 47], "113": [2, 15, 75], "133": 2, "179": [2, 47, 75, 86], "normal": [2, 7, 16, 18, 26, 27, 28, 31, 32, 33, 40, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 60, 61, 63, 66, 68, 70, 71, 73, 75, 82, 86, 88], "drawn": [2, 45, 47, 52, 57, 67, 69, 75, 88], "mu": [2, 16, 18, 24, 25, 28, 30, 35, 36, 51, 52, 53, 54, 56, 58, 69, 75, 88], "scale": [2, 25, 28, 30, 34, 35, 36, 37, 45, 46, 48, 49, 52, 54, 57, 58, 60, 66, 68, 70, 71, 72, 74, 82, 84, 86], "sigma": [2, 16, 18, 19, 24, 25, 28, 30, 31, 34, 35, 36, 48, 49, 51, 52, 53, 54, 56, 58, 66, 69, 70, 71, 72, 74, 75, 84], "begin": [2, 15, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 82, 84, 86, 88], "align": [2, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 82, 84, 86, 88], "y_i": [2, 24, 25, 34, 57, 60, 69, 72], "mid": [2, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 40, 41, 43, 45, 46, 47, 48, 49, 52, 54, 56, 57, 60, 61, 62, 65, 67, 69, 70, 71, 72, 74, 75, 82], "sim": [2, 25, 28, 30, 31, 32, 34, 36, 45, 47, 48, 49, 52, 53, 54, 55, 56, 58, 61, 63, 65, 66, 68, 69, 70, 71, 72, 74, 75, 84, 86, 88], "text": [2, 18, 19, 24, 25, 28, 30, 31, 32, 34, 36, 42, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 65, 66, 68, 69, 70, 71, 72, 74, 75, 77, 82, 86, 88], "norm": [2, 25, 28, 30, 34, 35, 36, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 58, 66, 68, 69, 71, 72, 75, 82], "foral": [2, 25, 30, 31, 34, 36, 45, 47, 48, 49, 52, 53, 55, 58, 61, 63, 68, 69, 71, 72, 75, 86, 88], "end": [2, 18, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 86, 88], "task": [2, 19, 28, 29, 34, 53, 58, 77, 82, 84, 86], "posterior": [2, 3, 5, 6, 7, 9, 11, 13, 16, 18, 20, 21, 23, 25, 28, 31, 36, 40, 41, 43, 46, 47, 48, 50, 52, 54, 55, 56, 58, 60, 61, 62, 63, 65, 66, 67, 68, 71, 72, 75, 82, 84, 86, 88, 92], "g": [2, 15, 16, 19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 40, 43, 45, 46, 47, 52, 54, 57, 61, 62, 63, 65, 67, 68, 69, 71, 75, 77, 82, 88], "improp": [2, 28, 30, 31], "uninform": 2, "becaus": [2, 15, 16, 17, 19, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 36, 41, 45, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 86, 88], "veri": [2, 19, 24, 25, 26, 28, 30, 32, 34, 35, 36, 41, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 66, 68, 69, 70, 71, 72, 74, 75, 82, 84, 86, 88], "broad": [2, 25, 26, 28, 30, 34, 52, 57, 68, 69, 77, 88, 92], "infinit": [2, 28, 45, 69, 84], "even": [2, 19, 25, 26, 28, 30, 46, 47, 51, 52, 55, 57, 66, 68, 69, 74, 77, 82, 84, 88], "normaliz": [2, 28], "constant": [2, 25, 28, 30, 31, 34, 52, 61, 69, 70, 72, 74, 75, 88], "1em": [2, 25, 28, 30, 31, 32, 34, 36, 41, 45, 47, 48, 49, 52, 53, 55, 56, 58, 60, 61, 63, 65, 66, 68, 69, 70, 71, 72, 74, 75, 84, 86, 88], "Of": [2, 25, 32, 61, 69], "both": [2, 19, 24, 30, 36, 45, 46, 52, 53, 55, 57, 58, 60, 68, 69, 71, 77, 82, 84, 86, 88], "assum": [2, 3, 15, 18, 25, 28, 30, 31, 32, 34, 35, 36, 45, 46, 47, 48, 52, 54, 57, 60, 61, 62, 65, 66, 69, 71, 75, 82, 85, 88], "nonneg": [2, 28], "again": [2, 16, 18, 19, 24, 25, 26, 30, 31, 34, 35, 36, 41, 43, 45, 47, 49, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 82, 88], "150": [2, 45, 47, 49, 75], "min": [2, 28, 37, 41, 52, 69, 70, 71, 72, 74, 86], "effect": [2, 10, 16, 18, 19, 26, 28, 34, 40, 45, 49, 54, 56, 58, 60, 61, 63, 65, 66, 68, 69, 71, 72, 74, 75, 77, 82, 84, 88], "oppos": [2, 31, 52, 77, 84, 86], "uniform": [2, 30, 31, 32, 37, 40, 47, 48, 63, 67, 84], "20": [2, 5, 15, 16, 18, 25, 30, 34, 35, 36, 45, 46, 47, 52, 53, 55, 58, 60, 63, 68, 69, 70, 71, 72, 74, 75, 77, 88, 92], "comment": [2, 14, 46, 69, 77, 86], "download": [3, 15, 16, 30, 31, 34, 36, 45, 47, 48, 49, 52, 53, 55, 58, 60, 68, 69, 70, 71, 72, 74, 82, 88], "wa": [3, 19, 28, 30, 32, 34, 36, 40, 41, 45, 46, 49, 52, 54, 55, 57, 66, 68, 69, 72, 74, 75, 82, 84, 86, 88, 89], "motiv": [3, 24, 32], "discuss": [3, 5, 16, 18, 19, 24, 26, 28, 30, 35, 36, 40, 42, 43, 45, 47, 49, 52, 53, 55, 60, 62, 67, 69, 70, 77, 82, 91], "section": [3, 16, 17, 18, 19, 24, 35, 46, 55, 56, 69, 77, 82, 86, 88], "holm": 3, "huber": 3, "book": [3, 19, 24, 32, 42, 91], "show": [3, 15, 16, 18, 28, 30, 31, 32, 34, 35, 36, 37, 41, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 77, 82, 86, 88], "gamma": [3, 31, 32, 35, 36, 37, 40, 47, 48, 49, 52, 53, 54, 58, 61, 68, 69, 70, 71, 72, 75, 86], "updat": [3, 15, 20, 26, 28, 32, 34, 47, 52, 54, 66, 67, 68, 71, 75, 82], "welcom": 3, "wikipedia": [3, 32, 55], "tabl": [3, 32, 46, 52, 85, 88], "check": [3, 5, 9, 11, 12, 13, 15, 16, 32, 38, 45, 46, 47, 48, 56, 58, 60, 63, 67, 69, 71, 72, 75, 77, 82, 85, 86, 88, 92], "answer": [3, 10, 46, 53, 54, 55, 57, 77, 85, 86, 88], "actual": [3, 26, 28, 30, 32, 35, 43, 45, 52, 53, 57, 60, 63, 65, 67, 68, 69, 71, 72, 74, 82, 86, 88], "proof": [3, 24, 71], "sequenc": [3, 82], "chromosom": 3, "dna": [3, 28, 45], "e": [3, 15, 16, 18, 19, 24, 26, 28, 30, 31, 35, 40, 45, 47, 52, 54, 56, 57, 58, 60, 61, 63, 65, 66, 68, 69, 71, 72, 74, 75, 77, 84, 86, 88], "coli": [3, 28, 66, 71], "strain": [3, 65], "atcc": 3, "baa": 3, "196": [3, 75], "fasta": 3, "format": [3, 12, 18, 34, 36, 46, 52, 63, 70, 71, 82], "resist": 3, "multipl": [3, 17, 35, 46, 55, 57, 74, 75, 82, 84, 86, 88], "drug": 3, "studi": [3, 5, 19, 26, 33, 45, 47, 48, 52, 65, 66, 69, 72, 75, 85, 88, 91], "antibiot": 3, "paper": [3, 25, 26, 32, 42, 45, 46, 47, 55, 56, 57, 60, 67, 68, 69, 71, 75, 82, 84, 85, 88], "read": [3, 5, 16, 25, 27, 34, 39, 40, 42, 46, 47, 54, 55, 57, 60, 65, 66, 67, 68, 75, 82, 85, 86, 92], "singl": [3, 20, 23, 24, 25, 27, 28, 32, 35, 45, 47, 49, 51, 53, 54, 55, 57, 60, 65, 66, 71, 72, 77, 85, 86, 88], "string": [3, 46, 66, 86], "below": [3, 5, 16, 18, 19, 24, 32, 36, 40, 46, 47, 48, 49, 51, 52, 53, 55, 56, 60, 66, 67, 69, 71, 74, 77, 82, 84, 86, 88], "1": [3, 4, 5, 16, 18, 19, 23, 24, 25, 26, 28, 30, 31, 32, 34, 35, 36, 37, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 78, 82, 84, 85, 86, 88, 92], "def": [3, 30, 31, 34, 36, 45, 51, 69, 70, 71, 72, 74, 75, 82, 86], "read_fasta_single_record": 3, "filenam": [3, 46, 77], "file": [3, 15, 46, 52, 71, 75, 77], "contain": [3, 19, 24, 28, 31, 32, 35, 43, 45, 46, 47, 49, 51, 52, 54, 60, 61, 65, 66, 69, 72, 74, 75, 77, 82, 84, 86, 91], "line": [3, 9, 15, 18, 25, 28, 30, 31, 32, 34, 35, 37, 45, 46, 47, 48, 49, 51, 52, 68, 69, 70, 71, 72, 74, 82, 84, 86, 88], "descriptor": 3, "all": [3, 5, 15, 16, 19, 23, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 41, 43, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 86, 88], "subsequ": [3, 26, 54, 69, 74, 88], "open": [3, 15, 16, 18, 75, 86], "r": [3, 18, 19, 41, 42, 46, 56, 66, 75, 84, 86], "f": [3, 16, 18, 20, 21, 23, 24, 25, 26, 28, 30, 32, 34, 35, 37, 40, 45, 47, 52, 54, 57, 60, 61, 62, 63, 65, 66, 67, 69, 70, 71, 72, 74, 75, 82, 84, 85, 86, 88], "readlin": 3, "rstrip": 3, "strip": [3, 66, 68, 72, 75, 77], "whitespac": 3, "seq": 3, "while": [3, 15, 28, 30, 31, 32, 34, 41, 42, 45, 46, 47, 49, 52, 55, 57, 67, 69, 70, 72, 75, 77, 82, 84, 86, 88], "return": [3, 5, 24, 30, 31, 34, 35, 36, 40, 42, 45, 46, 47, 48, 49, 52, 53, 58, 60, 69, 70, 71, 72, 74, 75, 82, 84, 86, 88], "find": [3, 6, 7, 15, 16, 23, 25, 26, 27, 28, 30, 31, 34, 35, 36, 47, 51, 52, 54, 57, 60, 67, 69, 70, 71, 74, 75, 77, 82, 84, 86, 91], "index": [3, 43, 45, 46, 47, 52, 53, 55, 60, 66, 72, 75], "shine": 3, "delgarno": 3, "motif": 3, "initi": [3, 15, 31, 32, 34, 36, 52, 54, 60, 70, 71, 82, 84, 88], "protein": [3, 52, 85, 88], "synthesi": 3, "aggaggt": 3, "recognit": 3, "recognition_sites_with_r": 3, "recog_seq": 3, "indic": [3, 6, 34, 47, 49, 52, 54, 55, 56, 58, 60, 61, 63, 66, 67, 68, 69, 71, 72, 74, 77, 82, 88], "findit": 3, "append": [3, 45, 51, 52, 72, 86], "start": [3, 15, 18, 19, 26, 28, 30, 31, 34, 36, 42, 45, 46, 47, 48, 49, 51, 52, 55, 56, 60, 66, 67, 69, 70, 71, 72, 82, 84, 85, 86, 88], "store": [3, 15, 30, 31, 46, 51, 52, 53, 55, 60, 70, 88], "number": [3, 10, 15, 16, 18, 19, 24, 25, 26, 28, 30, 32, 39, 43, 45, 46, 47, 49, 51, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 72, 74, 75, 77, 82, 84, 85, 86, 88], "base": [3, 5, 13, 15, 16, 19, 25, 26, 28, 45, 46, 47, 51, 52, 54, 55, 57, 58, 69, 70, 75, 82, 85, 86, 88, 91, 92], "between": [3, 19, 24, 26, 27, 28, 31, 36, 42, 45, 47, 48, 49, 52, 54, 55, 57, 58, 60, 61, 66, 67, 68, 69, 72, 75, 78, 82, 84, 85, 88, 89], "occurr": [3, 19], "distanc": [3, 28, 54, 75, 82], "explain": [3, 8, 10, 12, 71, 77, 85], "reason": [3, 5, 19, 25, 28, 30, 34, 35, 45, 47, 52, 53, 54, 55, 56, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 86, 88, 91], "exploratori": 3, "ecdf": [3, 43, 46, 47, 48, 49, 52, 53, 55, 58, 63, 75, 88], "inter": 3, "comput": [3, 5, 6, 7, 11, 15, 19, 23, 24, 25, 26, 28, 40, 41, 42, 43, 57, 62, 65, 66, 67, 84, 86], "rate": [3, 24, 41, 52, 69, 70, 71, 74, 85, 88], "invers": [3, 28, 34, 35, 40, 45, 47, 54, 69, 70, 72, 82], "characterist": [3, 34, 52, 71], "overwhelm": [4, 63, 84], "45": [4, 31, 32, 47, 51, 72], "exponenti": [4, 24, 27, 30, 31, 35, 36, 40, 51, 54, 57, 69, 70, 72, 74, 82, 84, 88], "conjug": [4, 6, 69], "55": [4, 45, 66, 72], "prequel": [5, 30], "tool": [5, 18, 19, 34, 36, 57, 77, 85, 91], "analysi": [5, 13, 19, 26, 28, 30, 36, 42, 43, 46, 47, 48, 52, 68, 69, 71, 72, 75, 77, 85, 86, 91], "pipelin": [5, 52, 68], "includ": [5, 15, 16, 17, 18, 19, 24, 26, 28, 34, 35, 40, 43, 45, 46, 47, 49, 51, 52, 53, 55, 57, 58, 60, 66, 67, 68, 69, 71, 75, 77, 82, 84, 85, 86, 88], "organ": [5, 45, 60, 66], "preserv": [5, 54, 84], "share": [5, 15, 28], "displai": [5, 47, 52, 55, 56, 69, 71, 75, 77, 92], "quantit": [5, 19, 52, 53], "basic": [5, 8, 14, 39, 45, 49, 75, 82, 84, 86, 88], "techniqu": [5, 28, 40, 45, 46, 49, 55, 57, 60, 67, 71, 75, 84], "resampl": [5, 46, 84], "method": [5, 16, 19, 26, 27, 30, 31, 34, 35, 36, 42, 45, 46, 47, 48, 49, 52, 53, 55, 57, 60, 66, 67, 70, 71, 75, 82, 86], "frequentist": [5, 28, 35, 46], "deeper": [5, 66], "mostli": [5, 28, 36, 67, 68, 84], "comparison": [5, 52, 53, 56, 58, 72, 75, 88, 92], "hierarch": [5, 12, 18, 26, 28, 52, 54, 69, 72, 92], "markov": [5, 8, 26, 28, 31, 35, 38, 40, 43, 44, 46, 52, 53, 55, 67, 74, 92], "chain": [5, 8, 10, 26, 28, 31, 35, 38, 40, 41, 42, 43, 44, 46, 47, 48, 49, 52, 53, 55, 56, 58, 60, 62, 65, 66, 67, 68, 69, 71, 72, 74, 82, 84, 86, 88, 92], "mont": [5, 8, 26, 28, 31, 35, 38, 41, 43, 44, 46, 52, 53, 67, 74, 88, 92], "carlo": [5, 8, 26, 28, 31, 35, 38, 41, 43, 44, 46, 52, 53, 67, 74, 88, 92], "graphic": [5, 9, 11, 35, 40, 52, 56, 66, 67, 77, 86], "principl": [5, 13, 28, 52, 54, 57, 68, 69, 84, 85, 92], "workflow": [5, 26, 52, 77, 86, 92], "topic": [5, 28, 38, 55, 61, 69, 82, 86], "real": [5, 16, 18, 19, 24, 28, 35, 45, 46, 47, 48, 49, 52, 53, 55, 56, 58, 60, 61, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 86, 88], "enrol": 5, "pleas": [5, 12, 28, 32, 67, 69, 77], "ed": [5, 77, 91], "commun": [5, 16, 45, 88], "canva": [5, 77], "assign": [5, 19, 24, 28, 46, 47, 52, 84, 86], "submiss": [5, 86], "solut": [5, 69, 74, 75, 77, 82, 84, 86], "password": [5, 86], "protect": [5, 60, 70, 71], "instructor": [5, 77, 92], "justin": [5, 86], "boi": [5, 46, 70, 71, 86], "caltech": [5, 15, 16, 17, 30, 34, 45, 77, 88], "dot": [5, 47, 82, 85], "edu": [5, 16, 30, 34, 45, 77, 86, 88], "ta": [5, 77, 78, 84, 89, 92], "kayla": 5, "jackson": 5, "logic": [5, 24, 49, 57, 69, 86, 91, 92], "scientif": [5, 16, 86, 91, 92], "2": [5, 16, 18, 19, 24, 25, 28, 30, 31, 32, 34, 35, 36, 37, 40, 43, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 84, 85, 86, 88, 89, 92], "introduct": [5, 38, 46, 55, 82, 88, 92], "3": [5, 16, 18, 19, 24, 28, 31, 32, 34, 35, 36, 43, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 57, 58, 60, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 81, 82, 84, 85, 86, 88, 92], "4": [5, 16, 18, 24, 28, 30, 32, 34, 35, 36, 41, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88, 92], "margin": [5, 6, 19, 22, 24, 25, 26, 34, 35, 36, 41, 43, 47, 48, 51, 54, 63, 67, 69, 70, 72, 74, 75, 84, 92], "numer": [5, 26, 34, 35, 36, 47, 57, 65, 69, 70, 74, 84, 86, 88], "quadratur": [5, 36], "5": [5, 16, 18, 24, 25, 28, 30, 31, 34, 35, 36, 37, 40, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 60, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 85, 86, 88, 92], "conjugaci": [5, 31, 69, 92], "e1": 5, "after": [5, 18, 19, 25, 26, 31, 32, 36, 40, 45, 46, 52, 53, 55, 57, 67, 68, 72, 74, 75, 77, 82, 84, 85, 88], "6": [5, 24, 30, 31, 34, 35, 36, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 86, 87, 88, 92], "optim": [5, 7, 26, 30, 31, 41, 45, 46, 60, 72, 73, 74, 75, 82, 86, 92], "e2": 5, "7": [5, 16, 18, 28, 30, 31, 34, 36, 37, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 86, 88, 92], "8": [5, 16, 18, 30, 31, 32, 34, 35, 36, 37, 45, 46, 47, 48, 51, 52, 53, 55, 56, 58, 60, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 86, 88, 89, 92], "mcmc": [5, 10, 12, 15, 26, 28, 39, 41, 42, 46, 52, 53, 56, 57, 60, 63, 67, 68, 69, 73, 75, 82, 84, 88, 91, 92], "stan": [5, 15, 16, 28, 38, 41, 42, 47, 49, 53, 54, 55, 56, 58, 60, 62, 63, 67, 68, 77, 84, 91, 92], "9": [5, 16, 18, 30, 31, 34, 36, 45, 46, 52, 53, 55, 56, 58, 60, 63, 65, 66, 68, 69, 70, 71, 72, 74, 75, 77, 82, 86, 88, 90, 92], "mixtur": [5, 51, 92], "label": [5, 57, 60, 61, 66, 82, 85, 88, 92], "switch": [5, 60, 61, 92], "variat": [5, 14, 25, 26, 30, 31, 33, 46, 49, 52, 65, 69, 72, 86, 92], "covari": [5, 25, 33, 34, 35, 49, 54, 70, 72, 74, 75, 82, 84, 92], "e3": 5, "11": [5, 16, 18, 30, 31, 32, 34, 35, 36, 45, 46, 47, 49, 52, 53, 54, 55, 56, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88, 92], "12": [5, 16, 18, 30, 31, 34, 36, 45, 46, 47, 48, 49, 51, 53, 54, 55, 56, 58, 60, 63, 65, 66, 68, 69, 70, 71, 72, 74, 75, 86, 88, 92], "predict": [5, 9, 11, 13, 19, 36, 45, 46, 48, 54, 58, 60, 63, 67, 68, 71, 75, 85, 86, 88, 92], "13": [5, 30, 31, 34, 36, 45, 46, 47, 48, 49, 51, 52, 55, 56, 58, 60, 66, 68, 69, 70, 71, 72, 75, 86, 88, 92], "e4": 5, "14": [5, 30, 31, 34, 36, 45, 46, 47, 49, 52, 53, 55, 56, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 86, 88, 92], "collector": [5, 92], "box": [5, 19, 40, 84, 92], "15": [5, 16, 18, 30, 31, 32, 34, 35, 36, 45, 46, 47, 51, 52, 53, 56, 60, 63, 66, 68, 69, 70, 71, 72, 75, 82, 86, 88, 92], "diagnost": [5, 10, 12, 42, 47, 49, 58, 60, 63, 68, 69, 71, 72, 74, 84, 88, 92], "16": [5, 16, 18, 30, 36, 45, 46, 47, 49, 52, 53, 55, 60, 66, 68, 69, 70, 71, 72, 75, 82, 86, 88, 92], "A": [5, 19, 21, 24, 25, 27, 28, 33, 35, 40, 46, 47, 49, 51, 53, 55, 57, 61, 68, 69, 71, 77, 85, 86, 88, 91], "case": [5, 15, 23, 24, 25, 26, 27, 28, 30, 31, 33, 35, 36, 40, 41, 43, 45, 46, 47, 48, 51, 52, 53, 54, 55, 57, 60, 61, 62, 65, 66, 67, 68, 69, 70, 71, 75, 77, 82, 84, 86, 88, 91], "artifici": [5, 51], "funnel": [5, 66, 72, 75, 84, 92], "hell": [5, 92], "e5": 5, "18": [5, 16, 18, 30, 45, 46, 47, 48, 51, 52, 53, 55, 58, 60, 63, 65, 66, 68, 69, 71, 72, 75, 82, 88, 92], "practic": [5, 19, 25, 28, 40, 47, 54, 55, 57, 69, 77, 82, 84, 86, 92], "e6": 5, "19": [5, 30, 35, 45, 46, 47, 52, 55, 60, 68, 69, 71, 72, 75, 88, 92], "e7": 5, "21": [5, 30, 31, 34, 36, 45, 46, 47, 48, 51, 52, 53, 54, 55, 56, 58, 60, 66, 68, 69, 75, 88, 92], "22": [5, 52, 54, 60, 66, 69, 72, 75, 86, 88, 92], "simul": [5, 13, 15, 52, 86, 88, 92], "calibr": [5, 13, 15, 52, 86, 92], "relat": [5, 13, 24, 25, 28, 34, 35, 40, 52, 56, 57, 67, 69, 77, 84, 86], "e8": 5, "23": [5, 47, 49, 52, 66, 68, 75, 88], "gaussian": [5, 14, 25, 31, 62, 71, 74, 75, 84], "process": [5, 15, 16, 19, 23, 25, 26, 27, 40, 45, 46, 52, 53, 54, 56, 57, 67, 71, 74, 84, 85, 88], "24": [5, 47, 49, 52, 68, 74, 75, 77, 88, 92], "25": [5, 16, 18, 30, 31, 34, 36, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 66, 68, 69, 70, 71, 72, 74, 86, 88, 92], "e9": 5, "26": [5, 16, 18, 30, 31, 32, 34, 35, 36, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 88, 92], "wrap": [5, 92], "analyt": [5, 26, 28, 32, 35, 36, 43, 48, 56, 72, 75, 84], "overview": [5, 83, 86], "due": [5, 16, 19, 28, 52, 57, 71, 77, 82, 86, 88], "date": [5, 77], "exercis": [5, 15, 30, 51, 52, 60], "weekli": [5, 77], "meet": 5, "session": [5, 15, 16, 46, 81, 90], "collabor": [5, 16], "honor": 5, "code": [5, 15, 16, 18, 25, 30, 31, 34, 36, 45, 48, 49, 51, 52, 53, 55, 56, 58, 60, 68, 69, 70, 71, 72, 74, 75, 88], "ediquett": 5, "softwar": [5, 15, 41], "tutori": [5, 56, 60, 86], "winter": 5, "2024": [5, 16, 45, 46, 47, 60], "2022": 5, "2021": [5, 55], "2020": [5, 42], "statement": [6, 47, 48, 52, 69, 74], "sens": [6, 19, 24, 25, 28, 30, 31, 32, 35, 36, 52, 57, 65, 67, 68, 69, 84, 85, 88], "curs": [6, 26, 30], "dimension": [6, 25, 26, 28, 30, 46, 47, 49, 53, 60, 69, 74, 82], "appear": [6, 15, 16, 30, 52, 75, 85], "few": [6, 17, 26, 28, 30, 32, 36, 42, 45, 46, 47, 48, 51, 52, 55, 57, 58, 60, 66, 67, 68, 69, 72, 75, 86, 88], "confus": [6, 7, 68, 69, 77], "map": [7, 36, 47, 51, 63, 69, 71, 74, 84, 86], "local": [7, 16, 18, 26, 31, 34, 35, 69, 86], "approxim": [7, 25, 26, 31, 40, 43, 45, 49, 51, 52, 54, 55, 56, 57, 60, 62, 66, 69, 71, 75, 82, 85, 88], "possibli": [7, 43, 49, 66, 67, 69, 88], "multivari": [7, 25, 26, 28, 35, 36, 54, 69, 72, 82, 84], "mean": [7, 8, 9, 13, 14, 15, 16, 18, 19, 25, 27, 28, 30, 34, 36, 40, 42, 43, 45, 46, 47, 51, 52, 54, 55, 56, 57, 60, 61, 65, 66, 67, 68, 70, 71, 72, 74, 75, 77, 82, 84, 86, 88], "ha": [7, 15, 18, 19, 24, 25, 26, 27, 28, 30, 31, 32, 34, 35, 40, 41, 42, 45, 46, 47, 49, 52, 54, 55, 56, 57, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 82, 84, 85, 86, 88, 91], "stori": [7, 25, 27, 28, 32, 47, 54, 82, 88], "meant": [7, 15, 47, 67, 84], "weakli": [7, 34, 48, 52, 61, 65, 66], "inform": [7, 15, 16, 19, 20, 24, 30, 31, 32, 34, 36, 46, 48, 51, 52, 53, 55, 58, 60, 61, 66, 67, 68, 75, 82, 84, 86, 88, 92], "credibl": [7, 36, 48, 49, 51, 63, 69, 70, 71, 74], "interv": [7, 28, 32, 36, 40, 46, 47, 48, 49, 51, 54, 62, 63, 67, 68, 69, 70, 71, 74, 82, 85], "off": [7, 25, 30, 34, 46, 48, 54, 56, 65, 68, 69, 71, 82, 84], "true": [7, 18, 19, 28, 30, 45, 46, 47, 48, 49, 51, 52, 56, 57, 58, 60, 63, 66, 67, 68, 69, 74, 75, 82, 86, 88], "word": [8, 11, 14, 19, 26, 40, 45, 48, 52, 57, 65, 67, 69, 86], "being": [8, 13, 16, 28, 30, 32, 45, 46, 48, 52, 54, 55, 57, 66, 69, 72, 74, 75, 77, 84], "abl": [8, 31, 36, 40, 43, 45, 49, 52, 55, 57, 66, 68, 69, 77, 84, 85, 86, 88], "behind": [8, 14, 25, 32, 39, 45, 57, 60, 75, 77], "warm": [8, 39, 45, 55, 82, 84], "sampler": [8, 10, 38, 41, 42, 45, 46, 47, 49, 53, 56, 58, 66, 67, 82, 88], "nonidentifi": [8, 47], "contend": 9, "fit": [9, 15, 19, 48, 52, 65, 69, 72, 91], "suffici": [9, 25, 30, 40, 41, 70], "assess": [9, 28, 34, 45, 47, 52, 54, 60, 67], "further": [9, 19, 30, 39, 52, 57, 66, 68, 69, 75], "better": [9, 28, 40, 47, 49, 53, 57, 58, 60, 66, 68, 69, 72, 75, 77], "agre": [9, 19, 28, 55, 57], "good": [9, 25, 30, 31, 35, 36, 42, 45, 46, 47, 48, 49, 52, 53, 54, 55, 56, 57, 58, 60, 61, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 86, 88, 91], "independ": [10, 14, 25, 27, 28, 30, 31, 36, 40, 47, 48, 54, 55, 56, 57, 58, 60, 61, 63, 66, 69, 75, 82, 88], "usual": [10, 16, 19, 30, 36, 46, 48, 52, 54, 55, 57, 60, 63, 67, 69, 70, 71, 72, 82, 86, 88], "than": [10, 15, 19, 24, 25, 26, 28, 30, 32, 34, 35, 36, 40, 42, 45, 46, 47, 51, 52, 54, 55, 57, 60, 61, 63, 65, 67, 68, 69, 71, 75, 77, 82, 84, 86, 88], "total": [10, 15, 34, 36, 51, 53, 55, 57, 58, 65, 66, 68, 69, 75, 77, 82, 84, 86, 88], "diverg": [10, 28, 46, 47, 56, 58, 60, 63, 66, 68, 69, 71, 72, 74, 75, 84, 88], "diagnos": [10, 49, 56, 66, 67, 68], "potenti": [10, 49, 82, 84, 88], "ever": [10, 15, 56, 75, 82], "guarante": [10, 18, 28, 34, 35, 47, 55, 75], "properli": [10, 30, 45, 46, 48, 49, 55, 56, 66, 67, 68, 71, 77, 88], "finit": [10, 40, 45, 71, 84], "step": [10, 15, 18, 19, 26, 30, 34, 36, 40, 41, 42, 46, 49, 52, 53, 55, 56, 57, 62, 66, 67, 69, 72, 75, 82, 84, 86, 88], "ye": [10, 46, 53], "stop": [10, 52, 60, 67, 75, 84], "underscor": [10, 47, 57], "need": [10, 15, 16, 17, 18, 19, 24, 25, 26, 27, 30, 31, 34, 36, 40, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 60, 61, 65, 66, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 85, 86, 88], "extens": [10, 47, 82, 86], "pointwis": [11, 58, 88], "log": [11, 15, 16, 28, 31, 34, 35, 36, 45, 47, 51, 52, 53, 54, 56, 58, 66, 68, 70, 71, 75, 82, 84], "still": [11, 25, 28, 35, 41, 45, 49, 51, 52, 53, 54, 56, 57, 60, 66, 68, 69, 75, 82, 86, 88], "necessari": [11, 15, 16, 30, 41, 42, 43, 47, 51, 54, 55, 66, 72, 77], "inde": [11, 24, 25, 26, 45, 46, 47, 52, 69, 74], "essenti": [11, 25, 46, 55, 66, 77, 84, 86], "waic": [11, 57], "loo": [11, 57, 58], "tidi": [12, 49, 66], "encount": [12, 24, 28, 30, 35, 46, 55, 68, 69, 70, 71, 72, 82, 85, 88], "structur": [12, 19, 31, 46, 47, 54, 72, 75, 77, 84, 86], "own": [12, 15, 16, 17, 18, 19, 46, 69, 71, 75, 77, 84, 86], "briefli": [12, 46, 49, 82], "situat": [12, 28, 60, 61, 88], "exchang": 12, "thoroughli": [12, 75], "especi": [12, 32, 34, 47, 51, 60, 77, 82, 86, 91], "addit": [12, 13, 14, 16, 26, 30, 47, 57, 63, 75, 84, 86, 88], "z": [13, 19, 68, 69, 71, 74], "score": [13, 68], "help": [13, 15, 20, 21, 30, 49, 52, 53, 54, 55, 56, 58, 67, 69, 77, 84, 86, 88, 92], "verifi": [13, 16, 18, 46, 53, 67, 70, 77], "shrinkag": [13, 68], "rank": [13, 14, 51, 55, 56, 58, 60, 66, 68, 75, 82, 88], "statist": [13, 15, 17, 18, 25, 42, 43, 46, 47, 51, 52, 54, 57, 66, 68, 69, 75, 82, 88, 91], "possibl": [13, 18, 19, 23, 25, 27, 28, 40, 46, 47, 48, 49, 51, 52, 57, 66, 67, 68, 69, 75, 82, 84, 86, 88], "pitfal": 13, "By": [13, 20, 25, 28, 43, 49, 55, 60, 67, 69, 82], "cautiou": 13, "sbc": [13, 15, 52, 67, 86], "analys": [13, 16, 26, 67, 86], "infer": [14, 15, 17, 21, 26, 28, 30, 31, 34, 35, 46, 47, 52, 55, 57, 63, 67, 68, 70, 71, 72, 91, 92], "elbo": [14, 75], "advantag": [14, 17, 18, 28, 32, 51, 52, 57, 65, 69, 84, 88], "disadvantag": [14, 17, 32], "field": [14, 75, 82, 84, 85], "famili": [14, 26, 69, 75, 84], "more": [15, 16, 19, 20, 24, 25, 26, 28, 30, 31, 32, 34, 36, 38, 41, 42, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 83, 84, 86, 88], "run": [15, 16, 17, 18, 19, 30, 36, 45, 46, 47, 52, 55, 56, 66, 67, 68, 72, 75, 77, 84, 88], "calcul": [15, 17, 19, 25, 26, 28, 31, 32, 34, 36, 45, 46, 51, 52, 54, 55, 57, 58, 67, 68, 69, 73, 74, 75, 77, 84, 86, 87, 88], "power": [15, 18, 43, 45, 46, 47, 55, 57, 67, 69, 82, 86], "instal": [15, 16, 45, 46, 86, 88], "suffic": [15, 34, 52], "serv": [15, 19, 20, 32, 45, 52, 63, 69, 70, 82], "well": [15, 16, 18, 25, 26, 27, 28, 30, 34, 35, 36, 43, 46, 47, 49, 53, 57, 60, 61, 65, 68, 69, 70, 71, 82, 84, 88], "expans": [15, 35], "resourc": [15, 16, 18, 35, 77, 86], "avail": [15, 16, 28, 30, 45, 46, 51, 52, 53, 55, 58, 68, 74, 77, 86, 91], "option": [15, 30, 34, 49, 52, 77, 84, 86], "googl": [15, 17, 18, 45, 46, 77, 88], "cloud": [15, 16, 17, 18], "platform": [15, 16], "microsoft": [15, 16, 17], "azur": [15, 17], "high": [15, 17, 25, 28, 35, 42, 49, 55, 56, 69, 70, 71, 82, 86], "center": [15, 28, 35, 47, 51, 52, 56, 66, 70, 71, 72, 74, 82, 88], "lesson": [15, 17, 18, 26, 28, 30, 31, 34, 35, 45, 46, 47, 48, 49, 52, 53, 55, 56, 58, 60, 62, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 86], "lot": [15, 19, 30, 45, 46, 49, 53, 54, 57, 58, 66, 69, 72, 88], "done": [15, 19, 25, 26, 34, 45, 46, 47, 49, 52, 57, 60, 65, 66, 69, 72, 74, 82, 84, 86, 88], "onli": [15, 16, 19, 25, 26, 28, 30, 32, 34, 36, 40, 41, 43, 47, 49, 52, 54, 55, 57, 65, 66, 68, 69, 71, 74, 75, 77, 82, 85, 86, 88], "onc": [15, 16, 42, 46, 53, 69, 82, 84, 86, 88], "much": [15, 16, 18, 19, 24, 25, 26, 30, 31, 34, 35, 36, 41, 43, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 60, 66, 67, 68, 69, 70, 71, 72, 75, 77, 82, 84, 88], "next": [15, 16, 19, 20, 28, 30, 31, 34, 35, 36, 40, 41, 46, 52, 53, 54, 63, 65, 69, 70, 75, 82, 84, 88], "quick": [15, 16, 30, 34, 36, 45, 48, 49, 52, 53, 55, 56, 57, 60, 68, 69, 72, 75, 88, 91], "refer": [15, 19, 25, 28, 35, 46, 47, 48, 51, 55, 57, 69, 71, 75, 77, 84, 88, 91], "spin": [15, 88], "outlin": [15, 42, 60, 71, 77, 84], "alreadi": [15, 16, 18, 20, 24, 26, 34, 35, 36, 40, 45, 47, 49, 52, 57, 69, 71, 72, 75, 84, 86], "cost": [15, 67], "100": [15, 19, 28, 30, 34, 35, 36, 45, 52, 56, 60, 66, 68, 69, 75, 77, 82, 86, 88, 92], "four": [15, 28, 45, 46, 49, 52, 53, 55, 62, 66, 67, 84], "core": [15, 16, 17, 46, 68, 86], "entir": [15, 28, 34, 52, 54, 66, 71, 77, 81, 82, 85, 86, 90], "consol": [15, 86], "http": [15, 16, 30, 34, 45, 55, 77, 82, 88], "com": [15, 16, 30, 34, 45, 77, 82, 86, 88], "click": [15, 16, 56], "button": 15, "upper": [15, 28, 35, 47, 48, 51, 52, 53, 55, 58, 60, 63, 69, 70, 71, 75, 88], "page": [15, 16, 32, 43, 77, 86, 92], "imag": [15, 30, 31, 46, 52, 54, 56, 72, 82, 85, 88], "ami": 15, "pre": [15, 16, 69, 77, 86], "oregon": [15, 46], "u": [15, 19, 20, 21, 23, 26, 30, 31, 34, 35, 36, 37, 43, 45, 46, 52, 53, 56, 57, 58, 60, 63, 66, 68, 69, 71, 77, 82, 86, 88], "west": 15, "Be": [15, 26, 66], "sure": [15, 18, 25, 28, 30, 34, 40, 45, 49, 52, 53, 54, 55, 57, 60, 66, 67, 68, 70, 74, 75, 77, 82, 85, 86, 88], "select": [15, 18, 31, 47, 49, 54, 59, 66, 75, 77, 88], "region": [15, 30, 35, 36, 42, 46, 49, 51, 52, 55, 56, 69, 82, 84], "top": [15, 16, 52, 63, 77], "corner": [15, 47, 48, 51, 53, 56, 58, 60, 63, 66, 68, 69, 71, 72, 74, 75, 82, 88], "same": [15, 16, 19, 20, 24, 25, 28, 31, 32, 34, 36, 41, 45, 46, 47, 49, 53, 55, 56, 57, 60, 61, 66, 67, 68, 69, 70, 71, 72, 75, 82, 84, 85, 88], "throughout": [15, 18, 25, 35, 52, 77, 88, 91], "sinc": [15, 19, 25, 28, 30, 31, 34, 35, 36, 40, 41, 45, 46, 47, 48, 51, 52, 53, 55, 56, 57, 58, 60, 61, 67, 68, 69, 70, 71, 72, 74, 75, 77, 82, 88], "physic": [15, 19, 26, 30, 31, 36, 48, 52, 69, 82, 84, 91], "live": [15, 68, 86], "ec2": 15, "among": [15, 23, 28, 52, 75, 77], "pulldown": [15, 77], "menu": [15, 77], "left": [15, 19, 24, 25, 28, 30, 31, 35, 36, 41, 43, 45, 47, 48, 49, 52, 53, 56, 57, 58, 60, 61, 65, 67, 69, 71, 75, 77, 82, 84, 86, 88], "screen": [15, 45, 49, 77], "pane": 15, "under": [15, 19, 28, 30, 31, 35, 47, 52, 53, 55, 63, 65, 67, 77, 84, 86, 88], "default": [15, 16, 26, 46, 47, 49, 55, 56, 60, 69, 75, 86], "me": [15, 19, 26, 28, 51, 52, 57, 86], "instead": [15, 18, 24, 28, 30, 31, 34, 35, 36, 40, 47, 49, 51, 52, 53, 54, 56, 57, 60, 65, 68, 69, 70, 71, 72, 75, 77, 82, 84, 86, 88], "public": 15, "search": [15, 74, 77], "bebi103": [15, 16, 18, 30, 31, 34, 35, 36, 45, 46, 47, 48, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 77, 86, 88, 91], "doubl": [15, 40, 47, 72, 84], "list": [15, 47, 51, 54, 61, 68, 69, 77, 85, 86, 88], "request": [15, 16, 45, 85, 86, 88], "spot": 15, "save": [15, 52, 86, 88], "monei": [15, 19], "lose": [15, 61, 75, 88], "whatev": [15, 69, 86], "taken": [15, 26, 40, 43, 46, 55, 56, 82], "name": [15, 19, 25, 27, 28, 40, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 77, 86, 88], "tag": [15, 88], "give": [15, 20, 23, 26, 28, 30, 31, 34, 36, 41, 45, 46, 47, 49, 51, 52, 55, 57, 60, 62, 66, 67, 68, 69, 70, 71, 75, 77, 82, 84, 85, 86, 88, 91], "recommend": [15, 16, 38, 55, 75, 82, 86], "back": [15, 65, 67, 68, 69, 75, 77, 82, 84, 86, 88], "simpli": [15, 16, 26, 28, 32, 36, 42, 43, 45, 47, 49, 53, 54, 57, 63, 82, 84, 86, 88], "mine": 15, "skip": [15, 18, 55, 69, 84], "applic": [15, 25, 28, 41, 57, 69, 70, 82, 88], "o": [15, 16, 30, 31, 34, 36, 45, 46, 47, 48, 49, 52, 53, 55, 58, 60, 68, 69, 70, 71, 72, 74, 75, 77, 86, 88], "type": [15, 28, 45, 46, 47, 48, 49, 68, 71, 82, 84, 86, 88], "choic": [15, 28, 32, 36, 49, 51, 53, 54, 65, 69, 70, 75, 77, 82, 88], "c5": 15, "xlarg": 15, "intens": [15, 25, 35, 66, 86], "2xlarg": 15, "larger": [15, 52, 54, 56, 66, 69, 72, 82, 84, 86, 88], "kei": [15, 45, 52, 60, 69, 82], "pair": [15, 19, 26, 30, 31, 47, 52, 69, 75], "login": [15, 86], "new": [15, 19, 24, 26, 28, 30, 45, 46, 47, 52, 53, 54, 57, 69, 70, 82, 84, 86, 91], "pop": 15, "window": [15, 77], "enter": [15, 82], "someth": [15, 19, 30, 32, 52, 57, 65, 67, 69, 77, 82, 84, 86], "bebi103_aws_keypair": 15, "fine": [15, 16, 49, 53, 58, 74, 77], "leav": [15, 17, 28, 46, 49, 60, 69, 70, 88], "radio": 15, "NOT": 15, "repeat": [15, 19, 24, 27, 29, 45, 49, 52, 53, 54, 64, 69, 72], "git": [15, 46], "repositori": 15, "anyth": [15, 16, 19, 28, 57, 66, 67, 82, 84, 88], "dropbox": [15, 46], "never": [15, 25, 30, 40, 41, 42, 46, 55, 60, 69, 75], "let": [15, 19, 20, 23, 25, 28, 30, 31, 34, 35, 42, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 63, 65, 66, 68, 69, 71, 72, 74, 75, 77, 82, 84, 88], "internet": [15, 17, 86], "reus": 15, "forward": [15, 19, 21, 31, 52, 57, 69, 74, 82, 84], "network": 15, "sourc": [15, 30, 31, 34, 36, 48, 49, 52, 68, 69, 70, 72, 75, 77, 86], "allow": [15, 16, 35, 40, 41, 43, 45, 47, 48, 52, 53, 55, 56, 58, 60, 63, 69, 71, 72, 74, 75, 77, 82, 84, 86, 88], "ssh": [15, 86], "traffic": 15, "anywher": [15, 45, 68, 77, 91], "everyth": [15, 19, 46, 49, 52, 55, 58, 60, 66, 68, 69, 72, 74], "els": [15, 16, 45, 46, 60, 77, 88], "secur": 15, "ip": 15, "prove": [15, 23, 25, 30, 69, 86], "inconveni": 15, "home": [15, 74, 86], "campu": [15, 86], "configur": [15, 17, 86], "storag": [15, 16, 88], "30": [15, 30, 31, 37, 52, 53, 58, 75, 77, 86, 88, 92], "gib": 15, "gp2": 15, "root": [15, 28, 66, 86], "volum": [15, 30, 52, 82, 84, 86], "enough": [15, 16, 28, 30, 36, 40, 47, 52, 55, 69, 84], "rest": [15, 16, 25, 26, 45, 55, 68, 82, 86], "bottom": [15, 56, 66], "summari": [15, 28, 30, 50, 55, 68, 69], "view": [15, 26, 47, 68, 82, 86], "dashboard": [15, 52], "It": [15, 16, 18, 19, 24, 25, 27, 28, 30, 31, 32, 34, 35, 36, 40, 41, 43, 45, 46, 47, 48, 49, 51, 52, 54, 55, 56, 57, 58, 60, 66, 67, 68, 69, 70, 71, 72, 74, 77, 78, 82, 84, 88, 89], "state": [15, 19, 24, 26, 28, 40, 41, 45, 47, 51, 55, 58, 69, 71, 75, 84, 88], "statu": 15, "readi": [15, 34, 55, 70, 71, 72, 88], "protocol": 15, "instruct": [15, 17, 18, 19, 31, 46, 52, 66, 77], "maco": 15, "linux": [15, 86], "bash": [15, 86], "zsh": 15, "accomplish": [15, 36, 43, 46, 47, 51, 55, 60, 69, 70, 72, 84, 88], "gitbash": 15, "identifi": [15, 26, 30, 31, 32, 35, 45, 47, 52, 55, 57, 67, 68, 69, 77, 82, 84], "put": [15, 28, 46, 48, 49, 52, 54, 55, 61, 67, 68, 69, 71, 82, 85, 86], "keypair": 15, "directori": [15, 16, 46, 74, 77, 86], "key_pair": 15, "pem": 15, "chang": [15, 16, 28, 45, 47, 52, 55, 56, 57, 65, 67, 71, 72, 75, 77, 82, 84, 86, 88, 92], "permiss": 15, "chmod": 15, "400": [15, 32, 35, 37, 55, 56, 66, 75, 82, 88], "clink": 15, "webpag": 15, "ipv4": 15, "54": [15, 47, 55, 63, 65, 66, 75], "92": [15, 60, 75], "67": 15, "command": [15, 18, 46, 82, 86], "user": [15, 46, 70, 71, 84, 86], "avoid": [15, 16, 25, 30, 31, 34, 45, 66, 68, 69, 72, 77, 82], "add": [15, 19, 36, 46, 47, 51, 53, 56, 57, 58, 61, 69, 70, 71, 72, 74, 77, 82, 85, 86, 88], "profil": [15, 75, 86], "echo": [15, 86], "k": [15, 36, 40, 41, 51, 60, 61, 63, 65, 66, 69, 70, 71, 72, 74, 75, 82], "zshrc": 15, "notic": [15, 28, 36, 45, 46, 47, 75, 86, 88], "environ": [15, 86], "world": [15, 44], "oyster": 15, "exampl": [15, 19, 21, 26, 27, 29, 30, 31, 32, 34, 35, 40, 42, 43, 45, 47, 49, 51, 52, 54, 55, 57, 59, 61, 62, 65, 66, 68, 71, 72, 74, 77, 82, 86, 88], "clone": 15, "keep": [15, 19, 21, 30, 42, 46, 52, 54, 55, 56, 60, 66, 70, 72, 75, 84, 86], "github": [15, 16, 45, 86, 88], "my_user_nam": 15, "my_favorite_repositori": 15, "folder": [15, 46, 75, 82], "appropri": [15, 19, 45, 47, 51, 52, 55, 66, 69, 77, 82], "rel": [15, 16, 19, 25, 57, 60, 67, 84], "path": [15, 16, 30, 31, 34, 36, 45, 47, 48, 49, 52, 53, 55, 58, 60, 68, 69, 70, 71, 72, 74, 75, 77, 82, 86], "ipynb": [15, 77], "whenev": 15, "ad": [15, 26, 47, 49, 60, 69, 70, 74, 86], "bebi103_upd": 15, "ing": 15, "document": [15, 18, 34, 45, 46, 67, 74, 75, 77, 86, 91], "edit": [15, 16, 77, 86], "manag": [15, 45, 46, 56, 86], "push": [15, 68, 70, 72, 84], "pull": [15, 30, 31, 34, 36, 48, 49, 52, 55, 68, 75, 84, 88], "execut": [15, 16, 46, 48, 86], "jupyt": [15, 16, 18, 46, 52, 77, 82, 86], "browser": [15, 16, 68, 86], "output": [15, 36, 45, 52, 57, 60, 66, 70, 75, 86], "server": [15, 86], "runtim": 15, "jpserver": 15, "30060": 15, "html": [15, 16, 52, 77], "Or": [15, 54, 69], "past": [15, 55, 74], "url": 15, "localhost": 15, "8888": 15, "token": 15, "e52184f06c9fb0f9ceea176b1d51d9cb36c72a019e688f": 15, "127": 15, "order": [15, 16, 19, 26, 28, 30, 31, 35, 40, 45, 46, 51, 52, 53, 54, 55, 57, 60, 66, 67, 68, 69, 71, 77, 82, 86, 88], "socket": 15, "anoth": [15, 20, 31, 32, 40, 46, 47, 49, 52, 54, 55, 56, 57, 60, 61, 66, 69, 82, 88, 91], "l": [15, 30, 31, 34, 36, 48, 52, 67, 69, 72, 75, 77], "8000": 15, "port": [15, 86], "abov": [15, 16, 20, 25, 28, 30, 31, 40, 45, 47, 49, 52, 53, 56, 60, 65, 66, 67, 69, 71, 74, 75, 82, 84, 86, 88], "got": [15, 20, 30, 45, 51, 55, 56, 57, 69, 70, 75, 82, 86, 88], "8889": 15, "substitut": [15, 26, 30, 57, 65, 69, 75], "8001": 15, "90": [15, 25, 52, 63, 66, 75], "direct": [15, 32, 69, 84], "note": [15, 18, 19, 21, 24, 26, 28, 30, 31, 32, 34, 35, 36, 41, 43, 45, 46, 47, 48, 52, 53, 54, 55, 56, 57, 58, 60, 61, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 84, 85, 86, 88], "specifi": [15, 25, 26, 30, 31, 34, 45, 46, 47, 48, 49, 52, 53, 54, 60, 61, 66, 69, 70, 75, 84, 86], "8890": 15, "correspond": [15, 19, 24, 45, 47, 66, 69, 71, 72, 75, 82, 88], "notebook": [15, 16, 18, 45, 46, 52, 68, 77, 82, 84, 86, 88], "move": [15, 28, 41, 52, 55, 56, 68, 84, 86], "commit": 15, "intermedi": [15, 36, 52, 88], "version": [15, 16, 18, 30, 31, 32, 34, 35, 36, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88], "scp": [15, 86], "yet": [15, 18, 28, 53, 69, 72, 77, 88], "my_fil": 15, "csv": [15, 30, 31, 34, 36, 45, 46, 47, 48, 49, 52, 53, 55, 58, 60, 68, 69, 70, 71, 72, 74, 75, 77, 86], "transfer": [15, 88], "colon": 15, "rememb": [15, 25, 26, 28, 30, 45, 46, 48, 52, 57, 60, 69, 70, 75], "second": [15, 18, 26, 28, 30, 31, 34, 35, 36, 45, 46, 49, 52, 53, 54, 60, 65, 67, 68, 69, 71, 75, 77, 86, 88], "argument": [15, 28, 30, 34, 36, 47, 48, 70, 74, 86], "similarli": [15, 19, 24, 36, 57, 69, 88], "upload": 15, "txt": [15, 46], "finish": [15, 46, 86, 88], "shut": 15, "shutdown": 15, "prompt": [15, 18, 84, 86], "hard": [15, 25, 34, 52, 66, 71, 72], "press": [15, 24, 36], "ctrl": 15, "unless": [15, 42, 46, 51, 75], "realli": [15, 19, 25, 26, 28, 30, 31, 34, 52, 54, 56, 57, 60, 67, 68, 69, 71, 72, 75, 77, 84, 88], "rid": 15, "charg": 15, "rack": 15, "massiv": 15, "bill": 15, "idl": [15, 16], "minor": [15, 52], "pain": 15, "wait": [15, 19, 25, 32, 69, 86], "forget": [15, 86], "caus": [15, 47, 56, 66], "pocketbook": 15, "easier": [15, 19, 25, 26, 30, 34, 47, 51, 57, 69, 70, 84], "navig": [15, 16], "either": [15, 16, 18, 30, 31, 45, 49, 52, 54, 55, 84, 86], "via": [15, 16, 27, 32, 45, 46, 66, 69, 77], "spun": 15, "fire": [15, 16], "per": [15, 28, 30, 45, 52, 54, 56, 60, 66, 68, 69, 75, 82, 86, 88], "eb": 15, "etc": [15, 16, 19, 25, 26, 46, 62, 65, 69, 74, 75, 77, 86], "intact": 15, "free": [15, 16, 17, 53, 57, 66, 70, 75, 77, 82], "tier": [15, 16], "expir": 15, "promo": 15, "These": [15, 16, 19, 30, 41, 45, 46, 47, 49, 52, 55, 63, 66, 68, 69, 74, 77, 82, 86, 88], "wipe": 15, "provid": [16, 24, 25, 30, 34, 35, 36, 40, 45, 46, 47, 55, 57, 60, 66, 67, 69, 70, 71, 77, 86, 91], "conveni": [16, 25, 28, 30, 34, 35, 36, 40, 43, 45, 46, 47, 49, 51, 52, 53, 55, 57, 60, 62, 66, 69, 71, 72, 74, 82, 84], "must": [16, 19, 24, 25, 30, 32, 34, 35, 45, 46, 48, 60, 67, 69, 72, 75, 77, 84, 86, 88, 92], "account": [16, 45, 55, 77, 86, 88], "student": [16, 30, 54, 65, 77, 78, 89, 91], "employe": 16, "suit": 16, "person": [16, 51, 86], "gmail": 16, "youtub": [16, 91], "facilit": [16, 27, 74, 86], "teammat": [16, 77], "staff": [16, 77], "machin": [16, 17, 46, 57, 68, 69, 86], "annoi": [16, 17, 46], "trick": [16, 26, 30, 41, 47, 66, 82, 88], "safari": 16, "edg": [16, 82], "web": 16, "brows": 16, "test": [16, 19, 53, 57, 67, 68, 75, 86, 88], "chrome": 16, "firefox": 16, "jupyterlab": [16, 18, 30, 31, 32, 34, 35, 36, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 88], "support": [16, 75], "three": [16, 25, 30, 36, 47, 48, 49, 51, 53, 54, 55, 57, 60, 62, 63, 65, 67, 77, 86], "launch": [16, 47], "research": [16, 19, 25, 26, 28, 36, 51, 77, 86, 91], "altern": [16, 34, 45, 54, 56, 57, 65, 82, 84, 86], "badg": 16, "content": [16, 27, 46, 47, 52, 54, 69, 71, 74, 75], "virtual": [16, 86], "two": [16, 17, 18, 19, 25, 26, 28, 30, 31, 32, 34, 36, 41, 45, 46, 47, 51, 52, 53, 54, 55, 57, 58, 60, 61, 62, 65, 66, 67, 68, 69, 74, 75, 76, 82, 84, 85, 86], "cpu": [16, 86], "limit": [16, 19, 25, 27, 28, 40, 41, 42, 46, 54, 55, 58, 67, 69, 71, 84, 86, 88], "gb": 16, "vari": [16, 18, 19, 25, 34, 49, 52, 65, 66, 69, 70, 72, 75, 82, 84], "ram": [16, 46], "gpu": [16, 86], "tpu": 16, "tensor": 16, "unit": [16, 25, 28, 34, 45, 46, 48, 52, 57, 66, 69, 72, 84], "too": [16, 19, 25, 28, 30, 31, 41, 51, 54, 55, 56, 67, 68, 69, 70, 72, 75, 77, 82, 84], "long": [16, 19, 28, 41, 42, 46, 51, 54, 55, 61, 71, 72, 82, 84, 85, 88], "disconnect": [16, 17], "cell": [16, 25, 28, 36, 45, 47, 48, 52, 55, 60, 66, 68, 69, 71, 72, 77, 82, 85, 86], "timeout": 16, "depend": [16, 25, 27, 30, 31, 32, 35, 40, 41, 45, 47, 53, 58, 62, 65, 68, 69, 75, 82, 85, 86, 88], "almost": [16, 24, 25, 26, 28, 30, 34, 36, 40, 42, 43, 45, 47, 54, 60, 68, 69, 70, 77], "alwai": [16, 18, 19, 25, 28, 30, 34, 36, 40, 43, 45, 47, 51, 52, 54, 60, 61, 69, 75, 77, 82, 88], "typic": [16, 25, 26, 28, 32, 36, 45, 47, 48, 52, 54, 55, 61, 66, 67, 68, 69], "effici": [16, 52, 55, 74, 84, 86], "exce": 16, "present": [16, 19, 30, 34, 46, 47, 49, 52, 56, 58, 66, 67, 70, 71, 74, 77, 84, 87], "place": [16, 34, 51, 52, 71, 72, 77, 84], "offer": [16, 30, 34, 41, 49, 55, 57, 60, 86, 88], "longer": [16, 28, 31, 45, 47, 52, 61, 70, 74, 82, 84], "pro": [16, 17], "howev": [16, 28, 30, 32, 35, 36, 43, 45, 47, 52, 53, 54, 55, 56, 57, 60, 67, 69, 70, 71, 77, 82, 84, 85, 86, 88], "encourag": [16, 66, 67, 69, 77], "bokeh": [16, 18, 30, 31, 32, 34, 35, 36, 37, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88], "app": [16, 82], "python": [16, 30, 31, 32, 34, 35, 36, 45, 46, 47, 48, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 77, 82, 88, 91], "callback": [16, 52], "instanc": [16, 17, 30, 45, 46, 52], "major": [16, 28, 30, 34, 36, 52, 67], "burden": 16, "circumv": 16, "upgrad": [16, 17, 45, 88], "faq": 16, "latest": 16, "januari": [16, 92], "wherea": [16, 35, 84], "anaconda": 16, "preinstal": 16, "often": [16, 19, 24, 25, 26, 28, 30, 35, 40, 43, 45, 46, 47, 49, 51, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 68, 69, 71, 77, 86, 88], "enabl": [16, 32, 35, 45, 46, 48, 49, 52, 53, 55, 70, 72, 86], "variant": [16, 60], "thereof": [16, 57, 60, 77], "affect": [16, 28, 32, 35, 68, 69], "importantli": [16, 24, 25, 26, 32, 36, 40, 41, 43, 45, 47, 52, 55, 57, 60, 66, 67, 68, 69, 72, 75], "cmdstanpi": [16, 45, 46, 47, 48, 49, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 86, 88, 91], "install_cmdstan": [16, 18, 45, 88], "sever": [16, 17, 18, 28, 30, 31, 34, 36, 42, 51, 56, 68], "setup": [16, 17, 45, 54, 71, 88], "sy": [16, 45, 77, 88], "subprocess": [16, 25, 45, 88], "modul": [16, 34, 40, 45, 49, 52, 69, 77, 86, 88], "cmd": [16, 45, 88], "pip": [16, 45, 86, 88], "polar": [16, 30, 31, 34, 36, 45, 47, 48, 49, 51, 52, 53, 55, 58, 60, 66, 68, 69, 70, 71, 72, 74, 75], "iqplot": [16, 45, 46, 47, 48, 51, 52, 55, 63, 66, 68, 72, 75, 88], "colorcet": [16, 45, 46, 88], "datashad": [16, 45], "arviz": [16, 18, 45, 47, 48, 51, 52, 53, 55, 56, 57, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 86, 88, 91], "watermark": [16, 18, 30, 31, 32, 34, 35, 36, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 88], "popen": [16, 45, 88], "split": [16, 19, 26, 45, 47, 52, 57, 86, 88], "stdout": [16, 45, 46, 86, 88], "pipe": [16, 45, 88], "stderr": [16, 45, 86, 88], "data_path": [16, 30, 31, 34, 36, 45, 47, 48, 49, 52, 53, 55, 58, 60, 68, 69, 70, 71, 72, 74, 75, 77, 88], "s3": [16, 30, 34, 45, 77, 86, 88], "amazonaw": [16, 30, 34, 45, 77, 88], "ensur": [16, 25, 42, 47, 55, 56, 67, 72, 74, 77, 84, 88], "recent": [16, 66, 77, 86], "cmdstan": [16, 18, 45, 46, 47, 48, 49, 52, 53, 55, 56, 58, 60, 66, 68, 69, 70, 71, 72, 74, 75, 88], "drawback": [16, 35, 49, 51], "built": [16, 30, 34, 40, 46, 47, 52, 55, 60, 63, 66, 69, 74, 88], "binari": 16, "shutil": [16, 45, 88], "urllib": [16, 45, 88], "latest_vers": [16, 45, 88], "cmdstan_vers": [16, 18, 45, 46, 47, 48, 49, 52, 53, 55, 56, 58, 60, 66, 68, 69, 70, 71, 72, 74, 75, 88], "cmdstan_url": [16, 45, 88], "dev": [16, 30, 45, 88], "releas": [16, 45, 49, 88], "v": [16, 18, 30, 31, 32, 34, 35, 36, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 84, 88], "fname": [16, 45, 75, 88], "tgz": [16, 45, 88], "urlretriev": [16, 45, 88], "unpack_arch": [16, 45, 88], "faster": [16, 28, 30, 35, 45, 52, 54, 68, 77, 86], "mode": [16, 35, 46, 47, 51, 84], "fetch": [16, 74], "aw": [16, 17, 46], "hidden": 16, "render": [16, 37, 49, 52, 77, 82], "clutter": [16, 25, 45, 46], "collab": 16, "az": [16, 18, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 86, 88], "io": [16, 18, 30, 31, 32, 34, 35, 36, 37, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88], "output_notebook": [16, 18, 30, 31, 32, 34, 35, 36, 37, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88], "schools_data": [16, 18], "j": [16, 18, 23, 28, 30, 31, 34, 36, 57, 75, 86, 88], "28": [16, 18, 47, 52, 68, 72, 75, 88, 92], "schools_cod": [16, 18], "int": [16, 18, 24, 25, 26, 28, 30, 40, 41, 43, 45, 47, 48, 49, 52, 53, 55, 56, 57, 58, 60, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88], "lower": [16, 18, 19, 28, 35, 45, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 84, 86, 88], "school": [16, 18], "vector": [16, 18, 47, 52, 60, 66, 69, 70, 71, 72, 74, 75, 82, 84], "treatment": [16, 18, 35, 36, 48, 67], "tau": [16, 18, 28, 66, 75], "eta": [16, 18, 75], "transform": [16, 18, 19, 24, 28, 40, 45, 46, 47, 48, 49, 53, 54, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88], "theta": [16, 18, 19, 20, 21, 23, 24, 26, 28, 30, 32, 34, 35, 40, 41, 43, 46, 47, 52, 54, 56, 57, 60, 61, 62, 63, 65, 66, 67, 72, 75, 82, 88], "w": [16, 18, 26, 47, 52, 60, 66, 75, 84, 86, 92], "disable_log": [16, 18, 45, 47, 48, 49, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 86, 88], "sm": [16, 18, 45, 46, 47, 48, 49, 53, 55, 56, 60, 63, 68, 70, 71, 72, 74, 75, 77, 86, 88], "cmdstanmodel": [16, 18, 45, 46, 47, 48, 49, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 77, 86, 88], "stan_fil": [16, 18, 45, 46, 47, 48, 49, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 86, 88], "output_dir": [16, 18, 86], "show_progress": [16, 18, 45, 46, 52, 75, 86, 88], "fals": [16, 18, 36, 45, 46, 47, 49, 51, 52, 55, 58, 60, 66, 68, 69, 70, 71, 75, 82, 86, 88], "from_cmdstanpi": [16, 18, 45, 46, 47, 48, 49, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 71, 72, 74, 75, 86, 88], "clean_cmdstan": [16, 18, 45, 46, 47, 48, 49, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 88], "p": [16, 18, 19, 21, 24, 30, 31, 32, 34, 35, 36, 37, 40, 41, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 57, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88], "figur": [16, 18, 19, 24, 30, 31, 32, 34, 35, 36, 37, 45, 48, 49, 52, 56, 66, 68, 69, 70, 71, 72, 75, 82, 84, 88], "frame_height": [16, 18, 30, 31, 32, 34, 35, 36, 37, 45, 47, 48, 49, 51, 52, 68, 69, 70, 71, 72, 75, 82, 88], "250": [16, 18, 30, 31, 34, 36, 45, 48, 49, 51, 52, 53, 58, 68, 69, 70, 71, 72, 74, 75], "frame_width": [16, 18, 30, 31, 32, 34, 35, 36, 37, 45, 47, 48, 49, 51, 52, 63, 68, 69, 70, 71, 72, 75, 82, 88], "x_axis_label": [16, 18, 30, 31, 32, 34, 35, 36, 37, 45, 47, 48, 49, 51, 52, 53, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 75, 82, 88], "\u03bc": [16, 18, 30], "y_axis_label": [16, 18, 30, 31, 32, 34, 35, 36, 37, 45, 48, 49, 51, 52, 53, 56, 58, 63, 66, 68, 69, 70, 71, 72, 75, 82, 88], "\u03c4": [16, 18, 66, 75], "scatter": [16, 18, 30, 31, 34, 36, 45, 47, 48, 49, 51, 52, 56, 66, 68, 69, 70, 71, 72, 75, 82], "ravel": [16, 18, 45, 46, 88], "alpha": [16, 18, 30, 31, 32, 34, 35, 36, 37, 40, 41, 45, 47, 48, 49, 52, 54, 55, 56, 60, 61, 63, 66, 67, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88], "bokehj": [16, 18, 30, 31, 32, 34, 35, 36, 37, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 88], "load_ext": [16, 18, 30, 31, 32, 34, 35, 36, 37, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 88], "cpython": [16, 18, 30, 31, 32, 34, 35, 36, 45, 46, 47, 48, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 88], "ipython": [16, 18, 30, 31, 32, 34, 35, 36, 45, 46, 47, 48, 51, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 82, 88], "27": [16, 18, 45, 47, 49, 52, 66, 68, 70, 71, 72, 74, 75, 88, 92], "requir": [17, 19, 26, 40, 43, 45, 52, 55, 57, 68, 75, 77, 82, 84, 85, 86], "signific": [17, 41, 52, 69, 86], "prefer": [17, 19, 28, 48, 49, 52, 57, 60, 86, 88], "connect": [17, 19, 57, 58, 82, 86], "larg": [17, 19, 25, 28, 30, 31, 43, 45, 48, 52, 55, 56, 57, 66, 68, 69, 70, 72, 75, 77, 82, 86, 88], "loud": 17, "hot": 17, "unavail": [17, 30], "other": [17, 18, 19, 21, 24, 25, 26, 28, 30, 31, 34, 35, 40, 43, 45, 46, 47, 48, 49, 52, 55, 57, 61, 63, 65, 66, 67, 69, 74, 75, 77, 82, 85, 86, 88, 91], "dure": [17, 42, 45, 52, 77], "colab": [17, 18, 45, 46, 77, 88], "pretti": [17, 28, 32, 40, 43, 47, 49, 52, 57, 68, 69, 84, 86, 88], "fast": [17, 34, 52, 57, 66], "biggest": [17, 86], "interact": [17, 46, 52, 54, 85, 86], "babysit": 17, "could": [17, 24, 25, 28, 30, 31, 34, 36, 41, 43, 45, 47, 48, 51, 52, 53, 54, 56, 57, 61, 65, 66, 68, 69, 72, 74, 75, 82, 84, 86, 88], "commerci": 17, "servic": [17, 26, 86], "hpc": 17, "oper": [18, 28, 45, 47, 69, 71, 84, 86, 88], "BE": [18, 76], "bi": [18, 49, 65, 76], "103": [18, 76], "probabilist": [18, 19, 24, 25, 28, 45, 46, 84], "program": [18, 25, 45, 48, 74, 86], "languag": [18, 25, 45, 46, 77, 88], "written": [18, 19, 21, 26, 28, 30, 31, 45, 46, 47, 52, 57, 61, 65, 72, 77, 78, 82, 86, 87, 88, 89], "translat": [18, 46, 84], "parser": 18, "compil": [18, 45, 46, 47, 52, 53, 55, 56, 58, 60, 63, 68, 69, 70, 71, 72, 74, 75, 77, 86, 88], "interfac": [18, 45, 46, 75, 91], "wide": [18, 25, 28, 30, 41, 42, 57, 68, 69, 71, 86], "rstan": 18, "pystan": [18, 46], "respect": [18, 25, 28, 30, 36, 46, 47, 49, 51, 56, 57, 60, 61, 63, 66, 69, 71, 74, 75, 77], "simpler": [18, 52, 54, 70, 88], "becom": [18, 19, 20, 26, 28, 30, 31, 36, 43, 47, 52, 54, 57, 82, 84, 85, 88], "appar": [18, 66, 71, 88], "whichev": 18, "tricki": [18, 30, 60, 69], "system": [18, 25, 46, 57, 65, 69, 82, 84, 86], "troubleshoot": 18, "worri": [18, 40, 51, 88], "troubl": [18, 52, 55, 56, 77], "On": [18, 54, 65, 82, 88], "xcode": 18, "accord": [18, 31, 35, 42, 47, 48, 49, 55, 65, 71, 72], "previous": [18, 49, 55, 75, 86], "One": [18, 24, 25, 26, 30, 40, 51, 52, 66, 75, 82, 84, 86, 88], "mingw": 18, "wai": [18, 19, 20, 26, 28, 30, 31, 41, 42, 45, 47, 49, 51, 52, 54, 55, 56, 57, 58, 60, 61, 65, 66, 69, 71, 72, 75, 77, 82, 84, 86, 88], "conda": [18, 86], "libpython": 18, "m2w64": 18, "msys2": 18, "util": [18, 24, 28, 32, 84, 86, 91], "raspberri": 18, "pi": [18, 21, 23, 24, 25, 26, 28, 30, 35, 49, 52, 53, 56, 58, 60, 63, 67, 69, 72, 75, 82, 84, 86, 88], "took": [18, 30, 32, 36, 41, 55, 57, 65, 75], "appreci": 18, "nifti": [18, 88], "demonstr": [18, 25, 28, 32, 46, 47, 51, 52, 60, 63, 69, 72, 74, 77, 84, 86], "trivial": [18, 19, 43, 46, 53, 82, 86], "feat": 18, "warn": [18, 35, 45, 56, 58, 60, 68], "print": [18, 30, 34, 36, 45, 46, 47, 48, 49, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 77, 82, 86, 88], "36": [18, 30, 31, 34, 47, 58, 70, 71, 72, 74, 75, 88], "thought": [19, 32, 34, 77], "inquiri": 19, "visit": [19, 30, 42], "refresh": [19, 57, 68, 75, 82], "sketch": [19, 25, 28], "cycl": 19, "itself": [19, 52, 57, 60, 66, 70, 84], "natur": [19, 25, 45, 52, 54, 57, 60, 88], "mileston": 19, "along": [19, 28, 42, 45, 46, 49, 54, 55, 58, 82, 84, 86], "arrow": 19, "orang": [19, 30, 32, 34, 36, 45, 47, 56, 66, 68, 69, 70, 71, 72, 74, 75, 82], "adapt": [19, 45, 46, 68, 75], "fig": [19, 67], "gregori": [19, 91], "cambridg": [19, 24], "2005": 19, "consid": [19, 25, 26, 28, 30, 31, 34, 35, 36, 41, 45, 47, 49, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 77, 84, 88], "hypothesi": [19, 20, 23, 26], "invent": 19, "refin": [19, 25], "stage": [19, 25, 52], "formul": [19, 82, 88], "hypothes": [19, 21, 23, 24], "theori": [19, 35, 45, 60], "pursu": 19, "innov": 19, "sometim": [19, 34, 47, 52, 54, 57, 75, 85, 86], "geniu": 19, "deduct": [19, 77], "deduc": 19, "experiment": [19, 52, 65, 66, 75, 88], "x": [19, 21, 24, 30, 31, 34, 35, 36, 37, 45, 46, 47, 48, 49, 51, 52, 56, 68, 69, 70, 71, 72, 74, 75, 82, 86], "deriv": [19, 24, 27, 28, 30, 34, 35, 40, 52, 54, 57, 67, 69, 73, 75, 82, 84], "seri": [19, 31, 32, 51, 67, 69, 85, 88, 91], "strong": [19, 45, 47, 55, 69, 72, 75, 88], "syllog": 19, "therefor": [19, 23, 25, 27, 28, 30, 31, 32, 34, 35, 36, 45, 46, 48, 52, 54, 55, 57, 60, 68, 69, 71, 72, 75, 77, 82, 85], "plausibl": [19, 25, 26], "perhap": [19, 26, 28, 32, 52, 54, 55, 60, 65, 69, 84], "least": [19, 31, 34, 35, 55, 68, 69, 75, 77, 84, 86, 88], "familiar": [19, 27, 46, 47, 52, 54, 68, 69, 82, 88], "talk": [19, 24, 25, 28, 32, 40, 49, 55, 67], "bullet": 19, "But": [19, 25, 28, 31, 34, 35, 40, 41, 43, 45, 46, 48, 51, 54, 55, 57, 68, 69, 70, 75], "knowledg": [19, 20, 25, 26, 28, 32, 41, 48, 52, 54, 57, 67, 70, 82], "design": [19, 52, 66, 85, 88], "Not": [19, 46, 52, 66, 68], "necessarili": [19, 28, 34, 45, 51, 52, 55, 57, 88], "weak": [19, 28, 84], "wastewat": 19, "inject": [19, 56], "hydraul": 19, "fractur": 19, "known": [19, 25, 26, 27, 28, 31, 32, 35, 40, 42, 51, 52, 54, 57, 60, 67, 69, 85, 86, 88], "frack": 19, "lead": [19, 26, 28, 35, 45, 47, 52, 56, 60, 72, 82], "greater": [19, 52, 54, 55], "earthquak": 19, "frequenc": [19, 45, 47, 52, 55, 68], "oklahoma": 19, "increas": [19, 30, 52, 66, 68, 69, 82, 84, 86, 88], "fold": [19, 34], "2010": 19, "becam": 19, "common": [19, 28, 49, 57, 61, 69], "busi": [19, 88], "quantifi": [19, 57, 70, 75, 84, 88], "obeserv": 19, "role": 19, "thu": [19, 20, 24, 28, 32, 34, 41, 48, 52, 54, 56, 57, 60, 65, 66, 68, 69, 70, 72, 75, 77, 84], "crucial": [19, 47, 55, 56, 57, 82], "t": [19, 24, 25, 28, 30, 34, 35, 40, 41, 46, 51, 52, 54, 55, 56, 57, 60, 66, 67, 68, 69, 70, 71, 72, 74, 75, 82, 84, 85, 86, 88], "jayn": [19, 24], "domin": [19, 30, 60, 63, 68], "interpret": [19, 20, 24, 26, 35, 51, 53, 57, 69, 86], "repres": [19, 45, 49, 63, 67, 69, 84, 88], "ident": [19, 24, 25, 34, 45, 55, 60, 88], "repetit": 19, "hypothet": [19, 88], "event": [19, 24, 27, 28, 41, 54, 55, 57], "restrict": [19, 32, 69, 75], "proposit": [19, 26], "random": [19, 24, 37, 39, 46, 47, 51, 52, 54, 55, 56, 68, 69, 70, 71, 72, 75, 82, 84, 86, 88], "quantiti": [19, 21, 24, 25, 26, 28, 30, 46, 52, 53, 54, 57, 58, 60, 68, 69, 71, 72, 74, 75, 84, 86, 88], "meaningfulli": 19, "degre": [19, 45], "belief": [19, 45], "heard": 19, "fight": 19, "peopl": 19, "who": [19, 77], "appli": [19, 20, 23, 24, 26, 45, 55, 56, 57, 61, 66, 69, 71, 75, 77, 82, 84, 86, 88], "valid": [19, 57, 60, 74], "exclus": 19, "great": [19, 27, 28, 42, 71, 86, 88, 91], "opinion": [19, 41, 49, 88], "express": [19, 20, 23, 25, 31, 32, 34, 35, 43, 45, 47, 48, 52, 54, 55, 56, 57, 61, 65, 66, 67, 69, 72, 75, 86, 88], "proce": [19, 30, 31, 35, 36, 60, 67, 70, 72, 74, 75], "conceptu": [19, 21, 28, 32, 38, 82], "cleaner": 19, "certainti": 19, "convers": [19, 24, 52, 57, 77], "fix": [19, 30, 45, 46, 47, 49, 55, 69, 70, 82, 88], "convert": [19, 28, 40, 45, 46, 47, 49, 52, 53, 54, 55, 57, 60, 66, 69, 71, 74, 75, 82], "1946": 19, "cox": 19, "laid": [19, 26, 32, 42, 46, 49, 55, 68, 74], "desir": [19, 42, 57, 69, 86], "properti": [19, 26, 40, 42, 43, 69, 72, 75, 84], "were": [19, 21, 28, 31, 35, 40, 45, 46, 49, 52, 53, 54, 55, 57, 60, 63, 66, 67, 68, 69, 72, 75, 86, 88], "expand": [19, 47, 84, 86], "1970": [19, 88], "ration": 19, "suppli": 19, "rise": [19, 85], "monoton": [19, 34, 57], "manner": 19, "obtain": [19, 26, 30, 31, 45, 46, 49, 51, 55, 57, 67, 71, 74, 75, 82], "consist": [19, 24, 28, 32, 43, 46, 55, 67, 68, 70, 77, 82], "proprieti": 19, "relev": [19, 28, 30, 34, 35, 36, 51], "equival": [19, 24, 28, 30, 47, 52, 54, 56, 72, 75, 84, 88], "satisfi": [19, 40, 41, 42, 43, 55, 56, 57, 67, 84], "paus": [19, 25, 26, 30, 47, 48, 57, 84], "without": [19, 24, 26, 27, 28, 32, 36, 42, 46, 56, 57, 69, 71, 77, 82, 86, 88], "mind": [19, 24, 25, 46, 55, 66, 69, 70, 86], "chapter": 19, "uniti": [19, 41, 55, 67, 68, 69], "except": [19, 45, 46, 52, 72, 77, 84, 88], "complement": 19, "Then": [19, 20, 23, 25, 28, 30, 41, 43, 46, 48, 56, 57, 67, 69, 82, 86, 88], "interest": [19, 25, 27, 30, 32, 36, 41, 43, 45, 46, 47, 49, 54, 55, 57, 63, 66, 69, 82, 85, 88], "happen": [19, 25, 35, 52, 53, 55, 56, 57, 69, 77, 86], "denot": [19, 21, 24, 26, 28, 35, 55, 57, 69, 82, 84], "notion": [19, 28, 57, 84], "bit": [19, 21, 24, 25, 28, 30, 32, 34, 40, 42, 47, 51, 52, 56, 57, 66, 67, 70, 71, 84, 86, 88], "abstract": 19, "bring": [19, 28, 54, 57, 69, 88], "realm": [19, 57, 88], "ll": [19, 31, 36, 45, 46, 51, 53, 54, 55, 56, 58, 60, 67, 68, 71, 72, 75, 82, 86], "been": [19, 24, 26, 36, 52, 57, 70, 72, 75, 86], "rewrit": [19, 52, 65], "explicitli": [19, 25, 30, 41, 46, 47, 57, 61, 69, 72, 77, 88], "henceforth": [19, 69], "vacuum": 19, "ahoi": 19, "exactli": [19, 25, 32, 47, 52, 54, 60, 69, 70, 71, 75, 82, 88], "pictur": [19, 30, 31, 48, 49, 55, 69, 86], "cannot": [19, 24, 28, 30, 31, 32, 36, 41, 43, 45, 47, 49, 52, 53, 54, 56, 57, 58, 66, 69, 71, 72, 75, 82], "perspect": [19, 82, 84], "analyz": [19, 26, 45, 58, 66, 67, 77, 85], "commut": 19, "side": [19, 24, 30, 36, 67, 69, 85, 88], "seemingli": [19, 45], "equal": [19, 28, 35, 41, 57, 67, 75, 85], "rearrang": [19, 75, 88], "frac": [19, 20, 21, 23, 24, 25, 26, 28, 30, 31, 32, 35, 36, 41, 42, 43, 47, 48, 49, 52, 53, 55, 56, 57, 58, 60, 61, 62, 65, 67, 69, 71, 75, 82, 84], "far": [19, 24, 26, 34, 35, 40, 45, 52, 56, 60, 67, 70, 72, 77, 86], "goal": [19, 26, 30, 32, 34, 35, 40, 43, 57, 72, 75], "hand": [19, 24, 30, 34, 45, 48, 51, 53, 65, 67, 71, 77, 82, 84, 88], "turn": [19, 25, 30, 45, 46, 47, 56, 57, 58, 62, 63, 68, 77, 82, 84], "item": [19, 47, 51, 82, 86, 88], "believ": [19, 28, 34, 61, 86], "acquir": [19, 20, 32, 45, 46, 70, 72], "nois": [19, 25, 71], "instrument": [19, 61], "whose": [19, 40], "constitut": [19, 57], "bulk": [19, 31, 52], "algebra": [19, 30, 69, 74], "outcom": [19, 24, 27, 28, 57, 65, 66, 82], "fulli": [19, 25, 26, 53, 69, 75, 85, 88], "cute": 19, "acronym": 19, "feel": [19, 28, 32, 45, 48, 77, 82], "try": [19, 25, 26, 28, 32, 47, 52, 54, 55, 56, 60, 65, 66, 72, 75, 77, 84, 86, 88], "head": [19, 31, 47, 49, 66, 68, 75, 82], "around": [19, 30, 31, 34, 41, 47, 49, 52, 54, 57, 66, 67, 72, 82, 84, 88], "y_1": [20, 24, 25, 34, 57, 60], "investig": [20, 31, 32, 41, 45, 52, 55, 56, 57, 63, 65], "y_2": [20, 24, 25, 34, 57, 60], "plug": [20, 25, 57], "product": [20, 25, 26, 28, 30, 47, 52, 65, 69, 75, 77, 84, 88], "rule": [20, 23, 28, 31, 41, 42, 53, 55, 58, 67, 77], "denomin": 20, "insert": [20, 32, 52, 67], "equat": [20, 25, 40, 57, 65, 67, 77, 82, 84, 88], "yield": [20, 47, 67, 69, 88], "gave": [20, 46, 68], "combin": [20, 47, 52, 60, 86, 88], "acquisit": [20, 54], "constantli": 20, "symbol": [21, 25, 69, 84], "overload": 21, "aid": 21, "convent": [21, 74], "densiti": [21, 24, 25, 28, 30, 31, 34, 35, 41, 43, 45, 48, 49, 51, 52, 56, 60, 69, 71, 75, 82, 84], "non": [21, 45, 47, 54, 56, 69, 73], "evid": [21, 23, 25, 26, 47, 54, 75, 82, 88], "joint": [21, 23, 26, 30, 41, 52, 56, 67, 69, 75, 82, 84, 88], "speak": [21, 26, 54, 55, 69, 84], "track": [21, 42, 55, 66, 75], "scienc": [22, 24, 34, 36, 48, 49, 52, 58, 69, 91], "notat": [22, 24, 25, 30, 40, 57, 69, 71], "bay": [22, 23, 25, 26, 32, 55, 57, 62, 65, 69, 75, 88], "theorem": [22, 23, 25, 26, 27, 32, 57, 62, 65, 67, 69, 82, 84, 88], "mention": [23, 28, 45, 56, 60, 65, 86], "sum": [23, 24, 26, 30, 31, 34, 36, 40, 41, 47, 51, 52, 54, 55, 57, 63, 75, 82, 84, 88], "theta_i": [23, 28, 35, 40, 41, 43, 61, 63, 65, 67, 75], "particular": [23, 28, 31, 43, 45, 46, 47, 49, 51, 53, 55, 56, 63, 69, 70, 84, 88], "theta_j": [23, 28, 34, 35, 75], "c_j": [23, 69], "nonumb": [23, 25, 41, 57], "sum_": [23, 25, 30, 31, 43, 57, 60, 65, 75, 88], "ne": [23, 57, 69, 72], "sum_i": [23, 24, 34, 57, 69, 82], "elimin": [23, 84], "lectur": [24, 26, 28, 38, 42, 45, 49, 57, 60, 67, 76, 77, 92], "verbatim": 24, "space": [24, 28, 30, 40, 41, 42, 48, 49, 51, 53, 55, 66, 67, 82, 86, 88], "zero": [24, 25, 28, 30, 31, 34, 35, 36, 40, 45, 46, 47, 48, 52, 54, 56, 65, 66, 67, 68, 69, 70, 72, 75, 82, 88], "introduc": [24, 28, 46, 47, 52, 69, 70, 75, 82, 84], "deal": [24, 28, 41, 47, 55, 66, 68, 84, 88], "link": [24, 49, 72, 86, 91], "discret": [24, 26, 28, 40, 41, 47, 54, 60, 69, 82, 84], "integ": [24, 40, 45, 47, 54, 86], "nonzero": [24, 25, 34], "notation": 24, "le": [24, 30, 31, 36, 52, 69], "cumul": [24, 35], "cdf": [24, 34, 35, 37, 40, 43, 45, 47, 49, 54, 63], "shown": [24, 28, 31, 34, 40, 41, 52, 57, 67, 69, 82], "panel": 24, "height": [24, 30, 56, 66, 82], "men": 24, "centimet": 24, "countri": 24, "mathrm": [24, 25, 26, 28, 30, 31, 35, 40, 41, 43, 55, 56, 57, 60, 67, 69, 70, 71, 72, 74, 82, 84, 88], "ly": [24, 70, 71, 74], "y_0": 24, "int_": [24, 82], "satisfact": 24, "axiom": [24, 82], "infti": [24, 25, 28, 30, 31, 34, 54, 69], "necessit": [24, 61], "pmf": [24, 27, 32, 47, 86, 88], "unlik": [24, 25, 36, 47, 52, 54, 56, 60, 66, 82, 88], "n": [24, 25, 30, 31, 32, 40, 43, 45, 47, 48, 49, 52, 53, 55, 57, 58, 60, 61, 63, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 82, 84, 85, 86, 88], "roll": 24, "fair": 24, "die": [24, 71], "seen": [24, 26, 30, 32, 40, 45, 47, 51, 53, 55, 58, 62, 69, 71, 74, 82], "similar": [24, 30, 32, 46, 47, 48, 52, 53, 57, 58, 66, 77, 85, 86, 88], "hold": [24, 40, 41, 47, 52, 67, 69], "obviou": [24, 25, 26, 52, 58, 60, 66, 67, 82], "immedi": [24, 32, 43, 46, 52, 56, 66, 68], "issu": [24, 25, 26, 28, 30, 49, 51, 52, 56, 66, 68, 69, 86], "consequ": 24, "conjectur": [24, 69], "final": [24, 31, 36, 43, 45, 57, 60, 66, 67, 68, 69, 70, 72, 75, 77, 84, 92], "f_x": 24, "subscript": [24, 43, 57, 66], "wish": [24, 25, 26, 30, 31, 40, 45, 46, 47, 48, 51, 52, 54, 56, 57, 66, 67, 69, 75, 77, 85], "f_y": 24, "enforc": [24, 47], "mathbf": [24, 45, 69, 70, 71, 72, 74, 82], "partial": [24, 28, 35, 71, 82, 84], "x_1": [24, 54, 71], "x_2": [24, 54, 71], "ldot": [24, 25, 40, 43, 54, 57, 60, 61, 65, 66, 69, 70], "factor": [24, 25, 30, 61, 62, 69, 75, 86], "jacobian": 24, "absolut": [24, 56, 82], "determin": [24, 28, 32, 47, 52, 54, 55, 57, 60, 63, 66, 69, 70, 82, 86, 88], "jacobi": [24, 28], "matrix": [24, 25, 28, 34, 35, 36, 47, 54, 60, 70, 71, 72, 74, 82, 84, 86], "pmatrix": [24, 28, 32, 69, 82], "cdot": [24, 25, 28, 34, 35, 43, 54, 65, 69, 71, 72, 82, 84, 88], "vdot": [24, 28], "ddot": [24, 28], "beta": [24, 35, 36, 37, 40, 45, 47, 48, 49, 52, 53, 54, 55, 58, 60, 61, 62, 63, 65, 68, 69, 71, 75, 84, 86, 88], "saw": [24, 26, 47, 49, 68, 71, 75], "rescal": [24, 82], "accordingli": [24, 75], "sqrt": [24, 25, 28, 30, 34, 35, 36, 56, 69, 70, 71, 82, 84, 86], "ln": [24, 28, 30, 34, 35, 40, 47, 52, 53, 57, 58, 60, 69, 70, 72, 74, 75, 88], "subtl": [24, 28], "univers": [24, 65], "2003": 24, "subtleti": [24, 57], "simplest": [25, 31, 43, 49, 86], "beak": [25, 60], "depth": [25, 30, 56, 58, 60, 63, 66, 68, 69, 71, 72, 74, 88], "finch": [25, 60], "fluoresc": [25, 45, 66, 85, 88], "abound": 25, "concret": [25, 26, 28, 57, 66, 69, 88], "elegan": [25, 27, 28, 54, 65], "egg": [25, 27, 28, 32, 34, 48, 54], "equiv": [25, 28, 52, 57, 66, 69], "y_n": [25, 57, 60], "ambigu": [25, 57], "sharpen": 25, "low": [25, 28, 36, 42, 47, 49, 66, 69, 70, 71, 84, 88], "codifi": [25, 26, 28, 48, 57], "light": [25, 26, 28, 52, 54, 65], "everi": [25, 28, 31, 34, 35, 41, 47, 48, 52, 53, 70, 72, 77, 82, 84, 86, 88], "error": [25, 30, 45, 47, 52, 54, 60, 65, 68, 69, 70, 71, 77, 82, 84, 86], "confound": 25, "prod_": [25, 30, 57, 61, 88], "delta": [25, 26, 57, 71, 72, 74], "dirac": [25, 26, 57], "theoret": [25, 26, 31, 32, 36, 45, 47, 52, 54, 68, 69, 70, 77, 84], "shall": [25, 30, 69], "heavi": [25, 51, 54, 70, 84, 86, 88], "univari": [25, 49, 53, 54, 72, 74], "pdf": [25, 27, 28, 30, 31, 32, 34, 35, 36, 43, 45, 49, 51, 52, 68, 70, 77, 84], "exp": [25, 30, 31, 34, 35, 36, 47, 56, 57, 60, 69, 70, 71, 72, 74, 82, 88], "standard": [25, 26, 46, 51, 52, 60, 66, 67, 68, 69, 70, 71, 77, 84], "deviat": [25, 51, 52, 54, 55, 66, 67, 68, 69, 70, 71, 82], "squar": [25, 28, 69, 70, 72, 74, 82, 86], "varianc": [25, 27, 34, 42, 46, 52, 54, 55, 56, 57, 66, 67, 68, 69, 71, 84], "confusingli": 25, "literatur": [25, 77], "central": [25, 27, 35, 49, 51, 84, 86], "emerg": 25, "tend": [25, 28, 34, 47, 55, 56, 57, 60, 63, 67, 69, 71], "none": [25, 27, 37, 45, 52, 54, 58, 68, 86], "broadli": 25, "mathsf": [25, 28, 34, 35, 54, 69, 70, 71, 72, 74, 75, 82], "boldsymbol": [25, 69, 70, 71, 72, 74, 75], "det": [25, 28, 82], "mu_1": 25, "mu_2": [25, 51], "mu_n": 25, "symmetr": [25, 35, 67, 69, 75], "posit": [25, 28, 30, 31, 34, 35, 40, 41, 42, 45, 52, 60, 61, 66, 69, 70, 71, 72, 74, 75, 82, 84], "diagon": [25, 34, 35, 47, 68, 69, 70, 72, 74, 75], "entri": [25, 28, 35, 47, 54, 66, 69, 70, 72, 75, 77, 86], "sigma_": [25, 28, 35, 67, 69], "ij": [25, 28, 35, 69, 71], "y_j": 25, "correl": [25, 45, 47, 55, 69, 82, 84], "anticorrel": [25, 49], "reduc": [25, 58, 86], "sigma_i": [25, 52, 53, 58, 69, 75], "mu_i": [25, 36, 48, 49, 52, 53, 54, 58, 69, 71, 75], "2_i": 25, "multi": [25, 51, 74, 88], "decid": [25, 28, 52, 72, 77, 85, 88], "spread": [25, 68, 72, 86], "sought": 25, "beyond": [25, 28, 30, 57, 68, 71, 77], "int_0": [25, 28, 30, 31], "captur": [25, 28, 30, 53, 54, 58, 65, 66, 67, 68, 69, 70, 72, 75, 88], "current": [25, 28, 30, 41, 49, 57, 84, 88], "guess": [25, 28, 31, 34, 36, 70, 71, 82], "50": [25, 28, 30, 31, 34, 35, 36, 37, 40, 48, 49, 51, 52, 53, 58, 63, 66, 68, 72, 75, 77, 88], "\u00b5m": [25, 28, 30, 31, 34, 36, 48, 49, 52, 53, 54, 58, 75], "mu_": [25, 28], "tini": [25, 35, 56], "five": [25, 62, 67, 68], "ten": [25, 28, 54, 85], "micron": [25, 28, 34, 48], "size": [25, 28, 31, 36, 37, 46, 47, 48, 49, 51, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 82, 84, 86, 88], "neg": [25, 28, 30, 34, 35, 36, 45, 47, 52, 54, 55, 60, 68, 70, 75, 82, 86, 88], "unphys": [25, 52, 68], "mathemat": [25, 28, 30, 31, 32, 34, 52, 54, 57, 69, 75, 77, 84, 86], "disallow": 25, "With": [25, 28, 45, 46, 48, 52, 53, 60, 61, 68, 71, 84, 88], "roughli": [25, 26, 67, 85, 88], "piec": [25, 34], "cover": [25, 28, 41, 58, 86], "exclud": 25, "unreason": [25, 69], "brace": [25, 46, 47, 48, 52], "oh": [25, 88], "mess": [25, 57], "challeng": [25, 26, 27, 28, 32, 47, 66, 69, 86], "easi": [25, 26, 32, 35, 47, 51, 52, 56, 75, 82, 86, 88], "shorthand": [25, 40], "integr": [25, 26, 28, 30, 31, 32, 36, 40, 41, 43, 56, 57, 67, 75, 88, 92], "omit": [25, 57], "english": [25, 67], "self": [25, 67, 68], "nasti": [25, 32, 43], "am": [25, 34, 43, 47, 54, 57, 60, 63, 77, 86, 88, 92], "nor": [25, 28, 34, 51, 60, 69, 70, 86], "maintain": [25, 28], "focu": [25, 26, 30, 40, 45, 47, 52, 69], "loos": [26, 55, 57, 84], "explicit": [26, 52, 69], "unambigu": [26, 47, 52], "commonli": [26, 28, 42, 46, 49, 51, 55, 71, 74, 86], "descript": [26, 45, 55, 67, 68, 84, 88], "prescrib": [26, 52, 54], "asid": [26, 55], "philosoph": 26, "gelman": [26, 40, 42, 57, 60, 91], "simpson": [26, 49], "betancourt": [26, 38, 47, 53, 55, 56, 67, 82, 84, 91], "clearli": [26, 30, 32, 45, 47, 53, 56, 60, 63, 66, 68, 75, 77, 85, 88], "dilemma": 26, "2017": [26, 63, 65, 75, 82], "apt": [26, 45], "titl": [26, 45, 51, 52, 82, 88], "understood": [26, 52, 57], "emphasi": [26, 51, 70], "sort": [26, 32, 52, 58, 86], "liter": 26, "extern": 26, "social": 26, "intervent": 26, "he": [26, 28, 34, 36, 57, 88], "she": 26, "pattern": [26, 66], "gather": 26, "form": [26, 28, 32, 35, 47, 49, 52, 57, 61, 69, 72, 75, 77, 82, 84, 85, 88], "unknown": [26, 52, 57, 69], "latter": [26, 47, 57, 67, 86], "destin": 26, "previou": [26, 27, 34, 35, 36, 47, 48, 49, 53, 55, 58, 60, 66, 67, 68, 70, 72, 74, 77, 84, 88], "complic": [26, 28, 46, 82, 84], "grow": [26, 28, 30, 52, 66, 69, 84], "manifest": [26, 47], "heart": [26, 69], "technic": [26, 82, 86], "langl": [26, 43, 67, 82], "xi": [26, 54, 62, 69, 74], "rangl": [26, 43, 82], "replac": [26, 40, 41, 66, 69, 71, 74, 75, 82, 88], "theta_1": [26, 28, 34, 61, 65, 66, 75], "theta_2": [26, 28, 34, 61, 65, 66, 75], "conjagaci": 26, "maxim": [26, 28, 30, 34, 35, 51, 70, 75, 88], "automat": [26, 30, 47, 52, 55, 56, 82, 86], "earlier": [26, 28, 47, 82], "resort": [26, 84], "candid": [26, 41], "nice": [26, 40, 45, 49, 51, 53, 67, 69, 71, 74, 88, 91], "eas": [26, 28, 69, 75], "therebi": [26, 28, 32], "enorm": 27, "amount": [27, 28, 34, 52, 54, 57, 58, 86], "molecul": [27, 45, 52, 54, 55, 72], "individu": [27, 31, 52, 60, 63, 66, 84, 88], "bind": [27, 85, 88], "ligand": [27, 85, 88], "receptor": [27, 85, 88], "record": 27, "memori": [27, 40, 86], "poisson": [27, 54, 69, 88], "arriv": [27, 40, 42, 75, 88], "exist": [27, 35, 40, 52, 84], "worth": [27, 69, 71, 82, 86], "invest": 27, "greatli": [27, 69, 84, 86], "felt": 28, "heat": 28, "framework": [28, 84], "invalid": [28, 45, 70, 71, 82], "bia": [28, 45, 67, 69], "maximum": [28, 30, 34, 49, 54, 55, 56, 58, 60, 63, 66, 68, 69, 71, 72, 74, 85, 86, 88], "entropi": [28, 75], "bernardo": 28, "eventu": [28, 40, 84, 88], "advoc": 28, "insuffici": 28, "old": [28, 32, 88], "flat": [28, 36, 57], "quit": [28, 47, 52, 54, 57, 60, 67, 69, 74, 77, 82, 84, 86, 88], "summar": [28, 34, 49], "Such": [28, 47, 67], "encod": [28, 48, 75], "machineri": [28, 45], "remedi": 28, "bound": [28, 30, 31, 34, 35, 45, 47, 48, 49, 51, 52, 55, 69, 70, 71, 75, 86], "outsid": [28, 46, 52, 57, 58, 67, 77, 82, 84], "small": [28, 30, 47, 52, 54, 55, 56, 66, 68, 69, 70, 71, 72, 74, 75, 77, 82, 84, 88], "epsilon": [28, 84], "speed": [28, 35, 51, 54, 72, 75, 82, 86], "kinesin": [28, 54], "motor": [28, 52, 54], "noth": [28, 46, 52, 68], "goe": [28, 36, 40, 52, 71, 84, 88], "absurd": 28, "primari": [28, 30, 51, 91], "critic": [28, 32, 52], "fisher": 28, "hi": [28, 32, 38, 42, 49], "contemporari": 28, "illustr": [28, 40, 47, 51, 60, 69, 82, 88], "resolut": 28, "earli": [28, 70, 71], "patholog": [28, 55, 56, 58, 60, 63, 66, 67, 68, 69, 71, 72, 74, 84, 88], "bad": [28, 45, 52, 53, 58, 60, 72, 88], "subject": [28, 55, 57, 75, 86, 92], "debat": 28, "complain": 28, "chosen": [28, 47, 51, 52, 53, 66, 69, 82], "recal": [28, 30, 35, 36, 46, 55, 57, 60, 68, 71, 88], "formula": [28, 56], "inconsist": 28, "invari": [28, 40, 41, 61], "harold": 28, "discov": [28, 47, 54, 56, 68], "coordin": [28, 45, 46, 47, 55, 56, 60, 66], "mathcal": [28, 75, 82, 84], "_": [28, 31, 35, 51, 57, 60, 69, 70, 71, 72, 74, 84, 88], "succinctli": 28, "hessian": [28, 34, 35, 36], "sharp": [28, 52, 61, 88], "peak": [28, 30, 31, 34, 35, 52, 57, 61, 88], "propto": [28, 30, 31, 35, 84, 88], "strictli": [28, 52, 54, 74, 86], "reparametr": [28, 56, 66, 84], "phi": [28, 30, 31, 34, 36, 48, 49, 52, 53, 58, 61, 62, 63, 65, 72, 75, 84, 88], "phi_1": 28, "phi_2": 28, "matric": [28, 69, 71, 74], "recogn": [28, 84, 85], "difficult": [28, 30, 35, 52, 55, 56, 75], "intract": [28, 36, 75], "against": [28, 36, 52, 53, 57, 58, 60, 67, 70, 71], "tediou": 28, "binomi": [28, 45, 47, 55, 60, 63, 65, 68, 82, 86, 88], "bernoulli": [28, 32, 65, 82], "success": [28, 30, 32, 65, 75, 82, 88], "trial": [28, 32, 63, 65, 67, 68, 82], "proper": [28, 30], "highli": [28, 41, 48, 52, 65, 71], "suggest": [28, 42, 47, 57], "priori": [28, 32, 52, 54], "regardless": [28, 55, 84], "littl": [28, 30, 34, 43, 51, 54, 55, 57, 72, 82], "influenc": [28, 69], "lack": [28, 40, 57], "imposs": [28, 41, 43, 47, 52, 54, 88], "nefari": 28, "care": [28, 30, 31, 45, 52, 57, 69, 75, 77], "anywai": [28, 30, 71], "travel": 28, "suppos": [28, 88], "somewhat": [28, 88], "breadth": [28, 30, 84], "broader": [28, 35], "opt": [28, 82], "wiki": [28, 55], "loss": [28, 57], "precis": [28, 54, 55, 71, 84], "compar": [28, 30, 35, 36, 49, 53, 56, 57, 58, 60, 66, 67, 71, 72, 74, 75, 86, 88], "popul": [28, 45, 47, 88], "expert": 28, "seriou": [28, 47, 75, 77], "gain": [28, 57], "robust": [28, 51, 60, 84], "separ": [28, 45, 46, 52, 54, 63, 65, 74, 77, 88], "sublim": 28, "ridicul": 28, "consider": [28, 30, 47, 52, 69], "difficulti": [28, 51, 62, 68, 77], "rare": [28, 35, 41, 52, 57], "complex": [28, 32, 46, 47, 52, 54, 69, 75, 82, 84, 85, 86, 88], "certainli": [28, 31, 35, 47, 52, 55, 86], "hierarchi": [28, 62, 66, 75], "parametriz": 28, "greatest": 28, "unbound": 28, "idiomat": 28, "giant": [28, 54], "wager": 28, "salari": 28, "pig": [28, 57], "fly": [28, 57], "comfort": 28, "wage": 28, "don": [28, 34, 55, 66, 69, 82, 84, 86, 88], "hope": [28, 47, 67, 86], "lo": 28, "angel": 28, "footbal": 28, "club": 28, "win": 28, "ml": 28, "cup": 28, "someon": [28, 32, 82], "tell": [28, 31, 32, 34, 35, 42, 45, 46, 52, 57, 66, 67, 68, 74, 82, 84], "bacterium": 28, "absurdli": 28, "bigger": [28, 34, 52, 60, 61, 72, 88], "nanomet": [28, 54], "diamet": [28, 30, 31, 34, 36, 48, 49, 52, 53, 58, 75], "strand": 28, "nm": [28, 34, 66, 75], "flinch": 28, "m": [28, 47, 52, 57, 66, 69, 70, 71, 72, 74, 75, 82, 84, 86, 88, 92], "bacteria": [28, 71], "smaller": [28, 34, 52, 56, 57, 60, 66, 82, 88], "uneasi": 28, "won": [28, 56, 66, 67, 82], "meter": [28, 54], "cm": 28, "gigant": 28, "mm": [28, 34], "huge": [28, 82, 88], "tremend": 28, "divers": 28, "eukaryot": [28, 52], "big": [28, 36, 45, 51, 52, 66, 75], "xenopu": [28, 34, 48, 52], "strongli": [28, 46, 52, 82, 88], "wouldn": [28, 88], "magnitud": [28, 30, 49, 52, 54, 67, 68, 69, 82, 84], "geometr": 28, "boundari": 28, "surprisingli": [28, 66], "bacteri": [28, 45, 71], "logarithm": [28, 30, 34, 35, 45, 47, 54, 56, 57, 60, 66, 69, 72, 75, 84], "ignor": [28, 35, 36, 43, 45, 48, 49, 52, 53, 57, 61, 84], "95": [28, 34, 35, 49, 51, 52, 54, 55, 69, 72, 77], "li": [28, 56], "width": [28, 52, 56, 66, 67, 82], "rang": [28, 30, 31, 34, 36, 40, 45, 47, 52, 53, 57, 63, 67, 68, 69, 70, 72, 75, 82, 86, 88], "ell": [28, 30, 31, 34, 36, 48, 49, 52, 53, 58, 75], "log_": [28, 34, 45, 47, 48, 49, 54, 55, 68, 69, 75], "approx": [28, 35, 42, 43, 52, 57, 60, 71, 82], "lognorm": [28, 34, 36, 52, 53, 55, 58, 60, 75, 77], "hesit": [28, 55], "theta_": [28, 40, 41, 75], "max": [28, 30, 31, 34, 36, 37, 47, 69, 70, 71, 72, 74, 82, 86, 88], "divid": [28, 31, 40, 68, 71], "conceiv": [28, 67, 72], "came": [28, 57, 77, 84], "firm": 28, "countless": 28, "pl": [30, 31, 34, 36, 45, 47, 48, 49, 51, 52, 53, 55, 58, 60, 66, 68, 69, 70, 71, 72, 74, 75], "scipi": [30, 31, 32, 34, 35, 36, 37, 45, 46, 47, 52, 68, 71, 72, 74, 82, 86, 88], "stat": [30, 31, 32, 34, 35, 36, 37, 45, 46, 47, 51, 52, 68, 70, 71, 74, 82, 86], "st": [30, 31, 32, 34, 35, 36, 37, 45, 46, 47, 52, 68, 70, 71, 74, 82, 86], "ve": [30, 86, 88], "whole": [30, 34, 56, 66, 88], "bread": 30, "butter": 30, "inaccess": 30, "viabl": 30, "mitot": [30, 52, 58], "encapsul": [30, 48], "droplet": [30, 31, 34, 36, 48, 49, 53, 58, 75], "matt": [30, 75], "refamiliar": [30, 34], "remind": [30, 31, 49, 55, 57, 63, 72, 74, 75], "versu": [30, 34, 49, 52, 53, 58, 66, 68, 69], "good_invitro_droplet_data": [30, 31, 34, 36, 48, 49, 52, 53, 58, 75], "frame": [30, 31, 34, 36, 46, 47, 48, 49, 51, 52, 55, 58, 66, 68, 70, 75], "df": [30, 31, 34, 36, 45, 47, 48, 49, 52, 53, 55, 58, 60, 66, 68, 69, 70, 71, 72, 74, 75, 86], "read_csv": [30, 31, 34, 36, 45, 47, 48, 49, 52, 53, 55, 58, 60, 66, 68, 69, 70, 71, 72, 74, 75, 86], "join": [30, 31, 34, 36, 45, 47, 48, 49, 52, 53, 55, 58, 60, 66, 68, 69, 70, 71, 72, 74, 75, 77, 85, 86, 88], "comment_prefix": [30, 31, 34, 36, 45, 47, 48, 49, 52, 53, 55, 58, 60, 68, 71, 75], "um": [30, 31, 34, 36, 48, 49, 52, 53, 58, 75], "to_numpi": [30, 31, 34, 36, 45, 47, 48, 49, 51, 52, 53, 55, 58, 60, 68, 69, 70, 71, 72, 74, 75], "300": [30, 31, 32, 34, 36, 37, 46, 48, 49, 52, 68, 75, 82, 88], "x_rang": [30, 31, 32, 34, 35, 36, 37, 45, 48, 49, 52, 53, 56, 58, 68, 69, 75], "y_rang": [30, 31, 34, 35, 36, 37, 48, 49, 52, 68, 75, 82], "to_dict": [30, 31, 34, 36, 48, 49, 52, 68, 69, 70, 72, 75], "object": [30, 32, 34, 46, 47, 55, 60, 70, 75, 77, 82, 84, 86], "treat": [30, 52, 69], "jeffrei": [30, 31, 34, 48], "l_i": [30, 31, 34, 36, 48, 49, 52, 53, 58, 75], "implicit": [30, 57], "somedistribut": 30, "vanilla": 30, "tubulin": [30, 34, 48, 49, 58], "conserv": [30, 34, 48, 49, 52, 58, 60, 82, 84], "proport": [30, 40, 43, 45, 57, 88], "evalu": [30, 31, 32, 35, 36, 69, 70, 71, 72, 75, 82, 84, 88], "handi": [30, 49], "progress": [30, 46, 69], "postpon": 30, "secondli": [30, 86], "hit": [30, 55, 66, 70, 82], "underflow": [30, 31, 34, 47, 88], "circumst": 30, "insid": [30, 84, 88], "behav": [30, 35, 47, 61, 69, 82, 88], "risk": 30, "logsumexp": 30, "log_marginalized_posterior": [30, 31], "inf": [30, 34, 36, 45, 60, 70, 71], "len": [30, 31, 34, 45, 47, 48, 49, 52, 53, 55, 58, 60, 63, 68, 69, 70, 71, 72, 74, 75, 82, 86, 88], "smooth": [30, 53, 57, 60, 69, 71], "curv": [30, 31, 36, 48, 52, 53, 69, 71, 82], "grung": [30, 69], "linspac": [30, 31, 32, 34, 35, 36, 37, 52, 53, 56, 58, 68, 69, 70, 71, 72, 74, 75, 82], "log_marg_post": 30, "phi_val": [30, 31], "\u03c6": [30, 31, 34, 36, 49, 75], "l\u1d62": [30, 31], "line_width": [30, 31, 32, 34, 35, 36, 37, 45, 47, 51, 52, 55, 56, 68, 69, 70, 71, 72, 82], "33": [30, 34, 45, 47, 51, 56, 88], "awai": [30, 34, 35, 36, 52, 54, 56, 60, 67, 68, 69, 70, 82, 84], "subtract": [30, 57, 88], "marg": 30, "log_marg_post_max": 30, "marg_post": 30, "visual": [30, 31, 34, 35, 45, 47, 48, 51, 52, 68, 69, 84], "axi": [30, 36, 40, 45, 49, 52, 54, 67, 68, 88], "g_": 30, "proportion": [30, 52], "clever": [30, 40, 75], "momentarili": [30, 55, 66, 69], "quad": [30, 31], "marginalized_posterior": [30, 31], "unnorm": [30, 31, 47, 88], "integrand": [30, 31], "resolv": [30, 52], "domain": [30, 48, 54, 70], "pass": [30, 34, 36, 45, 46, 47, 52, 53, 55, 58, 68, 75, 77, 86], "arg": [30, 31, 34, 36, 52, 70, 71, 86], "kwarg": [30, 34, 45, 46, 47, 49, 52, 53, 60, 72, 74, 75], "err": 30, "46386461926837497": 30, "981239131261995e": 30, "review": [30, 75, 76, 82], "unorm": 30, "found": [30, 34, 35, 36, 43, 65, 69, 74, 75, 86, 88], "straightforwardli": 30, "grungi": 30, "x_i": [30, 54, 69, 71, 88], "bar": [30, 46, 47, 65, 69], "hat": [30, 42, 56, 57, 84], "nu": [30, 54, 69, 71], "std": [30, 51, 69, 70, 71, 72, 74], "exact_pdf": 30, "color": [30, 32, 35, 36, 37, 45, 47, 49, 51, 56, 63, 66, 68, 69, 70, 71, 72, 74, 82, 88], "line_dash": 30, "dash": 30, "perfect": [30, 82], "efficaci": 30, "tough": 30, "contour": [30, 31, 34, 36, 56, 84], "minim": [30, 34, 35, 36, 46, 52, 70, 71, 75, 77, 82], "furthermor": [30, 34, 36, 43, 51, 53, 54, 66, 67, 69, 86], "clean": [30, 84], "log_prior_indep_s": 30, "param": [30, 31, 34, 36, 45, 47, 49, 52, 69, 70, 71, 74], "log_likelihood_indep_s": 30, "logpdf": [30, 34, 36, 70, 71], "loc": [30, 34, 35, 36, 37, 47, 52, 68, 70, 71], "log_posterior_indep_s": 30, "lp": [30, 34, 36, 46, 47, 70, 71, 88], "prevent": [30, 52, 86], "bug": [30, 55, 77, 86], "trade": 30, "overhead": 30, "log_likelihood_indep_size_numpy_onli": 30, "timeit": 30, "ntime": 30, "136": 30, "452": 30, "loop": [30, 47, 52, 86], "000": [30, 36, 55, 68, 75, 86], "nearli": [30, 52, 66, 77, 82, 88], "slow": [30, 34, 69, 71], "increasingli": 30, "fraction": [30, 52, 55, 84], "nonneglig": 30, "shrink": [30, 63], "rapidli": [30, 32, 69, 84], "dimens": [30, 35, 45, 46, 47, 53, 55, 60, 82, 84], "log_post": [30, 31, 36], "enumer": [30, 31], "sigma_v": 30, "overflow": [30, 31, 55], "post": [30, 31, 47, 67, 69, 71, 74, 77, 88], "packag": [30, 46, 49, 57, 60, 70, 71, 74, 77, 86, 91], "viz": [30, 31, 34, 35, 36, 45, 47, 48, 49, 52, 53, 55, 56, 58, 60, 63, 66, 68, 69, 70, 71, 72, 74, 75, 88], "overlaid": [30, 31, 36, 56, 57], "\u03c3": [30, 34, 36, 48, 49, 52, 70, 71, 74, 75], "harder": [30, 36, 46, 55], "zoom": [30, 31, 66, 71, 88], "31": [30, 37, 47, 51, 55, 56, 58, 75, 88, 92], "35": [30, 34, 36, 45, 46, 47, 48, 52, 53, 55, 56, 58, 60, 63, 65, 66, 68, 69, 75, 88], "shape": [30, 32, 36, 45, 47, 49, 51, 52, 53, 55, 56, 66, 68, 72, 75, 88], "spindl": [31, 34, 36, 48, 49, 53, 58], "d_i": [31, 36, 48, 49, 52, 53, 58, 75], "trivari": 31, "tri": [31, 52], "theor_spindle_length": 31, "cbrt": [31, 36, 48, 49, 52, 53, 58, 75], "eyebal": 31, "somewher": [31, 34, 52], "37": [31, 36, 47, 58, 66, 75, 88], "asymptot": [31, 52, 57, 75], "slope": 31, "gamma_v": 31, "adjust": [31, 46, 49, 52, 53, 58, 67, 71, 75], "\u03d5": [31, 34, 36, 48, 49, 52, 63], "\u03b3": [31, 36, 48, 49, 52, 75], "log_post_max": 31, "calc": 31, "varphi": 31, "infin": [31, 69, 82], "unnormalized_marg_post_phi": 31, "empty_lik": [31, 36], "d\u1d62": 31, "trapezoid": 31, "trapz": [31, 36, 88], "normalization_const": 31, "wrinkl": 31, "lambda": [31, 56, 69, 72, 82], "swap": 31, "input": [31, 45, 46, 52, 53, 60, 71, 72, 74, 86, 88], "unnormalized_marg_post_gamma": 31, "norm_const": 31, "valuabl": [31, 54, 91], "rear": 31, "doom": 31, "handl": [31, 41, 47, 67, 70, 84, 86], "spend": [31, 77, 86], "sophist": [31, 60], "posteriori": [32, 35, 70], "seem": [32, 41, 45, 52, 58, 66, 67, 68, 69, 75, 84, 86, 88], "mossman": 32, "2019": 32, "author": [32, 45, 86, 91], "ag": 32, "drosophila": 32, "parent": 32, "viabil": 32, "offspr": 32, "vial": 32, "mate": 32, "young": 32, "dai": [32, 41, 66, 75, 77, 86, 92], "male": 32, "femal": 32, "176": [32, 75], "period": [32, 40, 69], "94": [32, 49, 72], "hatch": 32, "remaind": 32, "fail": [32, 53, 60, 67, 68, 86], "154": 32, "failur": 32, "binom": [32, 60, 61, 63, 82], "seek": [32, 35, 45, 57, 60], "Its": 32, "mother": 32, "n_old": 32, "n_young": 32, "instanti": [32, 51, 52, 86], "\u03b8": [32, 56, 63, 66, 82], "legend_label": [32, 35, 51, 56, 63, 66, 69, 75, 82, 88], "legend": [32, 51, 56, 63, 66, 82, 88], "top_left": [32, 82], "disavantag": 32, "tractabl": [32, 35, 48], "paltri": 32, "hopeless": 32, "coin": 32, "slightli": [32, 70], "bias": [32, 84], "bimod": [32, 45, 47, 51, 60], "sivia": 32, "bear": [32, 40, 51, 55], "conduct": [32, 68, 85, 86], "strang": [32, 43, 52, 69, 88], "upon": [32, 52, 57, 66], "statsmodel": [34, 36], "numdiff": [34, 36], "smnd": [34, 36], "tqdm": [34, 36], "342": [34, 36, 48, 49, 52, 58], "856": [34, 36, 48, 49, 52, 55, 58], "860": [34, 36, 48, 49, 52, 58], "2013": [34, 36, 48, 49, 52, 58], "abandon": 34, "bet": [34, 45, 48, 54], "farm": [34, 45, 48, 54], "breviti": 34, "logspac": 34, "1e": [34, 52, 69, 70, 71, 72, 74], "1e5": 34, "x_axis_typ": [34, 68], "half": [34, 48, 52, 54, 61, 66, 70, 85], "halfnorm": [34, 36, 48, 49, 52, 61, 63, 66, 69, 70, 71, 72, 74, 75, 88], "albeit": 34, "themselv": [34, 46, 55], "y_3": 34, "sum_j": [34, 57], "fortun": [34, 36, 42, 47, 57, 60, 74, 88], "log_prior": [34, 36, 70, 71], "log_likelihood": [34, 36, 58, 60, 70, 71, 88], "log_posterior": [34, 36, 70, 71], "indpend": [34, 36], "algorithm": [34, 39, 40, 42, 46, 55, 57, 69], "powel": [34, 36, 70, 71], "reli": [34, 51, 84, 88], "discontinu": 34, "hurt": 34, "particularli": [34, 49, 55, 75, 84, 86], "constrain": [34, 47, 75, 84], "bfg": 34, "cobyla": 34, "neg_log_posterior": [34, 36, 70, 71], "routin": 34, "converg": [34, 55, 75], "params_0": [34, 36, 70, 71], "minimz": 34, "optimzi": 34, "attribut": [34, 45, 46, 47, 55, 60], "extra": [34, 69, 71, 75, 77, 82], "popt": [34, 36], "phi_map": [34, 36], "sigma_map": [34, 36], "2f": [34, 36], "3f": [34, 36, 52, 63], "32": [34, 47, 60, 66, 75, 86, 88], "86": [34, 55, 60], "784": 34, "successfulli": 34, "invert": [34, 36, 69], "element": [34, 35, 47, 48, 66, 84], "approx_hess": [34, 36], "shove": 34, "cov": [34, 36, 69], "linalg": [34, 36], "inv": [34, 36, 54, 74], "41668904e": 34, "02": [34, 46, 47, 68, 92], "09388085e": 34, "06": [34, 47, 66, 75, 92], "70799615e": 34, "multipli": [34, 57, 69, 70, 71, 88], "96": [34, 35, 36, 51, 66, 68, 69, 70, 71, 75], "report": [34, 35, 36, 45, 47, 50, 55, 57, 65, 66, 67, 85], "256": 34, "multivariate_norm": [34, 36, 69, 70, 71], "neighborhood": [34, 84], "post_norm": [34, 36], "empti": [34, 86], "log_post_exact": 34, "00": [34, 36, 45, 46, 47, 60, 68, 86, 92], "lt": [34, 36, 45, 46, 47, 55, 60, 68, 88], "50it": 34, "overlai": [34, 37, 53, 56, 70, 72], "post_exact": [34, 36], "line_kwarg": [34, 35, 36, 51, 52, 55, 56, 63, 75], "dict": [34, 35, 36, 45, 47, 48, 49, 52, 55, 56, 58, 63, 66, 68, 69, 70, 71, 72, 74, 75, 86, 88], "line_color": [34, 36, 37, 51, 63, 71, 72, 74, 75], "danger": [34, 36], "66": [34, 36, 51], "catch_warn": 35, "simplefilt": 35, "abbrevi": [35, 46], "paramount": 35, "solv": [35, 52, 69, 82, 84], "dwell": 35, "seldom": [35, 51, 77], "Near": 35, "taylor": 35, "truncat": [35, 49, 52], "b_": 35, "y_gamma": 35, "y_norm": 35, "tomato": [35, 69, 70], "percent": [35, 40], "confid": [35, 46, 67, 68], "erron": 35, "025": [35, 75], "975": 35, "benefit": [35, 67, 69, 75, 86], "afford": [35, 69], "ii": 35, "pm": [35, 51, 52, 77, 92], "asymmetr": [35, 51], "extrem": [35, 52, 54, 55, 60, 65, 66, 69, 70, 84], "flaw": [35, 42], "median": [35, 43, 51, 52, 53, 63, 75], "34": [35, 45, 47, 55, 63, 66, 75, 88], "ppf": [35, 37, 82], "99": [35, 45, 52, 53, 56, 58, 63, 66, 68, 69, 72, 75], "perc_cred_int": 35, "gamma_low": 35, "gamma_high": 35, "norm_low": 35, "norm_high": 35, "fill_between": [35, 69, 70, 71], "patch_kwarg": [35, 69, 70, 71], "shift": [35, 88], "rightward": 35, "notabl": [35, 55, 63, 88], "miss": [35, 54, 55, 58, 67, 68, 82, 84], "despit": [35, 74, 84], "character": [35, 47, 52, 54, 68, 84], "throughput": [35, 85], "attract": 35, "pathologi": [35, 56, 60, 84], "breakdown": [35, 46, 69, 77], "mechan": [35, 82, 88], "p_data": [36, 49], "relationship": [36, 57, 66], "homoscedast": [36, 48, 69, 70, 71], "toward": [36, 54, 63, 66, 67, 69, 75, 84, 88], "embark": 36, "solver": [36, 69, 84], "differenti": [36, 45, 47, 69, 71, 74], "theoretical_spindle_length": 36, "And": [36, 45, 52, 53, 55, 58, 60, 67, 68, 82], "gamma_map": 36, "38": [36, 40, 56, 68, 75, 88], "77": [36, 47, 60], "859": 36, "034": 36, "754": 36, "201": [36, 63], "grid": [36, 47, 51], "sigma_0": [36, 52, 53, 58, 75], "million": [36, 82], "brute": [36, 48, 52, 88], "forc": [36, 48, 52, 82, 88], "style": [36, 46, 63, 82], "tight": [36, 53], "sea": 36, "needl": [36, 56], "haystack": 36, "39": [36, 45, 46, 47, 49, 60, 66, 70, 75, 86, 88], "91": [36, 86], "meshgrid": [36, 56, 82], "51": [36, 46, 66, 75], "52": [36, 55], "post_margin": 36, "narrow": [36, 56, 67], "cut": 36, "instantan": 36, "dstack": 36, "discourag": 36, "week": [36, 53, 77, 92], "d_theor": 36, "ell_theor": [36, 48, 49, 52, 53, 58, 75], "linear": [36, 47, 52, 54, 69, 70, 71, 74], "regim": [36, 52], "caught": [36, 68], "dynam": [36, 45, 84], "blackcellmag": 37, "rng": [37, 46, 51, 52, 70, 72, 88], "default_rng": [37, 46, 51, 52, 69, 70, 72, 88], "seed": [37, 47, 51, 55, 56, 60, 66, 75, 88], "12341234": 37, "udraw": 37, "04": [37, 46, 68, 92], "xgrid": 37, "grid_line_color": 37, "ygrid": 37, "x_val": 37, "y_val": [37, 51], "grai": [37, 51, 82], "zeros_lik": [37, 69, 70, 71], "black": [37, 63, 72, 88], "circl": [37, 49, 82, 84, 88], "fill_color": [37, 71, 72, 74], "level": [37, 45, 47, 57, 62, 66, 69, 75, 82, 84], "educ": 38, "vignett": 38, "michael": [38, 47, 53, 55, 67, 82, 91], "hmc": [38, 41, 46, 66, 88], "hamiltonian": [38, 41, 55, 88], "transit": [39, 40, 42, 43, 75], "kernel": [39, 40, 42, 43, 49, 70, 72, 74, 82], "metropoli": [39, 84], "hast": [39, 84], "capabl": [40, 45, 60, 85, 86], "pcg64": 40, "128": [40, 60], "float": [40, 47, 52, 57, 60], "nonuniform": 40, "muller": 40, "absenc": [40, 55, 69], "quantil": [40, 43, 51, 55], "mark": [40, 88], "vertic": [40, 66, 69], "horizont": [40, 69], "target": [40, 41, 47, 55, 56, 60, 84, 86, 88], "arbitrari": [40, 41, 43, 47, 55, 66, 69, 72, 84], "correct": [40, 57, 77, 82], "simplic": [40, 69, 86], "walk": [40, 42, 54, 84], "walker": [40, 41, 42, 49, 55, 60, 84, 88], "bold": [40, 53], "sentenc": [40, 55], "achiev": [40, 41, 42, 55, 68, 82], "condit": [40, 41, 47, 52, 57, 62, 65, 66, 67, 69, 72, 75, 82, 84, 86], "stationari": [40, 42, 71], "uniqu": [40, 47, 69, 75], "ergod": [40, 41, 84], "aperiod": 40, "2k": 40, "3k": 40, "irreduc": 40, "recurr": [40, 84], "revisit": 40, "checklist": 40, "moment": [40, 42, 45, 52, 57, 66, 69, 82, 84, 88], "preced": [40, 47, 48, 54, 82], "1000": [40, 45, 46, 47, 48, 49, 52, 53, 55, 60, 61, 63, 67, 68, 69, 70, 72, 74, 75, 82, 86, 88], "margossian": 40, "randomli": 41, "ratio": [41, 55, 71, 84, 88], "ge": 41, "accept": [41, 52, 67, 77, 84, 86], "otherwis": [41, 42, 46, 67, 75, 84], "nut": [41, 82], "earth": 41, "sequenti": [41, 54, 86], "bracket": 41, "art": [41, 45, 53, 55], "origin": [41, 46, 56, 61, 66, 67, 68, 69, 82], "1953": 41, "thumb": [41, 42, 55, 67], "wander": [41, 54], "reject": [41, 56, 84], "tune": [41, 42, 66, 69, 84], "gibb": 41, "modern": 41, "popular": [41, 46, 88], "special": [41, 47, 54, 66, 67, 69, 71, 82, 84, 86, 88], "improv": [41, 66, 68, 69], "subclass": 41, "overemphas": 41, "naiv": 41, "anyhow": 41, "devis": [42, 56, 85], "theta_0": 42, "travers": 42, "incredibli": [42, 69, 82, 84], "began": 42, "weight": [42, 45, 58, 71], "burn": 42, "reach": [42, 55, 71], "heurist": 42, "coauthor": 42, "rubin": 42, "metric": [42, 55, 67, 82, 84], "stationar": [42, 55], "famou": 42, "defer": [42, 48], "vehtari": [42, 55, 57, 60], "stringent": 42, "01": [42, 46, 51, 55, 56, 60, 66, 69, 75, 84, 86, 88, 92], "regular": [42, 88], "neglect": [42, 54, 75], "bunch": [42, 88], "strategi": [42, 47, 56, 67, 84, 88], "phase": [42, 45, 71, 82, 84], "h": [43, 57, 82, 84], "histogram": [43, 45, 49, 51], "averag": [43, 57, 60, 67, 82, 84, 85, 88], "th": [43, 52, 57], "abundantli": 43, "abil": [43, 55, 57, 67, 69, 86, 88], "superscript": [43, 66], "parenthet": 43, "hello": 44, "drew": 45, "reconstruct": 45, "miracul": 45, "elowitz": [45, 68, 85, 86], "singer": [45, 55, 60], "heterogen": 45, "methyl": 45, "embryon": 45, "stem": 45, "molec": 45, "331": 45, "2014": 45, "paragraph": [45, 77], "eda": 45, "rna": [45, 60, 68, 69, 86], "situ": 45, "hybrid": 45, "smfish": [45, 47, 55], "transcript": [45, 47, 55, 60, 68, 69, 72], "focus": [45, 86], "pluripot": 45, "associ": [45, 46, 47, 54, 68, 84, 92], "regul": [45, 65], "hallmark": 45, "tempor": 45, "laps": [45, 85, 88], "movi": 45, "insight": [45, 84], "279": [45, 60, 88], "rex1": [45, 47, 60], "nanog": 45, "prdm14": 45, "singer_transcript_count": [45, 47, 55, 60, 68, 86], "q": [45, 49, 55, 57, 66, 68, 72, 82, 86, 88], "layout": [45, 49, 51, 52, 75, 82, 88], "column": [45, 46, 47, 49, 51, 52, 53, 55, 66, 68, 75, 86], "row": [45, 46, 51, 52, 53, 66, 69, 75, 82], "fewer": [45, 52, 56, 88], "copi": [45, 60, 68, 72, 74, 86], "presenc": 45, "inflect": [45, 54], "edcf": 45, "impli": [45, 52, 66], "bursti": [45, 47, 55, 69, 72], "n_i": [45, 47, 55, 60, 61, 63, 65, 68, 69, 72, 86], "negbinom": [45, 47, 55, 68, 86], "higher": [45, 47, 57, 82, 84, 85, 86], "frequent": 45, "assembl": 45, "shorter": [45, 86], "environment": [45, 86], "lifetim": [45, 68], "promot": [45, 68, 71], "strength": [45, 68, 82], "thousand": [45, 67, 68, 86], "syntax": [45, 46, 47, 49, 52, 74, 91], "log10_alpha": [45, 47, 55, 60, 68], "log10_b": [45, 47, 55, 60, 68], "beta_": [45, 47, 55, 60, 63, 68, 86, 88], "neg_binomi": [45, 55, 60, 68, 86], "rais": 45, "block": [45, 46, 48, 52, 53, 54, 69, 70, 71, 72, 74, 84, 86, 88], "declar": [45, 46, 47, 48], "dictionari": [45, 47, 58, 60, 66, 69, 70, 71, 74], "iter_sampl": [45, 46, 47, 48, 49, 52, 53, 55, 63, 68, 69, 86, 88], "inferencedata": [45, 46, 47, 52, 55, 60], "info": [45, 46, 86], "fatal": 45, "neg_binomial_lpmf": [45, 60, 86], "show_consol": 45, "unclear": 45, "fed": 45, "aris": [45, 47, 86, 88], "silenc": 45, "throw": [45, 67], "pedagog": [45, 91], "disabl": 45, "xarrai": [45, 46, 47, 53, 55, 60], "dataset": [45, 46, 47, 53, 55, 60, 86, 88], "gt": [45, 46, 47, 55, 60, 86, 88], "168kb": 45, "int64": [45, 46, 47, 55, 60], "32b": [45, 46, 47, 55, 60], "8kb": [45, 46, 47, 55, 60], "993": [45, 46, 47, 55, 60], "994": [45, 46, 47, 55, 60], "995": [45, 46, 47, 55, 60], "996": [45, 46, 47, 55, 60], "997": [45, 46, 47, 55, 60], "998": [45, 46, 47, 55, 60], "999": [45, 46, 47, 52, 55, 60], "float64": [45, 46, 47, 55, 60], "32kb": [45, 46, 47, 55], "722": [45, 55], "814": 45, "808": 45, "155": 45, "271": [45, 55, 60], "48": 45, "64": [45, 47], "07": [45, 46, 47, 60, 66, 75, 92], "05002": 45, "04916": 45, "0567": 45, "05535": 45, "5707": 45, "5814": 45, "6186": 45, "6305": 45, "301": [45, 75], "308": [45, 88], "246": 45, "257": 45, "created_at": [45, 46, 47, 60], "19t23": [45, 46], "29": [45, 47, 55, 68, 75, 88, 92], "089569": 45, "arviz_vers": [45, 46, 47, 60], "inference_librari": [45, 46, 47, 60], "inference_library_vers": [45, 46, 47, 60], "4xarrai": [45, 46, 47, 60], "datasetdimens": [45, 46, 47, 55, 60], "4draw": [45, 46, 47, 55, 60], "1000coordin": [45, 46, 47], "int640": [45, 46, 47, 55, 60], "3arrai": [45, 46, 47, 55, 60], "999arrai": [45, 46, 47, 55, 60], "float643": 45, "271arrai": 45, "72176": 45, "81412": 45, "8077": 45, "02461": 45, "95251": 45, "49689": 45, "82657": 45, "61593": 45, "68701": 45, "36608": 45, "37078": 45, "37826": 45, "87778": 45, "33051": 45, "30581": 45, "38294": 45, "52823": 45, "08891": 45, "80512": 45, "22812": 45, "36809": 45, "38976": 45, "15537": 45, "27078": 45, "float6419": 45, "07arrai": 45, "9922": 45, "3422": 45, "4787": 45, "5616": 45, "3612": 45, "3301": 45, "2128": 45, "9165": 45, "9441": 45, "5362": 45, "5644": 45, "7573": 45, "2453": 45, "2903": 45, "8039": 45, "0338": 45, "6761": 45, "7705": 45, "1302": 45, "1052": 45, "1311": 45, "5695": 45, "6351": 45, "0655": 45, "float640": [45, 46, 47], "05535arrai": 45, "0500194": 45, "049159": 45, "0488312": 45, "0686739": 45, "0650993": 45, "0612367": 45, "0616795": 45, "0591138": 45, "0590177": 45, "0570248": 45, "0569334": 45, "0563149": 45, "065594": 45, "0578358": 45, "05951": 45, "0587069": 45, "059966": 45, "0532751": 45, "0619955": 45, "0584618": 45, "0551539": 45, "0569168": 45, "056705": 45, "0553542": 45, "6305arrai": 45, "570748": 45, "581394": 45, "580663": 45, "701103": 45, "694826": 45, "652913": 45, "683638": 45, "664259": 45, "670896": 45, "640091": 45, "640559": 45, "641301": 45, "688222": 45, "636539": 45, "634055": 45, "641766": 45, "655928": 45, "611608": 45, "681705": 45, "626147": 45, "640292": 45, "642441": 45, "61861": 45, "630507": 45, "float641": [45, 46, 47, 55], "257arrai": 45, "30086": 45, "3084": 45, "3113": 45, "16321": 45, "18642": 45, "21299": 45, "20986": 45, "22831": 45, "22902": 45, "24394": 45, "24463": 45, "24938": 45, "18314": 45, "2378": 45, "22541": 45, "23131": 45, "2221": 45, "27348": 45, "20764": 45, "23313": 45, "25842": 45, "24476": 45, "24638": 45, "25685": 45, "chainpandasindexpandasindex": [45, 46, 47, 55, 60], "dtype": [45, 46, 47, 55, 60], "x27": [45, 46, 47, 55, 60], "drawpandasindexpandasindex": [45, 46, 47, 55, 60], "990": [45, 46, 47, 55, 60], "991": [45, 46, 47, 55, 60], "992": [45, 46, 47, 55, 60], "00arviz_vers": [45, 46, 47, 60], "0inference_librari": [45, 46, 47, 60], "cmdstanpyinference_library_vers": [45, 46, 47, 60], "puls": 45, "plot_scatt": 45, "\u03b1": [45, 52, 63, 68, 69, 70, 71], "bin": [45, 49, 51, 86], "rug": [45, 49, 51], "send": [45, 85], "foolishli": 45, "grab": [45, 71], "arang": [45, 47, 51, 72, 82], "251": [45, 75], "flatten": [45, 46, 47, 51, 56, 63, 66, 69, 70, 75, 88], "zip": [45, 47, 51, 52, 68, 72, 77, 82], "nbinom": [45, 47], "x_plot": [45, 47], "y_plot": [45, 47], "cdf_to_staircas": [45, 47], "underlai": [45, 47], "425": 45, "426": 45, "amazon": [46, 86], "julia": 46, "matlab": [46, 86], "stata": 46, "across": [46, 60, 86, 88], "dive": 46, "disk": 46, "seven": [46, 55], "intend": 46, "ventur": 46, "friend": [46, 88], "guid": [46, 91], "manual": [46, 47, 55, 88], "static": [46, 48], "semicolon": 46, "curli": 46, "prepar": [46, 66, 82, 84, 86, 88, 92], "favorit": [46, 51], "editor": [46, 86], "groundwork": 46, "hello_world": 46, "bebi103_cours": 46, "2025": 46, "08": [46, 66, 68, 75, 92], "ex": 46, "43": [46, 47], "iter": [46, 47, 49, 55, 56, 58, 60, 63, 66, 67, 68, 69, 71, 72, 74, 75, 82, 84, 86, 88], "44": [46, 47, 68, 75], "job": [46, 72, 82, 86], "cmdstanmcmc": 46, "num_sampl": 46, "engag": [46, 75], "csv_file": 46, "var": [46, 68, 75, 82, 84], "j_": [46, 75], "c5r9ch0913v3h1w4bdwzm0lh0000gn": [46, 75], "tmpvzktutt3": 46, "hello_worldg4sdgzab": 46, "20240719161944_1": 46, "20240719161944_2": 46, "20240719161944_3": 46, "20240719161944_4": 46, "output_fil": 46, "20240719161944_0": 46, "pronounc": 46, "rv": 46, "recreat": 46, "vehicl": 46, "40kb": 46, "6374": 46, "5841": 46, "5403": 46, "6269": 46, "542659": 46, "6269arrai": 46, "637411": 46, "58407": 46, "302226": 46, "474132": 46, "962219": 46, "03972": 46, "75933": 46, "254514": 46, "365888": 46, "96866": 46, "20111": 46, "82037": 46, "477287": 46, "556766": 46, "32425": 46, "55547": 46, "494835": 46, "364278": 46, "015963": 46, "141604": 46, "35541": 46, "39819": 46, "540314": 46, "626918": 46, "sample_stat": [46, 47, 55], "204kb": [46, 47], "acceptance_r": [46, 47], "9468": 46, "8258": 46, "9861": 46, "9895": 46, "bool": [46, 47], "4kb": [46, 47, 55], "energi": [46, 47, 55, 69, 75], "5121": 46, "564": [46, 55], "1502": 46, "215": 46, "2031": 46, "1706": 46, "1965": 46, "n_step": [46, 47], "step_siz": [46, 47], "015": 46, "tree_depth": [46, 47, 55], "549548": 46, "9895arrai": 46, "946755": 46, "82582": 46, "998086": 46, "91481": 46, "689701": 46, "794211": 46, "991144": 46, "725178": 46, "979043": 46, "928644": 46, "989108": 46, "945146": 46, "757333": 46, "998694": 46, "864913": 46, "978766": 46, "99792": 46, "791233": 46, "982238": 46, "986148": 46, "989484": 46, "boolfals": [46, 47], "falsearrai": [46, 47, 55], "139": [46, 66], "215arrai": 46, "512115": 46, "56356": 46, "138952": 46, "137244": 46, "462933": 46, "42688": 46, "55296": 46, "33155": 46, "0698188": 46, "39816": 46, "793701": 46, "70602": 46, "858483": 46, "6095": 46, "70213": 46, "43293": 46, "44248": 46, "113932": 46, "07941": 46, "0126613": 46, "4355": 46, "107657": 46, "150176": 46, "214951": 46, "146": 46, "1965arrai": 46, "03146e": 46, "70569e": 46, "56703e": 46, "12401e": 46, "62933e": 46, "40512e": 46, "54763e": 46, "23887e": 46, "69369e": 46, "69151e": 46, "21337e": 46, "65687e": 46, "13902e": 46, "54994e": 46, "70108e": 46, "20974e": 46, "22431e": 46, "63494e": 46, "27409e": 46, "00259e": 46, "18573e": 46, "92776e": 46, "45970e": 46, "96513e": 46, "int643": 46, "1arrai": [46, 47, 55], "0arrai": 46, "01508": 46, "07811": 46, "841159": 46, "00025": 46, "int641": 46, "group": [46, 47, 57, 66, 86], "dataarrai": [46, 47, 53, 55], "panda": [46, 47, 55, 70, 75, 86, 88], "interestingli": [46, 49], "arbitrarili": 46, "multidimension": [46, 49, 60, 69, 71], "999xarrai": [46, 55], "3022": 46, "2444": 46, "01371": 46, "3982": 46, "togeth": [46, 61, 63, 65, 66, 69, 70, 84, 85, 86, 88], "np_sampl": 46, "sp_sampl": 46, "staircas": [46, 63], "palett": [46, 51, 63, 82], "b_glasbey_category10": 46, "normal_rng": [46, 52, 53, 58, 68, 69, 71, 72, 74, 75], "sm_rng": 46, "norm_rng": 46, "mote": 46, "fixed_param": [46, 52, 68, 69, 86, 88], "stan_sampl": 46, "novel": 46, "occasion": [46, 52], "visibl": [46, 51, 63], "netcdf": 46, "to_netcdf": 46, "stan_hello_world": 46, "nc": 46, "from_netcdf": 46, "hpp": 46, "deposit": 46, "exit": 46, "delet": [46, 72], "outpur_dir": 46, "gene": [47, 54, 55, 60, 66, 68, 69, 72, 86], "datafram": [47, 51, 68, 72, 88], "count": [47, 54, 55, 60, 69, 72, 85, 88], "mrna": [47, 55, 60, 72], "unimod": 47, "alpha_1": 47, "alpha_2": 47, "beta_1": 47, "beta_2": 47, "burst": [47, 54, 55, 68], "concis": 47, "retain": [47, 54, 75], "alpha_i": [47, 88], "b_i": 47, "beta_i": 47, "hood": [47, 84, 86], "summand": [47, 57], "a_1": [47, 72], "a_2": 47, "a_i": 47, "stabl": [47, 57, 69, 70, 74, 84], "log_mix": [47, 60], "keyword": [47, 74], "n_val": [47, 60], "neg_binomial_lupmf": 47, "negative_binomial_lpmf": 47, "_lpmf": [47, 60], "_lpdf": [47, 60], "_lupmf": 47, "_lupdf": 47, "signifi": 47, "wise": [47, 70, 86], "vvector": 47, "log10_beta": 47, "front": [47, 84, 86], "slash": 47, "elementwis": 47, "smart": 47, "enclos": [47, 52], "inclus": [47, 69], "3252": [47, 51, 55, 56, 60, 66, 75], "360kb": 47, "alpha_dim_0": [47, 60], "b_dim_0": [47, 60], "beta__dim_0": 47, "log10_alpha_dim_0": 47, "log10_b_dim_0": 47, "16b": 47, "64kb": 47, "867": 47, "379": 47, "235": 47, "691": 47, "191": [47, 75], "2132": 47, "4575": 47, "7189": 47, "159": 47, "8032": 47, "8652": 47, "20t01": 47, "493203": 47, "1000alpha_dim_0": 47, "2b_dim_0": 47, "2beta__dim_0": 47, "2log10_alpha_dim_0": 47, "2log10_b_dim_0": 47, "2coordin": 47, "float642": 47, "773": 47, "745": 47, "842": 47, "379arrai": 47, "86735": 47, "77317": 47, "74531": 47, "08933": 47, "06105": 47, "65147": 47, "56703": 47, "75107": 47, "16542": 47, "79654": 47, "77347": 47, "10867": 47, "63497": 47, "5682": 47, "16957": 47, "98005": 47, "53614": 47, "5058": 47, "88295": 47, "46085": 47, "9517": 47, "19794": 47, "67976": 47, "08075": 47, "55802": 47, "94599": 47, "01463": 47, "48093": 47, "25886": 47, "19726": 47, "78945": 47, "78982": 47, "45851": 47, "7594": 47, "09546": 47, "03334": 47, "60415": 47, "37894": 47, "04128": 47, "18814": 47, "3936": 47, "73299": 47, "86744": 47, "82427": 47, "84191": 47, "37865": 47, "float645": 47, "406": 47, "691arrai": 47, "2351": 47, "3362": 47, "40603": 47, "9016": 47, "64434": 47, "5218": 47, "6283": 47, "2829": 47, "59981": 47, "1368": 47, "85139": 47, "3799": 47, "4836": 47, "88547": 47, "2705": 47, "66373": 47, "2696": 47, "29264": 47, "7265": 47, "78734": 47, "3232": 47, "54503": 47, "02042": 47, "726": 47, "6697": 47, "1807": 47, "61744": 47, "0982": 47, "98924": 47, "8056": 47, "25143": 47, "1896": 47, "27248": 47, "2288": 47, "2259": 47, "96834": 47, "481": 47, "33478": 47, "0416": 47, "76565": 47, "2165": 47, "88078": 47, "172": [47, 75], "65381": 47, "3025": 47, "69076": 47, "02912": 47, "02915": 47, "2132arrai": 47, "191018": 47, "0291238": 47, "184979": 47, "0303937": 47, "274398": 47, "0289672": 47, "150868": 47, "0341496": 47, "277793": 47, "0292939": 47, "350706": 47, "0308834": 47, "028182": 47, "101159": 47, "0366697": 47, "176562": 47, "0341652": 47, "188942": 47, "0296503": 47, "208884": 47, "0309375": 47, "132538": 47, "24873": 47, "0315199": 47, "0731546": 47, "0354853": 47, "276439": 47, "0355895": 47, "334533": 47, "0271698": 47, "444163": 47, "0292486": 47, "440048": 47, "0276023": 47, "030097": 47, "201274": 47, "0339201": 47, "157859": 47, "0302649": 47, "173441": 47, "0342272": 47, "25768": 47, "0301459": 47, "176872": 47, "0291524": 47, "213185": 47, "6788": 47, "685": 47, "5287arrai": 47, "457481": 47, "678807": 47, "438592": 47, "706661": 47, "608639": 47, "66759": 47, "409431": 47, "759749": 47, "619659": 47, "680928": 47, "761437": 47, "708308": 47, "666047": 47, "1954": 47, "790255": 47, "474224": 47, "743207": 47, "398946": 47, "688683": 47, "539182": 47, "694754": 47, "342016": 47, "565819": 47, "705928": 47, "192574": 47, "774224": 47, "603645": 47, "738854": 47, "629294": 47, "622966": 47, "762637": 47, "680319": 47, "737074": 47, "677552": 47, "707183": 47, "481921": 47, "74851": 47, "376383": 47, "70254": 47, "503538": 47, "731878": 47, "572057": 47, "687301": 47, "450906": 47, "685017": 47, "528744": 47, "536": 47, "535": 47, "6712arrai": 47, "718925": 47, "53575": 47, "732878": 47, "51722": 47, "561619": 47, "53809": 47, "821402": 47, "46661": 47, "556279": 47, "53322": 47, "455057": 47, "51028": 47, "55003": 47, "994998": 47, "43569": 47, "753102": 47, "46642": 47, "723672": 47, "52797": 47, "680094": 47, "50951": 47, "877661": 47, "604271": 47, "50141": 47, "13576": 47, "44995": 47, "558401": 47, "44868": 47, "475561": 47, "56591": 47, "352458": 47, "53389": 47, "3565": 47, "55905": 47, "52148": 47, "696211": 47, "46954": 47, "801731": 47, "51906": 47, "760848": 47, "46563": 47, "58892": 47, "52077": 47, "752341": 47, "53533": 47, "671243": 47, "8652arrai": 47, "179038": 47, "159009": 47, "133145": 47, "194928": 47, "146822": 47, "152438": 47, "806095": 47, "846002": 47, "835965": 47, "872181": 47, "858328": 47, "136364": 47, "213688": 47, "164984": 47, "133647": 47, "125085": 47, "12076": 47, "793301": 47, "801544": 47, "807659": 47, "822806": 47, "803243": 47, "865222": 47, "alpha_dim_0pandasindexpandasindex": 47, "b_dim_0pandasindexpandasindex": 47, "beta__dim_0pandasindexpandasindex": 47, "log10_alpha_dim_0pandasindexpandasindex": 47, "log10_b_dim_0pandasindexpandasindex": 47, "9871": 47, "9415": 47, "9976": 47, "9587": 47, "597e": 47, "03": [47, 55, 60, 75, 92], "598e": 47, "595e": 47, "1227": 47, "1186": 47, "501268": 47, "9587arrai": 47, "987143": 47, "941549": 47, "977411": 47, "99892": 47, "976145": 47, "732715": 47, "910988": 47, "992787": 47, "951251": 47, "9523": 47, "919331": 47, "63308": 47, "997946": 47, "999491": 47, "932981": 47, "886662": 47, "992565": 47, "839946": 47, "972186": 47, "989851": 47, "943136": 47, "999211": 47, "997595": 47, "958723": 47, "03arrai": [47, 55], "1596": 47, "84": [47, 72], "75": [47, 48, 49, 52, 53, 55, 58, 66, 75, 77, 82], "1597": 47, "82": 47, "1599": 47, "1600": [47, 75], "58": [47, 55, 66, 75, 88], "1598": 47, "47": [47, 66, 68], "1601": 47, "73": [47, 66, 75], "87": [47, 55], "53": [47, 55, 66, 72, 75], "69": [47, 55, 66, 75], "1602": 47, "68": [47, 52, 55, 66, 75], "1595": 47, "59": 47, "78": [47, 55, 60], "65": [47, 66, 75], "int6423": 47, "31arrai": 47, "63": [47, 66, 75], "1186arrai": 47, "122749": 47, "119707": 47, "102969": 47, "11862": 47, "int644": 47, "5arrai": 47, "futur": [47, 49, 55, 56], "doc": 47, "478": 47, "184b": 47, "8b": [47, 55], "642": 47, "802": [47, 75], "2082": 47, "02532": 47, "422": 47, "6277": 47, "6815": 47, "597": 47, "1674": 47, "int642arrai": 47, "int64478arrai": 47, "243arrai": 47, "64227": 47, "24292": 47, "float644": 47, "80233": 47, "4987": 47, "02532arrai": 47, "208232": 47, "0253173": 47, "6277arrai": 47, "421977": 47, "627665": 47, "597arrai": 47, "681452": 47, "59658": 47, "1674arrai": 47, "167433": 47, "1xarrai": 47, "int641arrai": 47, "scalar": [47, 70, 71], "to_datafram": 47, "from_panda": [47, 75], "include_index": 47, "chaindrawalpha_dim_0b_dim_0beta__dim_0log10_alpha_dim_0log10_b_dim_0alphabbeta_log10_alphalog10_bwi64i64i64i64i64i64i64f64f64f64f64f64f6400000002": 47, "867355": 47, "23510": 47, "1910180": 47, "4574810": 47, "7189250": 47, "17903800000012": 47, "4574811": 47, "535750": 47, "17903800000102": 47, "6788070": 47, "17903800000112": 47, "6788071": 47, "17903800001002": 47, "02912380": 47, "cumbersom": [47, 57, 71], "arviz_to_datafram": [47, 49], "df_mcmc": [47, 49], "wchain__draw__diverging__f64f64f64f64f64f64f64f64f64f64f64i64i64bool2": 47, "867354": 47, "773175": 47, "235134": 47, "33620": 47, "7189251": 47, "17903800false2": 47, "745315": 47, "089335": 47, "4060332": 47, "90160": 47, "1849790": 47, "03039370": 47, "4385920": 47, "7066610": 47, "7328781": 47, "517220": 47, "15900901false4": 47, "061054": 47, "651473": 47, "6443434": 47, "52180": 47, "2743980": 47, "02896720": 47, "6086390": 47, "667590": 47, "5616191": 47, "538090": 47, "13314502false5": 47, "017854": 47, "427832": 47, "7704935": 47, "84410": 47, "3609480": 47, "02789860": 47, "7005180": 47, "6461910": 47, "4425561": 47, "554420": 47, "14577403false2": 47, "309674": 47, "870747": 47, "4160534": 47, "1050": 47, "1348430": 47, "02932120": 47, "3635510": 47, "6875950": 47, "8701731": 47, "532820": 47, "19200404fals": 47, "chain__": 47, "draw__": 47, "diverging__": 47, "par": 47, "\u03b1\u2081": 47, "\u03b1\u2082": 47, "b\u2081": 47, "b\u2082": 47, "peculiar": 47, "reveal": 47, "glyph": [47, 49], "id": [47, 75, 86], "color_by_chain": [47, 88], "blue": [47, 52, 65], "red": [47, 88], "green": 47, "uncov": [47, 67, 68], "observation": 47, "emphas": [47, 55, 69], "devilish": 47, "vigil": 47, "b_1": 47, "b_2": 47, "overlap": [47, 57, 70, 88], "filter": [47, 51, 71], "col": [47, 51, 68, 69, 70, 71, 72, 74], "renam": 47, "with_column": [47, 51, 68, 69, 70, 72, 74], "alia": [47, 51, 68, 69, 70, 72, 74], "df_switch": 47, "concat": [47, 88], "blog": [47, 69, 77, 88], "alon": [47, 52], "param_mean": 47, "wf64f64f64f64f645": 47, "2096973": 47, "16429831": 47, "9572976": 47, "2381460": 47, "831563": 47, "init": [47, 60, 75], "unconstrain": 47, "warmup": 47, "advis": 47, "hoc": [47, 54], "05": [47, 66, 69, 70, 72, 74, 82, 92], "alpha0": 47, "alpha1": 47, "beta0": 47, "beta1": 47, "fragil": 47, "closer": [47, 52, 57, 58, 60, 75], "microtubul": [48, 52, 75, 88], "departur": [48, 75], "sacrific": 48, "drop": [48, 52, 69], "largest": 48, "smallest": 48, "uncomfort": 48, "millimet": 48, "gamma_": [48, 49, 52, 53, 58, 75], "denom_ratio": [48, 49, 52, 53, 58, 75], "log10_phi": [48, 49], "syntact": 48, "parenthes": 48, "plane": 48, "plot_ecdf": [48, 49], "depict": [48, 66], "eschew": 48, "promis": 49, "quickli": [49, 51, 77, 82, 86], "aesthet": 49, "trajectori": [49, 55, 82, 84], "trace_plot": 49, "plot_": 49, "backend": 49, "plot_trac": 49, "kde": 49, "bandwidth": 49, "dan": 49, "minimum": [49, 54], "plot_parallel": 49, "var_nam": [49, 68, 86], "norm_method": 49, "minmax": [49, 66], "parcoord": [49, 56, 66], "neck": 49, "vice": [49, 82], "versa": [49, 82], "plot_dens": 49, "highest": [49, 51], "hpd": [49, 51], "shortest": [49, 51], "backend_kwarg": 49, "bokehdeprecationwarn": 49, "deprec": 49, "remov": [49, 56, 57, 66, 72, 86], "gamma_log10_phiphisigmachain__draw__diverging__f64f64f64f64i64i64bool0": 49, "8760751": 49, "5813638": 49, "13823": 49, "7229800false0": 49, "8695911": 49, "5794137": 49, "96693": 49, "7328201false0": 49, "8521091": 49, "5858338": 49, "53243": 49, "803702false0": 49, "8800941": 49, "5797237": 49, "99453": 49, "7278603false0": 49, "8934751": 49, "5709837": 49, "23743": 49, "7522504fals": 49, "hist": 49, "transpar": 49, "plot_pair": 49, "scatter_kwarg": 49, "fill_alpha": [49, 68], "radius_unit": 49, "represent": [49, 84, 86], "uni": 49, "hex": 49, "hexbin": 49, "xtick_label_orient": [49, 53, 58, 60, 63, 66, 88], "beauti": [51, 57, 61, 82], "lie": [51, 52, 53, 58], "plu": [51, 69, 74, 82], "5th": [51, 55], "percentil": [51, 52, 53, 55, 58, 63], "97": [51, 66, 75], "hdi": 51, "scheme": 51, "tail": [51, 52, 54, 55, 56, 60, 66, 70, 84, 88], "sigma_2": [51, 54], "x_expon": 51, "15000": 51, "x_norm": 51, "which_norm": 51, "x_2norm": 51, "pareto": [51, 57, 60], "x_heavytail": 51, "readili": [51, 70], "trickier": [51, 70], "trace": [51, 55, 56, 88], "df_summari": 51, "hpd_low": 51, "hpd_high": 51, "schema": 51, "dist": 51, "concaten": [51, 72], "hdi_prob": 51, "statisticexponentialnormaltwo": 51, "normalsheavi": 51, "tailstrf64f64f64f64": 51, "quot": [51, 66, 68], "0078431": 51, "0014472": 51, "0040054": 51, "134071": 51, "0053510": 51, "249141": 51, "0738544": 51, "580247": 51, "0248750": 51, "5115520": 51, "5904380": 51, "02307": 51, "7010921": 51, "0006981": 51, "7679750": 51, "79814": 51, "6495411": 51, "492053": 51, "80497720": 51, "613608": 51, "0000880": 51, "5318630": 51, "5613620": 51, "000057": 51, "9965491": 51, "5073143": 51, "75565311": 51, "296449": 51, "y_valu": 51, "category10": [51, 63], "plot_interv": 51, "barx": 51, "is_in": 51, "asymmetri": 51, "finder": 51, "uniniti": 51, "suffer": [51, 84], "interquantil": 51, "modal": [51, 88], "mislead": 51, "futil": 51, "deceiv": 51, "chanc": [51, 55, 82, 88], "reeeealli": 51, "71": 51, "struggl": [52, 84], "symptom": [52, 66], "produc": [52, 53, 57, 67, 70, 85, 86, 88], "obei": 52, "cytoplasm": 52, "embryogenesi": 52, "colleagu": 52, "regress": [52, 53, 59, 69], "hone": 52, "670": [52, 53, 58], "uniformli": [52, 67, 68], "inher": [52, 55, 69], "resid": 52, "depolymer": 52, "e_i": 52, "stochast": [52, 69, 75, 84, 88], "compon": [52, 82, 85, 88], "datum": [52, 57], "establish": 52, "sound": 52, "varieti": [52, 60, 86], "uncertain": [52, 57], "irrelev": [52, 70], "ey": [52, 53, 60, 70, 71, 86], "nonposit": 52, "vanish": 52, "unrealist": 52, "ultim": [52, 54, 66, 68], "jettison": 52, "halfnorm_pdf": 52, "350": [52, 69, 70, 71, 72], "80": [52, 63, 75], "lognorm_pdf": 52, "n_ppc_sampl": 52, "ab": [52, 56, 68, 76], "ph": [52, 69], "sig": 52, "thin": [52, 63, 88], "20th": 52, "ell_val": 52, "line_alpha": [52, 56, 68], "predictive_ecdf": [52, 53, 58, 60, 68, 88], "n_": [52, 55, 72], "middl": [52, 53, 58, 75], "darker": 52, "fill": [52, 86], "extent": 52, "willing": 52, "toler": [52, 70], "tug": 52, "substanti": [52, 56, 67, 75], "059903": 52, "linearli": [52, 82, 85], "gamma_pdf": 52, "\u03c3\u2080": 52, "settl": 52, "clearer": [52, 68, 75], "_rng": 52, "lognormal_rng": 52, "gamma_rng": [52, 68, 86, 88], "tweak": 52, "recompil": 52, "phi_mu": 52, "phi_sigma": 52, "sigma_0_alpha": 52, "sigma_0_beta": 52, "sm_prior_pr": [52, 68], "indep_size_model_prior_predict": 52, "alert": [52, 77], "parallel": [52, 55, 56, 66, 84, 86], "prior_predict": [52, 68, 69, 86], "reshap": [52, 53], "2d": [52, 84], "verbos": 52, "hing": 52, "polymer": 52, "assembli": 52, "balanc": [52, 84], "catastroph": [52, 82, 88], "t_0": [52, 82], "t_1": 52, "t_": [52, 70, 84], "gg": [52, 58], "l_": 52, "mt": 52, "unimport": 52, "geometri": [52, 84], "nmol": 52, "threshold": 52, "ccl": 52, "assur": 52, "prolat": 52, "spheroid": 52, "spheric": 52, "microscop": [52, 54, 66, 88], "growth": [52, 71], "spectroscop": 52, "vitro": 52, "assai": 52, "2t_": 52, "distinguish": [52, 61, 82], "ones": [52, 55, 68, 70, 71, 75, 82, 88], "obvious": 52, "lest": [52, 55], "unidentifi": 52, "dire": 52, "commensur": [52, 53, 54, 57], "enhanc": [52, 86], "strive": [52, 77], "didn": [52, 68, 69], "slight": [52, 65], "baselin": 52, "continuum": 52, "basi": [52, 69, 84], "gamma_alpha": 52, "gamma_beta": 52, "beta_rng": 52, "cons_tubulin_model_prior_predict": 52, "span": [52, 60], "predictive_regress": [52, 53, 58, 69, 70, 71, 72, 74, 75], "30th": 52, "60th": 52, "90th": 52, "99th": [52, 53, 58], "samples_x": [52, 53, 58, 69], "60": [52, 68, 71, 75], "javascript": 52, "slider": [52, 66], "draw_slid": 52, "data_dict": 52, "str": 52, "sel": [52, 60, 63], "cd": 52, "columndatasourc": 52, "params_dict": 52, "squeez": [52, 68], "cds_param": 52, "div": 52, "js_code": 52, "cb_obj": 52, "tostr": 52, "toprecis": 52, "emit": 52, "customj": 52, "js_on_chang": 52, "spacer": 52, "encompass": [52, 67, 68, 69, 70], "replot": 52, "heavili": [52, 67, 75, 82, 84, 88], "coupl": [52, 53, 69, 88], "examin": 52, "mayb": [52, 54, 69], "relax": 52, "verif": 52, "spindle_volum": 52, "vol_ratio": 52, "ul": 52, "v0": 52, "nonconst": 52, "highlight": [52, 53, 75], "ell_ppc": [53, 58, 75], "indep_size_model": 53, "posterior_predict": [53, 58, 60, 68, 69, 71, 72, 74, 88], "n_sampl": 53, "stack": [53, 55, 58, 60, 68, 69, 70, 71, 72, 74, 88], "collaps": 53, "transpos": [53, 58, 60, 68, 69, 70, 71, 72, 74, 88], "ell_ppc_dim_0": [53, 58], "diff": [53, 58, 68, 88], "vstack": [53, 69], "trend": 53, "envelop": [53, 67, 68, 69, 70], "n_ppc": [53, 58, 60, 68, 69, 75, 86, 88], "d_ppc": [53, 58, 75], "mu_ppc": [53, 58, 75], "cons_tubulin_model": 53, "lost": 53, "former": [53, 84], "shelf": 54, "oftentim": 54, "pare": 54, "pixel": 54, "interpixel": 54, "optic": [54, 71], "digit": 54, "camera": 54, "simplifi": 54, "bivari": 54, "fourth": 54, "symmetri": 54, "s_": [54, 69], "sigma_1": 54, "c_": 54, "rho": [54, 69, 70, 71, 72, 74], "lkj": 54, "rethink": [54, 91], "underpin": [54, 84], "inappropri": 54, "underli": [54, 57, 67, 69, 72, 88], "inclin": 54, "depart": 54, "inadequ": 54, "adequ": [54, 68], "lightest": 54, "heaviest": 54, "cauchi": 54, "distirbut": 54, "heavier": [54, 84], "opposit": [54, 66], "slower": [54, 88], "log10_v": 54, "reproduc": [55, 77], "rhat": [55, 56, 58, 60, 63, 66, 68, 69, 71, 72, 74, 88], "40b": 55, "007": 55, "007xarrai": 55, "007arrai": 55, "00714323": 55, "00676445": 55, "00684101": 55, "00707471": 55, "00687351": 55, "sd": 55, "hdi_3": 55, "hdi_97": 55, "mcse_mean": 55, "mcse_sd": 55, "ess_bulk": 55, "ess_tail": 55, "r_hat": 55, "521": 55, "398": [55, 75], "769": 55, "266": 55, "014": [55, 75], "010": 55, "797": 55, "679": 55, "706": 55, "056": 55, "040": [55, 75], "763": 55, "709": 55, "060": 55, "006": [55, 60, 75], "049": 55, "070": 55, "654": 55, "038": [55, 75], "576": 55, "001": [55, 86], "221": 55, "142": 55, "295": 55, "samples_limited_warmup": 55, "iter_warmup": [55, 68, 69], "018": [55, 75], "876": 55, "119": [55, 66], "151": 55, "729": 55, "798": 55, "644": 55, "31633592": 55, "252": 55, "091": 55, "299": 55, "683": 55, "486": 55, "734": 55, "293": 55, "149": 55, "241": 55, "114": 55, "714": 55, "841": 55, "059": 55, "419": 55, "321": 55, "868": 55, "327": 55, "925": 55, "181": [55, 75], "661": 55, "506": [55, 72], "272": [55, 60], "395": 55, "314": 55, "866": [55, 75], "695": 55, "532": 55, "poor": [55, 56, 68, 88], "mix": [55, 56, 60, 66, 71, 88], "rejec": 55, "caveat": [55, 88], "ideal": [55, 68, 88], "ess": [55, 56, 60, 66, 68, 84, 88], "eff": 55, "prescript": [55, 69], "4000": [55, 56, 58, 60, 63, 66, 68, 69, 71, 72, 74, 75, 88], "500": [55, 75, 82, 88], "ess_mean": 55, "ess_sd": 55, "land": [55, 86], "mcse": 55, "msce_mean": 55, "accur": [55, 82], "wonder": 55, "curvatur": [55, 56, 82, 84], "veer": 55, "sharpli": [55, 57, 61], "detect": 55, "regist": 55, "1000fals": 55, "improperli": 55, "3002": 55, "yike": 55, "endem": 55, "whether": [55, 68, 70, 72, 77], "explan": [55, 82, 88, 91], "sciencei": 55, "unfamiliar": 55, "recurs": 55, "en": 55, "org": [55, 86], "recursion_": 55, "computer_sci": 55, "deep": [55, 56, 86], "cap": 55, "wrong": 55, "10003": 55, "decreas": [55, 56, 69, 82, 84, 86], "ineffici": [55, 84], "1379": 55, "1378": 55, "09": [55, 92], "1377": 55, "98": 55, "1381": 55, "76": [55, 66, 75], "62": 55, "1380": 55, "1383": 55, "1382": 55, "72": [55, 60, 66, 75], "10001": 55, "379e": 55, "38e": 55, "nope": 55, "wrote": [55, 57, 77, 88], "submodul": 55, "check_all_diagnost": [55, 56, 58, 60, 63, 66, 68, 69, 71, 72, 74, 88], "satur": [55, 56, 58, 60, 63, 66, 68, 69, 71, 72, 74, 88], "behavior": [55, 56, 58, 60, 63, 66, 68, 69, 71, 72, 74, 88], "forthcom": 56, "hack": 56, "probabilti": 56, "thoma": 56, "wiecki": 56, "microinject": 56, "tip": [56, 77], "radford": 56, "neal": 56, "girolami": 56, "450": [56, 66, 69, 82], "66c2a5": 56, "indep": 56, "bottom_left": 56, "short": [56, 71, 86], "2509935801914": 56, "17582178946987": 56, "061082354895177": 56, "103015323352217": 56, "483": 56, "075": 56, "tree": [56, 58, 60, 63, 66, 68, 69, 71, 72, 74, 88], "bfmi": [56, 58, 60, 63, 66, 68, 69, 71, 72, 74, 84, 88], "trust": 56, "hide": [56, 66], "fc8d62": 56, "click_polici": [56, 66], "penetr": 56, "correctli": 56, "awar": [56, 68], "clue": 56, "stuck": [56, 88], "log10": 56, "divergence_kwarg": 56, "advic": [56, 75], "messag": [56, 75, 77], "crank": 56, "8da0cb": 56, "335": 56, "8697624482687": 56, "188": [56, 75], "9130440674577": 56, "123": 56, "79148039281294": 56, "109": 56, "7300569471941": 56, "0225440084677622": 56, "028248959476883": 56, "825": 56, "5103845064002706": 56, "3791047493010087": 56, "6261488838631215": 56, "28202314605045126": 56, "shy": [56, 60], "tild": [56, 57, 60, 66, 67, 70, 72], "uncent": [56, 66, 67, 69, 70, 71, 72, 74, 92], "henc": [56, 66, 82, 84, 88], "theta_tild": 56, "bother": [56, 57, 68], "funnel_noncent": 56, "excel": [56, 67, 68, 70], "No": [56, 77, 82, 84, 86, 92], "e78ac3": 56, "spent": [57, 77], "biolog": [57, 65], "theta_m": [57, 69], "g_m": 57, "f_m": 57, "eq": 57, "model_bay": 57, "f_t": [57, 60], "digest": 57, "overli": 57, "flexibl": [57, 58, 60, 67, 75], "reduct": 57, "p_i": [57, 84], "haven": 57, "pope": 57, "cathol": 57, "improb": 57, "garner": 57, "p_ip_j": 57, "p_j": 57, "addabl": 57, "tradit": 57, "ensembl": 57, "surpris": [57, 72, 88], "shannon": [57, 75], "thermodynam": 57, "delv": 57, "although": [57, 82, 84, 88], "rich": [57, 86], "knew": 57, "unbias": 57, "shortcut": 57, "1948": 57, "claud": [57, 77], "desiderata": 57, "composit": 57, "law": [57, 69], "extend": [57, 77, 84], "cross": [57, 60, 88], "q_i": [57, 75, 82, 84], "govern": [57, 65, 66, 88], "induc": [57, 84], "kl": [57, 75], "d_": [57, 75], "sum_ip_i": 57, "f_": 57, "m_a": 57, "m_b": 57, "awkward": 57, "_i": [57, 60, 67, 69, 71, 72], "assumpt": [57, 60, 65], "nf_m": 57, "elppd": 57, "lpd": 57, "lppd": 57, "_j": [57, 60, 69], "_t": 57, "overestim": [57, 67, 75], "discrep": [57, 67], "p_": [57, 60], "gabri": [57, 60], "arxiv": [57, 60, 82], "therein": 57, "incred": 57, "histor": [57, 60], "held": 57, "remain": [57, 70, 75, 77], "y_": 57, "pleasant": 57, "expens": [57, 67, 75], "pacakg": 57, "criteria": [57, 58, 60, 84], "m_i": 57, "m_j": 57, "w_i": [57, 60], "plai": 57, "immens": [57, 86], "invis": 57, "log_lik": [58, 60, 88], "normal_lpdf": [58, 88], "sm_indep": 58, "indep_s": 58, "sm_con": 58, "cons_tubulin": 58, "samples_indep": 58, "samples_con": 58, "ic": [58, 60], "devianc": [58, 60, 69], "elpd_loo": [58, 60], "p_loo": [58, 60], "elpd_diff": [58, 60], "se": [58, 60, 69, 70, 71, 72, 74, 84], "dse": [58, 60], "3662": 58, "643494": 58, "260725": 58, "000000": [58, 60], "354190": 58, "00000": 58, "4003": 58, "001053": 58, "950445": 58, "340": 58, "357559": 58, "379594": 58, "52863": 58, "elpd": 60, "kullback": [60, 75], "leibler": [60, 75], "watanab": 60, "akaik": 60, "criterion": 60, "terribli": 60, "prospect": 60, "straightforward": [60, 61, 66], "easiest": [60, 66, 70], "scientist": [60, 77], "aim": [60, 69, 84], "yao": 60, "pure": [60, 69, 71], "academ": 60, "spectacularli": 60, "neg_binomial_rng": [60, 68, 86], "neg_binom": 60, "doesn": [60, 84, 88], "n_ppc_dim_0": [60, 68], "9mb": 60, "log_lik_dim_0": 60, "2kb": 60, "274": 60, "275": 60, "276": 60, "277": 60, "278": 60, "24t05": 60, "208975": 60, "1000log_lik_dim_0": 60, "279coordin": 60, "278arrai": 60, "871": 60, "571": 60, "006arrai": 60, "9195": 60, "87102": 60, "68695": 60, "26063": 60, "48547": 60, "87587": 60, "86585": 60, "88487": 60, "24419": 60, "48612": 60, "91271": 60, "66727": 60, "93771": 60, "63568": 60, "34274": 60, "58902": 60, "79424": 60, "68369": 60, "92896": 60, "68832": 60, "29315": 60, "55258": 60, "86131": 60, "83427": 60, "8913": 60, "70419": 60, "25863": 60, "50083": 60, "89138": 60, "72091": 60, "92151": 60, "6401": 60, "32705": 60, "56721": 60, "8041": 60, "69304": 60, "9281": 60, "75358": 60, "24444": 60, "5209": 60, "94195": 60, "63444": 60, "94668": 60, "80166": 60, "22269": 60, "52082": 60, "99609": 60, "90389": 60, "8773": 60, "59252": 60, "33818": 60, "53827": 60, "75795": 60, "83866": 60, "892": 60, "73364": 60, "23837": 60, "48808": 60, "92752": 60, "44289": 60, "99838": 60, "74154": 60, "30305": 60, "61111": 60, "90777": 60, "69926": 60, "9251": 60, "67632": 60, "29999": 60, "55376": 60, "84761": 60, "72413": 60, "91933": 60, "65612": 60, "3123": 60, "5567": 60, "82437": 60, "47554": 60, "99033": 60, "81682": 60, "24099": 60, "56584": 60, "0027": 60, "65642": 60, "93676": 60, "68018": 60, "30494": 60, "56586": 60, "84914": 60, "7639": 60, "90806": 60, "69262": 60, "2766": 60, "52578": 60, "87242": 60, "91387": 60, "87357": 60, "60488": 60, "32544": 60, "52772": 60, "77417": 60, "45548": 60, "99638": 60, "82115": 60, "2423": 60, "57115": 60, "00638": 60, "log_lik_dim_0pandasindexpandasindex": 60, "269": 60, "270": 60, "273": 60, "tradition": 60, "deviance_wa": 60, "3281": 60, "p_waic": 60, "single_loo": 60, "deviance_loo": 60, "pct": 60, "wider": 60, "_logpmf": 60, "uniform_rng": 60, "sm_mix": 60, "neg_binom_mix": 60, "samples_mix": 60, "004040383981042": 60, "318": 60, "7069921736581": 60, "836302265033044": 60, "2393686900295": 60, "432640073574931": 60, "126": 60, "12692598049735": 60, "210628341260978": 60, "183": [60, 75], "7239430399982": 60, "432641423716465": 60, "12692598048358": 60, "210629331032064": 60, "72394304000517": 60, "1460975400222795": 60, "170": [60, 75], "8943375375399": 60, "3240338139575638": 60, "3286803456589167": 60, "6654700530731357": 60, "72055885067414": 60, "665470122994841": 60, "7205589366050218": 60, "7356984105623074": 60, "oof": [60, 68, 72, 75], "2774578420000005": 60, "23979613": 60, "64700481": 60, "16986432480000002": 60, "nicer": 60, "3191": 60, "mix_loo": 60, "88": 60, "89": 60, "33459299576725": 60, "d_loo": 60, "w_singl": 60, "w_mix": 60, "99245113565338e": 60, "agreement": 60, "884444": 60, "778852": 60, "983497": 60, "718306": 60, "219037": 60, "927518": 60, "334593": 60, "016503": 60, "315398": 60, "565504": 60, "hyperprior": [61, 63, 65, 66, 69, 74], "theta_k": [61, 65, 69, 70, 71, 74], "permut": 61, "worm": [61, 62, 63, 65], "revers": [61, 62, 63, 86], "permuat": 61, "nuanc": 61, "advanc": 61, "recov": [61, 67, 84], "nonhierarch": 61, "concentr": [61, 67, 69, 82, 84], "kappa": [61, 63], "hyperparamet": [62, 63, 65, 66, 69, 71, 72, 73, 75], "portion": [62, 72, 77, 82, 84], "d3": 63, "2016": [63, 65], "synthet": [63, 72], "110": 63, "660": 63, "pool": [63, 66, 75], "worm_hier": 63, "adapt_delta": [63, 66, 69, 72, 75, 82, 84], "2000": [63, 68, 75], "global": [63, 65, 75, 86], "diamond": [63, 88], "650": 63, "theta_dim_0": 63, "\u03b2": [63, 88], "theta_map": 63, "bottom_right": [63, 66, 88], "significantli": [63, 75, 86], "240": 63, "292": 63, "exposur": 65, "channelrhodopsin": 65, "neuron": 65, "ash": 65, "sensori": 65, "1x": 65, "disfavor": 65, "n_1": 65, "n_2": 65, "indirectli": 65, "compris": 65, "dig": 66, "mondai": [66, 75, 77, 92], "batch": [66, 75, 86], "plate": 66, "coloni": [66, 75, 88], "mount": 66, "slide": [66, 76], "microscopi": [66, 85, 88], "wednesdai": [66, 75, 77, 92], "thursdai": [66, 75, 77, 92], "diagram": 66, "phantom": 66, "theta_3": [66, 75], "condition": 66, "j_1": [66, 75], "j_2": [66, 75], "j_k": 66, "j_3": [66, 75], "straight": 66, "clariti": 66, "index_1": [66, 75], "index_2": [66, 75], "index_3": [66, 75], "fabric": [66, 77], "weird": [66, 86], "compact": 66, "data_str": [66, 75], "41": [66, 75], "74": [66, 75], "nw": [66, 75], "42": [66, 75], "nr": [66, 75], "stringio": [66, 75], "daybatchcolonyystri64i64f64": 66, "1111": 66, "1110": 66, "1112": 66, "metadata": 66, "cat": [66, 68, 72, 75, 88], "color_column": [66, 68, 75], "marker_kwarg": [66, 68, 72, 75], "adher": 66, "categor": [66, 68, 88], "df_to_datadict_hi": [66, 75], "convei": 66, "level_col": [66, 75], "data_col": [66, 75], "hellip": [66, 75], "129": [66, 75], "1210": 66, "1310": 66, "1412": 66, "sm_center": 66, "samples_cent": 66, "hopefulli": [66, 68, 75, 84], "dianost": 66, "120": 66, "6206946627826": 66, "193": [66, 75], "46855809117585": 66, "0181667967555237": 66, "0104461055496787": 66, "17398128059170156": 66, "09851564271989993": 66, "12373822952024313": 66, "07573497349280298": 66, "whew": 66, "strikingli": [66, 68], "theta_1_dim_0": 66, "theta_2_dim_0": 66, "theta_3_dim_0": 66, "allevi": 66, "_1": [66, 69, 70, 71], "_2": [66, 70, 71], "_3": 66, "theta_1_tild": 66, "theta_2_tild": 66, "theta_3_tild": 66, "sm_noncent": 66, "samples_noncent": 66, "gone": 66, "y_axis_typ": [66, 68, 71], "articl": 67, "unsatisfi": [67, 88], "flow": [67, 85], "reliabl": [67, 68], "ground": [67, 68], "truth": [67, 68], "talt": 67, "umbrella": 67, "sensit": [67, 68], "abus": [67, 69, 82], "forgiv": 67, "ant": [67, 88], "experimentum": 67, "hundr": 67, "uncertainti": [67, 69], "z_i": 67, "rangle_": 67, "sign": [67, 82], "overfit": [67, 68], "s_i": 67, "drift": [67, 84], "permit": 67, "addition": [67, 77], "coverag": [67, 68], "surround": 67, "diagnosi": 67, "empir": [68, 84], "justif": 68, "prior_pr": [68, 86], "choke": 68, "samples_prior_pr": [68, 86], "range1d": 68, "3e5": 68, "nanmax": 68, "poissonian": 68, "dispers": 68, "upward": 68, "mammalian": 68, "ingredi": 68, "requisit": [68, 77], "df_sbc": [68, 86], "prior_predictive_model": [68, 86], "posterior_model": [68, 86], "prior_predictive_model_data": [68, 86], "posterior_model_data": [68, 86], "measured_data": [68, 86], "measured_data_dtyp": [68, 86], "progress_bar": [68, 86], "07it": 68, "ground_truthrank_statisticmeansdshrinkagez_scorerhatessess_per_itertail_esstail_ess_per_itern_divergencesn_bad_ebfmin_max_treedepthwarning_codeltrialerrorparameterf64i64f64f64f64f64f64f64f64f64f64i64i64i64i64i64i64strstr0": 68, "002862101": 68, "0053340": 68, "0052541": 68, "0190": 68, "8112971": 68, "0023851662": 68, "3330420": 68, "4155831245": 68, "9198970": 68, "31148000040000": 68, "592778483": 68, "8443910": 68, "3097990": 68, "9999590": 68, "8122061": 68, "004025732": 68, "4173080": 68, "183104694": 68, "8219580": 68, "173705000040001": 68, "2772539031": 68, "1166130": 68, "0717330": 68, "999998": 68, "2393821": 68, "004734780": 68, "7275920": 68, "1951821050": 68, "450650": 68, "262613200440002": 68, "62861396101": 68, "20665711": 68, "1994990": 68, "9459420": 68, "4087731": 68, "005957512": 68, "1181450": 68, "12803548": 68, "8116860": 68, "137203000040003": 68, "91851601": 68, "0684490": 68, "0510140": 68, "9999992": 68, "9390361": 68, "001264807": 68, "4313030": 68, "201858936": 68, "5215790": 68, "23413100440004": 68, "warning_cod": 68, "succinct": 68, "pars": [68, 69, 91], "parse_warning_cod": 68, "treedepth": 68, "tooltip": 68, "sub_df": 68, "1f77b4": 68, "group_bi": 68, "z_score": 68, "evidenc": 68, "good_z": 68, "ground_truth": 68, "jitter": [68, 72], "creat": [68, 71, 86], "expos": 68, "abort": 68, "signal": [68, 85, 88], "002": [68, 86], "5000": 68, "problemat": [68, 84], "sm_prior_pred_2": [68, 86], "prior_pred_2": 68, "1e6": 68, "sm_2": [68, 86], "model_2": 68, "posterior_predictive_var_nam": [68, 86], "48it": 68, "warning_codeleni64u32087721073818": 68, "sampling_kwarg": [68, 86], "93it": 68, "warning_codeleni64u32210999": 68, "decent": 68, "sbc_rank_ecdf": 68, "hadn": 69, "untest": 69, "amplitud": [69, 70, 72], "methylglucopyranosid": 69, "hydrolysi": 69, "cellulos": 69, "wolfenden": [69, 70, 72, 74], "snider": [69, 70, 74], "enzym": 69, "catalyst": 69, "glucosid": 69, "temperatur": [69, 70, 72, 74], "wolfenden_arrheniu": [69, 70, 72, 74], "chemic": [69, 72, 74], "arrheniu": 69, "e_a": 69, "k_bt": 69, "k_b": 69, "t_i": [69, 71, 72, 88], "k_i": 69, "fun": 69, "t_ppc": [69, 88], "log10_ea": 69, "log10_a": 69, "ea": 69, "k_ppc": [69, 70, 74], "uncatalyz": 69, "reaction": 69, "530": 69, "sm_parametr": 69, "max_treedepth": [69, 72], "16000": 69, "k_ppc_dim_0": 69, "sec": 69, "meaning": 69, "kinet": [69, 72], "capit": 69, "epsilon_i": 69, "primarili": 69, "_n": 69, "latent": [69, 74, 75, 88], "semi": 69, "hugo": 69, "bown": 69, "anderson": 69, "arithmet": 69, "certain": [69, 82, 86], "k_": [69, 71, 72], "gram": 69, "sigma_b": 69, "polynomi": 69, "sigma_p": 69, "vert": 69, "vert_2": 69, "mat\u00e9rn": 69, "sin": [69, 72], "modifi": [69, 71, 75, 82, 84, 86], "bessel": [69, 71], "quadrat": 69, "radial": 69, "spirit": 69, "realiz": 69, "rough": [69, 71], "farther": [69, 82], "apart": 69, "unrel": 69, "tunabl": 69, "multinorm": [69, 70, 71, 72, 74, 75], "nstar": [69, 70, 71, 72, 74], "xstar": [69, 70, 71, 72, 74], "gp_exp_quad_cov": [69, 70, 71, 72, 74], "diag_matrix": [69, 70, 71, 72, 74], "rep_vector": [69, 70, 71, 72, 74], "choleski": [69, 70, 72, 74], "decomposit": [69, 70, 72, 74], "cholesky_decompos": [69, 70, 71, 72, 74], "multi_normal_cholesky_rng": [69, 71, 74], "gp_cov_exp_quad": 69, "stabil": [69, 88], "sm_prior": 69, "gp_prior_fixed_rho_alpha": 69, "\u03c1": [69, 70, 71], "rougher": [69, 71], "cov_matern": [69, 71], "rg": 69, "spaghetti": 69, "cov_exp_quad": [69, 70, 71, 74], "multi_lin": 69, "mult_kern": 69, "x1": 69, "x2": 69, "rho_s": 69, "rho_per": 69, "periodic_kernel": 69, "se_kernel": 69, "cov_from_kernel": 69, "add_kern": 69, "linear_kernel": 69, "c_1": 69, "c_2": 69, "iptg": 69, "poi": 69, "c_i": 69, "heteroscedast": 69, "delta_": [69, 71], "lll": 69, "diag": [69, 70, 71], "unmeasur": 69, "5em": [69, 84], "triangular": 69, "stabli": 69, "shade": 69, "k_scale": [69, 70, 72, 74], "t_scale": [69, 70, 71, 72, 74], "t_rang": [69, 70, 72, 74], "manipul": [69, 74, 75, 86], "posterior_mean_cov": [69, 70, 71], "mstar": [69, 70, 71, 74], "sigmastar": [69, 70, 71, 74], "unscal": [69, 70, 71, 72, 74], "tstar": [69, 70, 71, 72, 74], "kstar": [69, 70, 71, 74], "show_lin": [69, 70, 71], "exent": 69, "muster": 69, "dampen": 69, "favor": [69, 71, 88], "flatter": 69, "simplif": 69, "gp": [70, 73], "stipul": 70, "wiggli": 70, "outlier": 70, "contort": 70, "invgamma": [70, 71, 72, 74], "singular": [70, 71, 84, 86], "diag_to_add": [70, 71], "ky": [70, 71, 74], "4f": [70, 71], "5887": 70, "5791": 70, "0886": 70, "miniconda3": [70, 71, 86], "env": [70, 71], "bebi103_build": [70, 71], "lib": [70, 71, 86], "python3": [70, 71, 86], "_optim": [70, 71], "py": [70, 71, 82, 86], "2472": [70, 71], "runtimewarn": [70, 71, 82], "tmp2": [70, 71], "fx": [70, 71], "fw": [70, 71], "nonparametr": [70, 71, 72, 74], "draw_gp_ppc": 70, "y_mean": 70, "y_std": 70, "nonparameter": 70, "inv_gamma": [70, 71, 72, 74], "multi_normal_choleski": [70, 71, 74], "gp_kinetics_no_ppc": [70, 74], "optimized_params_dict": 70, "ordereddict": 70, "lp__": [70, 75], "79106": 70, "40338": 70, "25657": 70, "0893158": 70, "optimized_params_pd": 70, "od": [71, 84], "remark": 71, "peter": 71, "swain": 71, "tom": [71, 82, 84], "r\u00f6schinger": [71, 82], "wild": 71, "roeschinger_growth_rate_data": 71, "tetracycline_conc_\u00b5g_per_ml": 71, "mg1655": 71, "a01": 71, "time_min": 71, "od600": 71, "hr": 71, "extrapol": 71, "od600_scal": 71, "solak": 71, "ourselv": 71, "2_x": 71, "z_j": 71, "partial_1": 71, "partial_2": 71, "pertin": 71, "matern": 71, "1420": 71, "5917": 71, "0118": 71, "augment": 71, "posterior_mean_cov_deriv": 71, "exp_quad_kernel": 71, "gstar": 71, "sigma_g_star": 71, "od600star": 71, "deriv_high": 71, "deriv_low": 71, "deriv_star": 71, "dt": [71, 82], "2_z": 71, "mu_z": 71, "mu_x": 71, "2_y": 71, "shortli": 71, "growth_rat": 71, "sigma_growth_r": 71, "gr_high": 71, "gr_low": 71, "redefin": 71, "matern_kernel": 71, "wiggl": 71, "gp_one_dimension": [71, 74], "stanfunct": 71, "fstar": [71, 72, 74], "dfstar": 71, "y_ppc": [71, 72, 74], "kstarstar": [71, 74], "d1_kstar": 71, "d1_cov_exp_quad": 71, "d1_d2_kstarstar": 71, "d1_d2_cov_exp_quad": 71, "gp_posterior_mstar": [71, 74], "lstar": [71, 74], "gp_posterior_sigmastar_choleski": [71, 74], "sigmag": 71, "l_g_star": 71, "gp_growth_curv": 71, "stanc_opt": [71, 74], "include_path": [71, 74], "y_ppc_dim_0": [71, 74], "od600_ppc": 71, "dfstar_scal": 71, "dfstar_dim_0": 71, "fstar_scal": [71, 72, 74], "fstar_dim_0": [71, 74], "experienc": 71, "unmargin": 72, "f_i": 72, "layer": 72, "hyperparamat": 72, "preprocess": 72, "xstar_ind": 72, "f_tild": 72, "append_sort_index": 72, "index_origin": 72, "duplic": 72, "indici": 72, "73988004": 72, "67222743": 72, "60457482": 72, "58919923": 72, "53692222": 72, "46926961": 72, "401617": 72, "3339644": 72, "26631179": 72, "22693001": 72, "19865918": 72, "13100658": 72, "06335397": 72, "99570136": 72, "96124699": 72, "92804876": 72, "86039615": 72, "79274354": 72, "72509093": 72, "65743833": 72, "58978572": 72, "52324311": 72, "52213311": 72, "45448051": 72, "3868279": 72, "31917529": 72, "25152269": 72, "18459205": 72, "18387008": 72, "11621747": 72, "04856487": 72, "01908774": 72, "08674035": 72, "15439295": 72, "22204556": 72, "28969817": 72, "35735077": 72, "42500338": 72, "49265599": 72, "50367757": 72, "56030859": 72, "6279612": 72, "69561381": 72, "76326641": 72, "81156517": 72, "83091902": 72, "89857163": 72, "96622423": 72, "03387684": 72, "10152945": 72, "16918205": 72, "23683466": 72, "2418742": 72, "30448727": 72, "37213987": 72, "42441689": 72, "43979248": 72, "50744509": 72, "57509769": 72, "56": [72, 86], "526": 72, "97268063": 72, "522": 72, "8398459": 72, "513": 72, "09748852": 72, "12679808": 72, "490": 72, "5441167": 72, "482": 72, "87692992": 72, "472": [72, 75], "96035845": 72, "466": 72, "94519538": 72, "458": 72, "74328484": 72, "leapfrog": [72, 75, 84], "gp_kinetics_no_marg": 72, "dial": 72, "475": 72, "f_dim_0": 72, "data_kwarg": [72, 74], "1f78b4": [72, 74], "contriv": [72, 75], "scenario": [72, 86, 88], "a_0": 72, "varying_funct": 72, "a0": 72, "a1": 72, "\u03bb": 72, "time_point": 72, "n_cell": 72, "astyp": 72, "plop": 72, "fram": 72, "q_axi": 72, "600": [72, 75], "t_ind": 72, "log_f_tild": 72, "log_f": 72, "poisson_log": 72, "poisson_log_rng": 72, "gp_transcript_count": 72, "184": [72, 75], "3782": 72, "log_fstar": 72, "log_f_dim_0": 72, "mdivide_left_tri_low": 74, "mdivide_right_tri_low": 74, "sigma_star": 74, "po": 74, "emploi": [74, 75, 85, 88], "wherev": 74, "encas": 74, "suffix": 74, "stan_includ": 74, "comma": 74, "gp_kinet": 74, "pathto": 74, "force_compil": 74, "k_ppc_scale": 74, "heidi": [75, 85], "klump": [75, 85], "selector": 75, "adopt": 75, "interchang": 75, "blei": 75, "dissimilar": 75, "leiber": 75, "resembl": [75, 82, 84], "poorli": 75, "prod_i": 75, "phi_i": 75, "partit": [75, 84], "neq": 75, "q_j": 75, "hurdl": 75, "q_": 75, "randon": 75, "advi": 75, "alp": 75, "kucukelbir": 75, "zeta": 75, "zeta_i": 75, "meanfield": 75, "optimum": 75, "samples_vi": 75, "pertain": 75, "stdout_fil": 75, "runset": 75, "_stdout_fil": 75, "10000": 75, "grad_sampl": 75, "elbo_sampl": 75, "tol_rel_obj": 75, "eval_elbo": 75, "output_sampl": 75, "tmpcshdblkp": 75, "01ufoem2": 75, "json": 75, "spindlezaxcnbxg": 75, "20240727161414": 75, "diagnostic_fil": 75, "sig_fig": 75, "profile_fil": 75, "save_cmdstan_config": 75, "num_thread": 75, "unstabl": 75, "buggi": 75, "gradient": [75, 82, 84], "000392": 75, "ascent": 75, "delta_elbo_mean": 75, "delta_elbo_m": 75, "6093": 75, "3580": 75, "851": 75, "3473": 75, "163": 75, "578": 75, "702": 75, "3406": 75, "187": 75, "438": 75, "3310": 75, "589": 75, "356": 75, "031": 75, "3197": 75, "393": 75, "303": 75, "035": 75, "700": 75, "3119": 75, "716": 75, "263": 75, "800": 75, "3118": 75, "230": 75, "900": 75, "3055": 75, "396": 75, "207": 75, "029": 75, "3007": 75, "033": 75, "1100": 75, "2958": 75, "594": 75, "090": 75, "1200": 75, "2882": 75, "045": 75, "022": 75, "1300": 75, "2825": 75, "021": 75, "1400": 75, "2755": 75, "1500": 75, "2656": 75, "2549": 75, "177": 75, "023": 75, "1700": 75, "2429": 75, "026": 75, "1800": 75, "2310": 75, "505": 75, "027": 75, "1900": 75, "2205": 75, "968": 75, "037": 75, "2103": 75, "036": 75, "042": 75, "2100": 75, "2027": 75, "055": 75, "039": 75, "2200": 75, "1952": 75, "219": 75, "2300": 75, "1908": 75, "2400": 75, "1881": 75, "840": [75, 86], "2500": 75, "1870": 75, "947": 75, "2600": 75, "1869": 75, "602": 75, "032": 75, "2700": 75, "1859": 75, "828": 75, "2800": 75, "1852": 75, "081": 75, "2900": 75, "1855": 75, "085": 75, "3000": [75, 88], "1848": 75, "013": 75, "variational_sample_pd": 75, "df_vi": 75, "1_546": 75, "lp__log_p__log_g__phigamma_sigma_0mu": 75, "164": 75, "165": 75, "166": 75, "167": 75, "168": 75, "169": 75, "171": 75, "173": 75, "174": 75, "175": 75, "178": 75, "180": 75, "182": 75, "185": 75, "186": [75, 88], "189": 75, "192": 75, "194": 75, "195": 75, "197": 75, "198": 75, "199": 75, "f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64": 75, "f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f640": 75, "1835": 75, "33121238": 75, "2270": 75, "8426290": 75, "11378121": 75, "410822": 75, "116822": 75, "863123": 75, "818223": 75, "818224": 75, "107224": 75, "221524": 75, "391524": 75, "5625": 75, "109525": 75, "217225": 75, "377425": 75, "483325": 75, "640725": 75, "796425": 75, "899425": 75, "899426": 75, "052426": 75, "153526": 75, "303726": 75, "40326": 75, "403": 75, "248343": 75, "154236": 75, "822544": 75, "668738": 75, "665544": 75, "02741": 75, "527232": 75, "699924": 75, "670637": 75, "833836": 75, "934941": 75, "205144": 75, "229931": 75, "700542": 75, "786742": 75, "284843": 75, "183633": 75, "922841": 75, "924440": 75, "99631": 75, "870935": 75, "84937": 75, "39738": 75, "296335": 75, "662538": 75, "725243": 75, "700342": 75, "188434": 75, "516936": 75, "389942": 75, "901239": 75, "483443": 75, "509634": 75, "06443": 75, "242134": 75, "12140": 75, "64320": 75, "1840": 75, "78530839": 75, "15010": 75, "8652280": 75, "11209321": 75, "974922": 75, "698523": 75, "463224": 75, "441524": 75, "737524": 75, "854625": 75, "028725": 75, "201225": 75, "763925": 75, "874125": 75, "874126": 75, "038126": 75, "146526": 75, "307626": 75, "46726": 75, "572426": 75, "72926": 75, "832426": 75, "986227": 75, "087827": 75, "0878": 75, "852838": 75, "859240": 75, "255547": 75, "723140": 75, "816530": 75, "954534": 75, "280637": 75, "754237": 75, "441734": 75, "807737": 75, "139236": 75, "539429": 75, "180541": 75, "470439": 75, "744540": 75, "545239": 75, "189340": 75, "0141": 75, "243634": 75, "44339": 75, "726140": 75, "452141": 75, "051329": 75, "214242": 75, "083739": 75, "000348": 75, "029239": 75, "175628": 75, "694240": 75, "588942": 75, "45241": 75, "212443": 75, "891929": 75, "079348": 75, "109934": 75, "261135": 75, "85890": 75, "1858": 75, "3135140": 75, "27760": 75, "8440270": 75, "12307621": 75, "626222": 75, "358723": 75, "135824": 75, "134924": 75, "438324": 75, "558524": 75, "914925": 75, "49525": 75, "608925": 75, "778525": 75, "890726": 75, "057726": 75, "223126": 75, "332526": 75, "495326": 75, "60326": 75, "763126": 75, "86926": 75, "869": 75, "305746": 75, "086545": 75, "675337": 75, "458641": 75, "120538": 75, "046242": 75, "214834": 75, "958247": 75, "576935": 75, "842340": 75, "759945": 75, "705848": 75, "77944": 75, "312848": 75, "809835": 75, "705734": 75, "544637": 75, "255641": 75, "519542": 75, "743345": 75, "759829": 75, "798840": 75, "612251": 75, "127443": 75, "244447": 75, "42946": 75, "350742": 75, "102934": 75, "758235": 75, "285637": 75, "087235": 75, "45129": 75, "324637": 75, "891744": 75, "517646": 75, "607338": 75, "60070": 75, "57": 75, "2506237": 75, "61070": 75, "8235380": 75, "12039920": 75, "9521": 75, "643522": 75, "376723": 75, "315823": 75, "600123": 75, "712623": 75, "879923": 75, "879924": 75, "045724": 75, "586724": 75, "692824": 75, "850524": 75, "954825": 75, "109825": 75, "263325": 75, "364725": 75, "515525": 75, "615225": 75, "763325": 75, "861125": 75, "8611": 75, "700133": 75, "765741": 75, "01630": 75, "692931": 75, "122833": 75, "522642": 75, "145236": 75, "1543": 75, "160140": 75, "126942": 75, "508540": 75, "00243": 75, "993937": 75, "575338": 75, "000436": 75, "304840": 75, "071936": 75, "101739": 75, "003932": 75, "224645": 75, "635435": 75, "53938": 75, "868137": 75, "839935": 75, "145742": 75, "555744": 75, "950539": 75, "690740": 75, "796237": 75, "734439": 75, "588133": 75, "151932": 75, "761429": 75, "640840": 75, "012242": 75, "179343": 75, "35860": 75, "1837": 75, "70917538": 75, "33510": 75, "8371120": 75, "11236821": 75, "305322": 75, "011622": 75, "758623": 75, "715523": 75, "715524": 75, "005224": 75, "119824": 75, "290424": 75, "459425": 75, "01125": 75, "119125": 75, "279925": 75, "386325": 75, "544425": 75, "700925": 75, "804325": 75, "958125": 75, "958126": 75, "059826": 75, "210826": 75, "310726": 75, "3107": 75, "389538": 75, "487935": 75, "552138": 75, "478339": 75, "257242": 75, "376948": 75, "535439": 75, "861436": 75, "31238": 75, "527838": 75, "715338": 75, "726839": 75, "719838": 75, "526837": 75, "728746": 75, "05735": 75, "144146": 75, "713130": 75, "492937": 75, "246445": 75, "322936": 75, "658942": 75, "086337": 75, "391944": 75, "149438": 75, "827439": 75, "504842": 75, "60740": 75, "123337": 75, "005437": 75, "151228": 75, "840532": 75, "462543": 75, "715541": 75, "509742": 75, "00435": 75, "4243": 75, "legaci": 75, "log_p__": 75, "log_g__": 75, "variational_params_pd": 75, "4521": 75, "853254": 75, "116228": 75, "6552": 75, "3666": 75, "1182": 75, "0794": 75, "4477": 75, "673": 75, "7122": 75, "1776": 75, "381": 75, "9442": 75, "6642": 75, "46": 75, "0142": 75, "2081": 75, "4419": 75, "1546": 75, "plot_marginal_ecdf": 75, "p_phi": 75, "p_gamma": 75, "fullrank": 75, "3251": 75, "88812": 75, "noncent": [75, 84], "hier_lognorm": 75, "32520": 75, "require_converg": 75, "tendenc": 75, "underestim": 75, "p_theta": 75, "p_sigma": 75, "p_tau": 75, "gridplot": [75, 88], "ncol": [75, 88], "custom": 75, "ranganath": 75, "morn": 77, "noon": [77, 92], "attend": 77, "recit": [77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 92], "offic": [77, 92], "tuesdai": [77, 92], "dilig": 77, "golden": 77, "opportun": 77, "submit": [77, 86, 92], "schedul": [77, 86], "skill": 77, "_lastname_firstnam": 77, "pacif": 77, "sundai": 77, "perfectli": 77, "aspect": 77, "fridai": 77, "hw": 77, "restart": 77, "runnabl": 77, "submitt": 77, "credit": [77, 82], "name_of_datafil": 77, "embed": 77, "mathjax": 77, "latex": 77, "inversegamma": 77, "justifi": 77, "guidelin": 77, "adjac": [77, 84], "explanatori": 77, "markdown": 77, "header": 77, "delin": 77, "late": 77, "six": 77, "grace": 77, "penalti": 77, "saturdai": 77, "ill": 77, "health": 77, "cass": 77, "accommod": 77, "coursework": 77, "exam": 77, "announc": 77, "offici": 77, "passag": 77, "receiv": [77, 82, 86], "nullifi": 77, "violat": 77, "publicli": 77, "unpublish": 77, "institut": 77, "faith": 77, "imper": 77, "dissemin": 77, "classmat": 77, "whom": 77, "consult": 77, "websit": 77, "materi": [77, 78, 87, 88, 89], "cite": 77, "llm": 77, "chatgpt": 77, "gpt": 77, "llama": 77, "gemini": 77, "cursor": 77, "copilot": 77, "ai": 77, "engin": [77, 91], "deni": 77, "contrari": 77, "basal": 77, "compet": 77, "reiter": 77, "chatbot": 77, "privat": 77, "email": [77, 86], "shot": 77, "anonym": 77, "spur": 77, "dialog": [78, 89], "factori": 82, "curdoc": 82, "ticker": 82, "fixedtick": 82, "holoview": 82, "hv": 82, "pallete1": 82, "9faeb2": 82, "ab6e7d": 82, "1c2630": 82, "autohid": 82, "text_font": 82, "helvetica": 82, "text_font_s": 82, "16px": 82, "xaxi": 82, "axis_label_text_font": 82, "yaxi": 82, "axis_label_text_font_s": 82, "13px": 82, "axis_label_text_font_styl": 82, "background_fill_alpha": 82, "toolbar": 82, "anyon": 82, "background": [82, 85, 86], "break": [82, 86], "subset": 82, "bob": 82, "carpent": 82, "weigh": 82, "coeffici": 82, "375": 82, "326": 82, "420": 82, "binomial_coeff": 82, "prob": 82, "patch": 82, "eaeaea": 82, "degeneraci": 82, "999999": 82, "1000000": 82, "imbal": 82, "classic": [82, 84, 88], "quantum": 82, "harmon": 82, "oscil": [82, 84], "attach": [82, 85], "spring": 82, "act": 82, "kx": 82, "movement": 82, "mv": 82, "2m": 82, "momentum": [82, 84], "fiat": 82, "brick": 82, "wall": 82, "wreck": 82, "train": 82, "stand": 82, "consum": [82, 86], "ellipsoid": 82, "simple_oscil": 82, "bupu": 82, "x_arr": 82, "p_plu": 82, "p_minu": 82, "add_layout": 82, "major_label_text_font_s": 82, "0pt": 82, "evolut": 82, "hamilton": [82, 84], "motion": [82, 84], "qquad": 82, "angl": 82, "mag": 82, "arctan2": 82, "vectorfield": 82, "cmap": 82, "viridi": 82, "xlabel": 82, "ylabel": 82, "interrupt": 82, "therm": 82, "preprint": 82, "1701": 82, "02434": 82, "momenta": 82, "scatter1": 82, "scatter2": 82, "arrow1": 82, "arrow1_1": 82, "arrow1_2": 82, "arrow2": 82, "arrow2_1": 82, "arrow2_2": 82, "partial_h": 82, "xlim": 82, "ylim": 82, "show_grid": 82, "distinct": 82, "h1": 82, "h2": 82, "h3": 82, "x_arr1": 82, "x_arr2": 82, "x_arr3": 82, "p_plus1": 82, "p_minus1": 82, "p_plus2": 82, "p_minus2": 82, "p_plus3": 82, "p_minus3": 82, "scatter12": 82, "79": 82, "scatter22": 82, "arrow12": 82, "arrow1_12": 82, "arrow1_22": 82, "arrow22": 82, "arrow2_12": 82, "arrow2_22": 82, "partial_h2": 82, "l3": 82, "n6j3jk1n1p94lc552kcbzq280000gn": 82, "ipykernel_5666": 82, "985606356": 82, "prime": 82, "prime_i": 82, "rotat": 82, "parameter": 82, "disrupt": 82, "regard": 82, "const": [82, 84], "lap": 82, "unexplor": 82, "backward": [82, 84], "met": 82, "euler": 82, "inaccuraci": [82, 84], "drastic": 82, "stackoverflow": 82, "33601089": 82, "n0": 82, "dn": 82, "dx_dt": 82, "liouvil": 82, "symplect": [82, 84], "detriment": 82, "shoot": 82, "bridg": 82, "rail": 82, "fought": 82, "rosita": 84, "fu": 84, "linger": 84, "r\u00f6esching": 84, "alongsid": 84, "math": [84, 86], "int_q": 84, "hspace": 84, "mathbb": 84, "entireti": 84, "ordinari": 84, "dq": 84, "1d": 84, "3d": 84, "cube": [84, 86], "denisti": 84, "predomin": 84, "sit": 84, "x_": 84, "sole": 84, "creativ": 84, "allud": 84, "determinist": [84, 88], "dictat": 84, "f_n": 84, "btw": 84, "habit": 84, "hover": 84, "overcompens": 84, "usag": 84, "diffus": 84, "irredeem": 84, "incapacit": 84, "jump": [84, 88], "sluggish": 84, "increment": 84, "overal": [84, 88], "q_1": 84, "q_2": 84, "q_3": 84, "cast": 84, "hearken": 84, "metaphor": 84, "planet": 84, "gravit": 84, "orbit": 84, "satellit": 84, "crash": [84, 86], "eject": 84, "auxiliari": 84, "2xd": 84, "q_n": 84, "rightarrow": 84, "p_n": 84, "canon": 84, "nbsphinx": 84, "8em": 84, "9em": 84, "interepret": 84, "lift": [84, 88], "omega": 84, "omega_": 84, "microcanon": 84, "ring": 84, "jointli": 84, "cfrac": 84, "2em": 84, "3em": 84, "phi_t": 84, "altogeth": 84, "somehow": 84, "unlock": 84, "expon": 84, "decoupl": 84, "retriev": [84, 86], "repeatedli": 84, "project": [84, 85, 86], "swiftli": 84, "euclidean": 84, "riemannian": 84, "pi_": 84, "pi_e": 84, "e_bfmi": 84, "proven": 84, "ke": 84, "pick": 84, "convolut": 84, "distribtuion": 84, "de": 84, "distribuion": 84, "Their": 84, "smoothen": 84, "persist": [84, 88], "stronger": 84, "suspicion": 84, "distribt": 84, "termin": [84, 86], "mysteri": 84, "impress": 84, "takeawai": 84, "life": 84, "exploit": 84, "glean": 84, "face": [84, 88], "cellular": 85, "pathwai": [85, 88], "architectur": 85, "extracellular": 85, "surfac": 85, "confoc": 85, "membran": [85, 88], "autom": 85, "cytometri": 85, "fluorophor": 85, "presum": 85, "cytomet": 85, "bead": 85, "subunit": 85, "spontan": 85, "weren": 85, "multimer": [85, 88], "intracellular": [85, 88], "fusion": [85, 88], "zachari": 86, "martinez": 86, "tailor": 86, "cluster": 86, "terabyt": 86, "petabyt": 86, "facillit": 86, "acceler": 86, "node": 86, "cento": 86, "admin": 86, "grant": 86, "authent": 86, "duo": 86, "wifi": 86, "vpn": 86, "zmartin": 86, "host": 86, "refus": 86, "ondemand": 86, "studio": 86, "desktop": 86, "compos": 86, "script": 86, "alloc": 86, "queue": 86, "princeton": 86, "my_slurm_script": 86, "sbatch": 86, "walltim": 86, "ntask": 86, "processor": 86, "mem": 86, "16g": 86, "my_first_job": 86, "mail": 86, "purg": 86, "export": 86, "ld_library_path": 86, "mthomson": 86, "zam": 86, "miniconda": 86, "librari": 86, "example_env": 86, "highly_parallelized_script": 86, "my_first_job_xxxxxx": 86, "cheatsheet": 86, "flag": 86, "gre": 86, "qo": 86, "debug": 86, "prioriti": 86, "forev": 86, "cascadelak": 86, "squeue": 86, "pend": 86, "scancel": 86, "12345678": 86, "kill": [86, 88], "jobid": 86, "srun": 86, "pty": 86, "xx": 86, "lastli": 86, "programat": 86, "slurm_ntask": 86, "n_task": 86, "gui": 86, "winscp": 86, "filezilla": 86, "cyberduck": 86, "awscli": 86, "forth": 86, "remote_script": 86, "local_script": 86, "local_filenam": 86, "currect": 86, "remote_filenam": 86, "3ish": 86, "50gb": 86, "10tb": 86, "thomson": 86, "80tb": 86, "scratch": 86, "20tb": 86, "scratchio": 86, "2tb": 86, "quota": 86, "mmlsquota": 86, "auto": 86, "ticket": 86, "vscode": 86, "plugin": 86, "vim": 86, "friendli": 86, "isn": [86, 88], "geeksforgeek": 86, "realpython": 86, "superfastpython": 86, "prematur": 86, "evil": 86, "donald": 86, "knuth": 86, "multiprocess": 86, "exhaust": 86, "unexpect": 86, "silent": 86, "multithread": 86, "lock": 86, "gil": 86, "thread": 86, "cpu_count": 86, "mp": 86, "laptop": 86, "squareroot": 86, "benchmark": 86, "square_list": 86, "input_list": 86, "num": [86, 88], "squareroot_list": 86, "mylist": 86, "100_000_001": 86, "100_000_000": 86, "ran": 86, "elaps": 86, "94840407371521": 86, "ascend": 86, "overcom": 86, "__name__": 86, "__main__": 86, "p1": [86, 88], "p2": [86, 88], "p3": 86, "30126214027405": 86, "demo": 86, "10_000_001": 86, "10_000_000": 86, "8647820949554443": 86, "teardown": 86, "3583669662475586": 86, "precari": 86, "race": 86, "cube_and_revers": 86, "val": 86, "arr": 86, "125": 86, "random_word": 86, "randomword": 86, "flush": 86, "get_random_word": 86, "consumer_process": 86, "producer_process": 86, "modulenotfounderror": 86, "traceback": 86, "firstli": 86, "dramat": 86, "bebi103b": 86, "thirdli": 86, "capac": 86, "infeas": 86, "simultan": 86, "benefici": 86, "timefram": 86, "paralleliz": 86, "pd": [86, 88], "prep": [86, 88], "prior_predictive_check": 86, "stan_model_cod": 86, "example_model": 86, "_perform_sbc": 86, "_get_output_dir": 86, "samples_dir": 86, "prior_sample_cmdstanpi": 86, "posterior_samples_cmdstanpi": 86, "parallel_chain": 86, "arg_input_gener": 86, "stan_sbc": 86, "my_job": 86, "thefilenam": 86, "6g": 86, "stan_sbc_test": 86, "touch": 86, "chunk": 86, "cpp_option": 86, "stan_thread": 86, "rewritten": 86, "reduce_sum": 86, "piecewis": 86, "partial_sum_neg_binom": 86, "slice_n": 86, "mere": 86, "iceberg": 86, "taught": 86, "foot": 86, "door": 86, "luck": 86, "zach": 87, "julian": 88, "wagner": 88, "bespok": 88, "ecolog": 88, "recaptur": 88, "afterward": 88, "worst": 88, "dread": 88, "nan": 88, "datatyp": 88, "explod": 88, "ecologi": 88, "leg": 88, "band": 88, "bird": 88, "fin": 88, "shark": 88, "stradl": 88, "radioact": 88, "phosphor": 88, "32p": 88, "tissu": 88, "worker": 88, "myrmica": 88, "rubra": 88, "gari": 88, "alpert": 88, "hypergeometr": 88, "white": 88, "ball": 88, "unlabel": 88, "stickler": 88, "todai": 88, "insist": 88, "stick": 88, "negative_binomi": 88, "log_sum_exp": 88, "game": 88, "mark_recapture_hypergeometr": 88, "max_pop": 88, "min_pop": 88, "neg_binomial_2_lpmf": 88, "hypergeometric_lpmf": 88, "simplex": 88, "pstate": 88, "funni": 88, "346": 88, "sample_it": 88, "aren": 88, "distibut": 88, "0000000284678414": 88, "yai": 88, "gotten": 88, "sake": 88, "ra": 88, "a_min": 88, "a_max": 88, "mt_gamma": 88, "20000": 88, "ndiagnost": 88, "t_ppc_dim_0": 88, "alpha_": 88, "t_j": 88, "a_": 88, "hei": 88, "sm2": 88, "mt_gamma_integer_alpha": 88, "beta2": 88, "binomial_lpmf": 88, "gamma_lpdf": 88, "log_p_norm": 88, "categorical_logit_rng": 88, "round": 88, "logit": 88, "samples_discret": 88, "odd": 88, "funki": 88, "intermediari": 88, "df_sample_compar": 88, "peaki": 88, "confirm": 88, "87136123": 88, "170593759154506": 88, "76135737638342": 88, "5281784828052738": 88, "mt_gamma_integer_alpha_jb": 88, "log_alpha_prior": 88, "un": 88, "log_q": 88, "samp": 88, "log_norm_const": 88, "log_g": 88, "net": 88, "monstrou": 88, "numba": 88, "3rd": 91, "freeli": 91, "channel": 91, "video": 91, "2nd": 91, "richard": 91, "mcelreath": 91, "ben": 91, "lambert": 91, "beginn": 91, "press\u00e9": 91, "sgourali": 91, "exposit": 91, "phil": 91, "supplement": 91, "b123": 92, "kerckhoff": 92, "kerkchoff": 92, "februari": 92, "march": 92, "martin": 92, "luther": 92, "king": 92, "presid": 92}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"homework": [0, 2, 3, 5, 77, 81, 90, 92], "1": [0, 1, 2, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 22, 52, 75], "first": 0, "attempt": 0, "bayesian": [0, 19, 25, 26, 29, 35, 69, 75, 85], "gener": [0, 1, 24, 40, 41, 45, 48, 52, 62, 66, 68, 72], "model": [0, 1, 20, 25, 26, 29, 30, 31, 34, 36, 45, 47, 48, 49, 52, 53, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 68, 72, 75, 85], "70": 0, "pt": [0, 2, 3], "intuit": 1, "2": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 29, 52, 75], "overwhelm": 2, "prior": [2, 3, 19, 25, 26, 28, 45, 52, 54, 61, 68, 69, 70, 79, 80], "45": 2, "exponenti": [3, 71], "conjug": [3, 28, 32], "55": 3, "analyt": [4, 30, 31, 69], "graphic": 4, "method": [4, 28, 51, 84], "analysi": [4, 34, 45, 67], "posterior": [4, 19, 26, 30, 32, 34, 35, 45, 49, 51, 53, 57, 69, 70, 74], "BE": 5, "bi": 5, "103": 5, "b": [5, 84], "statist": [5, 19, 53, 55, 67], "infer": [5, 19, 69, 75], "biolog": 5, "scienc": [5, 19], "us": [5, 15, 16, 28, 35, 46, 48, 69, 71, 72, 74, 82, 86, 87], "link": 5, "peopl": 5, "lesson": [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 77, 92], "schedul": [5, 92], "polici": [5, 77], "resourc": [5, 17], "previou": 5, "edit": 5, "cours": [5, 77], "e1": 6, "To": [6, 7, 8, 9, 10, 11, 12, 13, 14], "complet": [6, 7, 8, 9, 10, 11, 12, 13, 14], "after": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15], "5": [6, 7, 10, 12, 15, 32], "exercis": [6, 7, 8, 9, 10, 11, 12, 13, 14, 77, 92], "3": [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 30, 52], "4": [6, 7, 8, 9, 10, 11, 12, 14, 15, 31], "e2": 7, "6": [7, 11, 15, 33], "e3": 8, "10": [8, 48, 89], "e4": 9, "13": [9, 53], "e5": 10, "16": [10, 56], "e6": 11, "18": [11, 59], "e7": 12, "20": [12, 66], "7": [12, 15, 39], "e8": 13, "22": [13, 68], "8": [13, 15, 44], "e9": 14, "25": [14, 75], "9": [14, 15, 47], "aw": 15, "setup": 15, "usag": 15, "creat": 15, "an": [15, 24, 30, 60, 68, 69, 84], "amazon": 15, "web": 15, "servic": 15, "account": 15, "launch": 15, "your": [15, 18, 46], "instanc": 15, "connect": 15, "jupyterlab": 15, "copi": 15, "result": [15, 50, 51], "from": [15, 25, 71], "local": 15, "machin": [15, 18], "exit": 15, "serious": 15, "stop": 15, "you": 15, "ar": [15, 46], "them": 15, "again": 15, "termin": 15, "class": 15, "i": [15, 19, 34, 52, 86], "over": 15, "googl": 16, "colab": 16, "watchout": 16, "when": 16, "softwar": [16, 86, 91], "A": [16, 30, 36, 56, 65, 66, 67, 72, 75, 82, 84], "sampl": [16, 45, 46, 47, 48, 49, 51, 55, 56, 66, 68, 69, 70, 71, 72, 84, 88], "calcul": [16, 30, 60, 71], "comput": [16, 17, 18, 30, 31, 32, 34, 35, 36, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 68, 69, 70, 71, 72, 74, 75, 82, 88], "environ": [16, 18, 30, 31, 32, 34, 35, 36, 45, 46, 47, 48, 49, 51, 52, 53, 55, 56, 58, 60, 63, 68, 69, 70, 71, 72, 74, 75, 82, 88], "0": 17, "set": [17, 30, 45, 52, 54, 55, 66, 69, 82, 84], "up": [17, 42, 46, 47, 66, 76], "configur": 18, "instal": 18, "python": [18, 86], "packag": 18, "stan": [18, 44, 45, 46, 48, 52, 66, 69, 70, 71, 72, 74, 75, 86, 88], "c": [18, 84], "toolchain": 18, "maco": 18, "window": 18, "linux": 18, "cmdstanpi": 18, "check": [18, 36, 52, 53, 54, 55, 57, 66, 68, 74], "probabl": [19, 22, 24, 78, 88], "logic": [19, 22], "what": [19, 82, 86], "The": [19, 25, 26, 28, 30, 31, 32, 36, 40, 41, 45, 49, 52, 53, 55, 57, 65, 68, 69, 75, 82, 84], "problem": 19, "frequentist": 19, "desiderata": 19, "sum": 19, "rule": 19, "product": 19, "condit": [19, 24, 61], "applic": 19, "scientif": [19, 22], "measur": [19, 25], "bay": [19, 20, 21, 24], "": [19, 20, 21, 24, 52, 54, 86, 87], "theorem": [19, 20, 21, 24], "likelihood": [19, 25, 27, 30, 34, 52, 60, 69, 72, 74], "evid": 19, "learn": 20, "notat": [21, 84], "part": 21, "reason": 22, "margin": [23, 30, 31, 45, 49, 88], "distribut": [24, 25, 49, 51, 54, 61, 69, 88], "joint": 24, "pdf": 24, "chang": 24, "variabl": [24, 54, 72], "formula": 24, "continu": 24, "multipl": 24, "dimens": 24, "exampl": [24, 25, 28, 58, 60, 69, 75], "anoth": [24, 25], "log": [24, 30, 57, 60, 86, 88], "normal": [24, 25, 30, 34, 35, 36, 69, 72, 74], "paramet": [25, 30, 33, 34, 35, 36, 45, 49, 52, 65, 69, 88], "estim": [25, 33, 34, 35, 36, 45, 57, 69, 74], "repeat": [25, 65], "revisit": 25, "choic": [25, 61, 84], "succinctli": 25, "state": [25, 86], "task": 26, "build": [26, 45, 52, 67, 85], "role": 26, "make": 26, "sens": 26, "choos": [27, 28, 41, 54, 61, 75, 79, 80, 82], "uniform": 28, "jeffrei": 28, "why": [28, 35, 43, 46], "weakli": 28, "inform": [28, 57], "bet": 28, "farm": 28, "specifi": 28, "introduct": [29, 39, 44, 69, 83], "plot": [30, 32, 45, 47, 49, 67, 69], "data": [30, 34, 45, 52, 55, 65, 66, 69, 71], "spindl": [30, 52, 75], "size": [30, 34, 45, 52, 53, 55, 75], "singl": 30, "numer": [30, 31, 82], "quadratur": [30, 31], "prescript": 30, "1d": 30, "express": [30, 71], "2d": 30, "asid": [30, 66, 74], "speed": 30, "tubulin": [31, 36, 52, 53], "conserv": [31, 36, 53], "curs": 31, "dimension": [31, 84], "overcom": 31, "conjugaci": 32, "beta": 32, "binomi": 32, "pair": [32, 49], "find": 32, "comment": 32, "optim": [33, 34, 35, 36, 70, 71, 79, 80, 84], "case": [34, 56], "studi": [34, 56], "exploratori": 34, "independ": [34, 52, 53, 65, 86], "map": [34, 35, 70], "approxim": [34, 35, 36], "credibl": [34, 35], "interv": [34, 35], "how": [34, 51, 84, 86], "good": 34, "approach": 35, "summar": [35, 51], "its": 35, "maximum": 35, "demonstr": 35, "mai": 35, "skew": 35, "variat": [36, 48, 75], "covari": [36, 48, 69, 71], "displai": [36, 45, 46, 49, 50, 51], "best": [36, 45, 65], "fit": [36, 45], "line": 36, "further": 38, "read": [38, 91], "mcmc": [38, 40, 43, 44, 45, 47, 48, 49, 50, 51, 55, 72, 74, 86, 87], "markov": [39, 45, 84], "chain": [39, 45], "mont": [39, 45, 55, 82, 83, 84], "carlo": [39, 45, 55, 82, 83, 84], "random": 40, "number": [40, 54, 69], "basic": [40, 46], "idea": [40, 75], "behind": 40, "transit": [41, 82, 84], "kernel": [41, 69, 71], "metropoli": 41, "hast": 41, "algorithm": [41, 75, 84], "detail": [41, 82], "balanc": 41, "warm": 42, "our": [45, 68], "engin": 45, "ecdf": [45, 67, 68], "mrna": [45, 68], "count": [45, 68], "burst": 45, "inter": 45, "time": [45, 82, 84], "all": [45, 52, 84], "gene": 45, "hello": 46, "world": [46, 65], "program": 46, "sai": 46, "hi": 46, "pars": [46, 47], "output": [46, 47], "arviz": [46, 49], "direct": 46, "we": [46, 84], "code": [46, 47, 66, 77, 86], "save": 46, "clean": 46, "shrapnel": 46, "mixtur": [47, 60], "label": 47, "switch": 47, "initi": 47, "walker": 47, "conclus": [47, 66, 68, 69], "updat": 48, "visual": 49, "examin": 49, "trace": 49, "bebi103": 49, "interpet": 49, "parallel": 49, "coordin": 49, "intepret": 49, "one": [49, 57], "iqplot": 49, "two": [49, 88], "corner": 49, "11": 50, "report": 51, "summari": [51, 53, 75], "some": 51, "error": [51, 55], "bar": 51, "rel": 51, "merit": 51, "each": 51, "text": 51, "12": 52, "predict": [52, 53, 57, 69, 70, 74], "droplet": 52, "take": [52, 88], "depend": 52, "total": 52, "concentr": 52, "indentifi": 52, "limit": 52, "behavior": 52, "assumpt": 52, "v_": 52, "mathrm": 52, "v_0": 52, "ll": 52, "do": [52, 84], "have": 52, "same": 52, "aspect": 52, "ratio": 52, "k": [52, 84], "bewar": 53, "14": 54, "collector": 54, "box": 54, "out": [54, 56, 57, 69], "explor": 54, "start": 54, "simpl": 54, "ad": 54, "flexibl": 54, "support": [54, 86], "posit": 54, "real": 54, "15": 55, "diagnost": [55, 56, 66, 67], "ani": 55, "sampler": 55, "gelman": 55, "rubin": 55, "r": 55, "hat": 55, "effect": 55, "standard": 55, "hmc": [55, 82], "diverg": [55, 57, 82], "tree": 55, "depth": 55, "e": 55, "bfmi": 55, "quickli": 55, "artifici": 56, "funnel": 56, "hell": 56, "conquer": 56, "adjust": [56, 68], "adapt_delta": 56, "noncent": [56, 66, 72], "hierarch": [56, 61, 62, 63, 64, 65, 66, 75], "featur": [56, 84], "17": 57, "comparison": [57, 59, 60], "metric": 57, "assess": 57, "close": 57, "entropi": 57, "kullback": 57, "leibler": 57, "expect": 57, "pointwis": [57, 60], "densiti": 57, "watanab": 57, "akaik": 57, "criterion": 57, "leav": 57, "elpd": 57, "weight": [57, 60], "select": 58, "regress": 58, "practic": [59, 60, 68, 71], "waic": 60, "loo": 60, "exchang": 61, "implement": [63, 66, 73, 84], "19": 64, "experi": 65, "revers": 65, "pool": [65, 86], "ident": 65, "both": 65, "structur": 66, "quick": 66, "input": 66, "draw": 66, "parametr": 66, "21": 67, "principl": 67, "pipelin": 67, "workflow": 67, "refer": 67, "terminologi": 67, "simul": [67, 68], "base": [67, 68], "calibr": [67, 68], "z": 67, "score": 67, "shrinkag": 67, "v": 67, "rank": 67, "histogram": 67, "full": 67, "relat": 68, "perform": 68, "sbc": 68, "new": 68, "23": 69, "gaussian": [69, 70, 72, 73, 82], "process": [69, 70, 72, 73, 86], "nonparametr": 69, "finit": 69, "point": 69, "mean": 69, "function": [69, 75], "center": 69, "scale": 69, "matrix": 69, "gp": [69, 71, 72, 74], "numpi": 69, "compos": 69, "valu": [69, 88], "hyperparamet": [70, 74], "scipi": 70, "obtain": [70, 86], "hyperprior": 70, "deriv": 71, "squar": 71, "mat\u00e9rn": 71, "gradient": 71, "non": 72, "latent": 72, "poisson": 72, "24": 73, "includ": 74, "file": [74, 86], "main": 75, "q": [75, 84], "\u03b8": 75, "vi": 75, "automat": 75, "differenti": 75, "volum": 75, "multilevel": 75, "26": 76, "wrap": 76, "meet": 77, "lab": 77, "session": 77, "submiss": 77, "assign": 77, "grade": 77, "collabor": 77, "honor": 77, "commun": [77, 86], "ediquett": 77, "r1": 78, "review": [78, 79, 80, 88], "r2": [79, 80], "r3": 81, "just": [81, 90], "help": [81, 90], "more": 82, "hamiltonian": [82, 83, 84], "typic": [82, 84], "kinet": [82, 84], "energi": [82, 84], "euclidean": 82, "short": 82, "note": 82, "integr": [82, 84], "happen": 82, "r4": 83, "overview": [84, 92], "motiv": 84, "interest": 84, "high": 84, "space": 84, "But": 84, "question": 84, "remain": 84, "design": 84, "so": 84, "thi": 84, "lead": 84, "u": 84, "ideal": 84, "actual": 84, "consider": 84, "p": 84, "conclud": 84, "thought": 84, "r5": 85, "r6": [86, 87], "caltech": [86, 87], "hpc": [86, 87], "even": 86, "supercomput": 86, "hpcc": 86, "access": 86, "slurm": 86, "transfer": 86, "storag": 86, "pro": 86, "tip": 86, "write": 86, "concurr": 86, "between": 86, "share": 86, "run": 86, "foreword": 86, "r7": 88, "discret": 88, "logsumexp": 88, "cornerston": 88, "stabl": 88, "handl": 88, "vector": 88, "paremet": 88, "integ": 88, "\u03b1": 88, "gamma": 88, "via": 88, "r8": 89, "discuss": 89, "hw": 89, "project": 89, "propos": 89, "r9": 90, "tutori": 91, "due": 92, "date": 92, "weekli": 92}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"Homework 1.1: First attempts at Bayesian generative modeling (70 pts)": [[0, "Homework-1.1:-First-attempts-at-Bayesian-generative-modeling-(70-pts)"]], "1. Intuitive generative modeling": [[1, "intuitive-generative-modeling"]], "Homework 2.1: Overwhelming a prior (45 pts)": [[2, "Homework-2.1:-Overwhelming-a-prior-(45-pts)"]], "Homework 2.2: Exponential conjugate prior (55 pts)": [[3, "Homework-2.2:-Exponential-conjugate-prior-(55-pts)"]], "2. Analytical and graphical methods for analysis of the posterior": [[4, "analytical-and-graphical-methods-for-analysis-of-the-posterior"]], "BE/Bi 103 b: Statistical Inference in the Biological Sciences": [[5, "be-bi-103-b-statistical-inference-in-the-biological-sciences"]], "Useful links": [[5, "useful-links"]], "People": [[5, "people"]], "Lessons": [[5, null]], "Homework": [[5, null], [77, "homework"]], "Schedule": [[5, null]], "Policies": [[5, null]], "Resources": [[5, null]], "Previous editions of the course": [[5, "previous-editions-of-the-course"]], "E1. To be completed after lesson 5": [[6, "E1.-To-be-completed-after-lesson-5"]], "Exercise 1.1": [[6, "Exercise-1.1"]], "Exercise 1.2": [[6, "Exercise-1.2"]], "Exercise 1.3": [[6, "Exercise-1.3"]], "Exercise 1.4": [[6, "Exercise-1.4"]], "E2. To be completed after lesson 6": [[7, "E2.-To-be-completed-after-lesson-6"]], "Exercise 2.1": [[7, "Exercise-2.1"]], "Exercise 2.2": [[7, "Exercise-2.2"]], "Exercise 2.3": [[7, "Exercise-2.3"]], "Exercise 2.4": [[7, "Exercise-2.4"]], "Exercise 2.5": [[7, "Exercise-2.5"]], "E3. To be completed after lesson 10": [[8, "E3.-To-be-completed-after-lesson-10"]], "Exercise 3.1": [[8, "Exercise-3.1"]], "Exercise 3.2": [[8, "Exercise-3.2"]], "Exercise 3.3": [[8, "Exercise-3.3"]], "Exercise 3.4": [[8, "Exercise-3.4"]], "E4. To be completed after lesson 13": [[9, "E4.-To-be-completed-after-lesson-13"]], "Exercise 4.1": [[9, "Exercise-4.1"]], "Exercise 4.2": [[9, "Exercise-4.2"]], "Exercise 4.3": [[9, "Exercise-4.3"]], "Exercise 4.4": [[9, "Exercise-4.4"]], "E5. To be completed after lesson 16": [[10, "E5.-To-be-completed-after-lesson-16"]], "Exercise 5.1": [[10, "Exercise-5.1"]], "Exercise 5.2": [[10, "Exercise-5.2"]], "Exercise 5.3": [[10, "Exercise-5.3"]], "Exercise 5.4": [[10, "Exercise-5.4"]], "E6. To be completed after lesson 18": [[11, "E6.-To-be-completed-after-lesson-18"]], "Exercise 6.1": [[11, "Exercise-6.1"]], "Exercise 6.2": [[11, "Exercise-6.2"]], "Exercise 6.3": [[11, "Exercise-6.3"]], "Exercise 6.4": [[11, "Exercise-6.4"]], "E7. To be completed after lesson 20": [[12, "E7.-To-be-completed-after-lesson-20"]], "Exercise 7.1": [[12, "Exercise-7.1"]], "Exercise 7.2": [[12, "Exercise-7.2"]], "Exercise 7.3": [[12, "Exercise-7.3"]], "Exercise 7.4": [[12, "Exercise-7.4"]], "Exercise 7.5": [[12, "Exercise-7.5"]], "E8. To be completed after lesson 22": [[13, "E8.-To-be-completed-after-lesson-22"]], "Exercise 8.1": [[13, "Exercise-8.1"]], "Exercise 8.2": [[13, "Exercise-8.2"]], "Exercise 8.3": [[13, "Exercise-8.3"]], "E9. To be completed after lesson 25": [[14, "E9.-To-be-completed-after-lesson-25"]], "Exercise 9.1": [[14, "Exercise-9.1"]], "Exercise 9.2": [[14, "Exercise-9.2"]], "Exercise 9.3": [[14, "Exercise-9.3"]], "Exercise 9.4": [[14, "Exercise-9.4"]], "AWS setup and usage": [[15, "AWS-setup-and-usage"]], "1. Create an Amazon Web Services account": [[15, "1.-Create-an-Amazon-Web-Services-account"]], "2. Launch your instance": [[15, "2.-Launch-your-instance"]], "3. Connect to your instance": [[15, "3.-Connect-to-your-instance"]], "4. Launch JupyterLab": [[15, "4.-Launch-JupyterLab"]], "5. Copying results to and from AWS to your local machine": [[15, "5.-Copying-results-to-and-from-AWS-to-your-local-machine"]], "6. Exiting": [[15, "6.-Exiting"]], "7. Seriously. Stop your instances if you are not using them.": [[15, "7.-Seriously.-Stop-your-instances-if-you-are-not-using-them."]], "8. Using your instance again": [[15, "8.-Using-your-instance-again"]], "9. Terminate your instances after the class is over": [[15, "9.-Terminate-your-instances-after-the-class-is-over"]], "Using Google Colab": [[16, "Using-Google-Colab"]], "Watchouts when using Colab": [[16, "Watchouts-when-using-Colab"]], "Software in Colab": [[16, "Software-in-Colab"]], "A sample calculation": [[16, "A-sample-calculation"]], "Computing environment": [[16, "Computing-environment"], [18, "Computing-environment"], [30, "Computing-environment"], [31, "Computing-environment"], [32, "Computing-environment"], [34, "Computing-environment"], [35, "Computing-environment"], [36, "Computing-environment"], [45, "Computing-environment"], [46, "Computing-environment"], [47, "Computing-environment"], [48, "Computing-environment"], [49, "Computing-environment"], [51, "Computing-environment"], [52, "Computing-environment"], [53, "Computing-environment"], [55, "Computing-environment"], [56, "Computing-environment"], [58, "Computing-environment"], [60, "Computing-environment"], [63, "Computing-environment"], [68, "Computing-environment"], [69, "Computing-environment"], [70, "Computing-environment"], [71, "Computing-environment"], [72, "Computing-environment"], [74, "Computing-environment"], [75, "Computing-environment"], [88, "Computing-environment"]], "0. Setting up computing resources": [[17, "setting-up-computing-resources"]], "Configuring your machine": [[18, "Configuring-your-machine"]], "Installing Python packages": [[18, "Installing-Python-packages"]], "Stan installation": [[18, "Stan-installation"]], "Configuring a C++ toolchain for MacOS": [[18, "Configuring-a-C++-toolchain-for-MacOS"]], "Configuring a C++ toolchain for Windows": [[18, "Configuring-a-C++-toolchain-for-Windows"]], "Configuring a C++ toolchain for Linux": [[18, "Configuring-a-C++-toolchain-for-Linux"]], "Installing Stan with CmdStanPy": [[18, "Installing-Stan-with-CmdStanPy"]], "Checking your Stan installation": [[18, "Checking-your-Stan-installation"]], "Probability as the logic of science": [[19, "probability-as-the-logic-of-science"]], "What is statistical inference?": [[19, "what-is-statistical-inference"]], "The problem of probability": [[19, "the-problem-of-probability"]], "Frequentist probability.": [[19, "frequentist-probability"]], "Bayesian probability.": [[19, "bayesian-probability"]], "Desiderata for Bayesian probability": [[19, "desiderata-for-bayesian-probability"]], "The sum rule, the product rule, and conditional probability": [[19, "the-sum-rule-the-product-rule-and-conditional-probability"]], "Application to scientific measurement": [[19, "application-to-scientific-measurement"]], "Bayes\u2019s Theorem": [[19, "bayess-theorem"]], "The prior probability.": [[19, "the-prior-probability"]], "The likelihood.": [[19, "the-likelihood"]], "The evidence.": [[19, "the-evidence"]], "The posterior probability.": [[19, "the-posterior-probability"]], "Bayes\u2019s theorem as a model for learning": [[20, "bayes-s-theorem-as-a-model-for-learning"]], "Notation of parts of Bayes\u2019s Theorem": [[21, "notation-of-parts-of-bayess-theorem"]], "1. Probability and the logic of scientific reasoning": [[22, "probability-and-the-logic-of-scientific-reasoning"]], "Marginalization": [[23, "marginalization"]], "Probability distributions": [[24, "probability-distributions"]], "Joint and conditional distributions and Bayes\u2019s theorem for PDFs": [[24, "joint-and-conditional-distributions-and-bayess-theorem-for-pdfs"]], "Change of variables formula for continuous distributions": [[24, "change-of-variables-formula-for-continuous-distributions"]], "Generalization to multiple dimensions": [[24, "generalization-to-multiple-dimensions"]], "An example of change of variables": [[24, "an-example-of-change-of-variables"]], "Another example of change of variables: the Log-Normal distribution": [[24, "another-example-of-change-of-variables-the-log-normal-distribution"]], "Bayesian modeling example: parameter estimation from repeated measurements": [[25, "bayesian-modeling-example-parameter-estimation-from-repeated-measurements"]], "The likelihood": [[25, "the-likelihood"], [52, "The-likelihood"]], "The Normal distribution": [[25, "the-normal-distribution"]], "The likelihood revisited: and another parameter": [[25, "the-likelihood-revisited-and-another-parameter"]], "Choice of prior": [[25, "choice-of-prior"]], "Succinctly stating the model": [[25, "succinctly-stating-the-model"]], "Tasks of Bayesian modeling": [[26, "tasks-of-bayesian-modeling"]], "Model building": [[26, "model-building"]], "The role of the prior": [[26, "the-role-of-the-prior"]], "Making sense of the posterior": [[26, "making-sense-of-the-posterior"]], "Choosing likelihoods": [[27, "choosing-likelihoods"]], "Choosing priors": [[28, "choosing-priors"]], "Uniform priors": [[28, "uniform-priors"]], "Jeffreys priors": [[28, "jeffreys-priors"]], "Example Jeffreys priors": [[28, "example-jeffreys-priors"]], "Why not use Jeffreys priors?": [[28, "why-not-use-jeffreys-priors"]], "Weakly informative priors": [[28, "weakly-informative-priors"]], "Conjugate priors": [[28, "conjugate-priors"]], "The bet-the-farm method of specifying weakly informative priors": [[28, "the-bet-the-farm-method-of-specifying-weakly-informative-priors"]], "2. Introduction to Bayesian modeling": [[29, "introduction-to-bayesian-modeling"]], "3. Plotting posteriors": [[30, "3.-Plotting-posteriors"]], "The data set": [[30, "The-data-set"], [45, "The-data-set"], [52, "The-data-set"], [55, "The-data-set"]], "Models for spindle size": [[30, "Models-for-spindle-size"]], "Plotting the posterior for a single parameter": [[30, "Plotting-the-posterior-for-a-single-parameter"]], "Analytically marginalizing": [[30, "Analytically-marginalizing"]], "Computing and plotting the marginalized posterior": [[30, "Computing-and-plotting-the-marginalized-posterior"]], "Normalizing by numerical quadrature": [[30, "Normalizing-by-numerical-quadrature"]], "A prescription for plotting 1D posteriors": [[30, "A-prescription-for-plotting-1D-posteriors"]], "An analytical expression for the marginal posterior": [[30, "An-analytical-expression-for-the-marginal-posterior"]], "Plotting a 2D posterior": [[30, "Plotting-a-2D-posterior"]], "Aside: Speed of likelihood calculation": [[30, "Aside:-Speed-of-likelihood-calculation"]], "Computing the log of a 2D posterior": [[30, "Computing-the-log-of-a-2D-posterior"]], "4. Marginalization by numerical quadrature": [[31, "4.-Marginalization-by-numerical-quadrature"]], "The tubulin conservation model": [[31, "The-tubulin-conservation-model"], [36, "The-tubulin-conservation-model"], [53, "The-tubulin-conservation-model"]], "Analytical marginalization": [[31, "Analytical-marginalization"]], "Numerical marginalization": [[31, "Numerical-marginalization"]], "The curse of dimensionality and overcoming it": [[31, "The-curse-of-dimensionality-and-overcoming-it"]], "5. Conjugacy": [[32, "5.-Conjugacy"]], "The Beta-Binomial conjugate pair": [[32, "The-Beta-Binomial-conjugate-pair"]], "Finding the conjugate": [[32, "Finding-the-conjugate"]], "Plots of the posteriors": [[32, "Plots-of-the-posteriors"]], "Comments on conjugates": [[32, "Comments-on-conjugates"]], "6. Parameter estimation by optimization": [[33, "parameter-estimation-by-optimization"]], "Parameter estimation by optimization case study: Normal likelihood": [[34, "Parameter-estimation-by-optimization-case-study:-Normal-likelihood"]], "Exploratory data analysis": [[34, "Exploratory-data-analysis"]], "Independent size model": [[34, "Independent-size-model"]], "Estimation of the MAP parameters": [[34, "Estimation-of-the-MAP-parameters"]], "Normal approximation of the posterior": [[34, "Normal-approximation-of-the-posterior"]], "Credible intervals": [[34, "Credible-intervals"], [35, "Credible-intervals"]], "How good is the approximation?": [[34, "How-good-is-the-approximation?"]], "Bayesian approach to parameter estimation by optimization": [[35, "Bayesian-approach-to-parameter-estimation-by-optimization"]], "Summarizing the posterior near its maximum": [[35, "Summarizing-the-posterior-near-its-maximum"]], "Demonstration of the Normal approximation": [[35, "Demonstration-of-the-Normal-approximation"]], "Credible intervals may be skewed": [[35, "Credible-intervals-may-be-skewed"]], "Why use the MAP for parameter estimation?": [[35, "Why-use-the-MAP-for-parameter-estimation?"]], "Parameter estimation by optimization: A variate-covariate model": [[36, "Parameter-estimation-by-optimization:-A-variate-covariate-model"]], "Parameter estimation": [[36, "Parameter-estimation"]], "Checking the Normal approximation": [[36, "Checking-the-Normal-approximation"]], "Displaying the best fit line": [[36, "Displaying-the-best-fit-line"]], "Further reading on MCMC": [[38, "further-reading-on-mcmc"]], "7. Introduction to Markov chain Monte Carlo": [[39, "introduction-to-markov-chain-monte-carlo"]], "Random number generation": [[40, "random-number-generation"]], "The basic idea behind MCMC": [[40, "the-basic-idea-behind-mcmc"]], "Generating a transition kernel: The Metropolis-Hastings algorithm": [[41, "generating-a-transition-kernel-the-metropolis-hastings-algorithm"]], "The algorithm/kernel": [[41, "the-algorithm-kernel"]], "Detailed balance": [[41, "detailed-balance"]], "Choosing the transition kernel": [[41, "choosing-the-transition-kernel"]], "Warm-up": [[42, "warm-up"]], "Why MCMC?": [[43, "why-mcmc"]], "8. Introduction to MCMC with Stan": [[44, "introduction-to-mcmc-with-stan"]], "Parameter estimation with Markov chain Monte Carlo": [[45, "Parameter-estimation-with-Markov-chain-Monte-Carlo"]], "Stan: Our MCMC engine": [[45, "Stan:-Our-MCMC-engine"]], "ECDFs of mRNA counts": [[45, "ECDFs-of-mRNA-counts"], [68, "ECDFs-of-mRNA-counts"]], "Building a generative model": [[45, "Building-a-generative-model"], [52, "Building-a-generative-model"]], "Priors for burst size and inter-burst time": [[45, "Priors-for-burst-size-and-inter-burst-time"]], "Sampling the posterior": [[45, "Sampling-the-posterior"]], "Plots of the samples": [[45, "Plots-of-the-samples"]], "Marginalizing the posterior": [[45, "Marginalizing-the-posterior"]], "Analysis for all genes": [[45, "Analysis-for-all-genes"]], "Display of \u201cbest fit\u201d": [[45, "Display-of-%22best-fit%22"]], "\u201cHello, world\u201d \u2014Stan": [[46, "%22Hello,-world%22-\u2014Stan"]], "Basics of Stan programs": [[46, "Basics-of-Stan-programs"]], "Say hi, Stan": [[46, "Say-hi,-Stan"]], "Parsing output with ArviZ": [[46, "Parsing-output-with-ArviZ"]], "Direct sampling": [[46, "Direct-sampling"]], "Why are we using that?": [[46, "Why-are-we-using-that?"]], "Displaying your Stan code": [[46, "Displaying-your-Stan-code"]], "Saving samples": [[46, "Saving-samples"]], "Cleaning up the shrapnel": [[46, "Cleaning-up-the-shrapnel"]], "9. Mixture models and label switching with MCMC": [[47, "9.-Mixture-models-and-label-switching-with-MCMC"]], "Mixture models": [[47, "Mixture-models"]], "Coding up a mixture model": [[47, "Coding-up-a-mixture-model"]], "Parsing the output": [[47, "Parsing-the-output"]], "Plotting the samples": [[47, "Plotting-the-samples"]], "Label switching": [[47, "Label-switching"]], "Initializing walkers": [[47, "Initializing-walkers"]], "Conclusions": [[47, "Conclusions"], [66, "Conclusions"], [68, "Conclusions"], [69, "Conclusions"]], "10. Variate-covariate models with MCMC": [[48, "10.-Variate-covariate-models-with-MCMC"]], "Updated generative model": [[48, "Updated-generative-model"]], "Using Stan to sample": [[48, "Using-Stan-to-sample"]], "Display of MCMC samples": [[49, "Display-of-MCMC-samples"]], "Visualization with ArviZ": [[49, "Visualization-with-ArviZ"]], "The model and samples": [[49, "The-model-and-samples"]], "Examining traces": [[49, "Examining-traces"]], "Trace plots": [[49, "Trace-plots"]], "Trace plots with ArviZ": [[49, "Trace-plots-with-ArviZ"]], "Trace plots with bebi103": [[49, "Trace-plots-with-bebi103"]], "Interpetation of trace plots": [[49, "Interpetation-of-trace-plots"]], "Parallel coordinate plots": [[49, "Parallel-coordinate-plots"]], "Parallel coordinate plots with ArviZ": [[49, "Parallel-coordinate-plots-with-ArviZ"]], "Parallel coordinate plots with bebi103": [[49, "Parallel-coordinate-plots-with-bebi103"]], "Intepretation of parallel coordinate plots": [[49, "Intepretation-of-parallel-coordinate-plots"]], "Plots of marginalized distributions": [[49, "Plots-of-marginalized-distributions"]], "Plotting marginalized distributions of one parameter": [[49, "Plotting-marginalized-distributions-of-one-parameter"]], "Plotting marginalized distributions with ArviZ": [[49, "Plotting-marginalized-distributions-with-ArviZ"]], "Plotting marginalized distributions with iqplot": [[49, "Plotting-marginalized-distributions-with-iqplot"]], "Marginal posteriors of two parameters and corner plots": [[49, "Marginal-posteriors-of-two-parameters-and-corner-plots"]], "Pair plots with ArviZ": [[49, "Pair-plots-with-ArviZ"]], "Corner plots with bebi103": [[49, "Corner-plots-with-bebi103"]], "11. Display of MCMC results": [[50, "display-of-mcmc-results"]], "Reporting summaries of the posterior": [[51, "Reporting-summaries-of-the-posterior"]], "Reporting summaries of MCMC samples": [[51, "Reporting-summaries-of-MCMC-samples"]], "Some distributions to sample": [[51, "Some-distributions-to-sample"]], "Summarizing the \u201cMCMC\u201d results with error bars": [[51, "Summarizing-the-%22MCMC%22-results-with-error-bars"]], "Relative merits of each method": [[51, "Relative-merits-of-each-method"]], "How to display the summary in text.": [[51, "How-to-display-the-summary-in-text."]], "12. Model building with prior predictive checks": [[52, "12.-Model-building-with-prior-predictive-checks"]], "Model 1: Spindle size is independent of droplet size": [[52, "Model-1:-Spindle-size-is-independent-of-droplet-size"]], "The prior": [[52, "The-prior"]], "The prior, take 2": [[52, "The-prior,-take-2"]], "Prior predictive checks": [[52, "Prior-predictive-checks"], [52, "id1"]], "The prior, take 3": [[52, "The-prior,-take-3"]], "Prior predictive checks, take 2": [[52, "Prior-predictive-checks,-take-2"]], "Prior predictive checks with Stan": [[52, "Prior-predictive-checks-with-Stan"]], "Model 2: Spindle size dependent on total tubulin concentration": [[52, "Model-2:-Spindle-size-dependent-on-total-tubulin-concentration"]], "Indentifiability of parameters": [[52, "Indentifiability-of-parameters"]], "Limiting behavior": [[52, "Limiting-behavior"]], "Generative model": [[52, "Generative-model"]], "Checking model assumptions": [[52, "Checking-model-assumptions"]], "Is V_\\mathrm{s} / V_0 \\ll 1?": [[52, "Is-V_\\mathrm{s}-/-V_0-\\ll-1?"]], "Do all spindles have the same aspect ratio k?": [[52, "Do-all-spindles-have-the-same-aspect-ratio-k?"]], "13. Posterior predictive checks": [[53, "13.-Posterior-predictive-checks"]], "The independent size model": [[53, "The-independent-size-model"]], "Beware the summary statistic": [[53, "Beware-the-summary-statistic"]], "14. Collector\u2019s box of distributions": [[54, "collector-s-box-of-distributions"]], "Check out the Distribution Explorer": [[54, "check-out-the-distribution-explorer"]], "Choosing distributions": [[54, "choosing-distributions"]], "Starting simple and adding flexibility": [[54, "starting-simple-and-adding-flexibility"]], "Priors for variables with support on the set of positive real numbers": [[54, "priors-for-variables-with-support-on-the-set-of-positive-real-numbers"]], "15. MCMC diagnostics": [[55, "15.-MCMC-diagnostics"]], "The model": [[55, "The-model"]], "Diagnostics for any MCMC sampler": [[55, "Diagnostics-for-any-MCMC-sampler"]], "The Gelman-Rubin R-hat statistic": [[55, "The-Gelman-Rubin-R-hat-statistic"]], "Effective samples size": [[55, "Effective-samples-size"]], "Monte Carlo standard error": [[55, "Monte-Carlo-standard-error"]], "Diagnostics for HMC": [[55, "Diagnostics-for-HMC"]], "Divergences": [[55, "Divergences"]], "Tree depth": [[55, "Tree-depth"]], "E-BFMI": [[55, "E-BFMI"]], "Quickly checking the diagnostics": [[55, "Quickly-checking-the-diagnostics"]], "16. A diagnostics case study: Artificial funnel of hell": [[56, "16.-A-diagnostics-case-study:-Artificial-funnel-of-hell"]], "Sampling out of the funnel": [[56, "Sampling-out-of-the-funnel"]], "Conquering the Funnel of Hell": [[56, "Conquering-the-Funnel-of-Hell"]], "Adjusting adapt_delta": [[56, "Adjusting-adapt_delta"]], "Noncentering": [[56, "Noncentering"], [72, "Noncentering"]], "Hierarchical models feature a Funnel of Hell": [[56, "Hierarchical-models-feature-a-Funnel-of-Hell"]], "17. Model comparison": [[57, "model-comparison"]], "Metrics for model assessment": [[57, "metrics-for-model-assessment"]], "Posterior predictive checks": [[57, "posterior-predictive-checks"]], "Closeness metrics": [[57, "closeness-metrics"]], "Entropy and the Kullback-Leibler divergence": [[57, "entropy-and-the-kullback-leibler-divergence"]], "The expected log pointwise predictive density": [[57, "the-expected-log-pointwise-predictive-density"]], "The Watanabe-Akaike information criterion": [[57, "the-watanabe-akaike-information-criterion"]], "Leave-one-out estimates of elpd": [[57, "leave-one-out-estimates-of-elpd"]], "The Akaike weights": [[57, "the-akaike-weights"]], "Example model selection: regression": [[58, "Example-model-selection:-regression"]], "18. Model comparison in practice": [[59, "model-comparison-in-practice"]], "Model comparison in practice": [[60, "Model-comparison-in-practice"]], "An example model comparison": [[60, "An-example-model-comparison"]], "Computing the pointwise log likelihood": [[60, "Computing-the-pointwise-log-likelihood"]], "Computing the WAIC and LOO": [[60, "Computing-the-WAIC-and-LOO"]], "Calculations with the mixture model": [[60, "Calculations-with-the-mixture-model"]], "Computing the weights": [[60, "Computing-the-weights"]], "Choosing a hierarchical prior": [[61, "Choosing-a-hierarchical-prior"]], "Exchangeability": [[61, "Exchangeability"]], "Choice of the conditional distribution": [[61, "Choice-of-the-conditional-distribution"]], "Generalization of hierarchical models": [[62, "Generalization-of-hierarchical-models"]], "Implementation of a hierarchical model": [[63, "Implementation-of-a-hierarchical-model"]], "19. Hierarchical models": [[64, "hierarchical-models"]], "Modeling repeated experiments": [[65, "Modeling-repeated-experiments"]], "A model for reversals": [[65, "A-model-for-reversals"]], "Pooled data: identical parameters": [[65, "Pooled-data:-identical-parameters"]], "Independent parameters": [[65, "Independent-parameters"]], "The best of both worlds: A hierarchical model": [[65, "The-best-of-both-worlds:-A-hierarchical-model"]], "20. Implementation of hierarchical models": [[66, "20.-Implementation-of-hierarchical-models"]], "Hierarchical model structure": [[66, "Hierarchical-model-structure"]], "Coding up the hierarchical model in Stan": [[66, "Coding-up-the-hierarchical-model-in-Stan"]], "A quick aside: generating a data set": [[66, "A-quick-aside:-generating-a-data-set"]], "Generating input data for Stan": [[66, "Generating-input-data-for-Stan"]], "Drawing samples and checking diagnostics": [[66, "Drawing-samples-and-checking-diagnostics"]], "A noncentered parametrization": [[66, "A-noncentered-parametrization"]], "21. Principled analysis pipelines": [[67, "21.-Principled-analysis-pipelines"]], "Building a workflow": [[67, "Building-a-workflow"]], "References and terminology": [[67, "References-and-terminology"]], "Simulation-based calibration": [[67, "Simulation-based-calibration"]], "Diagnostics": [[67, "Diagnostics"]], "z-score": [[67, "z-score"]], "Shrinkage": [[67, "Shrinkage"]], "Shrinkage vs. z-score plot": [[67, "Shrinkage-vs.-z-score-plot"]], "Rank statistics": [[67, "Rank-statistics"]], "A rank statistic ECDF plot": [[67, "A-rank-statistic-ECDF-plot"]], "Rank statistic histograms": [[67, "Rank-statistic-histograms"]], "A full principled pipeline": [[67, "A-full-principled-pipeline"]], "22: Simulation based calibration and related checks in practice": [[68, "22:-Simulation-based-calibration-and-related-checks-in-practice"]], "The generative model": [[68, "The-generative-model"]], "Performing SBC": [[68, "Performing-SBC"]], "An adjusted prior": [[68, "An-adjusted-prior"]], "Sampling with our new model": [[68, "Sampling-with-our-new-model"]], "23. Introduction to Gaussian processes": [[69, "23.-Introduction-to-Gaussian-processes"]], "Predicting using posterior estimates": [[69, "Predicting-using-posterior-estimates"]], "An example data set": [[69, "An-example-data-set"]], "Processes and nonparametric Bayesian inference": [[69, "Processes-and-nonparametric-Bayesian-inference"]], "Gaussian processes with a finite number of points": [[69, "Gaussian-processes-with-a-finite-number-of-points"]], "The mean function and centering and scaling": [[69, "The-mean-function-and-centering-and-scaling"]], "The kernel and covariance matrix": [[69, "The-kernel-and-covariance-matrix"]], "Sampling out of a Gaussian process prior": [[69, "Sampling-out-of-a-Gaussian-process-prior"]], "Sampling out of a GP prior using Stan": [[69, "Sampling-out-of-a-GP-prior-using-Stan"]], "Sampling out of a GP prior using Numpy": [[69, "Sampling-out-of-a-GP-prior-using-Numpy"]], "Composing kernels": [[69, "Composing-kernels"]], "Inference with GPs": [[69, "Inference-with-GPs"]], "Normal likelihoods with Gaussian process priors": [[69, "Normal-likelihoods-with-Gaussian-process-priors"]], "The posterior predictive distribution of function values": [[69, "The-posterior-predictive-distribution-of-function-values"]], "Computing the parameters of the posterior predictive distribution": [[69, "Computing-the-parameters-of-the-posterior-predictive-distribution"]], "Plotting an analytical posterior": [[69, "Plotting-an-analytical-posterior"]], "Gaussian process hyperparameters by optimization": [[70, "Gaussian-process-hyperparameters-by-optimization"]], "Priors for hyperparameters": [[70, "Priors-for-hyperparameters"]], "Computing the MAP with SciPy": [[70, "Computing-the-MAP-with-SciPy"]], "Posterior predictive samples": [[70, "Posterior-predictive-samples"]], "Obtaining hyperpriors by optimizing with Stan": [[70, "Obtaining-hyperpriors-by-optimizing-with-Stan"]], "Calculating derivatives from data with GPs": [[71, "Calculating-derivatives-from-data-with-GPs"]], "Derivatives of GPs": [[71, "Derivatives-of-GPs"]], "Derivative of the squared exponential kernel": [[71, "Derivative-of-the-squared-exponential-kernel"]], "Derivatives of the Mat\u00e9rn kernel": [[71, "Derivatives-of-the-Mat\u00e9rn-kernel"]], "Expressions for the gradient and covariance of the gradient": [[71, "Expressions-for-the-gradient-and-covariance-of-the-gradient"]], "Derivatives of GPs in practice using optimization": [[71, "Derivatives-of-GPs-in-practice-using-optimization"]], "Derivatives with a Mat\u00e9rn kernel": [[71, "Derivatives-with-a-Mat\u00e9rn-kernel"]], "Sampling derivatives with Stan": [[71, "Sampling-derivatives-with-Stan"]], "Gaussian processes with non-Normal likelihoods": [[72, "Gaussian-processes-with-non-Normal-likelihoods"]], "Generating samples of latent variables using MCMC": [[72, "Generating-samples-of-latent-variables-using-MCMC"]], "A GP generative model": [[72, "A-GP-generative-model"]], "Sampling latent variables with Stan": [[72, "Sampling-latent-variables-with-Stan"]], "Sampling with a Poisson likelihood": [[72, "Sampling-with-a-Poisson-likelihood"]], "24. Implementation of Gaussian processes": [[73, "implementation-of-gaussian-processes"]], "MCMC with GPs with Normal likelihoods": [[74, "MCMC-with-GPs-with-Normal-likelihoods"]], "Hyperparameter estimation using MCMC": [[74, "Hyperparameter-estimation-using-MCMC"]], "Posterior predictive checks with GPs": [[74, "Posterior-predictive-checks-with-GPs"]], "Aside: Stan include files": [[74, "Aside:-Stan-include-files"]], "25. Variational Bayesian inference": [[75, "25.-Variational-Bayesian-inference"]], "The main ideas of variational inference": [[75, "The-main-ideas-of-variational-inference"]], "Choosing Q(\u03b8)": [[75, "Choosing-Q(\u03b8)"]], "Summary of VI algorithm": [[75, "Summary-of-VI-algorithm"]], "Automatic Differentiation Variational Inference and Stan": [[75, "Automatic-Differentiation-Variational-Inference-and-Stan"]], "Examples": [[75, "Examples"]], "Example 1: Spindle size as a function of volume": [[75, "Example-1:-Spindle-size-as-a-function-of-volume"]], "Example 2: A multilevel hierarchical model": [[75, "Example-2:-A-multilevel-hierarchical-model"]], "26: Wrap-up": [[76, "wrap-up"]], "Meetings": [[77, "meetings"]], "Lab sessions": [[77, "lab-sessions"]], "Submission of assignments": [[77, "submission-of-assignments"]], "Lessons and lesson exercises": [[77, "lessons-and-lesson-exercises"]], "Grading": [[77, "grading"]], "Collaboration policy and Honor Code": [[77, "collaboration-policy-and-honor-code"]], "Course communications": [[77, "course-communications"]], "\u201cEdiquette\u201d": [[77, "ediquette"]], "R1: Review of probability": [[78, "r1-review-of-probability"]], "R2: Choosing priors and review of optimization": [[79, "r2-choosing-priors-and-review-of-optimization"], [80, "r2-choosing-priors-and-review-of-optimization"]], "R3: Just homework help": [[81, "r3-just-homework-help"]], "More details on Hamiltonian Monte Carlo": [[82, "More-details-on-Hamiltonian-Monte-Carlo"]], "The typical set": [[82, "The-typical-set"]], "Hamiltonians": [[82, "Hamiltonians"]], "Hamiltonian Monte Carlo": [[82, "Hamiltonian-Monte-Carlo"]], "Transition using HMC": [[82, "Transition-using-HMC"]], "Choosing Kinetic Energy (Euclidean-Gaussian)": [[82, "Choosing-Kinetic-Energy-(Euclidean-Gaussian)"]], "A short note on integration times": [[82, "A-short-note-on-integration-times"]], "Numerical integration and what happens in divergences": [[82, "Numerical-integration-and-what-happens-in-divergences"]], "Computing Environment": [[82, "Computing-Environment"]], "R4. Introduction to Hamiltonian Monte Carlo": [[83, "r4-introduction-to-hamiltonian-monte-carlo"]], "Overview of Hamiltonian Monte Carlo": [[84, "Overview-of-Hamiltonian-Monte-Carlo"]], "Notation": [[84, "Notation"]], "Motivating interest:": [[84, "Motivating-interest:"]], "Features of a high-dimensional space Q:": [[84, "Features-of-a-high-dimensional-space-Q:"]], "But the question then remains: how do we design an algorithm to sample the typical set?": [[84, "But-the-question-then-remains:-how-do-we-design-an-algorithm-to-sample-the-typical-set?"]], "So this all leads us to \u2026 \ud83c\udf89 Hamiltonian Monte Carlo! \ud83c\udf89": [[84, "So-this-all-leads-us-to-...-\ud83c\udf89-Hamiltonian-Monte-Carlo!-\ud83c\udf89"]], "The Ideal Hamiltonian Markov Transition": [[84, "The-Ideal-Hamiltonian-Markov-Transition"]], "Actual Implementation of Hamiltonian Markov Transition Considerations": [[84, "Actual-Implementation-of-Hamiltonian-Markov-Transition-Considerations"]], "(A) Optimizing Choice of Kinetic Energy K(q, p)": [[84, "(A)-Optimizing-Choice-of-Kinetic-Energy-K(q,-p)"]], "(B) Integration method": [[84, "(B)-Integration-method"]], "(C) Integration time": [[84, "(C)-Integration-time"]], "Concluding thoughts": [[84, "Concluding-thoughts"]], "R5: Bayesian model building": [[85, "R5:-Bayesian-model-building"]], "R6: MCMC using Caltech\u2019s HPC": [[86, "R6:-MCMC-using-Caltech's-HPC"], [87, "r6-mcmc-using-caltech-s-hpc"]], "What even is a supercomputer?": [[86, "What-even-is-a-supercomputer?"]], "How to use the Caltech HPCC?": [[86, "How-to-use-the-Caltech-HPCC?"]], "Obtaining access": [[86, "Obtaining-access"]], "Logging on": [[86, "Logging-on"]], "SLURM": [[86, "SLURM"]], "Transferring files": [[86, "Transferring-files"]], "Storage": [[86, "Storage"]], "Software": [[86, "Software"], [91, "software"]], "Support": [[86, "Support"]], "Pro-Tip for writing code on the HPCC": [[86, "Pro-Tip-for-writing-code-on-the-HPCC"]], "Concurrency with Python": [[86, "Concurrency-with-Python"]], "Independent processes": [[86, "Independent-processes"]], "Pooling between processes": [[86, "Pooling-between-processes"]], "Sharing state between processes": [[86, "Sharing-state-between-processes"]], "Communicating between processes": [[86, "Communicating-between-processes"]], "Running Stan on the HPCC": [[86, "Running-Stan-on-the-HPCC"]], "Foreword": [[86, "Foreword"]], "R7: Sampling discrete parameters with Stan": [[88, "R7:-Sampling-discrete-parameters-with-Stan"]], "Review of LogSumExp, the cornerstone of stable marginalization with discrete parameters": [[88, "Review-of-LogSumExp,-the-cornerstone-of-stable-marginalization-with-discrete-parameters"]], "Handling log probabilities of discrete valued vectors in Stan": [[88, "Handling-log-probabilities-of-discrete-valued-vectors-in-Stan"]], "Discrete paremeters in Stan: integer \u03b1 for gamma distribution": [[88, "Discrete-paremeters-in-Stan:-integer-\u03b1-for-gamma-distribution"]], "Take two: handling discrete parameters via marginalization": [[88, "Take-two:-handling-discrete-parameters-via-marginalization"]], "R8: Discussion of HW 10 project proposals": [[89, "r8-discussion-of-hw-10-project-proposals"]], "R9: Just homework help": [[90, "r9-just-homework-help"]], "Reading/tutorials": [[91, "reading-tutorials"]], "Schedule overview": [[92, "schedule-overview"]], "Homework due dates": [[92, "homework-due-dates"]], "Lesson exercise due dates": [[92, "lesson-exercise-due-dates"]], "Weekly schedule": [[92, "weekly-schedule"]]}, "indexentries": {}})