Search.setIndex({"docnames": ["homework/01/hw1.1", "homework/01/index", "index", "lesson_exercises/exercise_01", "lesson_exercises/exercise_02", "lesson_exercises/exercise_03", "lesson_exercises/exercise_04", "lesson_exercises/exercise_05", "lesson_exercises/exercise_06", "lesson_exercises/exercise_07", "lesson_exercises/exercise_08", "lesson_exercises/exercise_09", "lessons/00/aws_setup", "lessons/00/colab", "lessons/00/index", "lessons/00/setup", "lessons/01/bayes_logic", "lessons/01/bayes_model_for_learning", "lessons/01/bayes_notation", "lessons/01/index", "lessons/01/marginalization", "lessons/01/probability_distributions", "lessons/02/bayesian_modeling_example", "lessons/02/bayesian_modeling_tasks", "lessons/02/choice_of_likelihood", "lessons/02/choice_of_prior", "lessons/02/index", "lessons/03/plotting_posteriors", "lessons/04/marginalization_by_numerical_quadrature", "lessons/05/conjugacy", "lessons/06/index", "lessons/06/normal_optimization", "lessons/06/optimization_basics", "lessons/06/variate_covariate_optimization", "lessons/07/Untitled", "lessons/07/further_reading", "lessons/07/index", "lessons/07/mcmc_idea", "lessons/07/metropolis_hastings", "lessons/07/warm_up", "lessons/07/why_mcmc", "lessons/08/index", "lessons/08/parameter_estimation_with_mcmc", "lessons/08/stan_hello_world", "lessons/09/mixture_model_stan", "lessons/10/variate_covariate_with_stan", "lessons/11/display_of_mcmc_samples", "lessons/11/index", "lessons/11/posterior_summaries", "lessons/12/prior_predictive_checks", "lessons/13/posterior_predictive_checks", "lessons/14/box_of_distributions", "lessons/15/mcmc_diagnostics", "lessons/16/funnel_of_hell", "lessons/17/model_comparison", "lessons/18/comparing_regressions", "lessons/18/index", "lessons/18/model_comparison", "lessons/19/choosing_a_hierarchical_prior", "lessons/19/generalization", "lessons/19/implementation", "lessons/19/index", "lessons/19/modeling_repeated_experiments", "lessons/20/hierarchical_implementation", "lessons/21/sbc", "lessons/22/sbc_in_practice", "lessons/23/intro_to_gps", "lessons/24/gp_hyperparams_by_optimization", "lessons/24/gps_and_derivatives", "lessons/24/gps_without_marginalization", "lessons/24/index", "lessons/24/mcmc_with_gps", "lessons/25/variational_inference", "lessons/26/wrapup", "lessons/causal_messaround/casual_example", "policies", "recitations/01/probability_review", "recitations/02/choosing_priors", "recitations/02/index", "recitations/03/just_hw_help", "recitations/04/hmc", "recitations/04/index", "recitations/04/overview", "recitations/05/practice_model_building", "recitations/06/HPC", "recitations/06/intro_to_hpc", "recitations/07/sampling_discrete_parameters", "recitations/08/project_proposals", "recitations/09/just_hw_help", "resources", "schedule"], "filenames": ["homework/01/hw1.1.ipynb", "homework/01/index.rst", "index.rst", "lesson_exercises/exercise_01.ipynb", "lesson_exercises/exercise_02.ipynb", "lesson_exercises/exercise_03.ipynb", "lesson_exercises/exercise_04.ipynb", "lesson_exercises/exercise_05.ipynb", "lesson_exercises/exercise_06.ipynb", "lesson_exercises/exercise_07.ipynb", "lesson_exercises/exercise_08.ipynb", "lesson_exercises/exercise_09.ipynb", "lessons/00/aws_setup.ipynb", "lessons/00/colab.ipynb", "lessons/00/index.rst", "lessons/00/setup.ipynb", "lessons/01/bayes_logic.rst", "lessons/01/bayes_model_for_learning.rst", "lessons/01/bayes_notation.rst", "lessons/01/index.rst", "lessons/01/marginalization.rst", "lessons/01/probability_distributions.rst", "lessons/02/bayesian_modeling_example.rst", "lessons/02/bayesian_modeling_tasks.rst", "lessons/02/choice_of_likelihood.rst", "lessons/02/choice_of_prior.rst", "lessons/02/index.rst", "lessons/03/plotting_posteriors.ipynb", "lessons/04/marginalization_by_numerical_quadrature.ipynb", "lessons/05/conjugacy.ipynb", "lessons/06/index.rst", "lessons/06/normal_optimization.ipynb", "lessons/06/optimization_basics.ipynb", "lessons/06/variate_covariate_optimization.ipynb", "lessons/07/Untitled.ipynb", "lessons/07/further_reading.rst", "lessons/07/index.rst", "lessons/07/mcmc_idea.rst", "lessons/07/metropolis_hastings.rst", "lessons/07/warm_up.rst", "lessons/07/why_mcmc.rst", "lessons/08/index.rst", "lessons/08/parameter_estimation_with_mcmc.ipynb", "lessons/08/stan_hello_world.ipynb", "lessons/09/mixture_model_stan.ipynb", "lessons/10/variate_covariate_with_stan.ipynb", "lessons/11/display_of_mcmc_samples.ipynb", "lessons/11/index.rst", "lessons/11/posterior_summaries.ipynb", "lessons/12/prior_predictive_checks.ipynb", "lessons/13/posterior_predictive_checks.ipynb", "lessons/14/box_of_distributions.rst", "lessons/15/mcmc_diagnostics.ipynb", "lessons/16/funnel_of_hell.ipynb", "lessons/17/model_comparison.rst", "lessons/18/comparing_regressions.ipynb", "lessons/18/index.rst", "lessons/18/model_comparison.ipynb", "lessons/19/choosing_a_hierarchical_prior.ipynb", "lessons/19/generalization.ipynb", "lessons/19/implementation.ipynb", "lessons/19/index.rst", "lessons/19/modeling_repeated_experiments.ipynb", "lessons/20/hierarchical_implementation.ipynb", "lessons/21/sbc.ipynb", "lessons/22/sbc_in_practice.ipynb", "lessons/23/intro_to_gps.ipynb", "lessons/24/gp_hyperparams_by_optimization.ipynb", "lessons/24/gps_and_derivatives.ipynb", "lessons/24/gps_without_marginalization.ipynb", "lessons/24/index.rst", "lessons/24/mcmc_with_gps.ipynb", "lessons/25/variational_inference.ipynb", "lessons/26/wrapup.rst", "lessons/causal_messaround/casual_example.ipynb", "policies.rst", "recitations/01/probability_review.rst", "recitations/02/choosing_priors.rst", "recitations/02/index.rst", "recitations/03/just_hw_help.rst", "recitations/04/hmc.ipynb", "recitations/04/index.rst", "recitations/04/overview.ipynb", "recitations/05/practice_model_building.ipynb", "recitations/06/HPC.ipynb", "recitations/06/intro_to_hpc.rst", "recitations/07/sampling_discrete_parameters.ipynb", "recitations/08/project_proposals.rst", "recitations/09/just_hw_help.rst", "resources.rst", "schedule.rst"], "titles": ["Homework 1.1: First attempts at Bayesian generative modeling (70 pts)", "1. Intuitive generative modeling", "BE/Bi 103 b: Statistical Inference in the Biological Sciences", "E1. To be completed after lesson 5", "E2. To be completed after lesson 6", "E3. To be completed after lesson 10", "E4. To be completed after lesson 13", "E5. To be completed after lesson 16", "E6. To be completed after lesson 18", "E7. To be completed after lesson 20", "E8. To be completed after lesson 22", "E9. To be completed after lesson 25", "AWS setup and usage", "Using Google Colab", "0. Setting up computing resources", "Configuring your machine", "Probability as the logic of science", "Bayes\u2019s theorem as a model for learning", "Notation of parts of Bayes\u2019s Theorem", "1. Probability and the logic of scientific reasoning", "Marginalization", "Probability distributions", "Bayesian modeling example: parameter estimation from repeated measurements", "Tasks of Bayesian modeling", "Choosing likelihoods", "Choosing priors", "2. Introduction to Bayesian modeling", "3. Plotting posteriors", "4. Marginalization by numerical quadrature", "5. Conjugacy", "6. Parameter estimation by optimization", "Parameter estimation by optimization case study: Normal likelihood", "Bayesian approach to parameter estimation by optimization", "Parameter estimation by optimization: A variate-covariate model", "&lt;no title&gt;", "Further reading on MCMC", "7. Introduction to Markov chain Monte Carlo", "Random number generation", "Generating a transition kernel: The Metropolis-Hastings algorithm", "Warm-up", "Why MCMC?", "8. Introduction to MCMC with Stan", "Parameter estimation with Markov chain Monte Carlo", "\u201cHello, world\u201d \u2014Stan", "9. Mixture models and label switching with MCMC", "10. Variate-covariate models with MCMC", "Display of MCMC samples", "11. Display of MCMC results", "Reporting summaries of the posterior", "12. Model building with prior predictive checks", "13. Posterior predictive checks", "14. Collector\u2019s box of distributions", "15. MCMC diagnostics", "16. A diagnostics case study: Artificial funnel of hell", "17. Model comparison", "Example model selection: regression", "18. Model comparison in practice", "Model comparison in practice", "Choosing a hierarchical prior", "Generalization of hierarchical models", "Implementation of a hierarchical model", "19. Hierarchical models", "Modeling repeated experiments", "20. Implementation of hierarchical models", "21. Principled analysis pipelines", "22: Simulation based calibration and related checks in practice", "23. Introduction to Gaussian processes", "Gaussian process hyperparameters by optimization", "Calculating derivatives from data with GPs", "Gaussian processes with non-Normal likelihoods", "24. Implementation of Gaussian processes", "MCMC with GPs with Normal likelihoods", "25. Variational Bayesian inference", "26: Wrap-up", "Model 1", "Meetings", "R1: Review of probability", "R2: Choosing priors and review of optimization", "R2: Choosing priors and review of optimization", "R3: Just homework help", "More details on Hamiltonian Monte Carlo", "R4. Introduction to Hamiltonian Monte Carlo", "Overview of Hamiltonian Monte Carlo", "R5: Bayesian model building", "R6: MCMC using Caltech\u2019s HPC", "R6: MCMC using Caltech\u2019s HPC", "R7: Sampling discrete parameters with Stan", "R8: Discussion of HW 10 project proposals", "R9: Just homework help", "Software", "Schedule overview"], "terms": {"collard": 0, "cowork": [0, 39, 49, 57, 64, 68, 72], "did": [0, 3, 15, 16, 17, 24, 25, 27, 28, 31, 33, 42, 43, 45, 46, 49, 50, 53, 54, 55, 57, 58, 60, 62, 64, 65, 66, 67, 75, 82, 83, 87], "simpl": [0, 16, 22, 23, 27, 29, 32, 39, 43, 44, 48, 53, 54, 58, 64, 65, 66, 67, 69, 71, 72, 75, 80, 82, 84], "experi": [0, 9, 16, 17, 21, 23, 24, 25, 27, 29, 42, 49, 51, 52, 54, 58, 59, 60, 61, 63, 64, 65, 66, 68, 72, 82, 83, 84, 86], "thei": [0, 16, 22, 25, 27, 29, 31, 32, 33, 42, 43, 44, 45, 46, 49, 52, 53, 54, 57, 63, 64, 66, 68, 69, 72, 75, 80, 82, 83, 84, 86], "collect": [0, 40, 42, 43, 50, 83], "sampl": [0, 5, 7, 8, 12, 15, 21, 23, 28, 33, 37, 38, 39, 40, 47, 49, 50, 54, 55, 57, 58, 59, 60, 64, 71, 72, 74, 80, 84, 90], "carrion": 0, "beetl": 0, "feed": [0, 86], "decai": [0, 27, 49, 65], "anim": [0, 80, 86], "matter": [0, 25, 40, 59, 75], "measur": [0, 18, 21, 23, 24, 25, 26, 27, 28, 31, 42, 43, 49, 50, 51, 52, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 80, 83, 86], "morpholog": 0, "featur": [0, 27, 31, 43, 51, 52, 54, 58, 59, 65, 66, 72, 76, 77, 84, 85, 87], "variou": [0, 23, 37, 43, 46, 48, 66, 68, 84, 86, 89], "speci": [0, 25], "from": [0, 13, 15, 16, 17, 20, 21, 23, 25, 26, 27, 29, 31, 32, 33, 35, 37, 38, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 80, 82, 83, 84, 86], "differ": [0, 12, 13, 16, 25, 27, 31, 32, 42, 44, 48, 49, 50, 53, 54, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 72, 74, 75, 80, 82, 83, 84, 86], "site": [0, 67, 68], "time": [0, 12, 13, 14, 16, 22, 24, 27, 28, 32, 38, 39, 43, 44, 45, 48, 49, 51, 54, 58, 62, 64, 65, 66, 67, 68, 69, 72, 75, 83, 84, 86, 89, 90], "year": [0, 12, 25, 38, 62], "imagin": [0, 21, 39, 42, 51, 53, 54, 59, 62, 65, 66, 68, 80, 82], "you": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 22, 23, 24, 25, 27, 29, 31, 32, 33, 35, 37, 38, 39, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 59, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 80, 82, 83, 84, 86, 89], "ar": [0, 2, 4, 6, 7, 8, 11, 13, 14, 15, 16, 18, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 44, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86], "cabin": 0, "main": [0, 25, 31, 32, 37, 42, 43, 46, 51, 64, 69, 82, 84, 89], "There": [0, 12, 13, 14, 15, 16, 22, 25, 29, 38, 39, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 63, 64, 66, 68, 69, 72, 75, 79, 82, 84, 86, 88, 89], "also": [0, 2, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 25, 27, 28, 29, 31, 32, 37, 38, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 80, 83, 84, 86, 89], "plenti": [0, 12, 52, 57, 74], "area": [0, 28, 52, 65, 80, 86], "which": [0, 12, 13, 14, 15, 16, 17, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86], "stai": [0, 44, 80], "so": [0, 9, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 83, 84, 86], "curiou": 0, "look": [0, 12, 25, 27, 29, 31, 32, 33, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 84, 86], "your": [0, 2, 9, 10, 13, 14, 16, 24, 25, 27, 31, 32, 33, 38, 44, 49, 50, 51, 52, 53, 54, 63, 64, 65, 66, 67, 71, 72, 75, 80, 82, 83, 84], "plan": [0, 86], "set": [0, 2, 4, 9, 12, 13, 15, 16, 17, 18, 21, 23, 25, 28, 31, 32, 33, 38, 40, 43, 44, 45, 46, 50, 54, 55, 57, 58, 59, 60, 62, 64, 65, 67, 68, 69, 71, 72, 74, 75, 83, 84, 86], "up": [0, 2, 5, 12, 13, 15, 22, 23, 25, 27, 28, 31, 33, 36, 37, 42, 49, 50, 51, 52, 53, 55, 59, 62, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 84, 86, 90], "trap": 0, "specimen": 0, "given": [0, 12, 16, 18, 21, 22, 23, 25, 27, 29, 32, 37, 40, 42, 44, 49, 52, 54, 57, 60, 62, 63, 66, 67, 68, 69, 71, 72, 73, 74, 75, 80, 82, 83, 86], "For": [0, 12, 13, 16, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 37, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 62, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 84, 86], "each": [0, 3, 8, 12, 13, 16, 22, 27, 28, 29, 31, 32, 37, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 54, 57, 58, 60, 62, 63, 64, 65, 66, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86, 90], "its": [0, 16, 22, 25, 27, 28, 29, 31, 42, 43, 44, 45, 48, 49, 51, 53, 54, 58, 60, 65, 66, 67, 68, 72, 74, 75, 80, 84, 86, 89], "mass": [0, 21, 25, 31, 44, 48, 51, 53, 57, 64, 65, 66, 75, 80, 82], "length": [0, 22, 24, 25, 27, 28, 31, 33, 42, 43, 44, 45, 46, 49, 50, 51, 52, 55, 57, 64, 66, 67, 69, 72, 80, 84], "elytra": 0, "As": [0, 12, 13, 15, 16, 21, 22, 23, 25, 27, 28, 29, 32, 37, 38, 42, 43, 44, 46, 49, 50, 51, 52, 53, 54, 55, 57, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 75, 80, 82, 84, 86], "we": [0, 2, 3, 4, 8, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 80, 83, 84, 86], "learn": [0, 2, 14, 16, 19, 23, 29, 31, 32, 42, 43, 44, 46, 49, 50, 52, 54, 62, 63, 64, 66, 67, 68, 84], "class": [0, 2, 13, 15, 18, 28, 38, 51, 66, 72, 75, 80, 84, 86, 89, 90], "prior": [0, 2, 3, 4, 6, 10, 17, 18, 20, 24, 26, 27, 28, 29, 31, 32, 33, 43, 44, 45, 50, 52, 54, 57, 59, 60, 61, 62, 63, 64, 68, 69, 71, 72, 74, 75, 82, 83, 84, 86, 90], "perform": [0, 4, 10, 12, 14, 23, 24, 25, 27, 28, 31, 38, 40, 42, 43, 44, 45, 48, 49, 50, 52, 54, 57, 60, 63, 64, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 84, 86], "an": [0, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 25, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 58, 60, 62, 63, 64, 67, 68, 69, 72, 74, 75, 80, 83, 84, 86], "i": [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 76, 79, 80, 82, 83, 86, 88, 89, 90], "us": [0, 4, 5, 6, 7, 8, 9, 11, 14, 15, 16, 18, 20, 21, 22, 23, 24, 27, 28, 29, 31, 33, 37, 38, 39, 40, 42, 44, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 67, 72, 74, 75, 82, 83, 86, 89], "think": [0, 16, 22, 23, 25, 31, 33, 37, 43, 44, 48, 49, 52, 54, 57, 63, 66, 67, 69, 80, 82, 86], "about": [0, 12, 13, 16, 17, 18, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 51, 52, 54, 57, 63, 64, 65, 66, 67, 68, 69, 72, 75, 80, 82, 83, 84, 86, 87, 89], "what": [0, 3, 4, 5, 8, 9, 10, 11, 12, 13, 18, 22, 23, 25, 27, 28, 33, 37, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 63, 64, 65, 66, 67, 68, 72, 75, 82, 83, 86], "kind": [0, 16, 38, 44, 46, 49, 52, 54, 65, 66, 67, 68, 86], "data": [0, 2, 9, 12, 13, 15, 16, 17, 18, 21, 22, 23, 24, 25, 28, 29, 32, 33, 39, 40, 43, 44, 45, 46, 48, 50, 51, 54, 55, 57, 58, 59, 60, 64, 65, 67, 69, 70, 71, 72, 75, 83, 84, 86, 89], "might": [0, 12, 13, 15, 22, 23, 24, 25, 27, 29, 37, 40, 43, 44, 46, 48, 49, 51, 53, 54, 58, 64, 65, 66, 67, 71, 72, 80, 82, 83, 84, 86], "expect": [0, 15, 16, 22, 23, 25, 27, 29, 31, 33, 40, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 57, 63, 64, 65, 66, 69, 72, 75, 80, 82, 86], "observ": [0, 16, 23, 29, 50, 51, 54, 57, 62, 66, 68, 69, 72, 74, 83], "thi": [0, 2, 7, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 83, 84, 86, 89, 90], "involv": [0, 12, 16, 22, 23, 25, 28, 32, 42, 46, 49, 52, 54, 59, 66, 71, 74, 82, 84], "propos": [0, 38, 39, 49, 52, 53, 54, 64, 80, 83], "draw": [0, 25, 37, 42, 43, 44, 48, 49, 50, 52, 53, 54, 55, 57, 60, 64, 65, 66, 67, 68, 69, 71, 72, 74, 80, 86], "befor": [0, 13, 16, 22, 23, 25, 27, 28, 29, 33, 42, 43, 44, 49, 50, 53, 54, 64, 65, 66, 67, 68, 69, 71, 72, 75, 80, 82, 84, 86, 90], "proceed": [0, 50, 53, 68, 72], "do": [0, 3, 4, 6, 10, 12, 13, 14, 15, 16, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 83, 85, 86], "want": [0, 3, 12, 13, 16, 21, 27, 28, 29, 31, 37, 38, 40, 42, 43, 44, 46, 49, 50, 51, 52, 54, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86], "clarifi": [0, 74], "purpos": [0, 12, 22, 42, 43, 44, 49, 51, 52, 57, 67, 80], "problem": [0, 7, 13, 14, 18, 21, 23, 25, 27, 28, 31, 32, 33, 37, 38, 44, 46, 48, 49, 52, 53, 54, 59, 62, 63, 64, 65, 67, 68, 69, 72, 75, 80, 82, 83, 84, 86], "address": [0, 12, 52, 63, 64, 66, 84], "question": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 50, 51, 52, 54, 64, 75], "mai": [0, 4, 5, 6, 7, 8, 12, 13, 14, 15, 16, 18, 21, 22, 23, 25, 31, 37, 40, 42, 43, 44, 48, 49, 50, 51, 52, 53, 54, 57, 58, 62, 63, 64, 66, 67, 69, 71, 72, 75, 82, 83, 86], "my": [0, 3, 15, 16, 21, 22, 25, 31, 38, 46, 48, 65, 72, 80, 82, 84, 86], "formal": [0, 16, 23, 49, 54, 63], "procedur": [0, 24, 25, 28, 33, 49, 50, 54, 64, 65, 68, 72, 86], "build": [0, 2, 24, 25, 43, 45, 51, 65, 66, 68, 71, 74, 75, 86, 90], "The": [0, 12, 13, 14, 15, 18, 21, 24, 31, 32, 36, 43, 44, 45, 48, 51, 53, 55, 57, 58, 59, 60, 63, 64, 67, 68, 69, 71, 73, 74, 75, 83, 84, 86, 89, 90], "concept": [0, 21, 37, 72, 75, 80, 82, 84, 86], "though": [0, 12, 13, 15, 21, 22, 23, 25, 27, 28, 31, 32, 33, 38, 39, 43, 46, 48, 49, 50, 51, 52, 54, 55, 57, 62, 63, 64, 65, 66, 67, 71, 72, 75, 82, 83, 86], "fairli": [0, 33, 44, 86], "intuit": [0, 2, 16, 25, 29, 49, 54, 65, 80, 82, 90], "At": [0, 12, 23, 25, 43, 66, 80, 86], "point": [0, 3, 4, 16, 25, 28, 31, 33, 37, 42, 43, 44, 45, 46, 49, 50, 51, 52, 54, 55, 57, 63, 64, 67, 68, 69, 71, 72, 75, 80, 82, 86], "re": [0, 22, 29, 31, 33, 37, 42, 46, 48, 52, 53, 62, 66, 67, 68, 69, 82, 86], "ask": [0, 22, 49, 54, 75, 82], "how": [0, 3, 4, 7, 12, 14, 15, 16, 17, 21, 22, 23, 25, 27, 29, 32, 33, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75, 80, 83, 85, 86, 89], "right": [0, 12, 13, 16, 21, 22, 25, 27, 28, 32, 33, 37, 38, 40, 44, 45, 46, 49, 50, 53, 54, 55, 57, 58, 64, 66, 67, 68, 72, 74, 75, 80, 82, 83, 86], "now": [0, 12, 16, 17, 20, 21, 22, 25, 27, 28, 29, 31, 32, 33, 37, 40, 42, 43, 44, 45, 46, 49, 50, 52, 53, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 80, 82, 84, 86], "concern": [0, 12, 23, 42], "some": [0, 10, 12, 13, 14, 15, 16, 21, 22, 23, 25, 32, 40, 42, 43, 44, 45, 46, 49, 51, 52, 53, 54, 55, 57, 60, 62, 63, 64, 65, 66, 67, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86, 89], "definit": [0, 16, 21, 22, 25, 27, 31, 32, 45, 51, 54, 58, 62, 64, 66, 68, 69, 71, 72, 80, 82, 84, 86], "soon": [0, 25, 46], "like": [0, 12, 13, 16, 21, 22, 25, 27, 29, 32, 33, 39, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 57, 58, 62, 63, 64, 65, 66, 68, 69, 72, 75, 80, 82, 83, 84, 86], "likelihood": [0, 3, 4, 8, 18, 20, 23, 25, 26, 28, 29, 30, 32, 33, 42, 44, 45, 50, 51, 52, 54, 55, 59, 60, 62, 64, 65, 67, 68, 70, 72, 74, 83, 84, 86], "function": [0, 13, 15, 16, 18, 21, 22, 23, 25, 27, 28, 29, 31, 32, 33, 37, 40, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 57, 63, 65, 67, 68, 69, 71, 74, 75, 80, 82, 84, 86, 89], "last": [0, 3, 15, 16, 21, 38, 42, 43, 50, 52, 60, 67, 68, 73, 80, 82, 84, 86], "term": [0, 4, 13, 14, 15, 16, 21, 22, 23, 25, 27, 31, 32, 38, 42, 43, 44, 49, 52, 54, 64, 66, 72, 73, 74, 75, 80, 82, 84, 86, 89], "rather": [0, 21, 23, 27, 32, 42, 43, 49, 52, 55, 57, 66, 67, 68, 72, 80], "just": [0, 13, 17, 21, 22, 23, 25, 27, 28, 29, 31, 33, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 59, 65, 66, 67, 68, 69, 71, 72, 75, 80, 82, 84, 86], "yourself": [0, 24, 27, 29, 31, 35, 63, 65], "when": [0, 4, 8, 9, 10, 12, 15, 16, 22, 23, 24, 25, 27, 28, 29, 33, 37, 39, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57, 62, 64, 65, 66, 68, 69, 71, 72, 75, 80, 82, 83, 84, 86], "thing": [0, 13, 16, 22, 23, 27, 40, 42, 43, 46, 48, 66, 69, 80, 82, 83, 84, 86], "later": [0, 14, 25, 27, 28, 39, 40, 46, 49, 52, 74], "suspect": [0, 25, 58, 67, 69], "see": [0, 12, 15, 20, 23, 25, 27, 29, 31, 32, 33, 42, 43, 44, 46, 49, 50, 51, 52, 53, 54, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 80, 82, 84, 86], "close": [0, 23, 25, 27, 31, 32, 33, 45, 50, 51, 53, 63, 64, 65, 66, 67, 69, 72, 80, 82], "match": [0, 22, 24, 25, 27, 29, 49, 51, 55, 63, 65, 86], "That": [0, 12, 13, 16, 17, 21, 22, 23, 25, 27, 29, 31, 42, 44, 49, 51, 52, 53, 54, 57, 62, 63, 64, 65, 66, 67, 72, 75, 80, 86], "said": [0, 16, 25, 29, 37, 38, 42, 43, 49, 58, 80], "most": [0, 12, 13, 15, 23, 25, 27, 28, 31, 32, 33, 38, 39, 40, 42, 43, 46, 48, 49, 51, 52, 54, 57, 58, 60, 63, 65, 66, 67, 72, 75, 80, 82, 84, 86], "take": [0, 2, 10, 12, 13, 14, 15, 16, 22, 23, 25, 27, 31, 33, 37, 38, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 57, 58, 63, 65, 66, 69, 72, 80, 82, 83, 84], "approach": [0, 2, 10, 14, 15, 16, 22, 23, 25, 27, 29, 30, 31, 37, 38, 44, 45, 48, 50, 51, 52, 53, 57, 62, 64, 65, 66, 67, 72, 75, 82, 83, 86, 89], "develop": [0, 2, 25, 49, 72], "cours": [0, 12, 13, 14, 16, 21, 22, 23, 25, 27, 32, 43, 44, 49, 52, 54, 58, 59, 65, 66, 69, 72, 80, 84, 90], "make": [0, 3, 12, 13, 15, 16, 21, 22, 25, 27, 28, 29, 31, 32, 33, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75, 80, 82, 83, 84, 86], "mistak": 0, "ok": [0, 45, 50, 57, 63, 64, 66, 72, 74, 86], "go": [0, 2, 12, 14, 16, 18, 23, 25, 27, 28, 32, 38, 39, 43, 44, 46, 48, 49, 50, 51, 52, 54, 57, 58, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 80, 86], "grade": [0, 2], "detail": [0, 2, 29, 31, 35, 39, 44, 46, 52, 54, 57, 66, 68, 72, 75, 81, 82], "implement": [0, 2, 13, 15, 27, 28, 29, 31, 32, 33, 37, 38, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 57, 61, 65, 66, 67, 68, 69, 71, 72, 80, 84, 86, 90], "our": [0, 12, 13, 15, 16, 17, 21, 22, 23, 24, 25, 27, 29, 31, 33, 37, 38, 40, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 62, 63, 64, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86, 89], "get": [0, 12, 13, 14, 16, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 46, 49, 50, 51, 52, 53, 54, 57, 62, 63, 64, 65, 66, 68, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86], "defin": [0, 16, 18, 21, 22, 23, 25, 27, 31, 32, 33, 37, 38, 42, 43, 45, 48, 49, 51, 54, 59, 60, 62, 63, 64, 66, 67, 68, 69, 72, 74, 75, 80, 82, 84, 86], "probabl": [0, 2, 5, 12, 13, 18, 20, 22, 23, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 58, 60, 62, 64, 65, 66, 67, 68, 72, 74, 80, 82, 83, 90], "distribut": [0, 2, 3, 4, 5, 7, 8, 16, 17, 19, 20, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 45, 49, 52, 53, 54, 55, 57, 59, 60, 62, 63, 64, 65, 67, 68, 69, 71, 72, 75, 80, 82, 84, 89, 90], "describ": [0, 8, 9, 10, 11, 16, 17, 18, 21, 22, 23, 24, 25, 29, 31, 32, 40, 42, 43, 48, 50, 51, 54, 57, 59, 62, 64, 66, 67, 68, 72, 74, 75, 80, 82, 83, 86], "b": [0, 5, 16, 21, 25, 29, 31, 32, 42, 43, 44, 49, 52, 54, 57, 64, 65, 80, 83, 84, 86], "sai": [0, 3, 4, 12, 16, 17, 21, 22, 23, 25, 27, 28, 38, 39, 40, 46, 49, 50, 52, 54, 62, 64, 66, 69, 71, 74, 75, 80, 86], "40": [0, 27, 28, 33, 42, 44, 49, 60, 63, 69, 72, 86], "would": [0, 12, 18, 22, 24, 25, 27, 28, 31, 32, 33, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 57, 58, 60, 64, 65, 66, 67, 69, 71, 72, 74, 80, 82, 83, 84, 86], "out": [0, 5, 6, 12, 13, 16, 22, 23, 25, 27, 28, 29, 31, 33, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 52, 55, 57, 58, 59, 62, 63, 64, 65, 67, 68, 69, 71, 72, 74, 75, 80, 82, 84, 86], "respons": [0, 2, 65], "part": [0, 12, 19, 21, 24, 25, 27, 32, 33, 39, 43, 44, 50, 66, 68, 75, 84], "unfortun": [0, 28, 37, 72, 82], "know": [0, 16, 17, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 39, 40, 44, 45, 48, 49, 51, 53, 54, 57, 64, 66, 68, 75, 80, 82, 83, 86], "paramet": [0, 2, 4, 13, 15, 16, 17, 18, 20, 21, 23, 25, 26, 28, 29, 37, 38, 39, 40, 41, 43, 44, 45, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 63, 64, 65, 67, 68, 69, 71, 72, 74, 80, 82, 83, 84, 90], "valu": [0, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 60, 62, 63, 64, 65, 67, 68, 69, 71, 72, 74, 80, 82, 83, 84], "chose": [0, 24, 25, 28, 33, 50, 58, 67, 69, 80, 83, 86], "In": [0, 2, 12, 13, 14, 15, 16, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 38, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86], "fact": [0, 13, 16, 23, 25, 27, 28, 29, 31, 32, 42, 49, 52, 53, 54, 65, 69, 72, 74, 80, 84], "ahead": [0, 17, 43, 51, 52, 54, 65, 71, 75, 90], "write": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 16, 18, 21, 22, 23, 25, 27, 28, 29, 31, 32, 33, 38, 40, 43, 44, 49, 51, 54, 62, 63, 66, 68, 69, 72, 74, 75, 80, 82, 83, 86, 89], "down": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 18, 22, 23, 25, 27, 28, 29, 32, 33, 40, 49, 51, 53, 54, 63, 66, 74, 80], "context": [0, 9, 18, 22, 23, 25, 27, 33, 42, 49, 52, 66, 80, 84], "full": [0, 11, 12, 13, 23, 31, 32, 33, 48, 51, 67, 72, 74, 75, 83], "specif": [0, 13, 16, 22, 27, 32, 37, 43, 46, 49, 52, 54, 57, 58, 62, 63, 64, 66, 67, 68, 69, 71, 72, 74, 75, 82, 84], "c": [0, 12, 16, 22, 24, 25, 43, 51, 52, 62, 66, 72], "To": [0, 2, 12, 13, 15, 16, 18, 20, 22, 25, 27, 28, 31, 32, 33, 35, 37, 38, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54, 57, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86], "one": [0, 12, 13, 15, 16, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 42, 43, 44, 45, 48, 49, 50, 51, 52, 57, 58, 62, 64, 65, 66, 69, 71, 72, 75, 80, 82, 83, 84, 86], "follow": [0, 3, 12, 13, 14, 15, 16, 18, 25, 27, 28, 33, 37, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 55, 63, 64, 65, 66, 67, 68, 69, 71, 74, 75, 80, 82, 83, 84, 86], "construct": [0, 3, 16, 23, 27, 28, 31, 42, 44, 46, 49, 50, 63, 64, 65, 66, 67, 68, 69, 75, 82, 84, 86], "those": [0, 12, 13, 18, 22, 25, 27, 28, 39, 40, 43, 44, 49, 50, 53, 54, 63, 64, 65, 66, 67, 71, 72, 82], "parametr": [0, 22, 25, 29, 42, 48, 49, 52, 53, 54, 58, 65, 66, 67, 69, 72, 82], "can": [0, 7, 8, 9, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86, 89], "mani": [0, 12, 13, 15, 20, 22, 24, 25, 29, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 48, 49, 51, 52, 53, 60, 63, 66, 67, 69, 72, 74, 75, 80, 82, 83, 84, 86, 89], "plot": [0, 2, 6, 13, 15, 23, 25, 28, 31, 32, 33, 34, 37, 40, 43, 45, 48, 49, 50, 52, 53, 54, 55, 57, 60, 63, 65, 67, 68, 69, 71, 72, 74, 80, 82, 84, 86, 90], "them": [0, 2, 16, 25, 27, 29, 37, 38, 39, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 54, 55, 60, 63, 64, 66, 67, 68, 75, 80, 84, 86, 89], "should": [0, 12, 13, 15, 16, 21, 22, 24, 25, 27, 28, 29, 31, 33, 35, 37, 42, 43, 44, 49, 50, 51, 52, 53, 54, 55, 57, 63, 64, 65, 66, 67, 69, 72, 75, 80, 82, 84, 86], "carefulli": [0, 16, 21, 45, 49, 57, 63, 67, 75], "best": [0, 6, 12, 13, 25, 29, 45, 48, 50, 54, 55, 57, 66, 72, 75, 80, 89], "clear": [0, 16, 28, 29, 32, 40, 44, 51, 55, 66, 68, 75, 80, 82, 83, 86, 89], "come": [0, 12, 22, 23, 25, 27, 29, 33, 37, 40, 42, 43, 44, 45, 49, 51, 53, 57, 58, 59, 63, 64, 65, 66, 67, 74, 80, 82, 83, 86], "doe": [0, 5, 6, 10, 12, 13, 16, 21, 22, 24, 25, 27, 31, 33, 38, 42, 43, 44, 48, 49, 52, 53, 54, 57, 63, 65, 66, 67, 69, 71, 72, 75, 76, 80, 82, 84, 85, 86], "jibe": 0, "If": [0, 2, 6, 7, 9, 12, 13, 15, 16, 21, 22, 23, 25, 27, 28, 29, 32, 33, 37, 38, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 58, 63, 64, 65, 66, 68, 69, 72, 74, 75, 80, 82, 83, 84, 86], "have": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86, 89], "ani": [0, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 22, 23, 25, 27, 29, 31, 32, 33, 37, 38, 40, 42, 43, 44, 48, 49, 51, 53, 54, 58, 62, 63, 64, 65, 66, 71, 72, 75, 76, 80, 82, 84, 85, 86, 87], "idea": [0, 5, 11, 16, 24, 25, 29, 36, 42, 44, 48, 49, 52, 54, 55, 57, 64, 66, 80, 82], "why": [0, 3, 4, 5, 6, 7, 8, 9, 21, 27, 36, 44, 46, 57, 63, 65, 72, 75, 80, 82, 83, 84, 86], "d": [0, 12, 15, 21, 22, 23, 25, 27, 28, 31, 32, 33, 37, 38, 40, 45, 46, 49, 50, 53, 54, 55, 57, 64, 66, 68, 72, 74, 80, 82], "until": [0, 64, 80, 84], "through": [0, 2, 12, 13, 14, 22, 25, 29, 32, 33, 40, 44, 46, 54, 63, 65, 66, 67, 68, 75, 80, 82, 84], "complet": [0, 2, 12, 15, 22, 27, 28, 29, 31, 33, 40, 43, 45, 49, 52, 58, 63, 64, 65, 66, 67, 71, 72, 75, 80, 82, 84], "access": [0, 12, 23, 37, 42, 43, 44, 48, 52, 75], "here": [0, 12, 16, 21, 22, 23, 25, 27, 31, 33, 37, 38, 39, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 80, 82, 84, 86], "extract": [0, 31, 33, 43, 49, 67, 68, 72, 84], "made": [0, 7, 12, 27, 42, 49, 51, 75, 80, 89], "nicrophoru": 0, "orbicolli": 0, "locat": [0, 7, 12, 22, 25, 29, 31, 43, 45, 51, 53, 60, 63, 67, 75, 80, 84, 86], "10": [0, 2, 13, 15, 22, 25, 27, 28, 29, 31, 32, 33, 37, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 80, 84, 86, 90], "0": [0, 2, 12, 13, 15, 25, 27, 28, 29, 31, 32, 33, 34, 37, 38, 39, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 80, 82, 84, 86, 90], "fall": [0, 48, 65, 66, 80, 82], "within": [0, 12, 25, 39, 42, 44, 45, 49, 50, 52, 54, 65, 75, 82, 84], "homework": [1, 12, 13, 23, 25, 51, 62, 87], "first": [1, 12, 13, 16, 17, 21, 22, 23, 25, 27, 28, 29, 31, 33, 37, 38, 39, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75, 80, 82, 83, 84, 86], "attempt": [1, 3, 25, 48, 53, 54, 72, 75], "bayesian": [1, 2, 18, 24, 25, 27, 28, 30, 31, 37, 39, 40, 42, 43, 48, 49, 52, 54, 64, 65, 74, 80, 82, 89, 90], "70": [1, 48, 50, 52, 55, 63, 72, 74], "pt": 1, "prequel": [2, 27], "tool": [2, 15, 16, 31, 33, 54, 75, 83, 89], "analysi": [2, 10, 16, 23, 25, 27, 33, 39, 40, 43, 44, 45, 49, 65, 66, 68, 69, 72, 75, 83, 84, 89], "pipelin": [2, 49, 65], "includ": [2, 12, 13, 14, 15, 16, 21, 23, 25, 31, 32, 37, 40, 42, 43, 44, 46, 48, 49, 50, 52, 54, 55, 57, 63, 64, 65, 66, 68, 72, 75, 80, 82, 83, 84, 86], "organ": [2, 42, 57, 63], "preserv": [2, 51, 82], "share": [2, 12, 25], "displai": [2, 44, 49, 52, 53, 66, 68, 72, 74, 75, 90], "quantit": [2, 16, 49, 50], "basic": [2, 5, 11, 36, 42, 46, 72, 80, 82, 84, 86], "techniqu": [2, 25, 37, 42, 43, 46, 52, 54, 57, 64, 68, 72, 82], "resampl": [2, 43, 82], "method": [2, 13, 16, 23, 24, 27, 28, 31, 32, 33, 39, 42, 43, 44, 45, 46, 49, 50, 52, 54, 57, 63, 64, 67, 68, 72, 80, 84], "frequentist": [2, 25, 32, 43], "deeper": [2, 63], "model": [2, 3, 5, 6, 9, 10, 13, 15, 16, 18, 19, 21, 24, 25, 29, 30, 32, 37, 40, 43, 48, 51, 58, 64, 66, 67, 68, 71, 75, 80, 82, 84, 86, 89, 90], "mostli": [2, 25, 33, 64, 65, 82], "discuss": [2, 13, 15, 16, 21, 23, 25, 27, 32, 33, 37, 39, 40, 42, 44, 46, 49, 50, 52, 57, 59, 64, 66, 67, 74, 75, 80, 89], "gener": [2, 3, 6, 13, 16, 18, 22, 23, 24, 25, 27, 28, 31, 32, 33, 36, 39, 40, 43, 44, 46, 48, 50, 51, 52, 53, 54, 55, 57, 61, 62, 64, 66, 67, 68, 71, 72, 74, 75, 80, 82, 83, 84, 86], "estim": [2, 4, 13, 15, 16, 18, 23, 25, 26, 27, 29, 37, 38, 41, 45, 46, 49, 51, 52, 57, 60, 62, 63, 64, 65, 67, 68, 72, 82, 83, 86, 90], "comparison": [2, 49, 50, 53, 55, 69, 72, 86, 90], "hierarch": [2, 9, 15, 23, 25, 49, 51, 66, 69, 90], "markov": [2, 5, 23, 25, 28, 32, 35, 37, 40, 41, 43, 49, 50, 52, 64, 71, 90], "chain": [2, 5, 7, 23, 25, 28, 32, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 49, 50, 52, 53, 55, 57, 59, 62, 63, 64, 65, 66, 68, 69, 71, 80, 82, 84, 86, 90], "mont": [2, 5, 23, 25, 28, 32, 35, 38, 40, 41, 43, 49, 50, 64, 71, 86, 90], "carlo": [2, 5, 23, 25, 28, 32, 35, 38, 40, 41, 43, 49, 50, 64, 71, 86, 90], "graphic": [2, 6, 8, 32, 37, 49, 53, 63, 64, 74, 75, 84], "result": [2, 16, 23, 24, 25, 27, 28, 31, 32, 33, 38, 42, 43, 44, 46, 49, 50, 52, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 72, 74, 75, 80, 82, 84, 86, 89], "principl": [2, 10, 25, 49, 51, 54, 65, 66, 82, 83, 90], "workflow": [2, 23, 49, 75, 84, 90], "all": [2, 12, 13, 16, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 38, 40, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 80, 84, 86], "topic": [2, 25, 35, 52, 58, 66, 80, 84], "explor": [2, 16, 23, 24, 25, 27, 29, 31, 43, 46, 49, 50, 53, 63, 66, 80, 82, 84, 86, 89], "real": [2, 13, 15, 16, 21, 25, 32, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 84, 86], "enrol": 2, "pleas": [2, 9, 25, 29, 64, 66, 75], "read": [2, 13, 22, 24, 31, 36, 37, 39, 43, 44, 51, 52, 54, 57, 62, 63, 64, 65, 72, 80, 83, 84, 90], "below": [2, 13, 15, 16, 21, 29, 33, 37, 43, 44, 45, 46, 48, 49, 50, 52, 53, 57, 63, 64, 66, 68, 71, 74, 75, 80, 82, 84, 86], "over": [2, 16, 20, 25, 27, 28, 29, 33, 38, 39, 40, 44, 49, 54, 57, 62, 64, 65, 66, 68, 69, 72, 74, 75, 80, 82, 84, 86], "understand": [2, 16, 22, 29, 31, 37, 40, 44, 49, 57, 63, 66, 72, 75, 80], "ed": [2, 75, 89], "commun": [2, 13, 42, 86], "canva": [2, 75], "assign": [2, 16, 21, 25, 43, 44, 49, 82, 84], "submiss": [2, 84], "return": [2, 21, 27, 28, 31, 32, 33, 37, 39, 42, 43, 44, 45, 46, 49, 50, 55, 57, 66, 67, 68, 69, 71, 72, 74, 80, 82, 84, 86], "solut": [2, 66, 71, 72, 75, 80, 82, 84], "password": [2, 84], "protect": [2, 57, 67, 68], "instructor": [2, 75, 90], "justin": [2, 84], "boi": [2, 43, 67, 68, 84], "caltech": [2, 12, 13, 14, 27, 31, 42, 75, 86], "dot": [2, 44, 80, 83], "edu": [2, 13, 27, 31, 42, 75, 84, 86], "ta": [2, 75, 76, 82, 87, 90], "kayla": 2, "jackson": 2, "comput": [2, 3, 4, 8, 12, 16, 20, 21, 22, 23, 25, 37, 38, 39, 40, 54, 59, 62, 63, 64, 74, 82, 84], "1": [2, 13, 15, 16, 20, 21, 22, 23, 25, 27, 28, 29, 31, 32, 33, 34, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 76, 80, 82, 83, 84, 86, 90], "logic": [2, 21, 46, 54, 66, 84, 89, 90], "scientif": [2, 13, 84, 89, 90], "reason": [2, 16, 22, 25, 27, 31, 32, 42, 44, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 84, 86, 89], "2": [2, 13, 15, 16, 21, 22, 25, 27, 28, 29, 31, 32, 33, 34, 37, 40, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 75, 77, 80, 82, 83, 84, 86, 87, 90], "introduct": [2, 35, 43, 52, 80, 86, 90], "3": [2, 13, 15, 16, 21, 25, 28, 29, 31, 32, 33, 40, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 57, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 79, 80, 82, 83, 84, 86, 90], "posterior": [2, 3, 4, 6, 8, 10, 13, 15, 17, 18, 20, 22, 25, 28, 33, 37, 38, 40, 43, 44, 45, 47, 49, 51, 52, 53, 55, 57, 58, 59, 60, 62, 63, 64, 65, 68, 69, 72, 80, 82, 84, 86, 90], "4": [2, 13, 15, 21, 25, 27, 29, 31, 32, 33, 38, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86, 90], "margin": [2, 3, 16, 19, 21, 22, 23, 31, 32, 33, 38, 40, 44, 45, 48, 51, 60, 64, 66, 67, 69, 71, 72, 74, 82, 90], "numer": [2, 23, 31, 32, 33, 44, 54, 62, 66, 67, 71, 82, 84, 86], "quadratur": [2, 33], "5": [2, 13, 15, 21, 22, 25, 27, 28, 31, 32, 33, 34, 37, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 55, 57, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 83, 84, 86, 90], "conjugaci": [2, 28, 66, 90], "e1": 2, "after": [2, 15, 16, 22, 23, 28, 29, 33, 37, 42, 43, 49, 50, 52, 54, 64, 65, 69, 71, 72, 75, 80, 82, 83, 86], "6": [2, 21, 27, 28, 31, 32, 33, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 80, 84, 85, 86, 90], "optim": [2, 4, 23, 27, 28, 38, 42, 43, 57, 69, 70, 71, 72, 80, 84, 90], "e2": 2, "7": [2, 13, 15, 25, 27, 28, 31, 33, 34, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 80, 84, 86, 90], "8": [2, 13, 15, 27, 28, 29, 31, 32, 33, 34, 42, 43, 44, 45, 48, 49, 50, 52, 53, 55, 57, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 84, 86, 87, 90], "mcmc": [2, 7, 9, 12, 23, 25, 36, 38, 39, 43, 49, 50, 53, 54, 57, 60, 64, 65, 66, 70, 72, 74, 80, 82, 86, 89, 90], "stan": [2, 12, 13, 25, 35, 38, 39, 44, 46, 50, 51, 52, 53, 55, 57, 59, 60, 64, 65, 74, 75, 82, 89, 90], "9": [2, 13, 15, 27, 28, 31, 33, 42, 43, 49, 50, 52, 53, 55, 57, 60, 62, 63, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 84, 86, 88, 90], "mixtur": [2, 48, 90], "label": [2, 54, 57, 58, 63, 74, 80, 83, 86, 90], "switch": [2, 57, 58, 90], "variat": [2, 11, 22, 23, 27, 28, 30, 43, 46, 49, 62, 66, 69, 84, 90], "covari": [2, 22, 30, 31, 32, 46, 51, 67, 69, 71, 72, 80, 82, 90], "e3": 2, "11": [2, 13, 15, 27, 28, 29, 31, 32, 33, 42, 43, 44, 46, 49, 50, 51, 52, 53, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 80, 84, 86, 90], "12": [2, 13, 15, 27, 28, 31, 33, 42, 43, 44, 45, 46, 48, 50, 51, 52, 53, 55, 57, 60, 62, 63, 65, 66, 67, 68, 69, 71, 72, 74, 84, 86, 90], "predict": [2, 6, 8, 10, 16, 33, 42, 43, 45, 51, 55, 57, 60, 64, 65, 68, 72, 83, 84, 86, 90], "check": [2, 6, 8, 9, 10, 12, 13, 29, 35, 42, 43, 44, 45, 53, 55, 57, 60, 64, 66, 68, 69, 72, 75, 80, 83, 84, 86, 90], "13": [2, 27, 28, 31, 33, 42, 43, 44, 45, 46, 48, 49, 52, 53, 55, 57, 63, 65, 66, 67, 68, 69, 72, 74, 84, 86, 90], "e4": 2, "14": [2, 27, 28, 31, 33, 42, 43, 44, 46, 49, 50, 52, 53, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 84, 86, 90], "collector": [2, 90], "": [2, 6, 12, 13, 14, 15, 19, 20, 22, 23, 25, 27, 28, 31, 32, 35, 37, 38, 39, 42, 43, 44, 45, 46, 48, 50, 52, 53, 54, 55, 57, 59, 60, 62, 63, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 86, 89, 90], "box": [2, 16, 37, 82, 90], "15": [2, 13, 15, 27, 28, 29, 31, 32, 33, 42, 43, 44, 48, 49, 50, 53, 57, 60, 63, 65, 66, 67, 68, 69, 72, 80, 84, 86, 90], "diagnost": [2, 7, 9, 39, 44, 46, 55, 57, 60, 65, 66, 68, 69, 71, 74, 82, 86, 90], "16": [2, 13, 15, 27, 33, 42, 43, 44, 46, 49, 50, 52, 57, 63, 65, 66, 67, 68, 69, 72, 80, 84, 86, 90], "A": [2, 16, 18, 21, 22, 24, 25, 30, 32, 37, 43, 44, 46, 48, 50, 52, 54, 58, 65, 66, 68, 75, 83, 84, 86, 89], "case": [2, 12, 20, 21, 22, 23, 24, 25, 27, 28, 30, 32, 33, 37, 38, 40, 42, 43, 44, 45, 48, 49, 50, 51, 52, 54, 57, 58, 59, 62, 63, 64, 65, 66, 67, 68, 72, 74, 75, 80, 82, 84, 86, 89], "studi": [2, 16, 23, 30, 42, 44, 45, 49, 62, 63, 66, 69, 72, 83, 86, 89], "artifici": [2, 48], "funnel": [2, 63, 69, 72, 82, 90], "hell": [2, 90], "e5": 2, "17": [2, 12, 27, 33, 42, 43, 44, 49, 50, 52, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 84, 86, 90], "18": [2, 13, 15, 27, 42, 43, 44, 45, 48, 49, 50, 52, 55, 57, 60, 62, 63, 65, 66, 68, 69, 72, 80, 86, 90], "practic": [2, 16, 22, 25, 37, 44, 51, 52, 54, 66, 75, 80, 82, 84, 90], "e6": 2, "19": [2, 27, 32, 42, 43, 44, 49, 52, 57, 65, 66, 68, 69, 72, 86, 90], "20": [2, 12, 13, 15, 22, 27, 31, 32, 33, 42, 43, 44, 49, 50, 52, 55, 57, 60, 65, 66, 67, 68, 69, 71, 72, 75, 86, 90], "e7": 2, "21": [2, 27, 28, 31, 33, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 55, 57, 63, 65, 66, 72, 86, 90], "22": [2, 49, 51, 57, 63, 66, 69, 72, 84, 86, 90], "simul": [2, 10, 12, 49, 84, 86, 90], "base": [2, 10, 12, 13, 16, 22, 23, 25, 42, 43, 44, 48, 49, 51, 52, 54, 55, 66, 67, 72, 74, 80, 83, 84, 86, 89, 90], "calibr": [2, 10, 12, 49, 84, 90], "relat": [2, 10, 21, 22, 25, 31, 32, 37, 49, 53, 54, 64, 66, 75, 82, 84], "e8": 2, "23": [2, 44, 46, 49, 63, 65, 72, 86], "gaussian": [2, 11, 22, 28, 59, 68, 71, 72, 74, 82], "process": [2, 12, 13, 16, 20, 22, 23, 24, 37, 42, 43, 49, 50, 51, 53, 54, 64, 68, 71, 74, 82, 83, 86], "24": [2, 44, 46, 49, 65, 71, 72, 75, 86, 90], "25": [2, 13, 15, 27, 28, 31, 33, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 63, 65, 66, 67, 68, 69, 71, 84, 86, 90], "e9": 2, "26": [2, 13, 15, 27, 28, 29, 31, 32, 33, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 80, 86, 90], "wrap": [2, 90], "overview": [2, 81, 84], "due": [2, 13, 16, 25, 49, 54, 68, 75, 80, 84, 86], "date": [2, 75], "exercis": [2, 12, 27, 48, 49, 57], "weekli": [2, 75], "meet": 2, "lab": [2, 12, 42, 65, 83, 84, 90], "session": [2, 12, 13, 43, 79, 88], "collabor": [2, 13], "honor": 2, "code": [2, 12, 13, 15, 22, 27, 28, 31, 33, 42, 45, 46, 48, 49, 50, 52, 53, 55, 57, 65, 66, 67, 68, 69, 71, 72, 74, 86], "ediquett": 2, "softwar": [2, 12, 38], "tutori": [2, 53, 57, 84], "winter": 2, "2024": [2, 13, 42, 43, 44, 57], "2022": 2, "2021": [2, 52], "2020": [2, 39], "indic": [3, 31, 44, 46, 49, 51, 52, 53, 55, 57, 58, 60, 63, 64, 65, 66, 68, 69, 71, 74, 75, 80, 86], "statement": [3, 44, 45, 49, 66, 71, 74], "sens": [3, 16, 21, 22, 25, 27, 28, 29, 32, 33, 49, 54, 62, 64, 65, 66, 82, 83, 86], "find": [3, 4, 12, 13, 20, 22, 23, 24, 25, 27, 28, 31, 32, 33, 44, 48, 49, 51, 54, 57, 64, 66, 67, 68, 71, 72, 75, 80, 82, 84, 89], "conjug": [3, 66], "curs": [3, 23, 27], "dimension": [3, 22, 23, 25, 27, 43, 44, 46, 50, 57, 66, 71, 80], "appear": [3, 12, 13, 27, 49, 72, 83], "few": [3, 14, 23, 25, 27, 29, 33, 39, 42, 43, 44, 45, 48, 49, 52, 54, 55, 57, 63, 64, 65, 66, 69, 72, 84, 86], "confus": [3, 4, 65, 66, 75], "map": [4, 33, 44, 48, 60, 66, 68, 71, 82, 84], "local": [4, 13, 15, 23, 28, 31, 32, 66, 84], "approxim": [4, 22, 23, 28, 37, 40, 42, 46, 48, 49, 51, 52, 53, 54, 57, 59, 63, 66, 68, 72, 80, 83, 86], "possibli": [4, 40, 46, 63, 64, 66, 86], "multivari": [4, 22, 23, 25, 32, 33, 51, 66, 69, 80, 82], "normal": [4, 13, 15, 23, 24, 25, 28, 29, 30, 37, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 55, 57, 58, 60, 63, 65, 67, 68, 70, 72, 74, 80, 84, 86], "mean": [4, 5, 6, 10, 11, 12, 13, 15, 16, 22, 24, 25, 27, 31, 33, 37, 39, 40, 42, 43, 44, 48, 49, 51, 52, 53, 54, 57, 58, 62, 63, 64, 65, 67, 68, 69, 71, 72, 74, 75, 80, 82, 84, 86], "ha": [4, 12, 15, 16, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 37, 38, 39, 42, 43, 44, 46, 49, 51, 52, 53, 54, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 69, 71, 72, 75, 80, 82, 83, 84, 86, 89], "stori": [4, 22, 24, 25, 29, 44, 51, 80, 86], "meant": [4, 12, 44, 64, 82], "weakli": [4, 31, 45, 49, 58, 62, 63], "inform": [4, 12, 13, 16, 17, 21, 27, 28, 29, 31, 33, 43, 45, 48, 49, 50, 52, 55, 57, 58, 63, 64, 65, 72, 80, 82, 84, 86, 90], "credibl": [4, 33, 45, 46, 48, 60, 66, 67, 68, 71], "interv": [4, 25, 29, 33, 37, 43, 44, 45, 46, 48, 51, 59, 60, 64, 65, 66, 67, 68, 71, 80, 83], "off": [4, 22, 27, 31, 43, 45, 51, 53, 62, 65, 66, 68, 80, 82], "true": [4, 15, 16, 25, 27, 42, 43, 44, 45, 46, 48, 49, 53, 54, 55, 57, 60, 63, 64, 65, 66, 71, 72, 74, 80, 84, 86], "explain": [5, 7, 9, 68, 75, 83], "word": [5, 8, 11, 16, 23, 37, 42, 45, 49, 54, 62, 64, 66, 84], "being": [5, 10, 13, 25, 27, 29, 42, 43, 45, 49, 51, 52, 54, 63, 66, 69, 71, 72, 75, 82], "abl": [5, 28, 33, 37, 40, 42, 46, 49, 52, 54, 63, 65, 66, 75, 82, 83, 84, 86], "behind": [5, 11, 22, 29, 36, 42, 54, 57, 72, 75], "import": [5, 6, 9, 13, 15, 16, 21, 22, 24, 27, 28, 29, 31, 32, 33, 34, 37, 38, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 84, 86], "warm": [5, 36, 42, 52, 80, 82], "sampler": [5, 7, 35, 38, 39, 42, 43, 44, 46, 50, 53, 55, 63, 64, 80, 86], "nonidentifi": [5, 44], "contend": 6, "fit": [6, 12, 16, 45, 49, 62, 66, 69, 89], "line": [6, 12, 15, 22, 25, 27, 28, 29, 31, 32, 34, 42, 43, 44, 45, 46, 48, 49, 65, 66, 67, 68, 69, 71, 80, 82, 84, 86], "suffici": [6, 22, 27, 37, 38, 67], "assess": [6, 25, 31, 42, 44, 49, 51, 57, 64], "further": [6, 16, 27, 36, 49, 54, 63, 65, 66, 72], "better": [6, 25, 37, 44, 46, 50, 54, 55, 57, 63, 65, 66, 69, 72, 75], "agre": [6, 16, 25, 52, 54], "good": [6, 22, 27, 28, 32, 33, 39, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57, 58, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 80, 84, 86, 89], "number": [7, 12, 13, 15, 16, 21, 22, 23, 25, 27, 29, 36, 40, 42, 43, 44, 46, 48, 49, 50, 52, 54, 57, 60, 62, 63, 64, 65, 69, 71, 72, 75, 80, 82, 83, 84, 86], "effect": [7, 13, 15, 16, 23, 25, 31, 37, 42, 46, 51, 53, 55, 57, 58, 60, 62, 63, 65, 66, 68, 69, 71, 72, 74, 75, 80, 82, 86], "independ": [7, 11, 22, 24, 25, 27, 28, 33, 37, 44, 45, 51, 52, 53, 54, 55, 57, 58, 60, 63, 66, 72, 74, 80, 86], "usual": [7, 13, 16, 27, 33, 43, 45, 49, 51, 52, 54, 57, 60, 64, 66, 67, 68, 69, 80, 84, 86], "less": [7, 21, 25, 27, 37, 42, 49, 52, 57, 64, 65, 82, 84, 86], "than": [7, 12, 16, 21, 22, 23, 25, 27, 29, 31, 32, 33, 37, 39, 42, 43, 44, 48, 49, 51, 52, 54, 57, 58, 60, 62, 64, 65, 66, 68, 72, 74, 75, 80, 82, 84, 86], "total": [7, 12, 31, 33, 48, 50, 52, 54, 55, 62, 63, 65, 66, 72, 75, 80, 82, 84, 86], "diverg": [7, 25, 43, 44, 53, 55, 57, 60, 63, 65, 66, 68, 69, 71, 72, 74, 82, 86], "diagnos": [7, 46, 53, 63, 64, 65], "potenti": [7, 46, 80, 82, 86], "ever": [7, 12, 53, 72, 80], "guarante": [7, 15, 25, 31, 32, 44, 52, 72], "properli": [7, 27, 42, 43, 45, 46, 52, 53, 63, 64, 65, 68, 75, 86], "finit": [7, 37, 42, 68, 82], "step": [7, 12, 15, 16, 23, 27, 31, 33, 37, 38, 39, 43, 46, 49, 50, 52, 53, 54, 59, 63, 64, 66, 69, 72, 80, 82, 84, 86], "answer": [7, 43, 50, 51, 52, 54, 75, 83, 84, 86], "ye": [7, 43, 50], "stop": [7, 49, 57, 64, 72, 82], "underscor": [7, 44, 54], "need": [7, 12, 13, 14, 15, 16, 21, 22, 23, 24, 27, 28, 31, 33, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 62, 63, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86], "extens": [7, 44, 80, 84], "pointwis": [8, 55, 86], "log": [8, 12, 13, 25, 28, 31, 32, 33, 42, 44, 48, 49, 50, 51, 53, 55, 63, 65, 67, 68, 72, 80, 82], "still": [8, 22, 25, 32, 38, 42, 46, 48, 49, 50, 51, 53, 54, 57, 63, 65, 66, 72, 80, 84, 86], "necessari": [8, 12, 13, 27, 38, 39, 40, 44, 48, 51, 52, 63, 69, 75], "inde": [8, 21, 22, 23, 42, 43, 44, 49, 66, 71, 74], "essenti": [8, 22, 43, 52, 63, 75, 82, 84], "waic": [8, 54], "loo": [8, 54, 55], "tidi": [9, 46, 63], "format": [9, 15, 31, 33, 43, 49, 60, 67, 68, 80], "encount": [9, 21, 25, 27, 32, 43, 52, 65, 66, 67, 68, 69, 80, 83, 86], "structur": [9, 16, 28, 43, 44, 51, 69, 72, 75, 82, 84], "own": [9, 12, 13, 14, 15, 16, 43, 66, 68, 72, 75, 82, 84], "work": [9, 12, 13, 14, 15, 16, 22, 25, 27, 28, 31, 32, 35, 38, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 71, 75, 80, 82, 83, 84, 86, 90], "briefli": [9, 43, 46, 80], "situat": [9, 25, 57, 58, 86], "exchang": 9, "thoroughli": [9, 72], "especi": [9, 29, 31, 44, 48, 57, 75, 80, 84, 89], "addit": [9, 10, 11, 13, 23, 27, 44, 54, 60, 72, 82, 84, 86], "z": [10, 16, 65, 66, 68, 71, 74], "score": [10, 65], "help": [10, 12, 17, 18, 27, 46, 49, 50, 51, 52, 53, 55, 64, 66, 75, 82, 84, 86, 90], "verifi": [10, 13, 15, 43, 50, 64, 67, 75], "shrinkag": [10, 65], "rank": [10, 11, 48, 52, 53, 55, 57, 63, 65, 72, 80, 86], "statist": [10, 12, 14, 15, 22, 39, 40, 43, 44, 48, 49, 51, 54, 63, 65, 66, 72, 80, 86, 89], "possibl": [10, 15, 16, 20, 22, 24, 25, 37, 43, 44, 45, 46, 48, 49, 54, 63, 64, 65, 66, 72, 80, 82, 84, 86], "pitfal": 10, "By": [10, 17, 22, 25, 40, 46, 52, 57, 64, 66, 80], "cautiou": 10, "sbc": [10, 12, 49, 64, 84], "analys": [10, 13, 23, 64, 84], "infer": [11, 12, 14, 18, 23, 25, 27, 28, 31, 32, 43, 44, 49, 52, 54, 60, 64, 65, 67, 68, 69, 89, 90], "elbo": [11, 72], "advantag": [11, 14, 15, 25, 29, 48, 49, 54, 62, 66, 82, 86], "disadvantag": [11, 14, 29], "field": [11, 72, 80, 82, 83], "famili": [11, 23, 66, 72, 82], "comment": [11, 43, 66, 75, 84], "start": [12, 15, 16, 23, 25, 27, 28, 31, 33, 39, 42, 43, 44, 45, 46, 48, 49, 52, 53, 57, 63, 64, 66, 67, 68, 69, 80, 82, 83, 84, 86], "more": [12, 13, 16, 17, 21, 22, 23, 25, 27, 28, 29, 31, 33, 35, 38, 39, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 81, 82, 84, 86], "run": [12, 13, 14, 15, 16, 27, 33, 42, 43, 44, 49, 52, 53, 63, 64, 65, 69, 72, 75, 82, 86], "calcul": [12, 14, 16, 22, 23, 25, 28, 29, 31, 33, 42, 43, 48, 49, 51, 52, 54, 55, 64, 65, 66, 70, 71, 72, 74, 75, 82, 84, 85, 86], "power": [12, 15, 40, 42, 43, 44, 52, 54, 64, 66, 80, 84], "while": [12, 25, 27, 28, 29, 31, 38, 39, 42, 43, 44, 46, 49, 52, 54, 64, 66, 67, 69, 72, 75, 80, 82, 84, 86], "instal": [12, 13, 42, 43, 84, 86], "suffic": [12, 31, 49], "serv": [12, 16, 17, 29, 42, 49, 60, 66, 67, 80], "well": [12, 13, 15, 22, 23, 24, 25, 27, 31, 32, 33, 40, 43, 44, 46, 50, 54, 57, 58, 62, 65, 66, 67, 68, 80, 82, 86], "expans": [12, 32], "resourc": [12, 13, 15, 32, 75, 84], "avail": [12, 13, 25, 27, 42, 43, 48, 49, 50, 52, 55, 65, 71, 75, 84, 89], "option": [12, 27, 31, 46, 49, 75, 82, 84], "googl": [12, 14, 15, 42, 43, 75, 86], "cloud": [12, 13, 14, 15], "platform": [12, 13], "microsoft": [12, 13, 14], "azur": [12, 14], "high": [12, 14, 22, 25, 32, 39, 46, 52, 53, 66, 67, 68, 80, 84], "center": [12, 25, 32, 44, 48, 49, 53, 63, 67, 68, 69, 71, 80, 86], "lesson": [12, 14, 15, 23, 25, 27, 28, 31, 32, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 57, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 84], "show": [12, 13, 15, 25, 27, 28, 29, 31, 32, 33, 34, 38, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 84, 86], "lot": [12, 16, 27, 42, 43, 46, 50, 51, 54, 55, 63, 66, 69, 86], "done": [12, 16, 22, 23, 31, 42, 43, 44, 46, 49, 54, 57, 62, 63, 66, 69, 71, 80, 82, 84, 86], "onli": [12, 13, 16, 22, 23, 25, 27, 29, 31, 33, 37, 38, 40, 44, 46, 49, 51, 52, 54, 62, 63, 65, 66, 68, 71, 72, 74, 75, 80, 83, 84, 86], "onc": [12, 13, 39, 43, 50, 66, 80, 82, 84, 86], "much": [12, 13, 15, 16, 21, 22, 23, 27, 28, 31, 32, 33, 38, 40, 43, 44, 48, 49, 50, 51, 52, 53, 54, 55, 57, 63, 64, 65, 66, 67, 68, 69, 72, 75, 80, 82, 86], "initi": [12, 28, 29, 31, 33, 49, 51, 57, 67, 68, 80, 82, 86], "next": [12, 13, 16, 17, 25, 27, 28, 31, 32, 33, 37, 38, 43, 49, 50, 51, 60, 62, 66, 67, 72, 80, 82, 86], "quick": [12, 13, 27, 31, 33, 42, 45, 46, 49, 50, 52, 53, 54, 57, 65, 66, 69, 72, 86, 89], "refer": [12, 16, 22, 25, 32, 43, 44, 45, 48, 52, 54, 66, 68, 72, 75, 82, 86, 89], "spin": [12, 86], "outlin": [12, 39, 57, 68, 75, 82], "alreadi": [12, 13, 15, 17, 21, 23, 31, 32, 33, 37, 42, 44, 46, 49, 54, 66, 68, 69, 72, 82, 84], "cost": [12, 64], "100": [12, 16, 25, 27, 31, 32, 33, 42, 49, 53, 57, 63, 65, 66, 72, 74, 75, 80, 84, 86, 90], "hour": [12, 13, 14, 15, 42, 75, 84, 90], "four": [12, 25, 42, 43, 46, 49, 50, 52, 59, 63, 64, 82], "core": [12, 13, 14, 43, 65, 84], "entir": [12, 25, 31, 49, 51, 63, 68, 75, 79, 80, 83, 84, 88], "consol": [12, 84], "http": [12, 13, 27, 31, 42, 52, 75, 80, 86], "com": [12, 13, 27, 31, 42, 75, 80, 84, 86], "click": [12, 13, 53], "button": 12, "upper": [12, 25, 32, 44, 45, 48, 49, 50, 52, 55, 57, 60, 66, 67, 68, 72, 86], "page": [12, 13, 29, 40, 75, 84, 90], "imag": [12, 27, 28, 43, 49, 51, 53, 69, 80, 83, 86], "ami": 12, "pre": [12, 13, 66, 75, 84], "load": [12, 13, 15, 27, 28, 29, 31, 32, 33, 34, 37, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 80, 84, 86], "oregon": [12, 43], "u": [12, 16, 17, 18, 20, 23, 27, 28, 31, 32, 33, 34, 40, 42, 43, 49, 50, 53, 54, 55, 57, 60, 63, 65, 66, 68, 74, 75, 80, 84, 86], "west": 12, "Be": [12, 23, 63], "sure": [12, 15, 22, 25, 27, 31, 37, 42, 46, 49, 50, 51, 52, 54, 57, 63, 64, 65, 67, 71, 72, 74, 75, 80, 83, 84, 86], "select": [12, 15, 28, 44, 46, 51, 56, 63, 72, 75, 86], "region": [12, 27, 32, 33, 39, 43, 46, 48, 49, 52, 53, 66, 80, 82], "top": [12, 13, 49, 60, 75], "corner": [12, 44, 45, 48, 50, 53, 55, 57, 60, 63, 65, 66, 68, 69, 71, 72, 80, 86], "same": [12, 13, 16, 17, 21, 22, 25, 28, 29, 31, 33, 38, 42, 43, 44, 46, 50, 52, 53, 54, 57, 58, 63, 64, 65, 66, 67, 68, 69, 72, 80, 82, 83, 86], "throughout": [12, 15, 22, 32, 49, 75, 86, 89], "sinc": [12, 16, 22, 25, 27, 28, 31, 32, 33, 37, 38, 42, 43, 44, 45, 48, 49, 50, 52, 53, 54, 55, 57, 58, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 86], "physic": [12, 16, 23, 27, 28, 33, 45, 49, 66, 80, 82, 89], "where": [12, 13, 16, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 37, 39, 40, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 63, 64, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 83, 84, 86], "live": [12, 65, 84], "choos": [12, 22, 23, 26, 27, 28, 29, 31, 33, 37, 39, 40, 42, 44, 45, 48, 49, 50, 53, 54, 61, 62, 66, 67, 68, 69, 74, 75, 82], "ec2": 12, "among": [12, 20, 25, 49, 72, 75], "pulldown": [12, 75], "menu": [12, 75], "left": [12, 16, 21, 22, 25, 27, 28, 32, 33, 38, 40, 42, 44, 45, 46, 49, 50, 53, 54, 55, 57, 58, 62, 64, 66, 68, 72, 74, 75, 80, 82, 84, 86], "screen": [12, 42, 46, 75], "pane": 12, "under": [12, 16, 25, 27, 28, 32, 44, 49, 50, 52, 60, 62, 64, 75, 82, 84, 86], "default": [12, 13, 23, 43, 44, 46, 52, 53, 57, 66, 72, 84], "me": [12, 16, 23, 25, 48, 49, 54, 84], "instead": [12, 15, 21, 25, 27, 28, 31, 32, 33, 37, 44, 46, 48, 49, 50, 51, 53, 54, 57, 62, 65, 66, 67, 68, 69, 72, 75, 80, 82, 84, 86], "public": 12, "search": [12, 71, 75], "bebi103": [12, 13, 15, 27, 28, 31, 32, 33, 42, 43, 44, 45, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 75, 84, 86, 89], "doubl": [12, 37, 44, 69, 82], "list": [12, 44, 48, 51, 58, 65, 66, 75, 83, 84, 86], "request": [12, 13, 42, 83, 84, 86], "spot": 12, "save": [12, 49, 84, 86], "monei": [12, 16], "lose": [12, 58, 72, 86], "whatev": [12, 66, 84], "store": [12, 27, 28, 43, 48, 49, 50, 52, 57, 67, 86], "taken": [12, 23, 37, 40, 43, 52, 53, 80], "name": [12, 16, 22, 24, 25, 37, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 74, 75, 84, 86], "tag": [12, 86], "give": [12, 17, 20, 23, 25, 27, 28, 31, 33, 38, 42, 43, 44, 46, 48, 49, 52, 54, 57, 59, 63, 64, 65, 66, 67, 68, 72, 75, 80, 82, 83, 84, 86, 89], "recommend": [12, 13, 35, 52, 72, 80, 84], "easili": [12, 27, 38, 42, 43, 49, 59, 66, 72, 80, 82], "back": [12, 62, 64, 65, 66, 72, 75, 80, 82, 84, 86], "simpli": [12, 13, 23, 25, 29, 33, 39, 40, 42, 44, 46, 50, 51, 54, 60, 80, 82, 84, 86], "mine": 12, "skip": [12, 15, 52, 66, 82], "applic": [12, 22, 25, 38, 54, 66, 67, 80, 86], "o": [12, 13, 27, 28, 31, 33, 42, 43, 44, 45, 46, 49, 50, 52, 55, 57, 65, 66, 67, 68, 69, 71, 72, 75, 84, 86], "becaus": [12, 13, 14, 16, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 38, 42, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 80, 84, 86], "type": [12, 25, 42, 43, 44, 45, 46, 65, 68, 80, 82, 84, 86], "choic": [12, 25, 29, 33, 46, 48, 50, 51, 62, 66, 67, 72, 75, 80, 86], "begin": [12, 16, 17, 18, 20, 21, 22, 23, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 80, 82, 84, 86], "c5": 12, "xlarg": 12, "computation": [12, 32, 54, 72, 84], "intens": [12, 22, 32, 63, 84], "2xlarg": 12, "larger": [12, 49, 51, 53, 63, 66, 69, 80, 82, 84, 86], "kei": [12, 42, 49, 57, 66, 80], "pair": [12, 16, 23, 27, 28, 44, 49, 66, 72], "login": [12, 84], "new": [12, 16, 21, 23, 25, 27, 42, 43, 44, 49, 50, 51, 54, 66, 67, 80, 82, 84, 89], "pop": 12, "window": [12, 75], "enter": [12, 80], "someth": [12, 16, 27, 29, 49, 54, 62, 64, 66, 75, 80, 82, 84], "bebi103_aws_keypair": 12, "fine": [12, 13, 46, 50, 55, 71, 75], "leav": [12, 14, 25, 43, 46, 57, 66, 67, 86], "radio": 12, "download": [12, 13, 27, 28, 31, 33, 42, 44, 45, 46, 49, 50, 52, 55, 57, 65, 66, 67, 68, 69, 71, 80, 86], "NOT": 12, "repeat": [12, 16, 21, 24, 26, 42, 46, 49, 50, 51, 61, 66, 69], "git": [12, 43], "repositori": 12, "anyth": [12, 13, 16, 25, 54, 63, 64, 80, 82, 86], "dropbox": [12, 43], "never": [12, 22, 27, 37, 38, 39, 43, 52, 57, 66, 72], "let": [12, 16, 17, 20, 22, 25, 27, 28, 31, 32, 39, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 57, 60, 62, 63, 65, 66, 68, 69, 71, 72, 74, 75, 80, 82, 86], "internet": [12, 14, 84], "reus": 12, "forward": [12, 16, 18, 28, 49, 54, 66, 71, 80, 82], "network": 12, "sourc": [12, 27, 28, 31, 33, 45, 46, 49, 65, 66, 67, 69, 72, 75, 84], "allow": [12, 13, 32, 37, 38, 40, 42, 44, 45, 49, 50, 52, 53, 55, 57, 60, 66, 68, 69, 71, 72, 75, 80, 82, 84, 86], "ssh": [12, 84], "traffic": 12, "anywher": [12, 42, 65, 75, 89], "everyth": [12, 16, 43, 46, 49, 52, 55, 57, 63, 65, 66, 69, 71, 74], "els": [12, 13, 42, 43, 57, 75, 86], "secur": 12, "ip": 12, "prove": [12, 20, 22, 27, 66, 84], "inconveni": 12, "home": [12, 71, 84], "campu": [12, 84], "configur": [12, 14, 84], "storag": [12, 13, 86], "30": [12, 27, 28, 34, 49, 50, 55, 72, 75, 84, 86, 90], "gib": 12, "gp2": 12, "root": [12, 25, 63, 84], "volum": [12, 27, 49, 80, 82, 84], "enough": [12, 13, 25, 27, 33, 37, 44, 49, 52, 66, 82], "rest": [12, 13, 22, 23, 42, 52, 65, 80, 84], "bottom": [12, 53, 63], "summari": [12, 25, 27, 47, 52, 65, 66], "view": [12, 23, 44, 65, 80, 84], "dashboard": [12, 49], "It": [12, 13, 15, 16, 21, 22, 24, 25, 27, 28, 29, 31, 32, 33, 37, 38, 40, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 54, 55, 57, 63, 64, 65, 66, 67, 68, 69, 71, 75, 76, 80, 82, 86, 87], "state": [12, 16, 21, 23, 25, 37, 38, 42, 44, 48, 52, 55, 66, 68, 72, 74, 82, 86], "statu": 12, "readi": [12, 31, 52, 67, 68, 69, 86], "protocol": 12, "instruct": [12, 14, 15, 16, 28, 43, 49, 63, 75], "maco": 12, "linux": [12, 84], "assum": [12, 15, 22, 25, 27, 28, 29, 31, 32, 33, 42, 43, 44, 45, 49, 51, 54, 57, 58, 59, 62, 63, 66, 68, 72, 80, 83, 86], "bash": [12, 84], "zsh": 12, "accomplish": [12, 33, 40, 43, 44, 48, 52, 57, 66, 67, 69, 82, 86], "gitbash": 12, "identifi": [12, 23, 27, 28, 29, 32, 42, 44, 49, 52, 54, 64, 65, 66, 75, 80, 82], "put": [12, 25, 43, 45, 46, 49, 51, 52, 58, 64, 65, 66, 68, 80, 83, 84], "keypair": 12, "file": [12, 43, 49, 68, 72, 75], "directori": [12, 13, 43, 71, 75, 84], "call": [12, 15, 16, 20, 21, 22, 23, 25, 27, 37, 39, 42, 43, 44, 46, 49, 53, 54, 55, 62, 63, 66, 69, 71, 72, 80, 82, 84, 86], "key_pair": 12, "pem": 12, "chang": [12, 13, 25, 42, 44, 49, 52, 53, 54, 62, 64, 68, 69, 72, 74, 75, 80, 82, 84, 86, 90], "permiss": 12, "chmod": 12, "400": [12, 29, 32, 34, 52, 53, 63, 72, 80, 86], "open": [12, 13, 15, 72, 84], "clink": 12, "webpag": 12, "ipv4": 12, "54": [12, 44, 52, 60, 62, 63, 72], "92": [12, 57, 72], "67": 12, "113": [12, 72], "command": [12, 15, 43, 80, 84], "user": [12, 43, 67, 68, 82, 84], "avoid": [12, 13, 22, 27, 28, 31, 42, 63, 65, 66, 69, 75, 80], "add": [12, 16, 33, 43, 44, 48, 50, 53, 54, 55, 58, 66, 67, 68, 69, 71, 75, 80, 83, 84, 86], "profil": [12, 72, 84], "e": [12, 13, 15, 16, 21, 23, 25, 27, 28, 32, 37, 42, 44, 49, 51, 53, 54, 55, 57, 58, 60, 62, 63, 65, 66, 68, 69, 71, 72, 74, 75, 82, 84, 86], "g": [12, 13, 16, 17, 18, 20, 21, 22, 23, 25, 27, 28, 29, 31, 32, 33, 37, 40, 42, 43, 44, 49, 51, 54, 58, 59, 60, 62, 64, 65, 66, 68, 72, 74, 75, 80, 86], "echo": [12, 84], "k": [12, 33, 37, 38, 48, 57, 58, 60, 62, 63, 66, 67, 68, 69, 71, 72, 80], "zshrc": 12, "notic": [12, 25, 33, 42, 43, 44, 72, 84, 86], "environ": [12, 84], "activ": [12, 39, 42, 65, 66, 75, 84], "world": [12, 41], "oyster": 12, "exampl": [12, 16, 18, 23, 24, 26, 27, 28, 29, 31, 32, 37, 39, 40, 42, 44, 46, 48, 49, 51, 52, 54, 56, 58, 59, 62, 63, 65, 68, 69, 71, 75, 80, 84, 86], "clone": 12, "keep": [12, 16, 18, 27, 39, 43, 49, 51, 52, 53, 57, 63, 67, 69, 72, 82, 84], "github": [12, 13, 42, 84, 86], "my_user_nam": 12, "my_favorite_repositori": 12, "folder": [12, 43, 72, 80], "appropri": [12, 16, 42, 44, 48, 49, 52, 63, 66, 75, 80], "rel": [12, 13, 16, 22, 54, 57, 64, 82], "path": [12, 13, 27, 28, 31, 33, 42, 44, 45, 46, 49, 50, 52, 55, 57, 65, 66, 67, 68, 69, 71, 72, 75, 80, 84], "ipynb": [12, 75], "whenev": 12, "updat": [12, 17, 23, 25, 29, 31, 44, 49, 51, 63, 64, 65, 68, 72, 80], "ad": [12, 23, 44, 46, 57, 66, 67, 71, 84], "bebi103_upd": 12, "ing": 12, "document": [12, 15, 31, 42, 43, 64, 71, 72, 75, 84, 89], "edit": [12, 13, 75, 84], "manag": [12, 42, 43, 53, 84], "push": [12, 65, 67, 69, 82], "pull": [12, 27, 28, 31, 33, 45, 46, 49, 52, 65, 72, 82, 86], "execut": [12, 13, 43, 45, 84], "jupyt": [12, 13, 15, 43, 49, 75, 80, 84], "browser": [12, 13, 65, 84], "output": [12, 33, 42, 49, 54, 57, 63, 67, 72, 84], "server": [12, 84], "runtim": 12, "jpserver": 12, "30060": 12, "html": [12, 13, 49, 75], "Or": [12, 51, 66], "past": [12, 52, 71], "url": 12, "localhost": 12, "8888": 12, "token": 12, "e52184f06c9fb0f9ceea176b1d51d9cb36c72a019e688f": 12, "127": 12, "order": [12, 13, 16, 23, 25, 27, 28, 32, 37, 42, 43, 48, 49, 50, 51, 52, 54, 57, 63, 64, 65, 66, 68, 74, 75, 80, 84, 86], "socket": 12, "anoth": [12, 17, 28, 29, 37, 43, 44, 46, 49, 51, 52, 53, 54, 57, 58, 63, 66, 80, 86, 89], "l": [12, 27, 28, 31, 33, 45, 49, 64, 66, 69, 72, 75], "8000": [12, 74], "port": [12, 84], "abov": [12, 13, 17, 22, 25, 27, 28, 37, 42, 44, 46, 49, 50, 53, 57, 62, 63, 64, 66, 68, 71, 72, 74, 80, 82, 84, 86], "got": [12, 17, 27, 42, 48, 52, 53, 54, 66, 67, 72, 80, 84, 86], "8889": 12, "substitut": [12, 23, 27, 54, 62, 66, 72], "8001": 12, "90": [12, 22, 49, 60, 63, 72], "direct": [12, 29, 66, 82], "note": [12, 15, 16, 18, 21, 23, 25, 27, 28, 29, 31, 32, 33, 38, 40, 42, 43, 44, 45, 49, 50, 51, 52, 53, 54, 55, 57, 58, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 82, 83, 84, 86], "specifi": [12, 22, 23, 27, 28, 31, 42, 43, 44, 45, 46, 49, 50, 51, 57, 58, 63, 66, 67, 72, 74, 82, 84], "8890": 12, "correspond": [12, 16, 21, 42, 44, 63, 66, 68, 69, 72, 80, 86], "notebook": [12, 13, 15, 42, 43, 49, 65, 75, 80, 82, 84, 86], "move": [12, 25, 38, 49, 52, 53, 65, 82, 84], "commit": 12, "directli": [12, 16, 22, 25, 27, 31, 32, 40, 42, 43, 44, 45, 46, 49, 54, 55, 57, 62, 64, 66, 68, 72, 74, 82], "intermedi": [12, 33, 49, 86], "version": [12, 13, 15, 27, 28, 29, 31, 32, 33, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 80, 84, 86], "control": [12, 43, 45, 49, 83], "scp": [12, 84], "yet": [12, 15, 25, 50, 66, 69, 75, 86], "my_fil": 12, "csv": [12, 27, 28, 31, 33, 42, 43, 44, 45, 46, 49, 50, 52, 55, 57, 65, 66, 67, 68, 69, 71, 72, 75, 84], "transfer": [12, 86], "colon": 12, "rememb": [12, 22, 23, 25, 27, 42, 43, 45, 49, 54, 57, 66, 67, 72], "second": [12, 15, 23, 25, 27, 28, 31, 32, 33, 42, 43, 46, 49, 50, 51, 57, 62, 64, 65, 66, 68, 72, 74, 75, 84, 86], "argument": [12, 25, 27, 31, 33, 44, 45, 67, 71, 84], "similarli": [12, 16, 21, 33, 54, 66, 86], "upload": 12, "txt": [12, 43], "finish": [12, 43, 84, 86], "shut": 12, "shutdown": 12, "prompt": [12, 15, 82, 84], "hard": [12, 22, 31, 49, 63, 68, 69], "press": [12, 21, 33], "ctrl": 12, "unless": [12, 39, 43, 48, 72], "realli": [12, 16, 22, 23, 25, 27, 28, 31, 49, 51, 53, 54, 57, 64, 65, 66, 68, 69, 72, 75, 82, 86], "rid": 12, "charg": 12, "rack": 12, "massiv": 12, "bill": 12, "idl": [12, 13], "minor": [12, 49], "pain": 12, "wait": [12, 16, 22, 29, 66, 84], "forget": [12, 84], "caus": [12, 44, 53, 63], "pocketbook": 12, "easier": [12, 16, 22, 23, 27, 31, 44, 48, 54, 66, 67, 82], "navig": [12, 13], "either": [12, 13, 15, 27, 28, 42, 46, 49, 51, 52, 82, 84], "via": [12, 13, 24, 29, 42, 43, 63, 66, 75], "spun": 12, "fire": [12, 13], "per": [12, 25, 27, 42, 49, 51, 53, 57, 63, 65, 66, 72, 80, 84, 86], "eb": 12, "etc": [12, 13, 16, 22, 23, 43, 59, 62, 66, 71, 72, 75, 84], "intact": 12, "free": [12, 13, 14, 50, 54, 63, 67, 72, 75, 80], "tier": [12, 13], "expir": 12, "promo": 12, "These": [12, 13, 16, 27, 38, 42, 43, 44, 46, 49, 52, 60, 63, 65, 66, 71, 75, 80, 84, 86], "wipe": 12, "provid": [13, 21, 22, 27, 31, 32, 33, 37, 42, 43, 44, 52, 54, 57, 63, 64, 66, 67, 68, 75, 84, 89], "conveni": [13, 22, 25, 27, 31, 32, 33, 37, 40, 42, 43, 44, 46, 48, 49, 50, 52, 54, 57, 59, 63, 66, 68, 69, 71, 74, 80, 82], "must": [13, 16, 21, 22, 27, 29, 31, 32, 42, 43, 45, 57, 64, 66, 69, 72, 75, 82, 84, 86, 90], "account": [13, 42, 52, 75, 84, 86], "student": [13, 27, 51, 62, 75, 76, 87, 89], "employe": 13, "suit": 13, "person": [13, 48, 84], "gmail": 13, "youtub": [13, 89], "facilit": [13, 24, 71, 84], "teammat": [13, 75], "staff": [13, 75], "machin": [13, 14, 43, 54, 65, 66, 84], "annoi": [13, 14, 43], "trick": [13, 23, 27, 38, 44, 63, 80, 86], "safari": 13, "edg": [13, 74, 80], "web": 13, "brows": 13, "test": [13, 16, 50, 54, 64, 65, 72, 84, 86], "chrome": 13, "firefox": 13, "jupyterlab": [13, 15, 27, 28, 29, 31, 32, 33, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 80, 86], "support": [13, 72], "three": [13, 22, 27, 33, 44, 45, 46, 48, 50, 51, 52, 54, 57, 59, 60, 62, 64, 74, 75, 84], "launch": [13, 44], "research": [13, 16, 22, 23, 25, 33, 48, 75, 84, 89], "altern": [13, 31, 42, 51, 53, 54, 62, 80, 82, 84], "badg": 13, "content": [13, 24, 43, 44, 49, 51, 66, 68, 71, 72], "virtual": [13, 84], "two": [13, 14, 15, 16, 22, 23, 25, 27, 28, 29, 31, 33, 38, 42, 43, 44, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 62, 63, 64, 65, 66, 71, 72, 73, 74, 80, 82, 83, 84], "cpu": [13, 84], "limit": [13, 16, 22, 24, 25, 37, 38, 39, 43, 51, 52, 55, 64, 66, 68, 82, 84, 86], "gb": 13, "vari": [13, 15, 16, 22, 31, 46, 49, 62, 63, 66, 67, 69, 72, 80, 82], "ram": [13, 43], "gpu": [13, 84], "tpu": 13, "tensor": 13, "unit": [13, 22, 25, 31, 42, 43, 45, 49, 54, 63, 66, 69, 82], "too": [13, 16, 22, 25, 27, 28, 38, 48, 51, 52, 53, 64, 65, 66, 67, 69, 72, 75, 80, 82], "long": [13, 16, 25, 38, 39, 43, 48, 51, 52, 58, 68, 69, 80, 82, 83, 86], "disconnect": [13, 14], "cell": [13, 22, 25, 33, 42, 44, 45, 49, 52, 57, 63, 65, 66, 68, 69, 75, 80, 83, 84], "timeout": 13, "depend": [13, 22, 24, 27, 28, 29, 32, 37, 38, 42, 44, 50, 55, 59, 62, 65, 66, 72, 74, 80, 83, 84, 86], "almost": [13, 21, 22, 23, 25, 27, 31, 33, 37, 39, 40, 42, 44, 51, 57, 65, 66, 67, 75], "alwai": [13, 15, 16, 22, 25, 27, 31, 33, 37, 40, 42, 44, 48, 49, 51, 57, 58, 66, 72, 75, 80, 86], "typic": [13, 22, 23, 25, 29, 33, 42, 44, 45, 49, 51, 52, 58, 63, 64, 65, 66], "again": [13, 15, 16, 21, 22, 23, 27, 28, 31, 32, 33, 38, 40, 42, 44, 46, 49, 50, 52, 54, 57, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 80, 86], "effici": [13, 49, 52, 71, 82, 84], "exce": 13, "present": [13, 16, 27, 31, 43, 44, 46, 49, 53, 55, 63, 64, 67, 68, 71, 75, 82, 85], "place": [13, 31, 48, 49, 68, 69, 75, 82], "offer": [13, 27, 31, 38, 46, 52, 54, 57, 84, 86], "longer": [13, 25, 28, 42, 44, 49, 58, 67, 71, 80, 82], "pro": [13, 14], "howev": [13, 25, 27, 29, 32, 33, 40, 42, 44, 49, 50, 51, 52, 53, 54, 57, 64, 66, 67, 68, 75, 80, 82, 83, 84, 86], "encourag": [13, 63, 64, 66, 75], "bokeh": [13, 15, 27, 28, 29, 31, 32, 33, 34, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 80, 84, 86], "app": [13, 80], "python": [13, 27, 28, 29, 31, 32, 33, 42, 43, 44, 45, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 75, 80, 86, 89], "callback": [13, 49], "instanc": [13, 14, 27, 42, 43, 49], "major": [13, 25, 27, 31, 33, 49, 64], "burden": 13, "section": [13, 14, 15, 16, 21, 32, 43, 52, 53, 66, 75, 80, 84, 86], "circumv": 13, "upgrad": [13, 14, 42, 86], "faq": 13, "latest": 13, "januari": [13, 90], "wherea": [13, 32, 82], "anaconda": 13, "nonetheless": [13, 16, 25, 31, 42, 49, 51, 52, 65, 66, 71, 72], "preinstal": 13, "often": [13, 16, 21, 22, 23, 25, 27, 32, 37, 40, 42, 43, 44, 46, 48, 49, 50, 51, 52, 53, 54, 57, 58, 59, 62, 65, 66, 68, 75, 84, 86], "enabl": [13, 29, 32, 42, 43, 45, 46, 49, 50, 52, 67, 69, 84], "variant": [13, 57], "thereof": [13, 54, 57, 75], "affect": [13, 25, 29, 32, 65, 66], "importantli": [13, 21, 22, 23, 29, 33, 37, 38, 40, 42, 44, 49, 52, 54, 57, 63, 64, 65, 66, 69, 72], "cmdstanpi": [13, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 84, 86, 89], "install_cmdstan": [13, 15, 42, 86], "sever": [13, 14, 15, 25, 27, 28, 31, 33, 39, 48, 53, 65], "minut": [13, 15, 16, 22, 33, 42, 65, 83], "setup": [13, 14, 42, 51, 68, 86], "sy": [13, 42, 75, 86], "subprocess": [13, 22, 42, 86], "modul": [13, 31, 37, 42, 46, 49, 66, 75, 84, 86], "cmd": [13, 42, 86], "pip": [13, 42, 84, 86], "polar": [13, 27, 28, 31, 33, 42, 44, 45, 46, 48, 49, 50, 52, 55, 57, 63, 65, 66, 67, 68, 69, 71, 72], "iqplot": [13, 42, 43, 44, 45, 48, 49, 52, 60, 63, 65, 69, 72, 74, 86], "colorcet": [13, 42, 43, 86], "datashad": [13, 42], "arviz": [13, 15, 42, 44, 45, 48, 49, 50, 52, 53, 54, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 84, 86, 89], "watermark": [13, 15, 27, 28, 29, 31, 32, 33, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 80, 86], "popen": [13, 42, 86], "split": [13, 16, 23, 42, 44, 49, 54, 84, 86], "stdout": [13, 42, 43, 84, 86], "pipe": [13, 42, 86], "stderr": [13, 42, 84, 86], "data_path": [13, 27, 28, 31, 33, 42, 44, 45, 46, 49, 50, 52, 55, 57, 65, 66, 67, 68, 69, 71, 72, 75, 86], "s3": [13, 27, 31, 42, 75, 84, 86], "amazonaw": [13, 27, 31, 42, 75, 86], "ensur": [13, 22, 39, 44, 52, 53, 64, 69, 71, 75, 82, 86], "recent": [13, 63, 75, 84], "cmdstan": [13, 15, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 57, 63, 65, 66, 67, 68, 69, 71, 72, 86], "drawback": [13, 32, 46, 48], "built": [13, 27, 31, 37, 43, 44, 49, 52, 57, 60, 63, 66, 71, 86], "binari": 13, "shutil": [13, 42, 86], "urllib": [13, 42, 86], "latest_vers": [13, 42, 86], "cmdstan_vers": [13, 15, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 57, 63, 65, 66, 67, 68, 69, 71, 72, 86], "cmdstan_url": [13, 42, 86], "f": [13, 15, 17, 18, 20, 21, 22, 23, 25, 27, 29, 31, 32, 34, 37, 42, 44, 49, 51, 54, 57, 58, 59, 60, 62, 63, 64, 66, 67, 68, 69, 71, 72, 74, 80, 82, 83, 84, 86], "dev": [13, 27, 42, 86], "releas": [13, 42, 46, 86], "v": [13, 15, 27, 28, 29, 31, 32, 33, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 80, 82, 86], "fname": [13, 42, 72, 86], "tgz": [13, 42, 86], "urlretriev": [13, 42, 86], "unpack_arch": [13, 42, 86], "faster": [13, 25, 27, 32, 42, 49, 51, 65, 75, 84], "mode": [13, 32, 43, 44, 48, 82], "fetch": [13, 71], "aw": [13, 14, 43], "hidden": 13, "render": [13, 34, 46, 49, 74, 75, 80], "clutter": [13, 22, 42, 43], "collab": 13, "numpi": [13, 15, 27, 28, 29, 31, 32, 33, 34, 37, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 67, 68, 69, 71, 72, 74, 80, 84, 86], "np": [13, 15, 27, 28, 29, 31, 32, 33, 34, 37, 42, 43, 44, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 80, 84, 86], "az": [13, 15, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 84, 86], "io": [13, 15, 27, 28, 29, 31, 32, 33, 34, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 80, 84, 86], "output_notebook": [13, 15, 27, 28, 29, 31, 32, 33, 34, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 80, 84, 86], "schools_data": [13, 15], "j": [13, 15, 20, 25, 27, 28, 31, 33, 54, 72, 84, 86], "y": [13, 15, 16, 18, 20, 21, 22, 23, 25, 27, 28, 31, 32, 33, 34, 37, 40, 42, 43, 44, 45, 46, 48, 49, 51, 54, 57, 59, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 80, 86], "28": [13, 15, 44, 49, 65, 69, 72, 86, 90], "sigma": [13, 15, 16, 21, 22, 25, 27, 28, 31, 32, 33, 45, 46, 48, 49, 50, 51, 53, 55, 63, 66, 67, 68, 69, 71, 72, 82], "schools_cod": [13, 15], "int": [13, 15, 21, 22, 23, 25, 27, 37, 38, 40, 42, 44, 45, 46, 49, 50, 52, 53, 54, 55, 57, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 80, 84, 86], "lower": [13, 15, 16, 25, 32, 42, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 82, 84, 86], "school": [13, 15], "vector": [13, 15, 44, 49, 57, 63, 66, 67, 68, 69, 71, 72, 74, 80, 82], "treatment": [13, 15, 32, 33, 45, 64], "mu": [13, 15, 21, 22, 25, 27, 32, 33, 48, 49, 50, 51, 53, 55, 66, 72, 86], "tau": [13, 15, 25, 63, 72], "eta": [13, 15, 72], "transform": [13, 15, 16, 21, 25, 37, 42, 43, 44, 45, 46, 50, 51, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 80, 84, 86], "theta": [13, 15, 16, 17, 18, 20, 21, 23, 25, 27, 29, 31, 32, 37, 38, 40, 43, 44, 49, 51, 53, 54, 57, 58, 59, 60, 62, 63, 64, 69, 72, 80, 86], "w": [13, 15, 23, 44, 49, 57, 63, 72, 82, 84, 90], "disable_log": [13, 15, 42, 44, 45, 46, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 84, 86], "sm": [13, 15, 42, 43, 44, 45, 46, 50, 52, 53, 57, 60, 65, 67, 68, 69, 71, 72, 74, 75, 84, 86], "cmdstanmodel": [13, 15, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 75, 84, 86], "stan_fil": [13, 15, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 84, 86], "output_dir": [13, 15, 84], "show_progress": [13, 15, 42, 43, 49, 72, 84, 86], "fals": [13, 15, 33, 42, 43, 44, 46, 48, 49, 52, 55, 57, 63, 65, 66, 67, 68, 72, 74, 80, 84, 86], "from_cmdstanpi": [13, 15, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 68, 69, 71, 72, 74, 84, 86], "clean_cmdstan": [13, 15, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 86], "p": [13, 15, 16, 18, 21, 27, 28, 29, 31, 32, 33, 34, 37, 38, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 80, 84, 86], "figur": [13, 15, 16, 21, 27, 28, 29, 31, 32, 33, 34, 42, 45, 46, 49, 53, 63, 65, 66, 67, 68, 69, 72, 74, 80, 82, 86], "frame_height": [13, 15, 27, 28, 29, 31, 32, 33, 34, 42, 44, 45, 46, 48, 49, 65, 66, 67, 68, 69, 72, 74, 80, 86], "250": [13, 15, 27, 28, 31, 33, 42, 45, 46, 48, 49, 50, 55, 65, 66, 67, 68, 69, 71, 72], "frame_width": [13, 15, 27, 28, 29, 31, 32, 33, 34, 42, 44, 45, 46, 48, 49, 60, 65, 66, 67, 68, 69, 72, 74, 80, 86], "x_axis_label": [13, 15, 27, 28, 29, 31, 32, 33, 34, 42, 44, 45, 46, 48, 49, 50, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 72, 74, 80, 86], "\u03bc": [13, 15, 27], "y_axis_label": [13, 15, 27, 28, 29, 31, 32, 33, 34, 42, 45, 46, 48, 49, 50, 53, 55, 60, 63, 65, 66, 67, 68, 69, 72, 74, 80, 86], "\u03c4": [13, 15, 63, 72], "scatter": [13, 15, 27, 28, 31, 33, 42, 44, 45, 46, 48, 49, 53, 63, 65, 66, 67, 68, 69, 72, 74, 80], "ravel": [13, 15, 42, 43, 86], "alpha": [13, 15, 27, 28, 29, 31, 32, 33, 34, 37, 38, 42, 44, 45, 46, 49, 51, 52, 53, 57, 58, 60, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 80, 84, 86], "bokehj": [13, 15, 27, 28, 29, 31, 32, 33, 34, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 80, 86], "load_ext": [13, 15, 27, 28, 29, 31, 32, 33, 34, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 80, 86], "cpython": [13, 15, 27, 28, 29, 31, 32, 33, 42, 43, 44, 45, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 80, 86], "ipython": [13, 15, 27, 28, 29, 31, 32, 33, 42, 43, 44, 45, 48, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 80, 86], "27": [13, 15, 42, 44, 46, 49, 63, 65, 67, 68, 69, 71, 72, 86, 90], "requir": [14, 16, 23, 37, 40, 42, 49, 52, 54, 65, 72, 75, 80, 82, 83, 84], "signific": [14, 38, 49, 66, 84], "multipl": [14, 32, 43, 52, 54, 71, 72, 80, 82, 84, 86], "prefer": [14, 16, 25, 45, 46, 49, 54, 57, 84, 86], "connect": [14, 16, 54, 55, 80, 84], "larg": [14, 16, 22, 25, 27, 28, 40, 42, 45, 49, 52, 53, 54, 63, 65, 66, 67, 69, 72, 75, 80, 84, 86], "loud": 14, "hot": 14, "unavail": [14, 27], "other": [14, 15, 16, 18, 21, 22, 23, 25, 27, 28, 31, 32, 37, 40, 42, 43, 44, 45, 46, 49, 52, 54, 58, 60, 62, 63, 64, 66, 71, 72, 74, 75, 80, 83, 84, 86, 89], "dure": [14, 39, 42, 49, 75], "colab": [14, 15, 42, 43, 75, 86], "pretti": [14, 25, 29, 37, 40, 44, 46, 49, 54, 65, 66, 82, 84, 86], "fast": [14, 31, 49, 54, 63], "biggest": [14, 84], "interact": [14, 43, 49, 51, 83, 84], "babysit": 14, "could": [14, 21, 22, 25, 27, 28, 31, 33, 38, 40, 42, 44, 45, 48, 49, 50, 51, 53, 54, 58, 62, 63, 65, 66, 69, 71, 72, 80, 82, 84, 86], "commerci": 14, "servic": [14, 23, 84], "hpc": 14, "oper": [15, 25, 42, 44, 66, 68, 82, 84, 86], "BE": [15, 73], "bi": [15, 46, 62, 73], "103": [15, 73], "probabilist": [15, 16, 21, 22, 25, 42, 43, 82], "program": [15, 22, 42, 45, 71, 84], "languag": [15, 22, 42, 43, 75, 86], "written": [15, 16, 18, 23, 25, 27, 28, 42, 43, 44, 49, 54, 58, 62, 69, 75, 76, 80, 84, 85, 86, 87], "translat": [15, 43, 82], "parser": 15, "compil": [15, 42, 43, 44, 49, 50, 52, 53, 55, 57, 60, 65, 66, 67, 68, 69, 71, 72, 75, 84, 86], "interfac": [15, 42, 43, 72, 89], "wide": [15, 22, 25, 27, 38, 39, 54, 65, 66, 68, 84], "rstan": 15, "pystan": [15, 43], "r": [15, 16, 38, 39, 43, 53, 63, 72, 82, 84], "respect": [15, 22, 25, 27, 33, 43, 44, 46, 48, 53, 54, 57, 58, 60, 63, 66, 68, 71, 72, 74, 75], "simpler": [15, 49, 51, 67, 86], "becom": [15, 16, 17, 23, 25, 27, 28, 33, 40, 44, 49, 51, 54, 80, 82, 83, 86], "appar": [15, 63, 68, 86], "whichev": 15, "tricki": [15, 27, 57, 66], "system": [15, 22, 43, 54, 62, 66, 80, 82, 84], "troubleshoot": 15, "worri": [15, 37, 48, 86], "troubl": [15, 49, 52, 53, 75], "On": [15, 51, 62, 80, 86], "xcode": 15, "accord": [15, 28, 32, 39, 44, 45, 46, 52, 62, 68, 69], "previous": [15, 46, 52, 72, 84], "One": [15, 21, 22, 23, 27, 37, 48, 49, 63, 72, 80, 82, 84, 86], "mingw": 15, "wai": [15, 16, 17, 23, 25, 27, 28, 38, 39, 42, 44, 46, 48, 49, 51, 52, 53, 54, 55, 57, 58, 62, 63, 66, 68, 69, 72, 75, 80, 82, 84, 86], "conda": [15, 84], "libpython": 15, "m2w64": 15, "msys2": 15, "util": [15, 21, 25, 29, 82, 84, 89], "raspberri": 15, "pi": [15, 18, 20, 21, 22, 23, 25, 27, 32, 46, 49, 50, 53, 55, 57, 60, 64, 66, 69, 72, 74, 80, 82, 84, 86], "took": [15, 27, 29, 33, 38, 52, 54, 62, 72], "end": [15, 16, 17, 18, 20, 21, 22, 23, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 82, 84, 86], "appreci": 15, "nifti": [15, 86], "demonstr": [15, 22, 25, 29, 43, 44, 48, 49, 57, 60, 66, 69, 71, 74, 75, 82, 84], "trivial": [15, 16, 40, 43, 50, 80, 84], "feat": 15, "warn": [15, 32, 42, 53, 55, 57, 65], "text": [15, 16, 21, 22, 25, 27, 28, 29, 31, 33, 39, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57, 58, 60, 62, 63, 65, 66, 67, 68, 69, 71, 72, 74, 75, 80, 84, 86], "print": [15, 27, 31, 33, 42, 43, 44, 45, 46, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 75, 80, 84, 86], "36": [15, 27, 28, 31, 44, 55, 67, 68, 69, 71, 72, 86], "thought": [16, 29, 31, 75], "inquiri": 16, "visit": [16, 27, 39], "refresh": [16, 54, 65, 72, 80], "sketch": [16, 22, 25], "cycl": 16, "itself": [16, 49, 54, 57, 63, 67, 82], "natur": [16, 22, 42, 49, 51, 54, 57, 86], "mileston": 16, "along": [16, 25, 39, 42, 43, 46, 51, 52, 55, 80, 82, 84], "arrow": [16, 74], "orang": [16, 27, 29, 31, 33, 42, 44, 53, 63, 65, 66, 67, 68, 69, 71, 72, 80], "task": [16, 25, 26, 31, 50, 55, 75, 80, 82, 84], "adapt": [16, 42, 43, 65, 72], "fig": [16, 64, 74], "gregori": [16, 89], "cambridg": [16, 21], "2005": 16, "consid": [16, 22, 23, 25, 27, 28, 31, 32, 33, 38, 42, 44, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 75, 82, 86], "hypothesi": [16, 17, 20, 23], "invent": 16, "refin": [16, 22], "stage": [16, 22, 49], "formul": [16, 80, 86], "hypothes": [16, 18, 20, 21], "theori": [16, 32, 42, 57], "pursu": 16, "innov": 16, "sometim": [16, 31, 44, 49, 51, 54, 72, 83, 84], "geniu": 16, "deduct": [16, 75], "deduc": 16, "experiment": [16, 49, 62, 63, 72, 86], "x": [16, 18, 21, 27, 28, 31, 32, 33, 34, 42, 43, 44, 45, 46, 48, 49, 53, 65, 66, 67, 68, 69, 71, 72, 74, 80, 84], "deriv": [16, 21, 24, 25, 27, 31, 32, 37, 49, 51, 54, 64, 66, 70, 72, 80, 82], "seri": [16, 28, 29, 48, 64, 66, 83, 86, 89], "strong": [16, 42, 44, 52, 66, 69, 72, 86], "syllog": 16, "therefor": [16, 20, 22, 24, 25, 27, 28, 29, 31, 32, 33, 42, 43, 45, 49, 51, 52, 54, 57, 65, 66, 68, 69, 72, 74, 75, 80, 83], "plausibl": [16, 22, 23], "perhap": [16, 23, 25, 29, 49, 51, 52, 57, 62, 66, 82], "least": [16, 28, 31, 32, 52, 65, 66, 72, 75, 82, 84, 86], "familiar": [16, 24, 43, 44, 49, 51, 65, 66, 80, 86], "talk": [16, 21, 22, 25, 29, 37, 46, 52, 64], "bullet": 16, "But": [16, 22, 25, 28, 31, 32, 37, 38, 40, 42, 43, 45, 48, 51, 52, 54, 65, 66, 67, 72], "knowledg": [16, 17, 22, 23, 25, 29, 38, 45, 49, 51, 54, 64, 67, 80], "design": [16, 49, 63, 83, 86], "wa": [16, 25, 27, 29, 31, 33, 37, 38, 42, 43, 46, 49, 51, 52, 54, 63, 65, 66, 69, 71, 72, 80, 82, 84, 86, 87], "Not": [16, 43, 49, 63, 65], "necessarili": [16, 25, 31, 42, 48, 49, 52, 54, 86], "weak": [16, 25, 82], "wastewat": 16, "inject": [16, 53], "hydraul": 16, "fractur": 16, "known": [16, 22, 23, 24, 25, 28, 29, 32, 37, 39, 48, 49, 51, 54, 57, 64, 66, 83, 84, 86], "frack": 16, "lead": [16, 23, 25, 32, 42, 44, 49, 53, 57, 69, 80], "greater": [16, 49, 51, 52], "occurr": 16, "earthquak": 16, "frequenc": [16, 42, 44, 49, 52, 65], "oklahoma": 16, "increas": [16, 27, 49, 63, 65, 66, 80, 82, 84, 86], "fold": [16, 31], "2010": 16, "becam": 16, "common": [16, 25, 46, 54, 58, 66], "busi": [16, 86], "quantifi": [16, 54, 67, 72, 82, 86], "obeserv": 16, "role": 16, "thu": [16, 17, 21, 25, 29, 31, 38, 45, 49, 51, 53, 54, 57, 62, 63, 65, 66, 67, 69, 72, 74, 75, 82], "crucial": [16, 44, 52, 53, 54, 80], "t": [16, 21, 22, 25, 27, 31, 32, 37, 38, 43, 48, 49, 51, 52, 53, 54, 57, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 80, 82, 83, 84, 86], "jayn": [16, 21], "domin": [16, 27, 57, 60, 65], "interpret": [16, 17, 21, 23, 32, 48, 50, 54, 66, 84], "repres": [16, 42, 46, 60, 64, 66, 74, 82, 86], "ident": [16, 21, 22, 31, 42, 52, 57, 74, 86], "repetit": 16, "hypothet": [16, 86], "event": [16, 21, 24, 25, 38, 51, 52, 54], "restrict": [16, 29, 66, 72], "proposit": [16, 23], "random": [16, 21, 34, 36, 43, 44, 48, 49, 51, 52, 53, 65, 66, 67, 68, 69, 72, 74, 80, 82, 84, 86], "variabl": [16, 20, 22, 25, 27, 28, 31, 38, 42, 43, 44, 45, 46, 49, 50, 52, 53, 57, 59, 62, 63, 64, 65, 66, 67, 68, 71, 72, 74, 80, 84, 86], "quantiti": [16, 18, 21, 22, 23, 25, 27, 43, 49, 50, 51, 54, 55, 57, 65, 66, 68, 69, 71, 72, 74, 82, 84, 86], "veri": [16, 21, 22, 23, 25, 27, 29, 31, 32, 33, 38, 40, 42, 43, 44, 45, 46, 48, 49, 50, 51, 52, 53, 54, 55, 57, 63, 65, 66, 67, 68, 69, 71, 72, 80, 82, 84, 86], "meaningfulli": 16, "degre": [16, 42], "belief": [16, 42], "heard": 16, "even": [16, 22, 23, 25, 27, 43, 44, 48, 49, 52, 54, 63, 65, 66, 71, 75, 80, 82, 86], "fight": 16, "between": [16, 21, 23, 24, 25, 28, 33, 39, 42, 44, 45, 46, 49, 51, 52, 54, 55, 57, 58, 63, 64, 65, 66, 69, 72, 74, 76, 80, 82, 83, 86, 87], "peopl": 16, "who": [16, 75], "appli": [16, 17, 20, 21, 23, 42, 52, 53, 54, 58, 63, 66, 68, 72, 75, 80, 82, 84, 86], "both": [16, 21, 27, 33, 42, 43, 49, 50, 52, 54, 55, 57, 65, 66, 68, 74, 75, 80, 82, 84, 86], "valid": [16, 54, 57, 71], "exclus": 16, "great": [16, 24, 25, 39, 68, 84, 86, 89], "opinion": [16, 38, 46, 86], "express": [16, 17, 20, 22, 28, 29, 31, 32, 40, 42, 44, 45, 49, 51, 52, 53, 54, 58, 62, 63, 64, 66, 69, 72, 84, 86], "proce": [16, 27, 28, 32, 33, 57, 64, 67, 69, 71, 72], "conceptu": [16, 18, 25, 29, 35, 80], "cleaner": 16, "certainti": 16, "convers": [16, 21, 49, 54, 75], "fix": [16, 27, 42, 43, 44, 46, 52, 66, 67, 74, 80, 86], "convert": [16, 25, 37, 42, 43, 44, 46, 49, 50, 51, 52, 54, 57, 63, 66, 68, 71, 72, 74, 80], "1946": 16, "cox": 16, "laid": [16, 23, 29, 39, 43, 46, 52, 65, 71], "desir": [16, 39, 54, 66, 84], "properti": [16, 23, 37, 39, 40, 66, 69, 72, 82], "were": [16, 18, 25, 28, 32, 37, 42, 43, 46, 49, 50, 51, 52, 54, 57, 60, 63, 64, 65, 66, 69, 72, 84, 86], "expand": [16, 44, 82, 84], "1970": [16, 86], "ration": 16, "suppli": 16, "rise": [16, 83], "continu": [16, 23, 25, 28, 32, 33, 37, 38, 40, 44, 46, 51, 54, 57, 64, 65, 66, 72, 80, 84, 86], "monoton": [16, 31, 54], "manner": 16, "obtain": [16, 23, 27, 28, 42, 43, 46, 48, 52, 54, 64, 68, 71, 72, 80], "consist": [16, 21, 25, 29, 40, 43, 52, 64, 65, 67, 75, 80], "proprieti": 16, "relev": [16, 25, 27, 31, 32, 33, 48], "equival": [16, 21, 25, 27, 44, 49, 51, 53, 69, 72, 82, 86], "satisfi": [16, 37, 38, 39, 40, 52, 53, 54, 64, 82], "paus": [16, 22, 23, 27, 44, 45, 54, 82], "without": [16, 21, 23, 24, 25, 29, 33, 39, 43, 53, 54, 66, 68, 75, 80, 84, 86], "mind": [16, 21, 22, 43, 52, 63, 66, 67, 84], "chapter": 16, "book": [16, 21, 29, 39, 74, 89], "uniti": [16, 38, 52, 64, 65, 66], "except": [16, 42, 43, 49, 69, 75, 82, 86], "complement": 16, "Then": [16, 17, 20, 22, 25, 27, 38, 40, 43, 45, 53, 54, 64, 66, 80, 84, 86], "align": [16, 17, 18, 20, 21, 22, 23, 25, 27, 28, 29, 31, 32, 33, 37, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 80, 82, 84, 86], "interest": [16, 22, 24, 27, 29, 33, 38, 40, 42, 43, 44, 46, 51, 52, 54, 60, 63, 66, 74, 80, 83, 86], "happen": [16, 22, 32, 49, 50, 52, 53, 54, 66, 75, 84], "denot": [16, 18, 21, 23, 25, 32, 52, 54, 66, 80, 82], "mid": [16, 17, 18, 20, 21, 22, 23, 25, 27, 28, 29, 31, 32, 33, 37, 38, 40, 42, 43, 44, 45, 46, 49, 51, 53, 54, 57, 58, 59, 62, 64, 66, 67, 68, 69, 71, 72, 74, 80], "notion": [16, 25, 54, 82], "bit": [16, 18, 21, 22, 25, 27, 29, 31, 37, 39, 44, 48, 49, 53, 54, 63, 64, 67, 68, 82, 84, 86], "abstract": 16, "bring": [16, 25, 51, 54, 66, 86], "realm": [16, 54, 86], "ll": [16, 28, 33, 42, 43, 48, 50, 51, 52, 53, 55, 57, 64, 65, 68, 69, 72, 74, 80, 84], "been": [16, 21, 23, 33, 49, 54, 67, 69, 72, 84], "rewrit": [16, 49, 62], "explicitli": [16, 22, 27, 38, 43, 44, 54, 58, 66, 69, 75, 86], "henceforth": [16, 66], "vacuum": 16, "ahoi": 16, "exactli": [16, 22, 29, 44, 49, 51, 57, 66, 67, 68, 72, 80, 86], "pictur": [16, 27, 28, 45, 46, 52, 66, 84], "cannot": [16, 21, 25, 27, 28, 29, 33, 38, 40, 42, 44, 46, 49, 50, 51, 53, 54, 55, 63, 66, 68, 69, 72, 74, 80], "perspect": [16, 80, 82], "analyz": [16, 23, 42, 55, 63, 64, 75, 83], "commut": 16, "side": [16, 21, 27, 33, 64, 66, 83, 86], "seemingli": [16, 42], "equal": [16, 25, 32, 38, 54, 64, 72, 83], "rearrang": [16, 72, 86], "frac": [16, 17, 18, 20, 21, 22, 23, 25, 27, 28, 29, 32, 33, 38, 39, 40, 44, 45, 46, 49, 50, 52, 53, 54, 55, 57, 58, 59, 62, 64, 66, 68, 72, 74, 80, 82], "far": [16, 21, 23, 31, 32, 37, 42, 49, 53, 57, 64, 67, 69, 75, 84], "goal": [16, 23, 27, 29, 31, 32, 37, 40, 54, 69, 72], "hand": [16, 21, 27, 31, 42, 45, 48, 50, 62, 64, 68, 75, 80, 82, 86], "turn": [16, 22, 27, 42, 43, 44, 53, 54, 55, 59, 60, 65, 75, 80, 82], "item": [16, 44, 48, 74, 80, 84, 86], "believ": [16, 25, 31, 58, 84], "acquir": [16, 17, 29, 42, 43, 67, 69], "contain": [16, 21, 25, 28, 29, 32, 40, 42, 43, 44, 46, 48, 49, 51, 57, 58, 62, 63, 66, 69, 71, 72, 75, 80, 82, 84, 89], "nois": [16, 22, 68], "instrument": [16, 58], "whose": [16, 37], "constitut": [16, 54], "bulk": [16, 28, 49], "algebra": [16, 27, 66, 71, 74], "outcom": [16, 21, 24, 25, 54, 62, 63, 80], "fulli": [16, 22, 23, 50, 66, 72, 83, 86], "cute": 16, "acronym": 16, "feel": [16, 25, 29, 42, 45, 75, 80], "try": [16, 22, 23, 25, 29, 44, 49, 51, 52, 53, 57, 62, 63, 69, 72, 75, 82, 84, 86], "head": [16, 28, 44, 46, 63, 65, 72, 80], "around": [16, 27, 28, 31, 38, 44, 46, 49, 51, 54, 63, 64, 69, 80, 82, 86], "y_1": [17, 21, 22, 31, 54, 57], "investig": [17, 28, 29, 38, 42, 49, 52, 53, 54, 60, 62], "y_2": [17, 21, 22, 31, 54, 57], "plug": [17, 22, 54], "product": [17, 22, 23, 25, 27, 44, 49, 62, 66, 72, 75, 82, 86], "rule": [17, 20, 25, 28, 38, 39, 50, 52, 55, 64, 75], "denomin": 17, "insert": [17, 29, 49, 64], "equat": [17, 22, 37, 54, 62, 64, 75, 80, 82, 86], "yield": [17, 44, 64, 66, 86], "gave": [17, 43, 65], "combin": [17, 44, 49, 57, 84, 86], "singl": [17, 20, 21, 22, 24, 25, 29, 32, 42, 44, 46, 48, 50, 51, 52, 54, 57, 62, 63, 68, 69, 75, 83, 84, 86], "acquisit": [17, 51], "constantli": 17, "symbol": [18, 22, 66, 82], "overload": 18, "aid": 18, "convent": [18, 71], "densiti": [18, 21, 22, 25, 27, 28, 31, 32, 38, 40, 42, 45, 46, 48, 49, 53, 57, 66, 68, 72, 74, 80, 82], "non": [18, 42, 44, 51, 53, 66, 70], "evid": [18, 20, 22, 23, 44, 51, 72, 80, 86], "joint": [18, 20, 23, 27, 38, 49, 53, 64, 66, 72, 74, 80, 82, 86], "speak": [18, 23, 51, 52, 66, 82], "track": [18, 39, 52, 63, 72], "scienc": [19, 21, 31, 33, 45, 46, 49, 55, 66, 89], "notat": [19, 21, 22, 27, 37, 54, 66, 68], "bay": [19, 20, 22, 23, 29, 52, 54, 59, 62, 66, 72, 86], "theorem": [19, 20, 22, 23, 24, 29, 54, 59, 62, 64, 66, 80, 82, 86], "mention": [20, 25, 42, 53, 57, 62, 84], "sum": [20, 21, 23, 27, 28, 31, 33, 37, 38, 44, 48, 49, 51, 52, 54, 60, 72, 80, 82, 86], "theta_i": [20, 25, 32, 37, 38, 40, 58, 60, 62, 64, 72], "particular": [20, 25, 28, 40, 42, 43, 44, 46, 48, 50, 52, 53, 60, 66, 67, 82, 86], "theta_j": [20, 25, 31, 32, 72], "c_j": [20, 66], "nonumb": [20, 22, 38, 54], "sum_": [20, 22, 27, 28, 40, 54, 57, 62, 72, 86], "ne": [20, 54, 66, 69], "sum_i": [20, 21, 31, 54, 66, 80], "elimin": [20, 82], "lectur": [21, 23, 25, 35, 39, 42, 46, 54, 57, 64, 73, 75, 90], "verbatim": 21, "space": [21, 25, 27, 37, 38, 39, 45, 46, 48, 50, 52, 63, 64, 80, 84, 86], "zero": [21, 22, 25, 27, 28, 31, 32, 33, 37, 42, 43, 44, 45, 49, 51, 53, 62, 63, 64, 65, 66, 67, 69, 72, 74, 80, 86], "motiv": [21, 29], "introduc": [21, 25, 43, 44, 49, 66, 67, 72, 80, 82], "deal": [21, 25, 38, 44, 52, 63, 65, 82, 86], "link": [21, 46, 69, 74, 84, 89], "discret": [21, 23, 25, 37, 38, 44, 51, 57, 66, 80, 82], "integ": [21, 37, 42, 44, 51, 84], "nonzero": [21, 22, 31], "notation": 21, "le": [21, 27, 28, 33, 49, 66], "cumul": [21, 32], "cdf": [21, 31, 32, 34, 37, 40, 42, 44, 46, 51, 60], "shown": [21, 25, 28, 31, 37, 38, 49, 54, 64, 66, 80], "panel": 21, "height": [21, 27, 53, 63, 80], "men": 21, "centimet": 21, "countri": 21, "mathrm": [21, 22, 23, 25, 27, 28, 32, 37, 38, 40, 52, 53, 54, 57, 64, 66, 67, 68, 69, 71, 74, 80, 82, 86], "ly": [21, 67, 68, 71], "y_0": 21, "int_": [21, 74, 80], "satisfact": 21, "axiom": [21, 80], "infti": [21, 22, 25, 27, 28, 31, 51, 66, 74], "necessit": [21, 58], "pmf": [21, 24, 29, 44, 84, 86], "unlik": [21, 22, 33, 44, 49, 51, 53, 57, 63, 80, 86], "n": [21, 22, 27, 28, 29, 37, 40, 42, 44, 45, 46, 49, 50, 52, 54, 55, 57, 58, 60, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 74, 80, 82, 83, 84, 86], "roll": 21, "fair": 21, "die": [21, 68], "seen": [21, 23, 27, 29, 37, 42, 44, 48, 50, 52, 55, 59, 66, 68, 71, 80], "similar": [21, 27, 29, 43, 44, 45, 49, 50, 54, 55, 63, 75, 83, 84, 86], "hold": [21, 37, 38, 44, 49, 64, 66], "obviou": [21, 22, 23, 49, 55, 57, 63, 64, 80], "immedi": [21, 29, 40, 43, 49, 53, 63, 65, 74], "issu": [21, 22, 23, 25, 27, 46, 48, 49, 53, 63, 65, 66, 84], "proof": [21, 68], "consequ": 21, "conjectur": [21, 66], "final": [21, 28, 33, 40, 42, 54, 57, 63, 64, 65, 66, 67, 69, 72, 74, 75, 82, 90], "y_i": [21, 22, 31, 54, 57, 66, 69, 74], "f_x": 21, "subscript": [21, 40, 54, 63], "wish": [21, 22, 23, 27, 28, 37, 42, 43, 44, 45, 48, 49, 51, 53, 54, 63, 64, 66, 72, 74, 75, 83], "f_y": 21, "enforc": [21, 44], "mathbf": [21, 42, 66, 67, 68, 69, 71, 80], "partial": [21, 25, 32, 68, 80, 82], "x_1": [21, 51, 68], "x_2": [21, 51, 68], "ldot": [21, 22, 37, 40, 51, 54, 57, 58, 62, 63, 66, 67], "factor": [21, 22, 27, 58, 59, 66, 72, 84], "jacobian": 21, "absolut": [21, 53, 80], "determin": [21, 25, 29, 44, 49, 51, 52, 54, 57, 60, 63, 66, 67, 80, 84, 86], "jacobi": [21, 25], "matrix": [21, 22, 25, 31, 32, 33, 44, 51, 57, 67, 68, 69, 71, 80, 82, 84], "pmatrix": [21, 25, 29, 66, 74, 80], "cdot": [21, 22, 25, 31, 32, 40, 51, 62, 66, 68, 69, 80, 82, 86], "vdot": [21, 25], "ddot": [21, 25], "exponenti": [21, 24, 27, 28, 32, 33, 37, 48, 51, 54, 66, 67, 69, 71, 80, 82, 86], "beta": [21, 32, 33, 34, 37, 42, 44, 45, 46, 49, 50, 51, 52, 55, 57, 58, 59, 60, 62, 65, 66, 68, 72, 82, 84, 86], "saw": [21, 23, 44, 46, 65, 68, 72], "rescal": [21, 80], "rate": [21, 38, 49, 66, 67, 68, 71, 83, 86], "accordingli": [21, 72], "sqrt": [21, 22, 25, 27, 31, 32, 33, 53, 66, 67, 68, 74, 80, 82, 84], "ln": [21, 25, 27, 31, 32, 37, 44, 49, 50, 54, 55, 57, 66, 67, 69, 71, 72, 86], "subtl": [21, 25], "univers": [21, 62], "2003": 21, "subtleti": [21, 54], "simplest": [22, 28, 40, 46, 84], "beak": [22, 57], "depth": [22, 27, 53, 55, 57, 60, 63, 65, 66, 68, 69, 71, 74, 86], "finch": [22, 57], "fluoresc": [22, 42, 63, 83, 86], "abound": 22, "concret": [22, 23, 25, 54, 63, 66, 86], "elegan": [22, 24, 25, 51, 62], "egg": [22, 24, 25, 29, 31, 45, 51], "equiv": [22, 25, 49, 54, 63, 66], "y_n": [22, 54, 57], "ambigu": [22, 54], "sharpen": 22, "low": [22, 25, 33, 39, 44, 46, 63, 66, 67, 68, 82, 86], "codifi": [22, 23, 25, 45, 54], "light": [22, 23, 25, 49, 51, 62], "constant": [22, 25, 27, 28, 31, 49, 58, 66, 67, 69, 71, 72, 86], "everi": [22, 25, 28, 31, 32, 38, 44, 45, 49, 50, 67, 69, 75, 80, 82, 84, 86], "error": [22, 27, 42, 44, 49, 51, 57, 62, 65, 66, 67, 68, 75, 80, 82, 84], "confound": 22, "prod_": [22, 27, 54, 58, 86], "delta": [22, 23, 54, 68, 69, 71], "dirac": [22, 23, 54], "Of": [22, 29, 58, 66], "theoret": [22, 23, 28, 29, 33, 42, 44, 49, 51, 65, 66, 67, 75, 82], "shall": [22, 27, 66], "heavi": [22, 48, 51, 67, 82, 84, 86], "univari": [22, 46, 50, 51, 69, 71], "pdf": [22, 24, 25, 27, 28, 29, 31, 32, 33, 40, 42, 46, 48, 49, 65, 67, 74, 75, 82], "exp": [22, 27, 28, 31, 32, 33, 44, 53, 54, 57, 66, 67, 68, 69, 71, 74, 80, 86], "scale": [22, 25, 27, 31, 32, 33, 34, 42, 43, 45, 46, 49, 51, 54, 55, 57, 63, 65, 67, 68, 69, 71, 80, 82, 84], "standard": [22, 23, 43, 48, 49, 57, 63, 64, 65, 66, 67, 68, 75, 82], "deviat": [22, 48, 49, 51, 52, 63, 64, 65, 66, 67, 68, 80], "squar": [22, 25, 66, 67, 69, 71, 80, 84], "varianc": [22, 24, 31, 39, 43, 49, 51, 52, 53, 54, 63, 64, 65, 66, 68, 82], "confusingli": 22, "literatur": [22, 75], "central": [22, 24, 32, 46, 48, 82, 84], "emerg": 22, "tend": [22, 25, 31, 44, 52, 53, 54, 57, 60, 64, 66, 68], "none": [22, 24, 34, 42, 49, 51, 55, 65, 84], "broadli": 22, "contribut": [22, 44, 57, 72, 80, 82], "mathsf": [22, 25, 31, 32, 51, 66, 67, 68, 69, 71, 72, 80], "boldsymbol": [22, 66, 67, 68, 69, 71, 72], "det": [22, 25, 80], "mu_1": [22, 74], "mu_2": [22, 48, 74], "mu_n": 22, "arrai": [22, 27, 28, 31, 33, 42, 43, 44, 45, 46, 48, 49, 50, 52, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 84, 86], "symmetr": [22, 32, 64, 66, 72], "posit": [22, 25, 27, 28, 31, 32, 37, 38, 39, 42, 49, 57, 58, 63, 66, 67, 68, 69, 71, 72, 80, 82], "diagon": [22, 31, 32, 44, 65, 66, 67, 69, 71, 72], "entri": [22, 25, 32, 44, 51, 63, 66, 67, 69, 72, 75, 84], "sigma_": [22, 25, 32, 64, 66], "ij": [22, 25, 32, 66, 68], "y_j": 22, "correl": [22, 42, 44, 52, 66, 74, 80, 82], "anticorrel": [22, 46], "reduc": [22, 55, 84], "sigma_i": [22, 49, 50, 55, 66, 72, 74], "mu_i": [22, 33, 45, 46, 49, 50, 51, 55, 66, 68, 72, 74], "2_i": 22, "multi": [22, 48, 71, 86], "decid": [22, 25, 49, 69, 75, 83, 86], "spread": [22, 65, 69, 84], "had": [22, 25, 33, 45, 49, 52, 53, 55, 58, 65, 71, 75, 80, 86], "sought": 22, "beyond": [22, 25, 27, 54, 65, 68, 75], "int_0": [22, 25, 27, 28], "captur": [22, 25, 27, 50, 51, 55, 62, 63, 64, 65, 66, 67, 69, 72, 86], "current": [22, 25, 27, 38, 46, 54, 82, 86], "guess": [22, 25, 28, 31, 33, 67, 68, 80], "50": [22, 25, 27, 28, 31, 32, 33, 34, 37, 45, 46, 48, 49, 50, 55, 60, 63, 65, 69, 72, 74, 75, 86], "\u00b5m": [22, 25, 27, 28, 31, 33, 45, 46, 49, 50, 51, 55, 72], "broad": [22, 23, 25, 27, 31, 49, 54, 65, 66, 75, 86, 90], "mu_": [22, 25], "tini": [22, 32, 53], "five": [22, 59, 64, 65], "ten": [22, 25, 51, 83], "micron": [22, 25, 31, 45], "size": [22, 25, 28, 33, 34, 43, 44, 45, 46, 48, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 74, 80, 82, 84, 86], "neg": [22, 25, 27, 31, 32, 33, 42, 44, 49, 51, 52, 57, 65, 67, 72, 80, 84, 86], "unphys": [22, 49, 65], "mathemat": [22, 25, 27, 28, 29, 31, 49, 51, 54, 66, 72, 75, 82, 84], "disallow": 22, "With": [22, 25, 42, 43, 45, 49, 50, 57, 58, 65, 68, 82, 86], "roughli": [22, 23, 64, 83, 86], "piec": [22, 31], "paper": [22, 23, 29, 39, 42, 43, 44, 52, 53, 54, 57, 64, 65, 66, 68, 72, 80, 82, 83, 86], "cover": [22, 25, 38, 55, 84], "exclud": 22, "unreason": [22, 66], "1em": [22, 25, 27, 28, 29, 31, 33, 38, 42, 44, 45, 46, 49, 50, 52, 53, 55, 57, 58, 60, 62, 63, 65, 66, 67, 68, 69, 71, 72, 74, 82, 84, 86], "brace": [22, 43, 44, 45, 49], "oh": [22, 86], "mess": [22, 54], "challeng": [22, 23, 24, 25, 29, 44, 63, 66, 84], "easi": [22, 23, 29, 32, 44, 48, 49, 53, 72, 80, 84, 86], "shorthand": [22, 37], "integr": [22, 23, 25, 27, 28, 29, 33, 37, 38, 40, 53, 54, 64, 72, 74, 86, 90], "omit": [22, 54], "english": [22, 64], "self": [22, 64, 65], "sim": [22, 25, 27, 28, 29, 31, 33, 42, 44, 45, 46, 49, 50, 51, 52, 53, 55, 58, 60, 62, 63, 65, 66, 67, 68, 69, 71, 72, 74, 82, 84, 86], "norm": [22, 25, 27, 31, 32, 33, 42, 43, 44, 45, 46, 49, 50, 51, 52, 53, 55, 63, 65, 66, 68, 69, 72, 74, 80], "foral": [22, 27, 28, 31, 33, 42, 44, 45, 46, 49, 50, 52, 55, 58, 60, 65, 66, 68, 69, 72, 74, 84, 86], "nasti": [22, 29, 40], "am": [22, 31, 40, 44, 51, 54, 57, 60, 75, 84, 86, 90], "nor": [22, 25, 31, 48, 57, 66, 67, 84], "maintain": [22, 25], "focu": [22, 23, 27, 37, 42, 44, 49, 66], "loos": [23, 52, 54, 82], "explicit": [23, 49, 66], "unambigu": [23, 44, 49], "commonli": [23, 25, 39, 43, 46, 48, 52, 68, 71, 84], "descript": [23, 42, 52, 64, 65, 82, 86], "prescrib": [23, 49, 51], "subsequ": [23, 51, 66, 71, 86], "asid": [23, 52], "philosoph": 23, "gelman": [23, 37, 39, 54, 57, 89], "simpson": [23, 46], "betancourt": [23, 35, 44, 50, 52, 53, 64, 80, 82, 89], "clearli": [23, 27, 29, 42, 44, 50, 53, 57, 60, 63, 65, 72, 75, 83, 86], "dilemma": 23, "2017": [23, 60, 62, 72, 80], "apt": [23, 42], "titl": [23, 42, 48, 49, 80, 86], "understood": [23, 49, 54], "emphasi": [23, 48, 67], "sort": [23, 29, 49, 55, 84], "liter": 23, "extern": 23, "social": 23, "intervent": 23, "he": [23, 25, 31, 33, 54, 86], "she": 23, "pattern": [23, 63], "gather": 23, "form": [23, 25, 29, 32, 44, 46, 49, 54, 58, 66, 69, 72, 75, 80, 82, 83, 86], "unknown": [23, 49, 54, 66], "latter": [23, 44, 54, 64, 84], "destin": 23, "previou": [23, 24, 31, 32, 33, 44, 45, 46, 50, 52, 55, 57, 63, 64, 65, 67, 69, 71, 75, 82, 86], "complic": [23, 25, 43, 80, 82], "grow": [23, 25, 27, 49, 63, 66, 82], "manifest": [23, 44], "heart": [23, 66], "technic": [23, 80, 84], "langl": [23, 40, 64, 80], "xi": [23, 51, 59, 66, 71], "rangl": [23, 40, 80], "replac": [23, 37, 38, 63, 66, 68, 71, 72, 80, 86], "theta_1": [23, 25, 31, 58, 62, 63, 72], "theta_2": [23, 25, 31, 58, 62, 63, 72], "conjagaci": 23, "maxim": [23, 25, 27, 31, 32, 48, 67, 72, 86], "analyt": [23, 25, 29, 32, 33, 40, 45, 53, 69, 72, 82], "automat": [23, 27, 44, 49, 52, 53, 80, 84], "actual": [23, 25, 27, 29, 32, 40, 42, 49, 50, 54, 57, 60, 62, 64, 65, 66, 68, 69, 71, 80, 84, 86], "earlier": [23, 25, 44, 80], "resort": [23, 82], "candid": [23, 38], "nice": [23, 37, 42, 46, 48, 50, 64, 66, 68, 71, 86, 89], "eas": [23, 25, 66, 72], "therebi": [23, 25, 29], "enorm": 24, "amount": [24, 25, 31, 49, 51, 54, 55, 84], "molecul": [24, 42, 49, 51, 52, 69], "individu": [24, 28, 49, 57, 60, 63, 82, 86], "bind": [24, 83, 86], "ligand": [24, 83, 86], "receptor": [24, 83, 86], "record": 24, "memori": [24, 37, 84], "poisson": [24, 51, 66, 86], "arriv": [24, 37, 39, 72, 86], "exist": [24, 32, 37, 49, 82], "worth": [24, 66, 68, 80, 84], "invest": 24, "greatli": [24, 66, 82, 84], "felt": 25, "heat": 25, "framework": [25, 82], "invalid": [25, 42, 67, 68, 80], "bia": [25, 42, 64, 66], "maximum": [25, 27, 31, 46, 51, 52, 53, 55, 57, 60, 63, 65, 66, 68, 69, 71, 74, 83, 84, 86], "entropi": [25, 72], "bernardo": 25, "eventu": [25, 37, 82, 86], "advoc": 25, "insuffici": 25, "old": [25, 29, 86], "flat": [25, 33, 54], "quit": [25, 44, 49, 51, 54, 57, 64, 66, 71, 75, 80, 82, 84, 86], "summar": [25, 31, 46], "normaliz": 25, "Such": [25, 44, 64], "improp": [25, 27, 28], "encod": [25, 45, 72], "machineri": [25, 42], "remedi": 25, "bound": [25, 27, 28, 31, 32, 42, 44, 45, 46, 48, 49, 52, 66, 67, 68, 72, 84], "infinit": [25, 42, 66, 82], "outsid": [25, 43, 49, 54, 55, 64, 75, 80, 82], "small": [25, 27, 44, 49, 51, 52, 53, 63, 65, 66, 67, 68, 69, 71, 72, 75, 80, 82, 86], "distanc": [25, 51, 72, 80], "epsilon": [25, 82], "speed": [25, 32, 48, 51, 69, 72, 80, 84], "kinesin": [25, 51], "motor": [25, 49, 51], "noth": [25, 43, 49, 65], "goe": [25, 33, 37, 49, 68, 82, 86], "absurd": 25, "primari": [25, 27, 48, 89], "critic": [25, 29, 49], "fisher": 25, "hi": [25, 29, 35, 39, 46], "contemporari": 25, "illustr": [25, 37, 44, 48, 57, 66, 80, 86], "resolut": 25, "earli": [25, 67, 68], "patholog": [25, 52, 53, 55, 57, 60, 63, 64, 65, 66, 68, 69, 71, 74, 82, 86], "bad": [25, 42, 49, 50, 55, 57, 69, 86], "subject": [25, 52, 54, 72, 84, 90], "debat": 25, "complain": 25, "chosen": [25, 44, 48, 49, 50, 63, 66, 80], "recal": [25, 27, 32, 33, 43, 52, 54, 57, 65, 68, 86], "formula": [25, 53], "inconsist": 25, "invari": [25, 37, 38, 58], "harold": 25, "discov": [25, 44, 51, 53, 65], "coordin": [25, 42, 43, 44, 52, 53, 57, 63], "mathcal": [25, 72, 80, 82], "_": [25, 28, 32, 48, 54, 57, 66, 67, 68, 69, 71, 82, 86], "succinctli": 25, "hessian": [25, 31, 32, 33], "sharp": [25, 49, 58, 86], "peak": [25, 27, 28, 31, 32, 49, 54, 58, 86], "propto": [25, 27, 28, 32, 82, 86], "strictli": [25, 49, 51, 71, 84], "nonneg": 25, "reparametr": [25, 53, 63, 82], "phi": [25, 27, 28, 31, 33, 45, 46, 49, 50, 55, 58, 59, 60, 62, 69, 72, 82, 86], "phi_1": 25, "phi_2": 25, "matric": [25, 66, 68, 71], "recogn": [25, 74, 82, 83], "difficult": [25, 27, 32, 49, 52, 53, 72], "intract": [25, 33, 72], "against": [25, 33, 49, 50, 54, 55, 57, 64, 67, 68], "tediou": 25, "invers": [25, 31, 32, 37, 42, 44, 51, 66, 67, 69, 80], "binomi": [25, 42, 44, 52, 57, 60, 62, 65, 80, 84, 86], "bernoulli": [25, 29, 62, 80], "success": [25, 27, 29, 62, 72, 80, 86], "trial": [25, 29, 60, 62, 64, 65, 80], "proper": [25, 27], "highli": [25, 38, 45, 49, 62, 68], "suggest": [25, 39, 44, 54], "priori": [25, 29, 49, 51], "regardless": [25, 52, 82], "littl": [25, 27, 31, 40, 48, 51, 52, 54, 69, 80], "influenc": [25, 66], "lack": [25, 37, 54], "imposs": [25, 38, 40, 44, 49, 51, 86], "nefari": 25, "care": [25, 27, 28, 42, 49, 54, 66, 72, 75], "anywai": [25, 27, 68], "travel": 25, "suppos": [25, 86], "somewhat": [25, 86], "breadth": [25, 27, 82], "broader": [25, 32], "opt": [25, 80], "wiki": [25, 52], "loss": [25, 54], "precis": [25, 51, 52, 68, 82], "compar": [25, 27, 32, 33, 46, 50, 53, 54, 55, 57, 63, 64, 68, 69, 71, 72, 74, 84, 86], "popul": [25, 42, 44, 86], "expert": 25, "seriou": [25, 44, 72, 75], "gain": [25, 54], "robust": [25, 48, 57, 82], "separ": [25, 42, 43, 49, 51, 60, 62, 71, 75, 86], "sublim": 25, "ridicul": 25, "consider": [25, 27, 44, 49, 66], "difficulti": [25, 48, 59, 65, 75], "rare": [25, 32, 38, 49, 54], "complex": [25, 29, 43, 44, 49, 51, 66, 72, 80, 82, 83, 84, 86], "certainli": [25, 28, 32, 44, 49, 52, 84], "hierarchi": [25, 59, 63, 72], "parametriz": 25, "greatest": 25, "unbound": 25, "idiomat": 25, "giant": [25, 51], "wager": 25, "salari": 25, "pig": [25, 54], "fly": [25, 54], "comfort": 25, "wage": 25, "don": [25, 31, 52, 63, 66, 80, 82, 84, 86], "hope": [25, 44, 64, 84], "lo": 25, "angel": 25, "footbal": 25, "club": 25, "win": 25, "ml": 25, "cup": 25, "someon": [25, 29, 80], "tell": [25, 28, 29, 31, 32, 39, 42, 43, 49, 54, 63, 64, 65, 71, 80, 82], "bacterium": 25, "absurdli": 25, "bigger": [25, 31, 49, 57, 58, 69, 86], "nanomet": [25, 51], "diamet": [25, 27, 28, 31, 33, 45, 46, 49, 50, 55, 72], "strand": 25, "dna": [25, 42], "nm": [25, 31, 63, 72], "flinch": 25, "m": [25, 44, 49, 54, 63, 66, 67, 68, 69, 71, 72, 80, 82, 84, 86, 90], "bacteria": [25, 68], "smaller": [25, 31, 49, 53, 54, 57, 63, 80, 86], "uneasi": 25, "won": [25, 53, 63, 64, 80], "meter": [25, 51], "cm": 25, "gigant": 25, "mm": [25, 31], "huge": [25, 80, 86], "tremend": 25, "divers": 25, "eukaryot": [25, 49], "big": [25, 33, 42, 48, 49, 63, 72], "xenopu": [25, 31, 45, 49], "strongli": [25, 43, 49, 80, 86], "wouldn": [25, 86], "magnitud": [25, 27, 46, 49, 51, 64, 65, 66, 80, 82], "geometr": 25, "boundari": 25, "surprisingli": [25, 63], "bacteri": [25, 42, 68], "coli": [25, 63, 68], "logarithm": [25, 27, 31, 32, 42, 44, 51, 53, 54, 57, 63, 66, 69, 72, 82], "ignor": [25, 32, 33, 40, 42, 45, 46, 49, 50, 54, 58, 82], "95": [25, 31, 32, 46, 48, 49, 51, 52, 66, 69, 75], "li": [25, 53], "width": [25, 49, 53, 63, 64, 80], "rang": [25, 27, 28, 31, 33, 37, 42, 44, 49, 50, 54, 60, 64, 65, 66, 67, 69, 72, 80, 84, 86], "ell": [25, 27, 28, 31, 33, 45, 46, 49, 50, 55, 72], "log_": [25, 31, 42, 44, 45, 46, 51, 52, 65, 66, 72], "approx": [25, 32, 39, 40, 49, 54, 57, 68, 80], "lognorm": [25, 31, 33, 49, 50, 52, 55, 57, 72, 75], "hesit": [25, 52], "theta_": [25, 37, 38, 72], "min": [25, 34, 38, 49, 66, 67, 68, 69, 71, 84], "max": [25, 27, 28, 31, 33, 34, 44, 66, 67, 68, 69, 71, 80, 84, 86], "divid": [25, 28, 37, 65, 68], "conceiv": [25, 64, 69], "came": [25, 54, 75, 82], "firm": 25, "countless": 25, "pl": [27, 28, 31, 33, 42, 44, 45, 46, 48, 49, 50, 52, 55, 57, 63, 65, 66, 67, 68, 69, 71, 72], "scipi": [27, 28, 29, 31, 32, 33, 34, 42, 43, 44, 49, 65, 68, 69, 71, 80, 84, 86], "stat": [27, 28, 29, 31, 32, 33, 34, 42, 43, 44, 48, 49, 65, 67, 68, 71, 80, 84], "st": [27, 28, 29, 31, 32, 33, 34, 42, 43, 44, 49, 65, 67, 68, 71, 80, 84], "ve": [27, 84, 86], "whole": [27, 31, 53, 63, 86], "bread": 27, "butter": 27, "inaccess": 27, "viabl": 27, "mitot": [27, 49, 55], "encapsul": [27, 45], "droplet": [27, 28, 31, 33, 45, 46, 50, 55, 72], "matt": [27, 72], "refamiliar": [27, 31], "remind": [27, 28, 46, 52, 54, 60, 69, 71, 72], "versu": [27, 31, 46, 49, 50, 55, 63, 65, 66], "good_invitro_droplet_data": [27, 28, 31, 33, 45, 46, 49, 50, 55, 72], "frame": [27, 28, 31, 33, 43, 44, 45, 46, 48, 49, 52, 55, 63, 65, 67, 72], "df": [27, 28, 31, 33, 42, 44, 45, 46, 49, 50, 52, 55, 57, 63, 65, 66, 67, 68, 69, 71, 72, 84], "read_csv": [27, 28, 31, 33, 42, 44, 45, 46, 49, 50, 52, 55, 57, 63, 65, 66, 67, 68, 69, 71, 72, 84], "join": [27, 28, 31, 33, 42, 44, 45, 46, 49, 50, 52, 55, 57, 63, 65, 66, 67, 68, 69, 71, 72, 75, 83, 84, 86], "comment_prefix": [27, 28, 31, 33, 42, 44, 45, 46, 49, 50, 52, 55, 57, 65, 68, 72], "um": [27, 28, 31, 33, 45, 46, 49, 50, 55, 72], "to_numpi": [27, 28, 31, 33, 42, 44, 45, 46, 48, 49, 50, 52, 55, 57, 65, 66, 67, 68, 69, 71, 72], "200": [27, 28, 29, 31, 32, 33, 34, 42, 44, 45, 46, 48, 49, 50, 55, 65, 66, 72, 74, 75, 86, 90], "300": [27, 28, 29, 31, 33, 34, 43, 45, 46, 49, 65, 72, 80, 86], "x_rang": [27, 28, 29, 31, 32, 33, 34, 42, 45, 46, 49, 50, 53, 55, 65, 66, 72], "y_rang": [27, 28, 31, 32, 33, 34, 45, 46, 49, 65, 72, 80], "to_dict": [27, 28, 31, 33, 45, 46, 49, 65, 66, 67, 69, 72], "object": [27, 29, 31, 43, 44, 52, 57, 67, 72, 75, 80, 82, 84], "treat": [27, 49, 66], "uniform": [27, 28, 29, 34, 37, 44, 45, 60, 64, 82], "jeffrei": [27, 28, 31, 45], "l_i": [27, 28, 31, 33, 45, 46, 49, 50, 55, 72], "implicit": [27, 54], "somedistribut": 27, "vanilla": 27, "tubulin": [27, 31, 45, 46, 55], "conserv": [27, 31, 45, 46, 49, 55, 57, 80, 82], "proport": [27, 37, 40, 42, 54, 86], "evalu": [27, 28, 29, 32, 33, 66, 67, 68, 69, 72, 80, 82, 86], "handi": [27, 46], "progress": [27, 43, 66], "postpon": 27, "secondli": [27, 84], "hit": [27, 52, 63, 67, 80], "underflow": [27, 28, 31, 44, 86], "circumst": 27, "insid": [27, 82, 86], "behav": [27, 32, 44, 58, 66, 80, 86], "risk": 27, "logsumexp": 27, "def": [27, 28, 31, 33, 42, 48, 66, 67, 68, 69, 71, 72, 74, 80, 84], "log_marginalized_posterior": [27, 28], "inf": [27, 31, 33, 42, 57, 67, 68], "len": [27, 28, 31, 42, 44, 45, 46, 49, 50, 52, 55, 57, 60, 65, 66, 67, 68, 69, 71, 72, 80, 84, 86], "smooth": [27, 50, 54, 57, 66, 68], "curv": [27, 28, 33, 45, 49, 50, 66, 68, 80], "grung": [27, 66, 74], "linspac": [27, 28, 29, 31, 32, 33, 34, 49, 50, 53, 55, 65, 66, 67, 68, 69, 71, 72, 80], "log_marg_post": 27, "phi_val": [27, 28], "\u03c6": [27, 28, 31, 33, 46, 72], "l\u1d62": [27, 28], "line_width": [27, 28, 29, 31, 32, 33, 34, 42, 44, 48, 49, 52, 53, 65, 66, 67, 68, 69, 80], "33": [27, 31, 42, 44, 48, 53, 86], "awai": [27, 31, 32, 33, 49, 51, 53, 57, 64, 65, 66, 67, 80, 82], "subtract": [27, 54, 86], "marg": 27, "log_marg_post_max": 27, "marg_post": 27, "visual": [27, 28, 31, 32, 42, 44, 45, 48, 49, 65, 66, 82], "axi": [27, 33, 37, 42, 46, 49, 51, 64, 65, 86], "g_": 27, "proportion": [27, 49], "clever": [27, 37, 72], "momentarili": [27, 52, 63, 66], "quad": [27, 28], "marginalized_posterior": [27, 28], "unnorm": [27, 28, 44, 86], "integrand": [27, 28], "third": [27, 44, 50, 74, 75], "resolv": [27, 49], "domain": [27, 45, 51, 67], "pass": [27, 31, 33, 42, 43, 44, 49, 50, 52, 55, 65, 72, 75, 84], "arg": [27, 28, 31, 33, 49, 67, 68, 84], "kwarg": [27, 31, 42, 43, 44, 46, 49, 50, 57, 69, 71, 72], "err": 27, "46386461926837497": 27, "981239131261995e": 27, "review": [27, 72, 73, 80], "unorm": 27, "found": [27, 31, 32, 33, 40, 62, 66, 71, 72, 84, 86], "straightforwardli": 27, "grungi": 27, "x_i": [27, 51, 66, 68, 74, 86], "bar": [27, 43, 44, 62, 66], "hat": [27, 39, 53, 54, 82], "nu": [27, 51, 66, 68], "std": [27, 48, 66, 67, 68, 69, 71], "exact_pdf": 27, "color": [27, 29, 32, 33, 34, 42, 44, 46, 48, 53, 60, 63, 65, 66, 67, 68, 69, 71, 74, 80, 86], "line_dash": 27, "dash": 27, "perfect": [27, 80], "exact": [27, 31, 72, 80, 82], "efficaci": 27, "tough": 27, "contour": [27, 28, 31, 33, 53, 82], "minim": [27, 31, 32, 33, 43, 49, 67, 68, 72, 75, 80], "furthermor": [27, 31, 33, 40, 48, 50, 51, 63, 64, 66, 84], "clean": [27, 82], "log_prior_indep_s": 27, "param": [27, 28, 31, 33, 42, 44, 46, 49, 66, 67, 68, 71], "log_likelihood_indep_s": 27, "logpdf": [27, 31, 33, 67, 68], "loc": [27, 31, 32, 33, 34, 44, 49, 65, 67, 68], "log_posterior_indep_s": 27, "lp": [27, 31, 33, 43, 44, 67, 68, 86], "prevent": [27, 49, 84], "bug": [27, 52, 75, 84], "trade": 27, "overhead": 27, "log_likelihood_indep_size_numpy_onli": 27, "timeit": 27, "ntime": 27, "136": 27, "452": 27, "loop": [27, 44, 49, 84], "000": [27, 33, 52, 65, 72, 84], "49": [27, 44, 84], "nearli": [27, 49, 63, 75, 80, 86], "slow": [27, 31, 66, 68], "increasingli": 27, "fraction": [27, 49, 52, 82], "nonneglig": 27, "shrink": [27, 60], "rapidli": [27, 29, 66, 82], "dimens": [27, 32, 42, 43, 44, 50, 52, 57, 80, 82], "log_post": [27, 28, 33], "enumer": [27, 28], "sigma_v": 27, "overflow": [27, 28, 52], "post": [27, 28, 44, 64, 66, 68, 71, 74, 75, 86], "packag": [27, 43, 46, 54, 57, 67, 68, 71, 75, 84, 89], "viz": [27, 28, 31, 32, 33, 42, 44, 45, 46, 49, 50, 52, 53, 55, 57, 60, 63, 65, 66, 67, 68, 69, 71, 72, 86], "overlaid": [27, 28, 33, 53, 54], "\u03c3": [27, 31, 33, 45, 46, 49, 67, 68, 71, 72], "harder": [27, 33, 43, 52], "zoom": [27, 28, 63, 68, 86], "31": [27, 34, 44, 48, 52, 53, 55, 72, 86, 90], "35": [27, 31, 33, 42, 43, 44, 45, 49, 50, 52, 53, 55, 57, 60, 62, 63, 65, 66, 72, 86], "shape": [27, 29, 33, 42, 44, 46, 48, 49, 50, 52, 53, 63, 65, 69, 72, 86], "spindl": [28, 31, 33, 45, 46, 50, 55], "gamma": [28, 29, 32, 33, 34, 37, 44, 45, 46, 49, 50, 51, 55, 58, 65, 66, 67, 68, 69, 72, 84], "d_i": [28, 33, 45, 46, 49, 50, 55, 72], "trivari": 28, "tri": [28, 49], "theor_spindle_length": 28, "cbrt": [28, 33, 45, 46, 49, 50, 55, 72], "eyebal": 28, "somewher": [28, 31, 49], "37": [28, 33, 44, 55, 63, 72, 86], "asymptot": [28, 49, 54, 72], "slope": 28, "45": [28, 29, 44, 48, 69], "gamma_v": 28, "adjust": [28, 43, 46, 49, 50, 55, 64, 68, 72], "\u03d5": [28, 31, 33, 45, 46, 49, 60], "\u03b3": [28, 33, 45, 46, 49, 72], "log_post_max": 28, "calc": 28, "varphi": 28, "infin": [28, 66, 80], "unnormalized_marg_post_phi": 28, "empty_lik": [28, 33], "d\u1d62": 28, "trapezoid": 28, "trapz": [28, 33, 86], "normalization_const": 28, "wrinkl": 28, "lambda": [28, 53, 66, 69, 80], "swap": 28, "input": [28, 42, 43, 49, 50, 57, 68, 69, 71, 74, 84, 86], "unnormalized_marg_post_gamma": 28, "norm_const": 28, "valuabl": [28, 51, 89], "oppos": [28, 49, 75, 82, 84], "rear": 28, "doom": 28, "handl": [28, 38, 44, 64, 67, 82, 84], "spend": [28, 75, 84], "sophist": [28, 57], "posteriori": [29, 32, 67], "seem": [29, 38, 42, 49, 55, 63, 64, 65, 66, 72, 82, 84, 86], "mossman": 29, "et": [29, 31, 33, 42, 45, 46, 49, 50, 52, 55, 64, 68, 69, 72, 89], "al": [29, 31, 33, 42, 45, 46, 49, 50, 52, 55, 64, 68, 69, 72, 86, 89], "2019": 29, "author": [29, 42, 84, 89], "ag": 29, "drosophila": 29, "parent": 29, "viabil": 29, "offspr": 29, "vial": 29, "mate": 29, "young": 29, "dai": [29, 38, 63, 72, 75, 84, 90], "male": 29, "femal": 29, "176": [29, 72], "period": [29, 37, 66], "94": [29, 46, 69], "hatch": 29, "remaind": 29, "fail": [29, 50, 57, 64, 65, 84], "190": [29, 72, 86], "154": 29, "failur": 29, "binom": [29, 57, 58, 60, 80], "seek": [29, 32, 42, 54, 57, 74], "Its": [29, 74], "wikipedia": [29, 52], "tabl": [29, 43, 49, 83, 86], "mother": 29, "n_old": 29, "n_young": 29, "instanti": [29, 48, 49, 74, 84], "\u03b8": [29, 53, 60, 63, 80], "legend_label": [29, 32, 48, 53, 60, 63, 66, 72, 80, 86], "legend": [29, 48, 53, 60, 63, 74, 80, 86], "top_left": [29, 80], "disavantag": 29, "tractabl": [29, 32, 45], "paltri": 29, "hopeless": 29, "coin": 29, "slightli": [29, 67], "bias": [29, 82], "bimod": [29, 42, 44, 48, 57], "sivia": 29, "bear": [29, 37, 48, 52], "conduct": [29, 65, 83, 84], "strang": [29, 40, 49, 66, 86], "upon": [29, 49, 54, 63], "statsmodel": [31, 33], "numdiff": [31, 33], "smnd": [31, 33], "tqdm": [31, 33], "342": [31, 33, 45, 46, 49, 55], "856": [31, 33, 45, 46, 49, 52, 55], "860": [31, 33, 45, 46, 49, 55], "2013": [31, 33, 45, 46, 49, 55], "abandon": 31, "characterist": [31, 49, 68], "bet": [31, 42, 45, 51], "farm": [31, 42, 45, 51], "breviti": 31, "logspac": 31, "1e": [31, 49, 66, 67, 68, 69, 71], "1e5": 31, "x_axis_typ": [31, 65], "half": [31, 45, 49, 51, 58, 63, 67, 83], "halfnorm": [31, 33, 45, 46, 49, 58, 60, 63, 66, 67, 68, 69, 71, 72, 74, 86], "albeit": 31, "themselv": [31, 43, 52], "y_3": 31, "sum_j": [31, 54], "fortun": [31, 33, 39, 44, 54, 57, 71, 86], "log_prior": [31, 33, 67, 68], "log_likelihood": [31, 33, 55, 57, 67, 68, 86], "log_posterior": [31, 33, 67, 68], "indpend": [31, 33], "algorithm": [31, 36, 37, 39, 43, 52, 54, 66], "powel": [31, 33, 67, 68], "reli": [31, 48, 82, 86], "discontinu": 31, "hurt": 31, "particularli": [31, 46, 52, 72, 82, 84], "constrain": [31, 44, 72, 82], "bfg": 31, "cobyla": 31, "neg_log_posterior": [31, 33, 67, 68], "routin": 31, "converg": [31, 52, 72], "params_0": [31, 33, 67, 68], "minimz": 31, "optimzi": 31, "attribut": [31, 42, 43, 44, 52, 57, 74], "extra": [31, 66, 68, 72, 75, 80], "popt": [31, 33], "phi_map": [31, 33], "sigma_map": [31, 33], "2f": [31, 33], "3f": [31, 33, 49, 60], "32": [31, 44, 57, 63, 72, 84, 86], "86": [31, 52, 57], "784": 31, "successfulli": 31, "invert": [31, 33, 66], "element": [31, 32, 44, 45, 63, 82], "approx_hess": [31, 33], "shove": 31, "cov": [31, 33, 66], "linalg": [31, 33], "inv": [31, 33, 51, 71], "41668904e": 31, "02": [31, 43, 44, 65, 90], "09388085e": 31, "06": [31, 44, 63, 72, 90], "70799615e": 31, "multipli": [31, 54, 66, 67, 68, 86], "96": [31, 32, 33, 48, 63, 65, 66, 67, 68, 72], "report": [31, 32, 33, 42, 44, 47, 52, 54, 62, 63, 64, 83], "256": 31, "multivariate_norm": [31, 33, 66, 67, 68, 74], "neighborhood": [31, 82], "post_norm": [31, 33], "empti": [31, 84], "log_post_exact": 31, "00": [31, 33, 42, 43, 44, 57, 65, 84, 90], "lt": [31, 33, 42, 43, 44, 52, 57, 65, 86], "50it": 31, "overlai": [31, 34, 50, 53, 67, 69], "post_exact": [31, 33], "line_kwarg": [31, 32, 33, 48, 49, 52, 53, 60, 72], "dict": [31, 32, 33, 42, 44, 45, 46, 49, 52, 53, 55, 60, 63, 65, 66, 67, 68, 69, 71, 72, 74, 84, 86], "line_color": [31, 33, 34, 48, 60, 68, 69, 71, 72], "danger": [31, 33], "66": [31, 33, 48], "catch_warn": 32, "simplefilt": 32, "abbrevi": [32, 43], "paramount": 32, "solv": [32, 49, 66, 80, 82], "dwell": 32, "seldom": [32, 48, 75], "Near": 32, "taylor": 32, "truncat": [32, 46, 49], "b_": 32, "y_gamma": 32, "y_norm": 32, "tomato": [32, 66, 67], "percent": [32, 37], "confid": [32, 43, 64, 65], "erron": 32, "025": [32, 72], "975": 32, "benefit": [32, 64, 66, 72, 84], "afford": [32, 66], "ii": 32, "pm": [32, 48, 49, 75, 90], "asymmetr": [32, 48], "extrem": [32, 49, 51, 52, 57, 62, 63, 66, 67, 82], "flaw": [32, 39], "median": [32, 40, 48, 49, 50, 60, 72], "34": [32, 42, 44, 52, 60, 63, 72, 86], "ppf": [32, 34, 80], "99": [32, 42, 49, 50, 53, 55, 60, 63, 65, 66, 69, 72], "perc_cred_int": 32, "gamma_low": 32, "gamma_high": 32, "norm_low": 32, "norm_high": 32, "fill_between": [32, 66, 67, 68], "patch_kwarg": [32, 66, 67, 68], "shift": [32, 86], "rightward": 32, "notabl": [32, 52, 60, 86], "miss": [32, 51, 52, 55, 64, 65, 80, 82], "despit": [32, 71, 82], "character": [32, 44, 49, 51, 65, 82], "throughput": [32, 83], "attract": 32, "pathologi": [32, 53, 57, 82], "breakdown": [32, 43, 66, 75], "mechan": [32, 80, 86], "p_data": [33, 46], "relationship": [33, 54, 63, 74], "homoscedast": [33, 45, 66, 67, 68], "toward": [33, 51, 60, 63, 64, 66, 72, 82, 86], "embark": 33, "solver": [33, 66, 82], "differenti": [33, 42, 44, 66, 68, 71], "theoretical_spindle_length": 33, "And": [33, 42, 49, 50, 52, 55, 57, 64, 65, 80], "gamma_map": 33, "38": [33, 37, 53, 65, 72, 86], "77": [33, 44, 57], "859": 33, "034": 33, "754": 33, "201": [33, 60], "grid": [33, 44, 48], "sigma_0": [33, 49, 50, 55, 72], "million": [33, 80], "brute": [33, 45, 49, 86], "forc": [33, 45, 49, 80, 86], "style": [33, 43, 60, 74, 80], "tight": [33, 50], "sea": 33, "needl": [33, 53], "haystack": 33, "39": [33, 42, 43, 44, 46, 57, 63, 67, 72, 84, 86], "91": [33, 84], "meshgrid": [33, 53, 80], "51": [33, 43, 63, 72], "52": [33, 52, 74], "post_margin": 33, "narrow": [33, 53, 64], "cut": 33, "instantan": 33, "dstack": 33, "discourag": 33, "week": [33, 50, 75, 90], "d_theor": 33, "ell_theor": [33, 45, 46, 49, 50, 55, 72], "linear": [33, 44, 49, 51, 66, 67, 68, 71], "regim": [33, 49], "caught": [33, 65], "dynam": [33, 42, 82], "blackcellmag": 34, "rng": [34, 43, 48, 49, 67, 69, 74, 86], "default_rng": [34, 43, 48, 49, 66, 67, 69, 74, 86], "seed": [34, 44, 48, 52, 53, 57, 63, 72, 86], "12341234": 34, "udraw": 34, "04": [34, 43, 65, 90], "xgrid": 34, "grid_line_color": 34, "ygrid": 34, "x_val": 34, "y_val": [34, 48], "grai": [34, 48, 80], "zeros_lik": [34, 66, 67, 68], "black": [34, 60, 69, 86], "circl": [34, 46, 80, 82, 86], "fill_color": [34, 68, 69, 71], "level": [34, 42, 44, 54, 59, 63, 66, 72, 80, 82], "educ": 35, "vignett": 35, "michael": [35, 44, 50, 52, 64, 80, 89], "hmc": [35, 38, 43, 63, 86], "hamiltonian": [35, 38, 52, 86], "transit": [36, 37, 39, 40, 72], "kernel": [36, 37, 39, 40, 46, 67, 69, 71, 80], "metropoli": [36, 82], "hast": [36, 82], "capabl": [37, 42, 57, 83, 84], "pcg64": 37, "128": [37, 57], "float": [37, 44, 49, 54, 57], "nonuniform": 37, "muller": 37, "absenc": [37, 52, 66], "quantil": [37, 40, 48, 52], "mark": [37, 86], "vertic": [37, 63, 66], "horizont": [37, 66], "target": [37, 38, 44, 52, 53, 57, 74, 82, 84, 86], "arbitrari": [37, 38, 40, 44, 52, 63, 66, 69, 82], "correct": [37, 54, 75, 80], "simplic": [37, 66, 84], "walk": [37, 39, 51, 82], "walker": [37, 38, 39, 46, 52, 57, 82, 86], "bold": [37, 50], "sentenc": [37, 52], "achiev": [37, 38, 39, 52, 65, 80], "condit": [37, 38, 44, 49, 54, 59, 62, 63, 64, 66, 69, 72, 80, 82, 84], "stationari": [37, 39, 68], "uniqu": [37, 44, 66, 72], "ergod": [37, 38, 82], "aperiod": 37, "2k": 37, "3k": 37, "irreduc": 37, "recurr": [37, 82], "revisit": 37, "checklist": 37, "moment": [37, 39, 42, 49, 54, 63, 66, 80, 82, 86], "preced": [37, 44, 45, 51, 80], "1000": [37, 42, 43, 44, 45, 46, 49, 50, 52, 57, 58, 60, 64, 65, 66, 67, 69, 71, 72, 80, 84, 86], "margossian": 37, "randomli": 38, "ratio": [38, 52, 68, 82, 86], "ge": 38, "accept": [38, 49, 64, 75, 82, 84], "otherwis": [38, 39, 43, 64, 72, 82], "nut": [38, 80], "earth": 38, "sequenti": [38, 51, 84], "bracket": 38, "art": [38, 42, 50, 52], "origin": [38, 43, 53, 58, 63, 64, 65, 66, 80], "1953": 38, "thumb": [38, 39, 52, 64], "wander": [38, 51], "reject": [38, 53, 82], "tune": [38, 39, 63, 66, 82], "gibb": 38, "modern": 38, "popular": [38, 43, 86], "special": [38, 44, 51, 63, 64, 66, 68, 80, 82, 84, 86], "improv": [38, 63, 65, 66], "subclass": 38, "overemphas": 38, "naiv": 38, "anyhow": 38, "devis": [39, 53, 83], "theta_0": 39, "travers": 39, "incredibli": [39, 66, 80, 82], "began": 39, "weight": [39, 42, 55, 68], "burn": 39, "reach": [39, 52, 68], "heurist": 39, "coauthor": 39, "rubin": 39, "metric": [39, 52, 64, 80, 82], "stationar": [39, 52], "famou": 39, "defer": [39, 45], "vehtari": [39, 52, 54, 57], "stringent": 39, "01": [39, 43, 48, 52, 53, 57, 63, 66, 72, 82, 84, 86, 90], "regular": [39, 86], "neglect": [39, 51, 72], "bunch": [39, 86], "strategi": [39, 44, 53, 64, 82, 86], "phase": [39, 42, 68, 80, 82], "h": [40, 54, 80, 82], "ecdf": [40, 43, 44, 45, 46, 49, 50, 52, 55, 60, 72, 86], "histogram": [40, 42, 46, 48, 74], "averag": [40, 54, 57, 64, 80, 82, 83, 86], "th": [40, 49, 54], "abundantli": 40, "abil": [40, 52, 54, 64, 66, 84, 86], "superscript": [40, 63], "parenthet": 40, "index": [40, 42, 43, 44, 49, 50, 52, 57, 63, 69, 72], "hello": 41, "drew": 42, "reconstruct": 42, "miracul": 42, "elowitz": [42, 65, 83, 84], "publish": [42, 52, 72], "singer": [42, 52, 57], "heterogen": 42, "methyl": 42, "embryon": 42, "stem": 42, "molec": 42, "55": [42, 63, 69], "319": 42, "331": 42, "2014": 42, "paragraph": [42, 75], "eda": 42, "rna": [42, 57, 65, 66, 84], "situ": 42, "hybrid": 42, "smfish": [42, 44, 52], "transcript": [42, 44, 52, 57, 65, 66, 69], "focus": [42, 84], "pluripot": 42, "associ": [42, 43, 44, 51, 65, 74, 82, 90], "regul": [42, 62], "hallmark": 42, "tempor": 42, "laps": [42, 83, 86], "movi": 42, "insight": [42, 82], "279": [42, 57, 86], "rex1": [42, 44, 57], "nanog": 42, "prdm14": 42, "singer_transcript_count": [42, 44, 52, 57, 65, 84], "q": [42, 46, 52, 54, 63, 65, 69, 80, 84, 86], "150": [42, 44, 46, 72], "layout": [42, 46, 48, 49, 72, 80, 86], "column": [42, 43, 44, 46, 48, 49, 50, 52, 63, 65, 72, 84], "row": [42, 43, 48, 49, 50, 63, 66, 72, 80], "fewer": [42, 49, 53, 86], "copi": [42, 57, 65, 69, 71, 84], "presenc": 42, "inflect": [42, 51], "edcf": 42, "impli": [42, 49, 63], "bursti": [42, 44, 52, 66, 69], "n_i": [42, 44, 52, 57, 58, 60, 62, 65, 66, 69, 84], "negbinom": [42, 44, 52, 65, 84], "higher": [42, 44, 54, 80, 82, 83, 84], "frequent": 42, "assembl": 42, "shorter": [42, 84], "environment": [42, 84], "lifetim": [42, 65], "promot": [42, 65, 68], "strength": [42, 65, 80], "thousand": [42, 64, 65, 84], "syntax": [42, 43, 44, 46, 49, 71, 89], "log10_alpha": [42, 44, 52, 57, 65], "log10_b": [42, 44, 52, 57, 65], "beta_": [42, 44, 52, 57, 60, 65, 84, 86], "neg_binomi": [42, 52, 57, 65, 84], "rais": 42, "block": [42, 43, 45, 49, 50, 51, 66, 67, 68, 69, 71, 82, 84, 86], "declar": [42, 43, 44, 45], "dictionari": [42, 44, 55, 57, 63, 66, 67, 68, 71], "iter_sampl": [42, 43, 44, 45, 46, 49, 50, 52, 60, 65, 66, 74, 84, 86], "inferencedata": [42, 43, 44, 49, 52, 57], "info": [42, 43, 84], "fatal": 42, "neg_binomial_lpmf": [42, 57, 84], "show_consol": 42, "unclear": 42, "fed": 42, "aris": [42, 44, 84, 86], "silenc": 42, "throw": [42, 64], "pedagog": [42, 89], "disabl": 42, "xarrai": [42, 43, 44, 50, 52, 57], "dataset": [42, 43, 44, 50, 52, 57, 84, 86], "gt": [42, 43, 44, 52, 57, 84, 86], "168kb": 42, "int64": [42, 43, 44, 52, 57], "32b": [42, 43, 44, 52, 57], "8kb": [42, 43, 44, 52, 57], "993": [42, 43, 44, 52, 57], "994": [42, 43, 44, 52, 57], "995": [42, 43, 44, 52, 57], "996": [42, 43, 44, 52, 57], "997": [42, 43, 44, 52, 57], "998": [42, 43, 44, 52, 57], "999": [42, 43, 44, 49, 52, 57], "float64": [42, 43, 44, 52, 57], "32kb": [42, 43, 44, 52], "722": [42, 52], "814": 42, "808": 42, "155": 42, "271": [42, 52, 57], "48": 42, "64": [42, 44], "07": [42, 43, 44, 57, 63, 72, 90], "05002": 42, "04916": 42, "0567": 42, "05535": 42, "5707": 42, "5814": 42, "6186": 42, "6305": 42, "301": [42, 72], "308": [42, 86], "311": 42, "246": 42, "257": 42, "created_at": [42, 43, 44, 57], "19t23": [42, 43], "29": [42, 44, 52, 65, 72, 86, 90], "089569": 42, "arviz_vers": [42, 43, 44, 57], "inference_librari": [42, 43, 44, 57], "inference_library_vers": [42, 43, 44, 57], "4xarrai": [42, 43, 44, 57], "datasetdimens": [42, 43, 44, 52, 57], "4draw": [42, 43, 44, 52, 57], "1000coordin": [42, 43, 44], "int640": [42, 43, 44, 52, 57], "3arrai": [42, 43, 44, 52, 57], "999arrai": [42, 43, 44, 52, 57], "float643": 42, "271arrai": 42, "72176": 42, "81412": 42, "8077": 42, "02461": 42, "95251": 42, "49689": 42, "82657": 42, "61593": 42, "68701": 42, "36608": 42, "37078": 42, "37826": 42, "87778": 42, "33051": 42, "30581": 42, "38294": 42, "52823": 42, "08891": 42, "80512": 42, "22812": 42, "36809": 42, "38976": 42, "15537": 42, "27078": 42, "float6419": 42, "07arrai": 42, "9922": 42, "3422": 42, "4787": 42, "5616": 42, "3612": 42, "3301": 42, "2128": 42, "9165": 42, "9441": 42, "5362": 42, "5644": 42, "7573": 42, "2453": 42, "2903": 42, "8039": 42, "0338": 42, "6761": 42, "7705": 42, "1302": 42, "1052": 42, "1311": 42, "5695": 42, "6351": 42, "0655": 42, "float640": [42, 43, 44], "05535arrai": 42, "0500194": 42, "049159": 42, "0488312": 42, "0686739": 42, "0650993": 42, "0612367": 42, "0616795": 42, "0591138": 42, "0590177": 42, "0570248": 42, "0569334": 42, "0563149": 42, "065594": 42, "0578358": 42, "05951": 42, "0587069": 42, "059966": 42, "0532751": 42, "0619955": 42, "0584618": 42, "0551539": 42, "0569168": 42, "056705": 42, "0553542": 42, "6305arrai": 42, "570748": 42, "581394": 42, "580663": 42, "701103": 42, "694826": 42, "652913": 42, "683638": 42, "664259": 42, "670896": 42, "640091": 42, "640559": 42, "641301": 42, "688222": 42, "636539": 42, "634055": 42, "641766": 42, "655928": 42, "611608": 42, "681705": 42, "626147": 42, "640292": 42, "642441": 42, "61861": 42, "630507": 42, "float641": [42, 43, 44, 52], "257arrai": 42, "30086": 42, "3084": 42, "3113": 42, "16321": 42, "18642": 42, "21299": 42, "20986": 42, "22831": 42, "22902": 42, "24394": 42, "24463": 42, "24938": 42, "18314": 42, "2378": 42, "22541": 42, "23131": 42, "2221": 42, "27348": 42, "20764": 42, "23313": 42, "25842": 42, "24476": 42, "24638": 42, "25685": 42, "chainpandasindexpandasindex": [42, 43, 44, 52, 57], "dtype": [42, 43, 44, 52, 57], "x27": [42, 43, 44, 52, 57], "drawpandasindexpandasindex": [42, 43, 44, 52, 57], "990": [42, 43, 44, 52, 57], "991": [42, 43, 44, 52, 57], "992": [42, 43, 44, 52, 57], "00arviz_vers": [42, 43, 44, 57], "0inference_librari": [42, 43, 44, 57], "cmdstanpyinference_library_vers": [42, 43, 44, 57], "puls": 42, "plot_scatt": 42, "\u03b1": [42, 49, 60, 65, 66, 67, 68], "bin": [42, 46, 48, 84], "rug": [42, 46, 48, 74], "send": [42, 83], "append": [42, 48, 49, 69, 84], "foolishli": 42, "drawn": [42, 44, 49, 54, 64, 66, 72, 74, 86], "grab": [42, 68], "arang": [42, 44, 48, 69, 80], "251": [42, 72], "flatten": [42, 43, 44, 48, 53, 60, 63, 66, 67, 72, 74, 86], "zip": [42, 44, 48, 49, 65, 69, 75, 80], "nbinom": [42, 44], "x_plot": [42, 44], "y_plot": [42, 44], "cdf_to_staircas": [42, 44], "underlai": [42, 44], "425": 42, "426": 42, "amazon": [43, 84], "julia": 43, "matlab": [43, 84], "stata": 43, "across": [43, 57, 84, 86], "dive": 43, "disk": 43, "seven": [43, 52], "intend": 43, "ventur": 43, "friend": [43, 86], "guid": [43, 89], "manual": [43, 44, 52, 86], "static": [43, 45], "semicolon": 43, "curli": 43, "prepar": [43, 63, 80, 82, 84, 86, 90], "favorit": [43, 48], "editor": [43, 84], "groundwork": 43, "hello_world": 43, "bebi103_cours": 43, "2025": 43, "08": [43, 63, 65, 72, 90], "ex": 43, "43": [43, 44], "iter": [43, 44, 46, 52, 53, 55, 57, 60, 63, 64, 65, 66, 68, 69, 71, 72, 74, 80, 82, 84, 86], "44": [43, 44, 65, 72], "job": [43, 69, 80, 84], "cmdstanmcmc": 43, "num_sampl": 43, "engag": [43, 72], "csv_file": 43, "var": [43, 65, 72, 80, 82], "j_": [43, 72], "c5r9ch0913v3h1w4bdwzm0lh0000gn": [43, 72], "tmpvzktutt3": 43, "hello_worldg4sdgzab": 43, "20240719161944_1": 43, "20240719161944_2": 43, "20240719161944_3": 43, "20240719161944_4": 43, "output_fil": 43, "20240719161944_0": 43, "pronounc": 43, "rv": 43, "recreat": 43, "vehicl": 43, "40kb": 43, "6374": 43, "5841": 43, "5403": 43, "6269": 43, "542659": 43, "6269arrai": 43, "637411": 43, "58407": 43, "302226": 43, "474132": 43, "962219": 43, "03972": 43, "75933": 43, "254514": 43, "365888": 43, "96866": 43, "20111": 43, "82037": 43, "477287": 43, "556766": 43, "32425": 43, "55547": 43, "494835": 43, "364278": 43, "015963": 43, "141604": 43, "35541": 43, "39819": 43, "540314": 43, "626918": 43, "sample_stat": [43, 44, 52], "204kb": [43, 44], "acceptance_r": [43, 44], "9468": 43, "8258": 43, "9861": 43, "9895": 43, "bool": [43, 44], "4kb": [43, 44, 52], "energi": [43, 44, 52, 66, 72], "5121": 43, "564": [43, 52], "1502": 43, "215": 43, "2031": 43, "1706": 43, "1965": 43, "n_step": [43, 44], "step_siz": [43, 44], "015": 43, "tree_depth": [43, 44, 52], "549548": 43, "9895arrai": 43, "946755": 43, "82582": 43, "998086": 43, "91481": 43, "689701": 43, "794211": 43, "991144": 43, "725178": 43, "979043": 43, "928644": 43, "989108": 43, "945146": 43, "757333": 43, "998694": 43, "864913": 43, "978766": 43, "99792": 43, "791233": 43, "982238": 43, "986148": 43, "989484": 43, "boolfals": [43, 44], "falsearrai": [43, 44, 52], "139": [43, 63], "215arrai": 43, "512115": 43, "56356": 43, "138952": 43, "137244": 43, "462933": 43, "42688": 43, "55296": 43, "33155": 43, "0698188": 43, "39816": 43, "793701": 43, "70602": 43, "858483": 43, "6095": 43, "70213": 43, "43293": 43, "44248": 43, "113932": 43, "07941": 43, "0126613": 43, "4355": 43, "107657": 43, "150176": 43, "214951": 43, "146": 43, "1965arrai": 43, "03146e": 43, "70569e": 43, "56703e": 43, "12401e": 43, "62933e": 43, "40512e": 43, "54763e": 43, "23887e": 43, "69369e": 43, "69151e": 43, "21337e": 43, "65687e": 43, "13902e": 43, "54994e": 43, "70108e": 43, "20974e": 43, "22431e": 43, "63494e": 43, "27409e": 43, "00259e": 43, "18573e": 43, "92776e": 43, "45970e": 43, "96513e": 43, "int643": 43, "1arrai": [43, 44, 52], "0arrai": 43, "01508": 43, "07811": 43, "841159": 43, "00025": 43, "int641": 43, "group": [43, 44, 54, 63, 84], "dataarrai": [43, 44, 50, 52], "panda": [43, 44, 52, 67, 72, 84, 86], "interestingli": [43, 46], "arbitrarili": 43, "multidimension": [43, 46, 57, 66, 68], "999xarrai": [43, 52], "3022": 43, "2444": 43, "01371": 43, "3982": 43, "togeth": [43, 58, 60, 62, 63, 66, 67, 82, 83, 84, 86], "np_sampl": 43, "sp_sampl": 43, "staircas": [43, 60], "palett": [43, 48, 60, 80], "b_glasbey_category10": 43, "normal_rng": [43, 49, 50, 55, 65, 66, 68, 69, 71, 72, 74], "sm_rng": 43, "norm_rng": 43, "mote": 43, "fixed_param": [43, 49, 65, 66, 84, 86], "stan_sampl": 43, "novel": 43, "occasion": [43, 49], "visibl": [43, 48, 60], "netcdf": 43, "to_netcdf": 43, "stan_hello_world": 43, "nc": 43, "string": [43, 63, 84], "filenam": [43, 75], "from_netcdf": 43, "hpp": 43, "deposit": 43, "exit": 43, "delet": [43, 69, 74], "outpur_dir": 43, "gene": [44, 51, 52, 57, 63, 65, 66, 69, 84], "datafram": [44, 48, 65, 69, 86], "count": [44, 51, 52, 57, 66, 69, 83, 86], "mrna": [44, 52, 57, 69], "unimod": 44, "alpha_1": 44, "alpha_2": 44, "beta_1": 44, "beta_2": 44, "burst": [44, 51, 52, 65], "concis": 44, "retain": [44, 51, 72], "alpha_i": [44, 86], "b_i": 44, "beta_i": 44, "hood": [44, 82, 84], "summand": [44, 54], "a_1": [44, 69], "a_2": 44, "a_i": 44, "stabl": [44, 54, 66, 67, 71, 82], "log_mix": [44, 57], "keyword": [44, 71], "n_val": [44, 57], "neg_binomial_lupmf": 44, "negative_binomial_lpmf": 44, "_lpmf": [44, 57], "_lpdf": [44, 57], "_lupmf": 44, "_lupdf": 44, "signifi": 44, "wise": [44, 67, 84], "vvector": 44, "log10_beta": 44, "front": [44, 82, 84], "slash": 44, "elementwis": 44, "smart": 44, "enclos": [44, 49], "inclus": [44, 66], "3252": [44, 48, 52, 53, 57, 63, 72, 74], "360kb": 44, "alpha_dim_0": [44, 57], "b_dim_0": [44, 57], "beta__dim_0": 44, "log10_alpha_dim_0": 44, "log10_b_dim_0": 44, "16b": 44, "64kb": 44, "867": 44, "379": 44, "235": 44, "691": 44, "191": [44, 72], "2132": 44, "4575": 44, "7189": 44, "179": [44, 72, 84], "159": 44, "8032": 44, "8652": 44, "20t01": 44, "493203": 44, "1000alpha_dim_0": 44, "2b_dim_0": 44, "2beta__dim_0": 44, "2log10_alpha_dim_0": 44, "2log10_b_dim_0": 44, "2coordin": 44, "float642": 44, "773": 44, "745": 44, "842": 44, "379arrai": 44, "86735": 44, "77317": 44, "74531": 44, "08933": 44, "06105": 44, "65147": 44, "56703": 44, "75107": 44, "16542": 44, "79654": 44, "77347": 44, "10867": 44, "63497": 44, "5682": 44, "16957": 44, "98005": 44, "53614": 44, "5058": 44, "88295": 44, "46085": 44, "9517": 44, "19794": 44, "67976": 44, "08075": 44, "55802": 44, "94599": 44, "01463": 44, "48093": 44, "25886": 44, "19726": 44, "78945": 44, "78982": 44, "45851": 44, "7594": 44, "09546": 44, "03334": 44, "60415": 44, "37894": 44, "04128": 44, "18814": 44, "3936": 44, "73299": 44, "86744": 44, "82427": 44, "84191": 44, "37865": 44, "float645": 44, "406": 44, "691arrai": 44, "2351": 44, "3362": 44, "40603": 44, "9016": 44, "64434": 44, "5218": 44, "6283": 44, "2829": 44, "59981": 44, "1368": 44, "85139": 44, "3799": 44, "4836": 44, "88547": 44, "2705": 44, "66373": 44, "2696": 44, "29264": 44, "7265": 44, "78734": 44, "3232": 44, "54503": 44, "02042": 44, "726": 44, "6697": 44, "1807": 44, "61744": 44, "0982": 44, "98924": 44, "8056": 44, "25143": 44, "1896": 44, "27248": 44, "2288": 44, "2259": 44, "96834": 44, "481": 44, "33478": 44, "0416": 44, "76565": 44, "2165": 44, "88078": 44, "172": [44, 72], "65381": 44, "3025": 44, "69076": 44, "02912": 44, "02915": 44, "2132arrai": 44, "191018": 44, "0291238": 44, "184979": 44, "0303937": 44, "274398": 44, "0289672": 44, "150868": 44, "0341496": 44, "277793": 44, "0292939": 44, "350706": 44, "0308834": 44, "028182": 44, "101159": 44, "0366697": 44, "176562": 44, "0341652": 44, "188942": 44, "0296503": 44, "208884": 44, "0309375": 44, "132538": 44, "24873": 44, "0315199": 44, "0731546": 44, "0354853": 44, "276439": 44, "0355895": 44, "334533": 44, "0271698": 44, "444163": 44, "0292486": 44, "440048": 44, "0276023": 44, "030097": 44, "201274": 44, "0339201": 44, "157859": 44, "0302649": 44, "173441": 44, "0342272": 44, "25768": 44, "0301459": 44, "176872": 44, "0291524": 44, "213185": 44, "6788": 44, "685": 44, "5287arrai": 44, "457481": 44, "678807": 44, "438592": 44, "706661": 44, "608639": 44, "66759": 44, "409431": 44, "759749": 44, "619659": 44, "680928": 44, "761437": 44, "708308": 44, "666047": 44, "1954": 44, "790255": 44, "474224": 44, "743207": 44, "398946": 44, "688683": 44, "539182": 44, "694754": 44, "342016": 44, "565819": 44, "705928": 44, "192574": 44, "774224": 44, "603645": 44, "738854": 44, "629294": 44, "622966": 44, "762637": 44, "680319": 44, "737074": 44, "677552": 44, "707183": 44, "481921": 44, "74851": 44, "376383": 44, "70254": 44, "503538": 44, "731878": 44, "572057": 44, "687301": 44, "450906": 44, "685017": 44, "528744": 44, "536": 44, "535": 44, "6712arrai": 44, "718925": 44, "53575": 44, "732878": 44, "51722": 44, "561619": 44, "53809": 44, "821402": 44, "46661": 44, "556279": 44, "53322": 44, "455057": 44, "51028": 44, "55003": 44, "994998": 44, "43569": 44, "753102": 44, "46642": 44, "723672": 44, "52797": 44, "680094": 44, "50951": 44, "877661": 44, "604271": 44, "50141": 44, "13576": 44, "44995": 44, "558401": 44, "44868": 44, "475561": 44, "56591": 44, "352458": 44, "53389": 44, "3565": 44, "55905": 44, "52148": 44, "696211": 44, "46954": 44, "801731": 44, "51906": 44, "760848": 44, "46563": 44, "58892": 44, "52077": 44, "752341": 44, "53533": 44, "671243": 44, "8652arrai": 44, "179038": 44, "159009": 44, "133145": 44, "194928": 44, "146822": 44, "152438": 44, "806095": 44, "846002": 44, "835965": 44, "872181": 44, "858328": 44, "136364": 44, "213688": 44, "164984": 44, "133647": 44, "125085": 44, "12076": 44, "793301": 44, "801544": 44, "807659": 44, "822806": 44, "803243": 44, "865222": 44, "alpha_dim_0pandasindexpandasindex": 44, "b_dim_0pandasindexpandasindex": 44, "beta__dim_0pandasindexpandasindex": 44, "log10_alpha_dim_0pandasindexpandasindex": 44, "log10_b_dim_0pandasindexpandasindex": 44, "9871": 44, "9415": 44, "9976": 44, "9587": 44, "597e": 44, "03": [44, 52, 57, 72, 90], "598e": 44, "595e": 44, "1227": 44, "1186": 44, "501268": 44, "9587arrai": 44, "987143": 44, "941549": 44, "977411": 44, "99892": 44, "976145": 44, "732715": 44, "910988": 44, "992787": 44, "951251": 44, "9523": 44, "919331": 44, "63308": 44, "997946": 44, "999491": 44, "932981": 44, "886662": 44, "992565": 44, "839946": 44, "972186": 44, "989851": 44, "943136": 44, "999211": 44, "997595": 44, "958723": 44, "03arrai": [44, 52], "1596": 44, "84": [44, 69], "75": [44, 45, 46, 49, 50, 52, 55, 63, 72, 75, 80], "1597": 44, "82": 44, "1599": 44, "1600": [44, 72], "58": [44, 52, 63, 72, 86], "1598": 44, "47": [44, 63, 65], "1601": 44, "73": [44, 63, 72], "87": [44, 52], "53": [44, 52, 63, 69, 72], "69": [44, 52, 63, 72], "1602": 44, "68": [44, 49, 52, 63, 72], "1595": 44, "59": 44, "78": [44, 52, 57], "93": [44, 57], "65": [44, 63, 72], "int6423": 44, "31arrai": 44, "63": [44, 63, 72], "1186arrai": 44, "122749": 44, "119707": 44, "102969": 44, "11862": 44, "int644": 44, "5arrai": 44, "futur": [44, 46, 52, 53], "doc": 44, "478": 44, "184b": 44, "8b": [44, 52], "642": 44, "243": 44, "802": [44, 72], "2082": 44, "02532": 44, "422": 44, "6277": 44, "6815": 44, "597": 44, "1674": 44, "int642arrai": 44, "int64478arrai": 44, "243arrai": 44, "64227": 44, "24292": 44, "float644": 44, "80233": 44, "4987": 44, "02532arrai": 44, "208232": 44, "0253173": 44, "6277arrai": 44, "421977": 44, "627665": 44, "597arrai": 44, "681452": 44, "59658": 44, "1674arrai": 44, "167433": 44, "1xarrai": 44, "int641arrai": 44, "scalar": [44, 67, 68], "to_datafram": 44, "from_panda": [44, 72], "include_index": 44, "chaindrawalpha_dim_0b_dim_0beta__dim_0log10_alpha_dim_0log10_b_dim_0alphabbeta_log10_alphalog10_bwi64i64i64i64i64i64i64f64f64f64f64f64f6400000002": 44, "867355": 44, "23510": 44, "1910180": 44, "4574810": 44, "7189250": 44, "17903800000012": 44, "4574811": 44, "535750": 44, "17903800000102": 44, "6788070": 44, "17903800000112": 44, "6788071": 44, "17903800001002": 44, "02912380": 44, "cumbersom": [44, 54, 68], "arviz_to_datafram": [44, 46], "df_mcmc": [44, 46], "wchain__draw__diverging__f64f64f64f64f64f64f64f64f64f64f64i64i64bool2": 44, "867354": 44, "773175": 44, "235134": 44, "33620": 44, "7189251": 44, "17903800false2": 44, "745315": 44, "089335": 44, "4060332": 44, "90160": 44, "1849790": 44, "03039370": 44, "4385920": 44, "7066610": 44, "7328781": 44, "517220": 44, "15900901false4": 44, "061054": 44, "651473": 44, "6443434": 44, "52180": 44, "2743980": 44, "02896720": 44, "6086390": 44, "667590": 44, "5616191": 44, "538090": 44, "13314502false5": 44, "017854": 44, "427832": 44, "7704935": 44, "84410": 44, "3609480": 44, "02789860": 44, "7005180": 44, "6461910": 44, "4425561": 44, "554420": 44, "14577403false2": 44, "309674": 44, "870747": 44, "4160534": 44, "1050": 44, "1348430": 44, "02932120": 44, "3635510": 44, "6875950": 44, "8701731": 44, "532820": 44, "19200404fals": 44, "chain__": 44, "draw__": 44, "diverging__": 44, "par": 44, "\u03b1\u2081": 44, "\u03b1\u2082": 44, "b\u2081": 44, "b\u2082": 44, "peculiar": 44, "reveal": 44, "glyph": [44, 46], "id": [44, 72, 84], "color_by_chain": [44, 86], "blue": [44, 49, 62], "red": [44, 86], "green": 44, "uncov": [44, 64, 65], "observation": 44, "emphas": [44, 52, 66], "devilish": 44, "vigil": 44, "b_1": 44, "b_2": 44, "overlap": [44, 54, 67, 86], "filter": [44, 48, 68], "col": [44, 48, 65, 66, 67, 68, 69, 71], "renam": 44, "with_column": [44, 48, 65, 66, 67, 69, 71], "alia": [44, 48, 65, 66, 67, 69, 71], "df_switch": 44, "concat": [44, 86], "blog": [44, 66, 74, 75, 86], "alon": [44, 49], "param_mean": 44, "wf64f64f64f64f645": 44, "2096973": 44, "16429831": 44, "9572976": 44, "2381460": 44, "831563": 44, "init": [44, 57, 72], "unconstrain": 44, "warmup": 44, "advis": 44, "hoc": [44, 51], "05": [44, 63, 66, 67, 69, 71, 80, 90], "alpha0": 44, "alpha1": 44, "beta0": 44, "beta1": 44, "fragil": 44, "closer": [44, 49, 54, 55, 57, 72], "microtubul": [45, 49, 72, 86], "departur": [45, 72], "sacrific": 45, "drop": [45, 49, 66], "largest": 45, "smallest": 45, "uncomfort": 45, "millimet": 45, "gamma_": [45, 46, 49, 50, 55, 72], "denom_ratio": [45, 46, 49, 50, 55, 72], "log10_phi": [45, 46], "syntact": 45, "parenthes": 45, "plane": 45, "plot_ecdf": [45, 46], "depict": [45, 63], "eschew": 45, "promis": 46, "quickli": [46, 48, 75, 80, 84], "aesthet": 46, "trajectori": [46, 52, 80, 82], "trace_plot": 46, "plot_": 46, "backend": 46, "plot_trac": 46, "kde": 46, "bandwidth": 46, "dan": 46, "minimum": [46, 51], "plot_parallel": 46, "var_nam": [46, 65, 84], "norm_method": 46, "minmax": [46, 63], "parcoord": [46, 53, 63], "neck": 46, "vice": [46, 80], "versa": [46, 80], "plot_dens": 46, "highest": [46, 48], "hpd": [46, 48], "shortest": [46, 48], "backend_kwarg": 46, "bokehdeprecationwarn": 46, "deprec": 46, "remov": [46, 53, 54, 63, 69, 84], "gamma_log10_phiphisigmachain__draw__diverging__f64f64f64f64i64i64bool0": 46, "8760751": 46, "5813638": 46, "13823": 46, "7229800false0": 46, "8695911": 46, "5794137": 46, "96693": 46, "7328201false0": 46, "8521091": 46, "5858338": 46, "53243": 46, "803702false0": 46, "8800941": 46, "5797237": 46, "99453": 46, "7278603false0": 46, "8934751": 46, "5709837": 46, "23743": 46, "7522504fals": 46, "hist": 46, "transpar": 46, "plot_pair": 46, "scatter_kwarg": 46, "fill_alpha": [46, 65], "radius_unit": 46, "represent": [46, 74, 82, 84], "uni": 46, "hex": 46, "hexbin": 46, "xtick_label_orient": [46, 50, 55, 57, 60, 63, 86], "beauti": [48, 54, 58, 80], "lie": [48, 49, 50, 55], "plu": [48, 66, 71, 80], "5th": [48, 52], "percentil": [48, 49, 50, 52, 55, 60], "97": [48, 63, 72], "hdi": 48, "scheme": 48, "tail": [48, 49, 51, 52, 53, 57, 63, 67, 82, 86], "sigma_2": [48, 51, 74], "x_expon": 48, "15000": 48, "x_norm": 48, "which_norm": 48, "x_2norm": 48, "pareto": [48, 54, 57], "x_heavytail": 48, "readili": [48, 67], "trickier": [48, 67], "trace": [48, 52, 53, 86], "df_summari": 48, "hpd_low": 48, "hpd_high": 48, "schema": 48, "dist": 48, "concaten": [48, 69], "hdi_prob": 48, "statisticexponentialnormaltwo": 48, "normalsheavi": 48, "tailstrf64f64f64f64": 48, "quot": [48, 63, 65], "0078431": 48, "0014472": 48, "0040054": 48, "134071": 48, "0053510": 48, "249141": 48, "0738544": 48, "580247": 48, "0248750": 48, "5115520": 48, "5904380": 48, "02307": 48, "7010921": 48, "0006981": 48, "7679750": 48, "79814": 48, "6495411": 48, "492053": 48, "80497720": 48, "613608": 48, "0000880": 48, "5318630": 48, "5613620": 48, "000057": 48, "9965491": 48, "5073143": 48, "75565311": 48, "296449": 48, "y_valu": 48, "category10": [48, 60], "plot_interv": 48, "barx": 48, "is_in": 48, "asymmetri": 48, "finder": 48, "uniniti": 48, "suffer": [48, 82], "interquantil": 48, "modal": [48, 86], "mislead": 48, "futil": 48, "deceiv": 48, "chanc": [48, 52, 80, 86], "reeeealli": 48, "71": 48, "struggl": [49, 82], "symptom": [49, 63], "produc": [49, 50, 54, 64, 67, 83, 84, 86], "obei": 49, "constraint": [49, 67, 84], "cytoplasm": 49, "embryogenesi": 49, "colleagu": 49, "regress": [49, 50, 56, 66], "hone": 49, "670": [49, 50, 55], "uniformli": [49, 64, 65], "inher": [49, 52, 66], "resid": 49, "depolymer": 49, "protein": [49, 83, 86], "e_i": 49, "stochast": [49, 66, 72, 82, 86], "compon": [49, 80, 83, 86], "datum": [49, 54], "establish": 49, "sound": 49, "varieti": [49, 57, 84], "uncertain": [49, 54], "irrelev": [49, 67], "ey": [49, 50, 57, 67, 68, 84], "nonposit": 49, "vanish": 49, "unrealist": 49, "ultim": [49, 51, 63, 65], "jettison": 49, "halfnorm_pdf": 49, "350": [49, 66, 67, 68, 69], "80": [49, 60, 72, 74], "lognorm_pdf": 49, "n_ppc_sampl": 49, "ab": [49, 53, 65, 73], "ph": [49, 66], "sig": 49, "thin": [49, 60, 74, 86], "20th": 49, "ell_val": 49, "line_alpha": [49, 53, 65], "predictive_ecdf": [49, 50, 55, 57, 65, 86], "n_": [49, 52, 69], "middl": [49, 50, 55, 72], "darker": 49, "fill": [49, 74, 84], "extent": 49, "willing": 49, "toler": [49, 67], "tug": 49, "substanti": [49, 53, 64, 72], "059903": 49, "linearli": [49, 80, 83], "gamma_pdf": 49, "\u03c3\u2080": 49, "settl": 49, "clearer": [49, 65, 72], "_rng": 49, "lognormal_rng": 49, "gamma_rng": [49, 65, 84, 86], "tweak": 49, "recompil": 49, "phi_mu": 49, "phi_sigma": 49, "sigma_0_alpha": 49, "sigma_0_beta": 49, "sm_prior_pr": [49, 65], "indep_size_model_prior_predict": 49, "alert": [49, 75], "parallel": [49, 52, 53, 63, 82, 84], "prior_predict": [49, 65, 66, 84], "reshap": [49, 50], "2d": [49, 82], "verbos": 49, "hing": 49, "polymer": 49, "assembli": 49, "balanc": [49, 82], "catastroph": [49, 80, 86], "t_0": [49, 80], "t_1": 49, "t_": [49, 67, 82], "gg": [49, 55], "l_": 49, "mt": 49, "unimport": 49, "geometri": [49, 82], "nmol": 49, "threshold": 49, "ccl": 49, "assur": 49, "prolat": 49, "spheroid": 49, "spheric": 49, "microscop": [49, 51, 63, 86], "growth": [49, 68], "spectroscop": 49, "vitro": 49, "assai": 49, "2t_": 49, "distinguish": [49, 58, 80], "ones": [49, 52, 65, 67, 68, 72, 80, 86], "obvious": 49, "lest": [49, 52], "unidentifi": 49, "dire": 49, "commensur": [49, 50, 51, 54], "enhanc": [49, 84], "strive": [49, 75], "didn": [49, 65, 66], "slight": [49, 62], "baselin": 49, "continuum": 49, "basi": [49, 66, 82], "gamma_alpha": 49, "gamma_beta": 49, "beta_rng": 49, "cons_tubulin_model_prior_predict": 49, "span": [49, 57], "predictive_regress": [49, 50, 55, 66, 67, 68, 69, 71, 72], "30th": 49, "60th": 49, "90th": 49, "99th": [49, 50, 55], "samples_x": [49, 50, 55, 66], "60": [49, 65, 68, 72], "javascript": 49, "slider": [49, 63], "draw_slid": 49, "data_dict": 49, "str": 49, "sel": [49, 57, 60], "cd": 49, "columndatasourc": 49, "params_dict": 49, "squeez": [49, 65], "cds_param": 49, "div": 49, "js_code": 49, "cb_obj": 49, "tostr": 49, "toprecis": 49, "emit": 49, "customj": 49, "js_on_chang": 49, "spacer": 49, "encompass": [49, 64, 65, 66, 67], "replot": 49, "heavili": [49, 64, 72, 80, 82, 86], "coupl": [49, 50, 66, 86], "examin": 49, "mayb": [49, 51, 66], "relax": 49, "verif": 49, "spindle_volum": 49, "vol_ratio": 49, "ul": 49, "v0": 49, "nonconst": 49, "highlight": [49, 50, 72, 74], "ell_ppc": [50, 55, 72], "indep_size_model": 50, "posterior_predict": [50, 55, 57, 65, 66, 68, 69, 71, 74, 86], "n_sampl": [50, 74], "stack": [50, 52, 55, 57, 65, 66, 67, 68, 69, 71, 86], "collaps": 50, "transpos": [50, 55, 57, 65, 66, 67, 68, 69, 71, 74, 86], "ell_ppc_dim_0": [50, 55], "diff": [50, 55, 65, 86], "vstack": [50, 66], "trend": 50, "envelop": [50, 64, 65, 66, 67], "n_ppc": [50, 55, 57, 65, 66, 72, 84, 86], "d_ppc": [50, 55, 72], "mu_ppc": [50, 55, 72], "cons_tubulin_model": 50, "lost": 50, "former": [50, 82], "shelf": 51, "oftentim": 51, "pare": 51, "pixel": 51, "interpixel": 51, "optic": [51, 68], "digit": 51, "camera": 51, "simplifi": 51, "bivari": [51, 74], "fourth": 51, "symmetri": 51, "s_": [51, 66], "sigma_1": [51, 74], "c_": 51, "rho": [51, 66, 67, 68, 69, 71, 74], "lkj": 51, "rethink": [51, 89], "underpin": [51, 82], "inappropri": 51, "underli": [51, 54, 64, 66, 69, 86], "inclin": 51, "depart": 51, "inadequ": 51, "adequ": [51, 65], "lightest": 51, "heaviest": 51, "cauchi": 51, "distirbut": 51, "heavier": [51, 82], "opposit": [51, 63], "slower": [51, 86], "log10_v": 51, "fish": [52, 57, 65, 66, 69, 84], "reproduc": [52, 75], "rhat": [52, 53, 55, 57, 60, 63, 65, 66, 68, 69, 71, 74, 86], "40b": 52, "007": 52, "007xarrai": 52, "007arrai": 52, "00714323": 52, "00676445": 52, "00684101": 52, "00707471": 52, "00687351": 52, "sd": 52, "hdi_3": 52, "hdi_97": 52, "mcse_mean": 52, "mcse_sd": 52, "ess_bulk": 52, "ess_tail": 52, "r_hat": 52, "521": 52, "398": [52, 72], "769": 52, "266": 52, "014": [52, 72], "010": 52, "797": 52, "679": 52, "706": 52, "056": 52, "040": [52, 72], "763": 52, "709": 52, "060": 52, "006": [52, 57, 72], "049": 52, "070": 52, "654": 52, "038": [52, 72], "576": 52, "001": [52, 84], "221": 52, "142": 52, "295": 52, "samples_limited_warmup": 52, "iter_warmup": [52, 65, 66], "018": [52, 72], "876": 52, "119": [52, 63], "151": 52, "729": 52, "798": 52, "644": 52, "31633592": 52, "252": 52, "091": 52, "299": 52, "683": 52, "486": 52, "734": 52, "293": 52, "149": 52, "241": 52, "114": 52, "714": 52, "841": 52, "059": 52, "419": 52, "321": 52, "868": 52, "327": 52, "925": 52, "181": [52, 72], "661": 52, "506": [52, 69], "272": [52, 57], "395": 52, "314": 52, "866": [52, 72], "695": 52, "532": 52, "poor": [52, 53, 65, 86], "mix": [52, 53, 57, 63, 68, 86], "rejec": 52, "caveat": [52, 86], "ideal": [52, 65, 86], "ess": [52, 53, 57, 63, 65, 82, 86], "eff": 52, "prescript": [52, 66], "4000": [52, 53, 55, 57, 60, 63, 65, 66, 68, 69, 71, 72, 74, 86], "500": [52, 72, 80, 86], "ess_mean": 52, "ess_sd": 52, "land": [52, 84], "mcse": 52, "msce_mean": 52, "accur": [52, 80], "wonder": 52, "curvatur": [52, 53, 80, 82], "veer": 52, "sharpli": [52, 54, 58], "detect": 52, "regist": 52, "1000fals": 52, "improperli": 52, "3002": 52, "yike": 52, "endem": 52, "whether": [52, 65, 67, 69, 75], "explan": [52, 80, 86, 89], "sciencei": 52, "unfamiliar": 52, "recurs": 52, "en": 52, "org": [52, 84], "recursion_": 52, "computer_sci": 52, "deep": [52, 53, 84], "cap": 52, "wrong": 52, "10003": 52, "decreas": [52, 53, 66, 80, 82, 84], "ineffici": [52, 82], "1379": 52, "1378": 52, "09": [52, 90], "1377": 52, "98": 52, "1381": 52, "76": [52, 63, 72], "62": 52, "1380": 52, "1383": 52, "1382": 52, "72": [52, 57, 63, 72], "10001": 52, "379e": 52, "38e": 52, "nope": 52, "wrote": [52, 54, 75, 86], "submodul": 52, "check_all_diagnost": [52, 53, 55, 57, 60, 63, 65, 66, 68, 69, 71, 74, 86], "satur": [52, 53, 55, 57, 60, 63, 65, 66, 68, 69, 71, 74, 86], "behavior": [52, 53, 55, 57, 60, 63, 65, 66, 68, 69, 71, 74, 86], "forthcom": 53, "hack": 53, "probabilti": 53, "thoma": 53, "wiecki": 53, "microinject": 53, "tip": [53, 75], "radford": 53, "neal": 53, "girolami": 53, "450": [53, 63, 66, 80], "66c2a5": 53, "indep": 53, "bottom_left": 53, "short": [53, 68, 84], "2509935801914": 53, "17582178946987": 53, "061082354895177": 53, "103015323352217": 53, "483": 53, "075": 53, "tree": [53, 55, 57, 60, 63, 65, 66, 68, 69, 71, 74, 86], "bfmi": [53, 55, 57, 60, 63, 65, 66, 68, 69, 71, 74, 82, 86], "trust": 53, "hide": [53, 63, 74], "fc8d62": 53, "click_polici": [53, 63, 74], "penetr": 53, "correctli": 53, "awar": [53, 65], "clue": 53, "stuck": [53, 86], "log10": 53, "divergence_kwarg": 53, "advic": [53, 72], "messag": [53, 72, 75], "crank": 53, "8da0cb": 53, "335": 53, "8697624482687": 53, "188": [53, 72], "9130440674577": 53, "123": 53, "79148039281294": 53, "109": 53, "7300569471941": 53, "0225440084677622": 53, "028248959476883": 53, "825": 53, "5103845064002706": 53, "3791047493010087": 53, "6261488838631215": 53, "28202314605045126": 53, "shy": [53, 57], "tild": [53, 54, 57, 63, 64, 67, 69], "uncent": [53, 63, 64, 66, 67, 68, 69, 71, 90], "henc": [53, 63, 80, 82, 86], "theta_tild": 53, "bother": [53, 54, 65], "funnel_noncent": 53, "excel": [53, 64, 65, 67], "No": [53, 75, 80, 82, 84, 90], "e78ac3": 53, "spent": [54, 75], "biolog": [54, 62], "theta_m": [54, 66], "g_m": 54, "f_m": 54, "eq": 54, "model_bay": 54, "f_t": [54, 57], "digest": 54, "overli": 54, "flexibl": [54, 55, 57, 64, 72], "reduct": 54, "p_i": [54, 82], "haven": 54, "pope": 54, "cathol": 54, "improb": 54, "garner": 54, "p_ip_j": 54, "p_j": 54, "addabl": 54, "tradit": 54, "ensembl": 54, "surpris": [54, 69, 86], "shannon": [54, 72], "thermodynam": 54, "delv": 54, "although": [54, 80, 82, 86], "rich": [54, 84], "knew": 54, "unbias": 54, "shortcut": 54, "1948": 54, "claud": [54, 75], "desiderata": 54, "composit": 54, "law": [54, 66], "extend": [54, 75, 82], "cross": [54, 57, 86], "q_i": [54, 72, 80, 82], "govern": [54, 62, 63, 86], "induc": [54, 82], "kl": [54, 72], "d_": [54, 72], "sum_ip_i": 54, "f_": 54, "m_a": 54, "m_b": 54, "awkward": 54, "_i": [54, 57, 64, 66, 68, 69], "assumpt": [54, 57, 62], "nf_m": 54, "elppd": 54, "lpd": 54, "lppd": 54, "_j": [54, 57, 66], "_t": 54, "overestim": [54, 64, 72], "discrep": [54, 64], "p_": [54, 57], "gabri": [54, 57], "arxiv": [54, 57, 80], "therein": 54, "incred": 54, "histor": [54, 57], "held": 54, "remain": [54, 67, 72, 75], "y_": 54, "pleasant": 54, "expens": [54, 64, 72], "pacakg": 54, "criteria": [54, 55, 57, 82], "m_i": 54, "m_j": 54, "w_i": [54, 57], "plai": 54, "immens": [54, 84], "invis": 54, "log_lik": [55, 57, 86], "normal_lpdf": [55, 86], "sm_indep": 55, "indep_s": 55, "sm_con": 55, "cons_tubulin": 55, "samples_indep": 55, "samples_con": 55, "ic": [55, 57], "devianc": [55, 57, 66], "elpd_loo": [55, 57], "p_loo": [55, 57], "elpd_diff": [55, 57], "se": [55, 57, 66, 67, 68, 69, 71, 82], "dse": [55, 57], "3662": 55, "643494": 55, "260725": 55, "000000": [55, 57], "354190": 55, "00000": 55, "4003": 55, "001053": 55, "950445": 55, "340": 55, "357559": 55, "379594": 55, "52863": 55, "elpd": 57, "kullback": [57, 72], "leibler": [57, 72], "watanab": 57, "akaik": 57, "criterion": 57, "terribli": 57, "prospect": 57, "straightforward": [57, 58, 63], "easiest": [57, 63, 67], "scientist": [57, 75], "aim": [57, 66, 82], "yao": 57, "pure": [57, 66, 68], "academ": 57, "spectacularli": 57, "neg_binomial_rng": [57, 65, 84], "neg_binom": 57, "doesn": [57, 82, 86], "n_ppc_dim_0": [57, 65], "9mb": 57, "log_lik_dim_0": 57, "2kb": 57, "274": 57, "275": 57, "276": 57, "277": 57, "278": 57, "24t05": 57, "208975": 57, "1000log_lik_dim_0": 57, "279coordin": 57, "278arrai": 57, "871": 57, "571": 57, "006arrai": 57, "9195": 57, "87102": 57, "68695": 57, "26063": 57, "48547": 57, "87587": 57, "86585": 57, "88487": 57, "24419": 57, "48612": 57, "91271": 57, "66727": 57, "93771": 57, "63568": 57, "34274": 57, "58902": 57, "79424": 57, "68369": 57, "92896": 57, "68832": 57, "29315": 57, "55258": 57, "86131": 57, "83427": 57, "8913": 57, "70419": 57, "25863": 57, "50083": 57, "89138": 57, "72091": 57, "92151": 57, "6401": 57, "32705": 57, "56721": 57, "8041": 57, "69304": 57, "9281": 57, "75358": 57, "24444": 57, "5209": 57, "94195": 57, "63444": 57, "94668": 57, "80166": 57, "22269": 57, "52082": 57, "99609": 57, "90389": 57, "8773": 57, "59252": 57, "33818": 57, "53827": 57, "75795": 57, "83866": 57, "892": 57, "73364": 57, "23837": 57, "48808": 57, "92752": 57, "44289": 57, "99838": 57, "74154": 57, "30305": 57, "61111": 57, "90777": 57, "69926": 57, "9251": 57, "67632": 57, "29999": 57, "55376": 57, "84761": 57, "72413": 57, "91933": 57, "65612": 57, "3123": 57, "5567": 57, "82437": 57, "47554": 57, "99033": 57, "81682": 57, "24099": 57, "56584": 57, "0027": 57, "65642": 57, "93676": 57, "68018": 57, "30494": 57, "56586": 57, "84914": 57, "7639": 57, "90806": 57, "69262": 57, "2766": 57, "52578": 57, "87242": 57, "91387": 57, "87357": 57, "60488": 57, "32544": 57, "52772": 57, "77417": 57, "45548": 57, "99638": 57, "82115": 57, "2423": 57, "57115": 57, "00638": 57, "log_lik_dim_0pandasindexpandasindex": 57, "269": 57, "270": 57, "273": 57, "tradition": 57, "deviance_wa": 57, "3281": 57, "p_waic": 57, "single_loo": 57, "deviance_loo": 57, "pct": 57, "wider": 57, "_logpmf": 57, "uniform_rng": 57, "sm_mix": 57, "neg_binom_mix": 57, "samples_mix": 57, "004040383981042": 57, "318": 57, "7069921736581": 57, "836302265033044": 57, "2393686900295": 57, "432640073574931": 57, "126": 57, "12692598049735": 57, "210628341260978": 57, "183": [57, 72], "7239430399982": 57, "432641423716465": 57, "12692598048358": 57, "210629331032064": 57, "72394304000517": 57, "1460975400222795": 57, "170": [57, 72], "8943375375399": 57, "3240338139575638": 57, "3286803456589167": 57, "6654700530731357": 57, "72055885067414": 57, "665470122994841": 57, "7205589366050218": 57, "7356984105623074": 57, "oof": [57, 65, 69, 72], "2774578420000005": 57, "23979613": 57, "64700481": 57, "16986432480000002": 57, "nicer": 57, "3191": 57, "mix_loo": 57, "88": 57, "89": 57, "33459299576725": 57, "d_loo": 57, "w_singl": 57, "w_mix": 57, "99245113565338e": 57, "agreement": 57, "884444": 57, "778852": 57, "983497": 57, "718306": 57, "219037": 57, "927518": 57, "334593": 57, "016503": 57, "315398": 57, "565504": 57, "hyperprior": [58, 60, 62, 63, 66, 71], "theta_k": [58, 62, 66, 67, 68, 71], "permut": 58, "worm": [58, 59, 60, 62], "revers": [58, 59, 60, 84], "permuat": 58, "nuanc": 58, "advanc": 58, "recov": [58, 64, 82], "nonhierarch": 58, "concentr": [58, 64, 66, 80, 82], "kappa": [58, 60], "hyperparamet": [59, 60, 62, 63, 66, 68, 69, 70, 72], "portion": [59, 69, 75, 80, 82], "d3": 60, "2015": [60, 62], "2016": [60, 62], "synthet": [60, 69], "110": 60, "660": 60, "pool": [60, 63, 72], "worm_hier": 60, "adapt_delta": [60, 63, 66, 69, 72, 80, 82], "2000": [60, 65, 72], "global": [60, 62, 72, 84], "diamond": [60, 86], "650": 60, "theta_dim_0": 60, "\u03b2": [60, 86], "theta_map": 60, "bottom_right": [60, 63, 86], "significantli": [60, 72, 84], "overwhelm": [60, 82], "240": 60, "292": 60, "exposur": 62, "channelrhodopsin": 62, "neuron": 62, "strain": 62, "ash": 62, "sensori": 62, "1x": 62, "disfavor": 62, "n_1": 62, "n_2": 62, "indirectli": 62, "compris": 62, "dig": 63, "mondai": [63, 72, 75, 90], "batch": [63, 72, 84], "plate": 63, "coloni": [63, 72, 86], "mount": 63, "slide": [63, 73], "microscopi": [63, 83, 86], "wednesdai": [63, 72, 75, 90], "thursdai": [63, 72, 75, 90], "diagram": 63, "phantom": 63, "theta_3": [63, 72], "condition": 63, "j_1": [63, 72], "j_2": [63, 72], "j_k": 63, "j_3": [63, 72], "straight": 63, "clariti": 63, "index_1": [63, 72], "index_2": [63, 72], "index_3": [63, 72], "fabric": [63, 75], "weird": [63, 84], "compact": 63, "data_str": [63, 72], "41": [63, 72], "74": [63, 72], "nw": [63, 72], "42": [63, 72], "nr": [63, 72], "stringio": [63, 72], "daybatchcolonyystri64i64f64": 63, "1111": 63, "1110": 63, "1112": 63, "metadata": 63, "strip": [63, 65, 69, 72, 75], "cat": [63, 65, 69, 72, 86], "color_column": [63, 65, 72], "marker_kwarg": [63, 65, 69, 72], "adher": 63, "categor": [63, 65, 86], "df_to_datadict_hi": [63, 72], "convei": 63, "level_col": [63, 72], "data_col": [63, 72], "hellip": [63, 72], "129": [63, 72], "1210": 63, "1310": 63, "1412": 63, "sm_center": 63, "samples_cent": 63, "hopefulli": [63, 65, 72, 82], "dianost": 63, "120": 63, "6206946627826": 63, "193": [63, 72], "46855809117585": 63, "0181667967555237": 63, "0104461055496787": 63, "17398128059170156": 63, "09851564271989993": 63, "12373822952024313": 63, "07573497349280298": 63, "whew": 63, "strikingli": [63, 65], "theta_1_dim_0": 63, "theta_2_dim_0": 63, "theta_3_dim_0": 63, "allevi": 63, "_1": [63, 66, 67, 68], "_2": [63, 67, 68], "_3": 63, "theta_1_tild": 63, "theta_2_tild": 63, "theta_3_tild": 63, "sm_noncent": 63, "samples_noncent": 63, "gone": 63, "y_axis_typ": [63, 65, 68], "articl": 64, "unsatisfi": [64, 86], "flow": [64, 83], "reliabl": [64, 65], "ground": [64, 65], "truth": [64, 65], "talt": 64, "umbrella": 64, "sensit": [64, 65], "effort": 64, "abus": [64, 66, 80], "forgiv": 64, "ant": [64, 86], "experimentum": 64, "hundr": 64, "uncertainti": [64, 66], "z_i": 64, "rangle_": 64, "sign": [64, 80], "overfit": [64, 65], "s_i": 64, "drift": [64, 82], "permit": 64, "addition": [64, 75], "coverag": [64, 65], "surround": 64, "diagnosi": 64, "empir": [65, 82], "justif": 65, "prior_pr": [65, 84], "choke": 65, "samples_prior_pr": [65, 84], "range1d": 65, "3e5": 65, "nanmax": 65, "poissonian": 65, "dispers": 65, "upward": 65, "mammalian": 65, "ingredi": 65, "requisit": [65, 75], "df_sbc": [65, 84], "prior_predictive_model": [65, 84], "posterior_model": [65, 84], "prior_predictive_model_data": [65, 84], "posterior_model_data": [65, 84], "measured_data": [65, 84], "measured_data_dtyp": [65, 84], "progress_bar": [65, 84], "07it": 65, "ground_truthrank_statisticmeansdshrinkagez_scorerhatessess_per_itertail_esstail_ess_per_itern_divergencesn_bad_ebfmin_max_treedepthwarning_codeltrialerrorparameterf64i64f64f64f64f64f64f64f64f64f64i64i64i64i64i64i64strstr0": 65, "002862101": 65, "0053340": 65, "0052541": 65, "0190": 65, "8112971": 65, "0023851662": 65, "3330420": 65, "4155831245": 65, "9198970": 65, "31148000040000": 65, "592778483": 65, "8443910": 65, "3097990": 65, "9999590": 65, "8122061": 65, "004025732": 65, "4173080": 65, "183104694": 65, "8219580": 65, "173705000040001": 65, "2772539031": 65, "1166130": 65, "0717330": 65, "999998": 65, "2393821": 65, "004734780": 65, "7275920": 65, "1951821050": 65, "450650": 65, "262613200440002": 65, "62861396101": 65, "20665711": 65, "1994990": 65, "9459420": 65, "4087731": 65, "005957512": 65, "1181450": 65, "12803548": 65, "8116860": 65, "137203000040003": 65, "91851601": 65, "0684490": 65, "0510140": 65, "9999992": 65, "9390361": 65, "001264807": 65, "4313030": 65, "201858936": 65, "5215790": 65, "23413100440004": 65, "warning_cod": 65, "succinct": 65, "pars": [65, 66, 89], "parse_warning_cod": 65, "treedepth": 65, "tooltip": 65, "sub_df": 65, "1f77b4": 65, "group_bi": 65, "z_score": 65, "evidenc": 65, "good_z": 65, "ground_truth": 65, "jitter": [65, 69], "creat": [65, 68, 84], "expos": 65, "abort": 65, "signal": [65, 83, 86], "002": [65, 84], "5000": 65, "problemat": [65, 82], "sm_prior_pred_2": [65, 84], "prior_pred_2": 65, "1e6": 65, "sm_2": [65, 84], "model_2": 65, "posterior_predictive_var_nam": [65, 84], "48it": 65, "warning_codeleni64u32087721073818": 65, "sampling_kwarg": [65, 84], "93it": 65, "warning_codeleni64u32210999": 65, "decent": 65, "sbc_rank_ecdf": 65, "hadn": 66, "untest": 66, "amplitud": [66, 67, 69], "methylglucopyranosid": 66, "hydrolysi": 66, "cellulos": 66, "wolfenden": [66, 67, 69, 71], "snider": [66, 67, 71], "enzym": 66, "catalyst": 66, "glucosid": 66, "temperatur": [66, 67, 69, 71], "wolfenden_arrheniu": [66, 67, 69, 71], "chemic": [66, 69, 71], "arrheniu": 66, "e_a": 66, "k_bt": 66, "k_b": 66, "t_i": [66, 68, 69, 86], "k_i": 66, "fun": 66, "t_ppc": [66, 86], "log10_ea": 66, "log10_a": 66, "ea": 66, "k_ppc": [66, 67, 71], "uncatalyz": 66, "reaction": 66, "530": 66, "sm_parametr": 66, "max_treedepth": [66, 69], "16000": 66, "k_ppc_dim_0": 66, "sec": 66, "meaning": 66, "kinet": [66, 69], "capit": 66, "epsilon_i": 66, "primarili": [66, 74], "_n": 66, "latent": [66, 71, 72, 86], "semi": 66, "hugo": 66, "bown": 66, "anderson": 66, "arithmet": 66, "certain": [66, 80, 84], "k_": [66, 68, 69], "gram": 66, "sigma_b": 66, "polynomi": 66, "sigma_p": 66, "vert": 66, "vert_2": 66, "mat\u00e9rn": 66, "sin": [66, 69], "modifi": [66, 68, 72, 80, 82, 84], "bessel": [66, 68], "quadrat": 66, "radial": 66, "spirit": 66, "realiz": 66, "rough": [66, 68], "farther": [66, 80], "apart": 66, "unrel": 66, "tunabl": 66, "multinorm": [66, 67, 68, 69, 71, 72], "nstar": [66, 67, 68, 69, 71], "xstar": [66, 67, 68, 69, 71], "gp_exp_quad_cov": [66, 67, 68, 69, 71], "diag_matrix": [66, 67, 68, 69, 71], "rep_vector": [66, 67, 68, 69, 71], "choleski": [66, 67, 69, 71], "decomposit": [66, 67, 69, 71], "cholesky_decompos": [66, 67, 68, 69, 71], "multi_normal_cholesky_rng": [66, 68, 71], "gp_cov_exp_quad": 66, "stabil": [66, 86], "sm_prior": 66, "gp_prior_fixed_rho_alpha": 66, "\u03c1": [66, 67, 68], "rougher": [66, 68], "cov_matern": [66, 68], "rg": 66, "spaghetti": 66, "cov_exp_quad": [66, 67, 68, 71], "multi_lin": 66, "mult_kern": 66, "x1": [66, 74], "x2": [66, 74], "rho_s": 66, "rho_per": 66, "periodic_kernel": 66, "se_kernel": 66, "cov_from_kernel": 66, "add_kern": 66, "linear_kernel": 66, "c_1": 66, "c_2": 66, "iptg": 66, "poi": 66, "c_i": 66, "heteroscedast": 66, "delta_": [66, 68], "lll": 66, "diag": [66, 67, 68], "unmeasur": 66, "5em": [66, 82], "triangular": 66, "stabli": 66, "shade": 66, "k_scale": [66, 67, 69, 71], "t_scale": [66, 67, 68, 69, 71], "t_rang": [66, 67, 69, 71], "manipul": [66, 71, 72, 84], "posterior_mean_cov": [66, 67, 68], "mstar": [66, 67, 68, 71], "sigmastar": [66, 67, 68, 71], "unscal": [66, 67, 68, 69, 71], "tstar": [66, 67, 68, 69, 71], "kstar": [66, 67, 68, 71], "show_lin": [66, 67, 68], "exent": 66, "muster": 66, "dampen": 66, "favor": [66, 68, 86], "flatter": 66, "simplif": 66, "gp": [67, 70], "stipul": 67, "wiggli": 67, "outlier": 67, "contort": 67, "invgamma": [67, 68, 69, 71], "singular": [67, 68, 82, 84], "diag_to_add": [67, 68], "ky": [67, 68, 71], "4f": [67, 68], "5887": 67, "5791": 67, "0886": 67, "miniconda3": [67, 68, 84], "env": [67, 68], "bebi103_build": [67, 68], "lib": [67, 68, 84], "python3": [67, 68, 84], "_optim": [67, 68], "py": [67, 68, 80, 84], "2472": [67, 68], "runtimewarn": [67, 68, 80], "tmp2": [67, 68], "fx": [67, 68], "fw": [67, 68], "nonparametr": [67, 68, 69, 71], "draw_gp_ppc": 67, "y_mean": 67, "y_std": 67, "nonparameter": 67, "inv_gamma": [67, 68, 69, 71], "multi_normal_choleski": [67, 68, 71], "gp_kinetics_no_ppc": [67, 71], "optimized_params_dict": 67, "ordereddict": 67, "lp__": [67, 72], "79106": 67, "40338": 67, "25657": 67, "0893158": 67, "optimized_params_pd": 67, "od": [68, 82], "remark": 68, "peter": 68, "swain": 68, "tom": [68, 80, 82], "r\u00f6schinger": [68, 80], "wild": 68, "roeschinger_growth_rate_data": 68, "tetracycline_conc_\u00b5g_per_ml": 68, "mg1655": 68, "a01": 68, "time_min": 68, "od600": 68, "hr": 68, "extrapol": 68, "od600_scal": 68, "solak": 68, "ourselv": 68, "2_x": 68, "z_j": 68, "partial_1": 68, "partial_2": 68, "pertin": 68, "matern": 68, "1420": 68, "5917": 68, "0118": 68, "augment": 68, "posterior_mean_cov_deriv": 68, "exp_quad_kernel": 68, "gstar": 68, "sigma_g_star": 68, "od600star": 68, "deriv_high": 68, "deriv_low": 68, "deriv_star": 68, "dt": [68, 80], "2_z": 68, "mu_z": [68, 74], "mu_x": [68, 74], "2_y": 68, "shortli": 68, "growth_rat": 68, "sigma_growth_r": 68, "gr_high": 68, "gr_low": 68, "redefin": 68, "matern_kernel": 68, "wiggl": 68, "gp_one_dimension": [68, 71], "stanfunct": 68, "fstar": [68, 69, 71], "dfstar": 68, "y_ppc": [68, 69, 71, 74], "kstarstar": [68, 71], "d1_kstar": 68, "d1_cov_exp_quad": 68, "d1_d2_kstarstar": 68, "d1_d2_cov_exp_quad": 68, "gp_posterior_mstar": [68, 71], "lstar": [68, 71], "gp_posterior_sigmastar_choleski": [68, 71], "sigmag": 68, "l_g_star": 68, "gp_growth_curv": 68, "stanc_opt": [68, 71], "include_path": [68, 71], "y_ppc_dim_0": [68, 71], "od600_ppc": 68, "dfstar_scal": 68, "dfstar_dim_0": 68, "fstar_scal": [68, 69, 71], "fstar_dim_0": [68, 71], "experienc": 68, "unmargin": 69, "f_i": 69, "layer": 69, "hyperparamat": 69, "preprocess": 69, "xstar_ind": 69, "f_tild": 69, "append_sort_index": 69, "index_origin": 69, "duplic": 69, "indici": 69, "73988004": 69, "67222743": 69, "60457482": 69, "58919923": 69, "53692222": 69, "46926961": 69, "401617": 69, "3339644": 69, "26631179": 69, "22693001": 69, "19865918": 69, "13100658": 69, "06335397": 69, "99570136": 69, "96124699": 69, "92804876": 69, "86039615": 69, "79274354": 69, "72509093": 69, "65743833": 69, "58978572": 69, "52324311": 69, "52213311": 69, "45448051": 69, "3868279": 69, "31917529": 69, "25152269": 69, "18459205": 69, "18387008": 69, "11621747": 69, "04856487": 69, "01908774": 69, "08674035": 69, "15439295": 69, "22204556": 69, "28969817": 69, "35735077": 69, "42500338": 69, "49265599": 69, "50367757": 69, "56030859": 69, "6279612": 69, "69561381": 69, "76326641": 69, "81156517": 69, "83091902": 69, "89857163": 69, "96622423": 69, "03387684": 69, "10152945": 69, "16918205": 69, "23683466": 69, "2418742": 69, "30448727": 69, "37213987": 69, "42441689": 69, "43979248": 69, "50744509": 69, "57509769": 69, "56": [69, 84], "526": 69, "97268063": 69, "522": 69, "8398459": 69, "513": 69, "09748852": 69, "12679808": 69, "490": 69, "5441167": 69, "482": 69, "87692992": 69, "472": [69, 72], "96035845": 69, "466": 69, "94519538": 69, "458": 69, "74328484": 69, "leapfrog": [69, 72, 82], "gp_kinetics_no_marg": 69, "dial": 69, "475": 69, "f_dim_0": 69, "data_kwarg": [69, 71], "1f78b4": [69, 71], "contriv": [69, 72], "scenario": [69, 84, 86], "a_0": 69, "varying_funct": 69, "a0": 69, "a1": 69, "\u03bb": 69, "time_point": 69, "n_cell": 69, "astyp": 69, "plop": 69, "fram": 69, "q_axi": 69, "600": [69, 72], "t_ind": 69, "log_f_tild": 69, "log_f": 69, "poisson_log": 69, "poisson_log_rng": 69, "gp_transcript_count": 69, "184": [69, 72], "3782": 69, "log_fstar": 69, "log_f_dim_0": 69, "mdivide_left_tri_low": 71, "mdivide_right_tri_low": 71, "sigma_star": 71, "po": 71, "emploi": [71, 72, 83, 86], "wherev": 71, "encas": 71, "suffix": 71, "stan_includ": 71, "comma": 71, "gp_kinet": 71, "pathto": 71, "force_compil": 71, "k_ppc_scale": 71, "heidi": [72, 83], "klump": [72, 83], "selector": 72, "adopt": 72, "interchang": 72, "david": 72, "blei": 72, "dissimilar": 72, "leiber": 72, "resembl": [72, 80, 82], "poorli": 72, "prod_i": 72, "phi_i": 72, "partit": [72, 82], "neq": 72, "q_j": 72, "hurdl": 72, "q_": 72, "randon": 72, "advi": 72, "alp": 72, "kucukelbir": 72, "zeta": 72, "zeta_i": 72, "meanfield": 72, "optimum": 72, "samples_vi": 72, "pertain": 72, "stdout_fil": 72, "runset": 72, "_stdout_fil": 72, "10000": 72, "grad_sampl": 72, "elbo_sampl": 72, "tol_rel_obj": 72, "eval_elbo": 72, "output_sampl": 72, "tmpcshdblkp": 72, "01ufoem2": 72, "json": 72, "spindlezaxcnbxg": 72, "20240727161414": 72, "diagnostic_fil": 72, "sig_fig": 72, "profile_fil": 72, "save_cmdstan_config": 72, "num_thread": 72, "unstabl": 72, "buggi": 72, "gradient": [72, 80, 82], "000392": 72, "ascent": 72, "delta_elbo_mean": 72, "delta_elbo_m": 72, "6093": 72, "3580": 72, "851": 72, "3473": 72, "163": 72, "578": 72, "702": 72, "3406": 72, "187": 72, "438": 72, "3310": 72, "589": 72, "356": 72, "031": 72, "3197": 72, "393": 72, "303": 72, "035": 72, "700": 72, "3119": 72, "716": 72, "263": 72, "800": 72, "3118": 72, "230": 72, "900": 72, "3055": 72, "396": 72, "207": 72, "029": 72, "3007": 72, "033": 72, "1100": 72, "2958": 72, "594": 72, "090": 72, "1200": 72, "2882": 72, "045": 72, "022": 72, "1300": 72, "2825": 72, "021": 72, "1400": 72, "2755": 72, "1500": 72, "2656": 72, "2549": 72, "177": 72, "023": 72, "1700": 72, "2429": 72, "026": 72, "1800": 72, "2310": 72, "505": 72, "027": 72, "1900": 72, "2205": 72, "968": 72, "037": 72, "2103": 72, "036": 72, "042": 72, "2100": 72, "2027": 72, "055": 72, "039": 72, "2200": 72, "1952": 72, "219": 72, "2300": 72, "1908": 72, "2400": 72, "1881": 72, "840": [72, 84], "2500": 72, "1870": 72, "947": 72, "2600": 72, "1869": 72, "602": 72, "032": 72, "2700": 72, "1859": 72, "828": 72, "2800": 72, "1852": 72, "081": 72, "2900": 72, "1855": 72, "085": 72, "3000": [72, 86], "1848": 72, "013": 72, "variational_sample_pd": 72, "df_vi": 72, "1_546": 72, "lp__log_p__log_g__phigamma_sigma_0mu": 72, "164": 72, "165": 72, "166": 72, "167": 72, "168": 72, "169": 72, "171": 72, "173": 72, "174": 72, "175": 72, "178": 72, "180": 72, "182": 72, "185": 72, "186": [72, 86], "189": 72, "192": 72, "194": 72, "195": 72, "196": 72, "197": 72, "198": 72, "199": 72, "f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64": 72, "f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f640": 72, "1835": 72, "33121238": 72, "2270": 72, "8426290": 72, "11378121": 72, "410822": 72, "116822": 72, "863123": 72, "818223": 72, "818224": 72, "107224": 72, "221524": 72, "391524": 72, "5625": 72, "109525": 72, "217225": 72, "377425": 72, "483325": 72, "640725": 72, "796425": 72, "899425": 72, "899426": 72, "052426": 72, "153526": 72, "303726": 72, "40326": 72, "403": 72, "248343": 72, "154236": 72, "822544": 72, "668738": 72, "665544": 72, "02741": 72, "527232": 72, "699924": 72, "670637": 72, "833836": 72, "934941": 72, "205144": 72, "229931": 72, "700542": 72, "786742": 72, "284843": 72, "183633": 72, "922841": 72, "924440": 72, "99631": 72, "870935": 72, "84937": 72, "39738": 72, "296335": 72, "662538": 72, "725243": 72, "700342": 72, "188434": 72, "516936": 72, "389942": 72, "901239": 72, "483443": 72, "509634": 72, "06443": 72, "242134": 72, "12140": 72, "64320": 72, "1840": 72, "78530839": 72, "15010": 72, "8652280": 72, "11209321": 72, "974922": 72, "698523": 72, "463224": 72, "441524": 72, "737524": 72, "854625": 72, "028725": 72, "201225": 72, "763925": 72, "874125": 72, "874126": 72, "038126": 72, "146526": 72, "307626": 72, "46726": 72, "572426": 72, "72926": 72, "832426": 72, "986227": 72, "087827": 72, "0878": 72, "852838": 72, "859240": 72, "255547": 72, "723140": 72, "816530": 72, "954534": 72, "280637": 72, "754237": 72, "441734": 72, "807737": 72, "139236": 72, "539429": 72, "180541": 72, "470439": 72, "744540": 72, "545239": 72, "189340": 72, "0141": 72, "243634": 72, "44339": 72, "726140": 72, "452141": 72, "051329": 72, "214242": 72, "083739": 72, "000348": 72, "029239": 72, "175628": 72, "694240": 72, "588942": 72, "45241": 72, "212443": 72, "891929": 72, "079348": 72, "109934": 72, "261135": 72, "85890": 72, "1858": 72, "3135140": 72, "27760": 72, "8440270": 72, "12307621": 72, "626222": 72, "358723": 72, "135824": 72, "134924": 72, "438324": 72, "558524": 72, "914925": 72, "49525": 72, "608925": 72, "778525": 72, "890726": 72, "057726": 72, "223126": 72, "332526": 72, "495326": 72, "60326": 72, "763126": 72, "86926": 72, "869": 72, "305746": 72, "086545": 72, "675337": 72, "458641": 72, "120538": 72, "046242": 72, "214834": 72, "958247": 72, "576935": 72, "842340": 72, "759945": 72, "705848": 72, "77944": 72, "312848": 72, "809835": 72, "705734": 72, "544637": 72, "255641": 72, "519542": 72, "743345": 72, "759829": 72, "798840": 72, "612251": 72, "127443": 72, "244447": 72, "42946": 72, "350742": 72, "102934": 72, "758235": 72, "285637": 72, "087235": 72, "45129": 72, "324637": 72, "891744": 72, "517646": 72, "607338": 72, "60070": 72, "57": 72, "2506237": 72, "61070": 72, "8235380": 72, "12039920": 72, "9521": 72, "643522": 72, "376723": 72, "315823": 72, "600123": 72, "712623": 72, "879923": 72, "879924": 72, "045724": 72, "586724": 72, "692824": 72, "850524": 72, "954825": 72, "109825": 72, "263325": 72, "364725": 72, "515525": 72, "615225": 72, "763325": 72, "861125": 72, "8611": 72, "700133": 72, "765741": 72, "01630": 72, "692931": 72, "122833": 72, "522642": 72, "145236": 72, "1543": 72, "160140": 72, "126942": 72, "508540": 72, "00243": 72, "993937": 72, "575338": 72, "000436": 72, "304840": 72, "071936": 72, "101739": 72, "003932": 72, "224645": 72, "635435": 72, "53938": 72, "868137": 72, "839935": 72, "145742": 72, "555744": 72, "950539": 72, "690740": 72, "796237": 72, "734439": 72, "588133": 72, "151932": 72, "761429": 72, "640840": 72, "012242": 72, "179343": 72, "35860": 72, "1837": 72, "70917538": 72, "33510": 72, "8371120": 72, "11236821": 72, "305322": 72, "011622": 72, "758623": 72, "715523": 72, "715524": 72, "005224": 72, "119824": 72, "290424": 72, "459425": 72, "01125": 72, "119125": 72, "279925": 72, "386325": 72, "544425": 72, "700925": 72, "804325": 72, "958125": 72, "958126": 72, "059826": 72, "210826": 72, "310726": 72, "3107": 72, "389538": 72, "487935": 72, "552138": 72, "478339": 72, "257242": 72, "376948": 72, "535439": 72, "861436": 72, "31238": 72, "527838": 72, "715338": 72, "726839": 72, "719838": 72, "526837": 72, "728746": 72, "05735": 72, "144146": 72, "713130": 72, "492937": 72, "246445": 72, "322936": 72, "658942": 72, "086337": 72, "391944": 72, "149438": 72, "827439": 72, "504842": 72, "60740": 72, "123337": 72, "005437": 72, "151228": 72, "840532": 72, "462543": 72, "715541": 72, "509742": 72, "00435": 72, "4243": 72, "legaci": 72, "log_p__": 72, "log_g__": 72, "variational_params_pd": 72, "4521": 72, "853254": 72, "116228": 72, "6552": 72, "3666": 72, "1182": 72, "0794": 72, "4477": 72, "673": 72, "7122": 72, "1776": 72, "381": 72, "9442": 72, "6642": 72, "46": 72, "0142": 72, "2081": 72, "4419": 72, "1546": 72, "plot_marginal_ecdf": 72, "p_phi": 72, "p_gamma": 72, "fullrank": 72, "3251": 72, "88812": 72, "noncent": [72, 82], "hier_lognorm": 72, "32520": 72, "require_converg": 72, "tendenc": 72, "underestim": 72, "p_theta": 72, "p_sigma": 72, "p_tau": 72, "gridplot": [72, 86], "ncol": [72, 86], "custom": 72, "ranganath": 72, "daft": 74, "graphviz": 74, "config": 74, "inlinebackend": 74, "figure_format": 74, "retina": 74, "ferenc": 74, "husz\u00e1r": 74, "sigma_x": 74, "pgm": 74, "add_nod": 74, "add_edg": 74, "graph": 74, "graph_attr": 74, "node_attr": 74, "lightgrei": 74, "fontnam": 74, "helvetica": [74, 80], "edge_attr": 74, "arrows": 74, "rankdir": 74, "lr": 74, "labelloc": 74, "dag": 74, "digraph": 74, "node": [74, 84], "y1": 74, "tail_nam": 74, "head_nam": 74, "sigma_z": 74, "coeffici": [74, 80], "rho_": 74, "xz": 74, "yz": 74, "rho_zx": 74, "rho_zi": 74, "cond_norm": 74, "cond_sampl": 74, "x0": 74, "y0": 74, "y2": 74, "x3": 74, "y3": 74, "e41a1c": 74, "377eb8": 74, "4daf4a": 74, "984ea3": 74, "legend_item": 74, "add_layout": [74, 80], "x_0": 74, "unsurprisingli": 74, "fundament": 74, "add_text": 74, "x\u2080": 74, "z1": 74, "dx": 74, "z2": 74, "z3": 74, "causal": 74, "pearl": 74, "unobserv": 74, "mu_u": 74, "sigma_u": 74, "z_0": 74, "z\u2080": 74, "z_intervent": 74, "y_intervent": 74, "er": 74, "rip": 74, "79": [74, 80], "pearl_3": 74, "went": 74, "81": 74, "morn": 75, "noon": [75, 90], "attend": 75, "recit": [75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 90], "offic": [75, 90], "tuesdai": [75, 90], "dilig": 75, "golden": 75, "opportun": 75, "submit": [75, 84, 90], "schedul": [75, 84], "skill": 75, "_lastname_firstnam": 75, "pacif": 75, "sundai": 75, "perfectli": 75, "aspect": 75, "fridai": 75, "hw": 75, "restart": 75, "runnabl": 75, "submitt": 75, "credit": [75, 80], "name_of_datafil": 75, "embed": 75, "mathjax": 75, "latex": 75, "inversegamma": 75, "justifi": 75, "guidelin": 75, "adjac": [75, 82], "explanatori": 75, "markdown": 75, "header": 75, "delin": 75, "late": 75, "six": 75, "grace": 75, "penalti": 75, "saturdai": 75, "ill": 75, "health": 75, "cass": 75, "accommod": 75, "coursework": 75, "exam": 75, "announc": 75, "offici": 75, "passag": 75, "receiv": [75, 80, 84], "nullifi": 75, "violat": 75, "publicli": 75, "unpublish": 75, "institut": 75, "faith": 75, "imper": 75, "dissemin": 75, "classmat": 75, "whom": 75, "consult": 75, "websit": 75, "materi": [75, 76, 85, 86, 87], "cite": 75, "llm": 75, "chatgpt": 75, "gpt": 75, "llama": 75, "gemini": 75, "cursor": 75, "copilot": 75, "ai": 75, "engin": [75, 89], "deni": 75, "contrari": 75, "basal": 75, "compet": 75, "reiter": 75, "chatbot": 75, "privat": 75, "email": [75, 84], "shot": 75, "anonym": 75, "spur": 75, "dialog": [76, 87], "factori": 80, "curdoc": 80, "ticker": 80, "fixedtick": 80, "holoview": 80, "hv": 80, "pallete1": 80, "9faeb2": 80, "ab6e7d": 80, "1c2630": 80, "autohid": 80, "text_font": 80, "text_font_s": 80, "16px": 80, "xaxi": 80, "axis_label_text_font": 80, "yaxi": 80, "axis_label_text_font_s": 80, "13px": 80, "axis_label_text_font_styl": 80, "background_fill_alpha": 80, "toolbar": 80, "anyon": 80, "background": [80, 83, 84], "break": [80, 84], "subset": 80, "bob": 80, "carpent": 80, "sequenc": 80, "weigh": 80, "375": 80, "326": 80, "420": 80, "binomial_coeff": 80, "prob": 80, "patch": 80, "eaeaea": 80, "degeneraci": 80, "999999": 80, "1000000": 80, "imbal": 80, "classic": [80, 82, 86], "quantum": 80, "harmon": 80, "oscil": [80, 82], "attach": [80, 83], "spring": 80, "act": 80, "kx": 80, "movement": 80, "mv": 80, "2m": 80, "momentum": [80, 82], "fiat": 80, "brick": 80, "wall": 80, "wreck": 80, "train": 80, "stand": 80, "consum": [80, 84], "ellipsoid": 80, "simple_oscil": 80, "bupu": 80, "x_arr": 80, "p_plu": 80, "p_minu": 80, "major_label_text_font_s": 80, "0pt": 80, "evolut": 80, "hamilton": [80, 82], "motion": [80, 82], "qquad": 80, "angl": 80, "mag": 80, "arctan2": 80, "vectorfield": 80, "cmap": 80, "viridi": 80, "xlabel": 80, "ylabel": 80, "interrupt": 80, "therm": 80, "preprint": 80, "1701": 80, "02434": 80, "momenta": 80, "scatter1": 80, "scatter2": 80, "arrow1": 80, "arrow1_1": 80, "arrow1_2": 80, "arrow2": 80, "arrow2_1": 80, "arrow2_2": 80, "partial_h": 80, "xlim": 80, "ylim": 80, "show_grid": 80, "distinct": 80, "h1": 80, "h2": 80, "h3": 80, "x_arr1": 80, "x_arr2": 80, "x_arr3": 80, "p_plus1": 80, "p_minus1": 80, "p_plus2": 80, "p_minus2": 80, "p_plus3": 80, "p_minus3": 80, "scatter12": 80, "scatter22": 80, "arrow12": 80, "arrow1_12": 80, "arrow1_22": 80, "arrow22": 80, "arrow2_12": 80, "arrow2_22": 80, "partial_h2": 80, "l3": 80, "n6j3jk1n1p94lc552kcbzq280000gn": 80, "ipykernel_5666": 80, "985606356": 80, "prime": 80, "prime_i": 80, "rotat": 80, "parameter": 80, "disrupt": 80, "regard": 80, "const": [80, 82], "lap": 80, "unexplor": 80, "backward": [80, 82], "met": 80, "euler": 80, "inaccuraci": [80, 82], "drastic": 80, "stackoverflow": 80, "33601089": 80, "n0": 80, "dn": 80, "dx_dt": 80, "liouvil": 80, "symplect": [80, 82], "detriment": 80, "shoot": 80, "bridg": 80, "rail": 80, "fought": 80, "rosita": 82, "fu": 82, "linger": 82, "r\u00f6esching": 82, "alongsid": 82, "math": [82, 84], "int_q": 82, "hspace": 82, "mathbb": 82, "entireti": 82, "ordinari": 82, "dq": 82, "1d": 82, "3d": 82, "cube": [82, 84], "denisti": 82, "predomin": 82, "sit": 82, "x_": 82, "sole": 82, "creativ": 82, "allud": 82, "determinist": [82, 86], "dictat": 82, "f_n": 82, "btw": 82, "habit": 82, "hover": 82, "overcompens": 82, "usag": 82, "diffus": 82, "irredeem": 82, "incapacit": 82, "jump": [82, 86], "sluggish": 82, "increment": 82, "overal": [82, 86], "q_1": 82, "q_2": 82, "q_3": 82, "cast": 82, "hearken": 82, "metaphor": 82, "planet": 82, "gravit": 82, "orbit": 82, "satellit": 82, "crash": [82, 84], "eject": 82, "auxiliari": 82, "2xd": 82, "q_n": 82, "rightarrow": 82, "p_n": 82, "canon": 82, "nbsphinx": 82, "8em": 82, "9em": 82, "interepret": 82, "lift": [82, 86], "omega": 82, "omega_": 82, "microcanon": 82, "ring": 82, "jointli": 82, "cfrac": 82, "2em": 82, "3em": 82, "phi_t": 82, "altogeth": 82, "somehow": 82, "unlock": 82, "expon": 82, "decoupl": 82, "retriev": [82, 84], "repeatedli": 82, "project": [82, 83, 84], "swiftli": 82, "euclidean": 82, "riemannian": 82, "pi_": 82, "pi_e": 82, "e_bfmi": 82, "proven": 82, "ke": 82, "pick": 82, "convolut": 82, "distribtuion": 82, "de": 82, "distribuion": 82, "Their": 82, "smoothen": 82, "persist": [82, 86], "stronger": 82, "suspicion": 82, "distribt": 82, "termin": [82, 84], "mysteri": 82, "impress": 82, "takeawai": 82, "life": 82, "exploit": 82, "glean": 82, "face": [82, 86], "cellular": 83, "pathwai": [83, 86], "architectur": 83, "extracellular": 83, "surfac": 83, "confoc": 83, "membran": [83, 86], "autom": 83, "cytometri": 83, "fluorophor": 83, "presum": 83, "cytomet": 83, "bead": 83, "subunit": 83, "spontan": 83, "weren": 83, "multimer": [83, 86], "intracellular": [83, 86], "fusion": [83, 86], "zachari": 84, "martinez": 84, "tailor": 84, "cluster": 84, "terabyt": 84, "petabyt": 84, "facillit": 84, "acceler": 84, "cento": 84, "admin": 84, "grant": 84, "authent": 84, "duo": 84, "wifi": 84, "vpn": 84, "zmartin": 84, "host": 84, "refus": 84, "ondemand": 84, "studio": 84, "desktop": 84, "compos": 84, "script": 84, "alloc": 84, "queue": 84, "princeton": 84, "my_slurm_script": 84, "sbatch": 84, "walltim": 84, "ntask": 84, "processor": 84, "mem": 84, "16g": 84, "my_first_job": 84, "mail": 84, "purg": 84, "export": 84, "ld_library_path": 84, "mthomson": 84, "zam": 84, "miniconda": 84, "librari": 84, "example_env": 84, "highly_parallelized_script": 84, "my_first_job_xxxxxx": 84, "cheatsheet": 84, "flag": 84, "gre": 84, "qo": 84, "debug": 84, "prioriti": 84, "forev": 84, "cascadelak": 84, "squeue": 84, "pend": 84, "scancel": 84, "12345678": 84, "kill": [84, 86], "jobid": 84, "srun": 84, "pty": 84, "xx": 84, "lastli": 84, "programat": 84, "slurm_ntask": 84, "n_task": 84, "gui": 84, "winscp": 84, "filezilla": 84, "cyberduck": 84, "awscli": 84, "forth": 84, "remote_script": 84, "local_script": 84, "local_filenam": 84, "currect": 84, "remote_filenam": 84, "3ish": 84, "50gb": 84, "10tb": 84, "thomson": 84, "80tb": 84, "scratch": 84, "20tb": 84, "scratchio": 84, "2tb": 84, "quota": 84, "mmlsquota": 84, "auto": 84, "ticket": 84, "vscode": 84, "plugin": 84, "vim": 84, "friendli": 84, "isn": [84, 86], "geeksforgeek": 84, "realpython": 84, "superfastpython": 84, "prematur": 84, "evil": 84, "donald": 84, "knuth": 84, "multiprocess": 84, "exhaust": 84, "unexpect": 84, "silent": 84, "multithread": 84, "lock": 84, "gil": 84, "thread": 84, "cpu_count": 84, "mp": 84, "laptop": 84, "squareroot": 84, "benchmark": 84, "square_list": 84, "input_list": 84, "num": [84, 86], "squareroot_list": 84, "mylist": 84, "100_000_001": 84, "100_000_000": 84, "ran": 84, "elaps": 84, "94840407371521": 84, "ascend": 84, "overcom": 84, "__name__": 84, "__main__": 84, "p1": [84, 86], "p2": [84, 86], "p3": 84, "30126214027405": 84, "demo": 84, "10_000_001": 84, "10_000_000": 84, "8647820949554443": 84, "teardown": 84, "3583669662475586": 84, "precari": 84, "race": 84, "cube_and_revers": 84, "val": 84, "arr": 84, "125": 84, "random_word": 84, "randomword": 84, "flush": 84, "get_random_word": 84, "consumer_process": 84, "producer_process": 84, "modulenotfounderror": 84, "traceback": 84, "firstli": 84, "dramat": 84, "bebi103b": 84, "thirdli": 84, "capac": 84, "infeas": 84, "simultan": 84, "benefici": 84, "timefram": 84, "paralleliz": 84, "pd": [84, 86], "prep": [84, 86], "prior_predictive_check": 84, "stan_model_cod": 84, "example_model": 84, "_perform_sbc": 84, "_get_output_dir": 84, "samples_dir": 84, "prior_sample_cmdstanpi": 84, "posterior_samples_cmdstanpi": 84, "parallel_chain": 84, "arg_input_gener": 84, "stan_sbc": 84, "my_job": 84, "thefilenam": 84, "6g": 84, "stan_sbc_test": 84, "touch": 84, "chunk": 84, "cpp_option": 84, "stan_thread": 84, "rewritten": 84, "reduce_sum": 84, "piecewis": 84, "partial_sum_neg_binom": 84, "slice_n": 84, "mere": 84, "iceberg": 84, "taught": 84, "foot": 84, "door": 84, "luck": 84, "zach": 85, "julian": 86, "wagner": 86, "bespok": 86, "ecolog": 86, "recaptur": 86, "afterward": 86, "worst": 86, "dread": 86, "nan": 86, "datatyp": 86, "explod": 86, "ecologi": 86, "leg": 86, "band": 86, "bird": 86, "fin": 86, "shark": 86, "stradl": 86, "radioact": 86, "phosphor": 86, "32p": 86, "tissu": 86, "worker": 86, "myrmica": 86, "rubra": 86, "gari": 86, "alpert": 86, "hypergeometr": 86, "white": 86, "ball": 86, "unlabel": 86, "stickler": 86, "todai": 86, "insist": 86, "stick": 86, "negative_binomi": 86, "log_sum_exp": 86, "game": 86, "mark_recapture_hypergeometr": 86, "max_pop": 86, "min_pop": 86, "neg_binomial_2_lpmf": 86, "hypergeometric_lpmf": 86, "simplex": 86, "pstate": 86, "funni": 86, "346": 86, "sample_it": 86, "aren": 86, "distibut": 86, "0000000284678414": 86, "yai": 86, "gotten": 86, "sake": 86, "ra": 86, "a_min": 86, "a_max": 86, "mt_gamma": 86, "20000": 86, "ndiagnost": 86, "t_ppc_dim_0": 86, "alpha_": 86, "t_j": 86, "a_": 86, "hei": 86, "sm2": 86, "mt_gamma_integer_alpha": 86, "beta2": 86, "binomial_lpmf": 86, "gamma_lpdf": 86, "log_p_norm": 86, "categorical_logit_rng": 86, "round": 86, "logit": 86, "samples_discret": 86, "odd": 86, "funki": 86, "intermediari": 86, "df_sample_compar": 86, "peaki": 86, "confirm": 86, "87136123": 86, "170593759154506": 86, "76135737638342": 86, "5281784828052738": 86, "mt_gamma_integer_alpha_jb": 86, "log_alpha_prior": 86, "un": 86, "log_q": 86, "samp": 86, "log_norm_const": 86, "log_g": 86, "net": 86, "monstrou": 86, "numba": 86, "3rd": 89, "freeli": 89, "channel": 89, "video": 89, "2nd": 89, "richard": 89, "mcelreath": 89, "ben": 89, "lambert": 89, "beginn": 89, "press\u00e9": 89, "sgourali": 89, "exposit": 89, "phil": 89, "supplement": 89, "b123": 90, "kerckhoff": 90, "kerkchoff": 90, "februari": 90, "march": 90, "martin": 90, "luther": 90, "king": 90, "presid": 90}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"homework": [0, 2, 75, 79, 88, 90], "1": [0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 19, 49, 72, 74], "first": 0, "attempt": 0, "bayesian": [0, 16, 22, 23, 26, 32, 66, 72, 83], "gener": [0, 1, 21, 37, 38, 42, 45, 49, 59, 63, 65, 69], "model": [0, 1, 17, 22, 23, 26, 27, 28, 31, 33, 42, 44, 45, 46, 49, 50, 52, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 65, 69, 72, 74, 83], "70": 0, "pt": 0, "intuit": 1, "BE": 2, "bi": 2, "103": 2, "b": [2, 82], "statist": [2, 16, 50, 52, 64], "infer": [2, 16, 66, 72], "biolog": 2, "scienc": [2, 16], "us": [2, 12, 13, 25, 32, 43, 45, 66, 68, 69, 71, 80, 84, 85], "link": 2, "peopl": 2, "lesson": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 75, 90], "schedul": [2, 90], "polici": [2, 75], "resourc": [2, 14], "previou": 2, "edit": 2, "cours": [2, 75], "e1": 3, "To": [3, 4, 5, 6, 7, 8, 9, 10, 11], "complet": [3, 4, 5, 6, 7, 8, 9, 10, 11], "after": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12], "5": [3, 4, 7, 9, 12, 29], "exercis": [3, 4, 5, 6, 7, 8, 9, 10, 11, 75, 90], "2": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 26, 49, 72, 74], "3": [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 27, 49, 74], "4": [3, 4, 5, 6, 7, 8, 9, 11, 12, 28], "e2": 4, "6": [4, 8, 12, 30], "e3": 5, "10": [5, 45, 87], "e4": 6, "13": [6, 50], "e5": 7, "16": [7, 53], "e6": 8, "18": [8, 56], "e7": 9, "20": [9, 63], "7": [9, 12, 36], "e8": 10, "22": [10, 65], "8": [10, 12, 41], "e9": 11, "25": [11, 72], "9": [11, 12, 44], "aw": 12, "setup": 12, "usag": 12, "creat": 12, "an": [12, 21, 27, 57, 65, 66, 82], "amazon": 12, "web": 12, "servic": 12, "account": 12, "launch": 12, "your": [12, 15, 43], "instanc": 12, "connect": 12, "jupyterlab": 12, "copi": 12, "result": [12, 47, 48], "from": [12, 22, 68], "local": 12, "machin": [12, 15], "exit": 12, "serious": 12, "stop": 12, "you": 12, "ar": [12, 43], "them": 12, "again": 12, "termin": 12, "class": 12, "i": [12, 16, 31, 49, 84], "over": 12, "googl": 13, "colab": 13, "watchout": 13, "when": 13, "softwar": [13, 84, 89], "A": [13, 27, 33, 53, 62, 63, 64, 69, 72, 80, 82], "sampl": [13, 42, 43, 44, 45, 46, 48, 52, 53, 63, 65, 66, 67, 68, 69, 82, 86], "calcul": [13, 27, 57, 68], "comput": [13, 14, 15, 27, 28, 29, 31, 32, 33, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 65, 66, 67, 68, 69, 71, 72, 80, 86], "environ": [13, 15, 27, 28, 29, 31, 32, 33, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 57, 60, 65, 66, 67, 68, 69, 71, 72, 80, 86], "0": [14, 74], "set": [14, 27, 42, 49, 51, 52, 63, 66, 80, 82], "up": [14, 39, 43, 44, 63, 73], "configur": 15, "instal": 15, "python": [15, 84], "packag": 15, "stan": [15, 41, 42, 43, 45, 49, 63, 66, 67, 68, 69, 71, 72, 84, 86], "c": [15, 82], "toolchain": 15, "maco": 15, "window": 15, "linux": 15, "cmdstanpi": 15, "check": [15, 33, 49, 50, 51, 52, 54, 63, 65, 71], "probabl": [16, 19, 21, 76, 86], "logic": [16, 19], "what": [16, 80, 84], "The": [16, 22, 23, 25, 27, 28, 29, 33, 37, 38, 42, 46, 49, 50, 52, 54, 62, 65, 66, 72, 80, 82], "problem": 16, "frequentist": 16, "desiderata": 16, "sum": 16, "rule": 16, "product": 16, "condit": [16, 21, 58, 74], "applic": 16, "scientif": [16, 19], "measur": [16, 22], "bay": [16, 17, 18, 21], "": [16, 17, 18, 21, 49, 51, 84, 85], "theorem": [16, 17, 18, 21], "prior": [16, 22, 23, 25, 42, 49, 51, 58, 65, 66, 67, 77, 78], "likelihood": [16, 22, 24, 27, 31, 49, 57, 66, 69, 71], "evid": 16, "posterior": [16, 23, 27, 29, 31, 32, 42, 46, 48, 50, 54, 66, 67, 71], "learn": 17, "notat": [18, 82], "part": 18, "reason": 19, "margin": [20, 27, 28, 42, 46, 86], "distribut": [21, 22, 46, 48, 51, 58, 66, 74, 86], "joint": 21, "pdf": 21, "chang": 21, "variabl": [21, 51, 69], "formula": 21, "continu": 21, "multipl": 21, "dimens": 21, "exampl": [21, 22, 25, 55, 57, 66, 72, 74], "anoth": [21, 22], "log": [21, 27, 54, 57, 84, 86], "normal": [21, 22, 27, 31, 32, 33, 66, 69, 71], "paramet": [22, 27, 30, 31, 32, 33, 42, 46, 49, 62, 66, 86], "estim": [22, 30, 31, 32, 33, 42, 54, 66, 71], "repeat": [22, 62], "revisit": 22, "choic": [22, 58, 82], "succinctli": 22, "state": [22, 84], "task": 23, "build": [23, 42, 49, 64, 83], "role": 23, "make": 23, "sens": 23, "choos": [24, 25, 38, 51, 58, 72, 77, 78, 80], "uniform": 25, "jeffrei": 25, "why": [25, 32, 40, 43], "weakli": 25, "inform": [25, 54], "conjug": [25, 29], "bet": 25, "farm": 25, "method": [25, 48, 82], "specifi": 25, "introduct": [26, 36, 41, 66, 81], "plot": [27, 29, 42, 44, 46, 64, 66], "data": [27, 31, 42, 49, 52, 62, 63, 66, 68, 74], "spindl": [27, 49, 72], "size": [27, 31, 42, 49, 50, 52, 72], "singl": 27, "analyt": [27, 28, 66], "numer": [27, 28, 80], "quadratur": [27, 28], "prescript": 27, "1d": 27, "express": [27, 68], "2d": 27, "asid": [27, 63, 71], "speed": 27, "tubulin": [28, 33, 49, 50], "conserv": [28, 33, 50], "curs": 28, "dimension": [28, 82], "overcom": 28, "conjugaci": 29, "beta": 29, "binomi": 29, "pair": [29, 46], "find": 29, "comment": 29, "optim": [30, 31, 32, 33, 67, 68, 77, 78, 82], "case": [31, 53], "studi": [31, 53], "exploratori": 31, "analysi": [31, 42, 64], "independ": [31, 49, 50, 62, 84], "map": [31, 32, 67], "approxim": [31, 32, 33], "credibl": [31, 32], "interv": [31, 32], "how": [31, 48, 82, 84], "good": 31, "approach": 32, "summar": [32, 48], "its": 32, "maximum": 32, "demonstr": 32, "mai": 32, "skew": 32, "variat": [33, 45, 72], "covari": [33, 45, 66, 68], "displai": [33, 42, 43, 46, 47, 48], "best": [33, 42, 62], "fit": [33, 42], "line": 33, "further": 35, "read": [35, 89], "mcmc": [35, 37, 40, 41, 42, 44, 45, 46, 47, 48, 52, 69, 71, 84, 85], "markov": [36, 42, 82], "chain": [36, 42], "mont": [36, 42, 52, 80, 81, 82], "carlo": [36, 42, 52, 80, 81, 82], "random": 37, "number": [37, 51, 66], "basic": [37, 43], "idea": [37, 72], "behind": 37, "transit": [38, 80, 82], "kernel": [38, 66, 68], "metropoli": 38, "hast": 38, "algorithm": [38, 72, 82], "detail": [38, 80], "balanc": 38, "warm": 39, "our": [42, 65], "engin": 42, "ecdf": [42, 64, 65], "mrna": [42, 65], "count": [42, 65], "burst": 42, "inter": 42, "time": [42, 80, 82], "all": [42, 49, 74, 82], "gene": 42, "hello": 43, "world": [43, 62], "program": 43, "sai": 43, "hi": 43, "pars": [43, 44], "output": [43, 44], "arviz": [43, 46], "direct": 43, "we": [43, 82], "code": [43, 44, 63, 75, 84], "save": 43, "clean": 43, "shrapnel": 43, "mixtur": [44, 57], "label": 44, "switch": 44, "initi": 44, "walker": 44, "conclus": [44, 63, 65, 66], "updat": 45, "visual": 46, "examin": 46, "trace": 46, "bebi103": 46, "interpet": 46, "parallel": 46, "coordin": 46, "intepret": 46, "one": [46, 54], "iqplot": 46, "two": [46, 86], "corner": 46, "11": 47, "report": 48, "summari": [48, 50, 72], "some": 48, "error": [48, 52], "bar": 48, "rel": 48, "merit": 48, "each": 48, "text": 48, "12": 49, "predict": [49, 50, 54, 66, 67, 71], "droplet": 49, "take": [49, 86], "depend": 49, "total": 49, "concentr": 49, "indentifi": 49, "limit": 49, "behavior": 49, "assumpt": 49, "v_": 49, "mathrm": 49, "v_0": 49, "ll": 49, "do": [49, 82], "have": 49, "same": [49, 74], "aspect": 49, "ratio": 49, "k": [49, 82], "bewar": 50, "14": 51, "collector": 51, "box": 51, "out": [51, 53, 54, 66], "explor": 51, "start": 51, "simpl": 51, "ad": 51, "flexibl": 51, "support": [51, 84], "posit": 51, "real": 51, "15": 52, "diagnost": [52, 53, 63, 64], "ani": 52, "sampler": 52, "gelman": 52, "rubin": 52, "r": 52, "hat": 52, "effect": 52, "standard": 52, "hmc": [52, 80], "diverg": [52, 54, 80], "tree": 52, "depth": 52, "e": 52, "bfmi": 52, "quickli": 52, "artifici": 53, "funnel": 53, "hell": 53, "conquer": 53, "adjust": [53, 65], "adapt_delta": 53, "noncent": [53, 63, 69], "hierarch": [53, 58, 59, 60, 61, 62, 63, 72], "featur": [53, 82], "17": 54, "comparison": [54, 56, 57], "metric": 54, "assess": 54, "close": 54, "entropi": 54, "kullback": 54, "leibler": 54, "expect": 54, "pointwis": [54, 57], "densiti": 54, "watanab": 54, "akaik": 54, "criterion": 54, "leav": 54, "elpd": 54, "weight": [54, 57], "select": 55, "regress": 55, "practic": [56, 57, 65, 68], "waic": 57, "loo": 57, "exchang": 58, "implement": [60, 63, 70, 82], "19": 61, "experi": 62, "revers": 62, "pool": [62, 84], "ident": 62, "both": 62, "structur": 63, "quick": 63, "input": 63, "draw": 63, "parametr": 63, "21": 64, "principl": 64, "pipelin": 64, "workflow": 64, "refer": 64, "terminologi": 64, "simul": [64, 65], "base": [64, 65], "calibr": [64, 65], "z": 64, "score": 64, "shrinkag": 64, "v": 64, "rank": 64, "histogram": 64, "full": 64, "relat": 65, "perform": 65, "sbc": 65, "new": 65, "23": 66, "gaussian": [66, 67, 69, 70, 80], "process": [66, 67, 69, 70, 84], "nonparametr": 66, "finit": 66, "point": 66, "mean": 66, "function": [66, 72], "center": 66, "scale": 66, "matrix": 66, "gp": [66, 68, 69, 71], "numpi": 66, "compos": 66, "valu": [66, 86], "hyperparamet": [67, 71], "scipi": 67, "obtain": [67, 84], "hyperprior": 67, "deriv": 68, "squar": 68, "exponenti": 68, "mat\u00e9rn": 68, "gradient": 68, "non": 69, "latent": 69, "poisson": 69, "24": 70, "includ": 71, "file": [71, 84], "main": 72, "q": [72, 82], "\u03b8": 72, "vi": 72, "automat": 72, "differenti": 72, "volum": 72, "multilevel": 72, "26": 73, "wrap": 73, "thei": 74, "give": 74, "intervent": 74, "more": [74, 80], "complex": 74, "meet": 75, "lab": 75, "session": 75, "submiss": 75, "assign": 75, "grade": 75, "collabor": 75, "honor": 75, "commun": [75, 84], "ediquett": 75, "r1": 76, "review": [76, 77, 78, 86], "r2": [77, 78], "r3": 79, "just": [79, 88], "help": [79, 88], "hamiltonian": [80, 81, 82], "typic": [80, 82], "kinet": [80, 82], "energi": [80, 82], "euclidean": 80, "short": 80, "note": 80, "integr": [80, 82], "happen": 80, "r4": 81, "overview": [82, 90], "motiv": 82, "interest": 82, "high": 82, "space": 82, "But": 82, "question": 82, "remain": 82, "design": 82, "so": 82, "thi": 82, "lead": 82, "u": 82, "ideal": 82, "actual": 82, "consider": 82, "p": 82, "conclud": 82, "thought": 82, "r5": 83, "r6": [84, 85], "caltech": [84, 85], "hpc": [84, 85], "even": 84, "supercomput": 84, "hpcc": 84, "access": 84, "slurm": 84, "transfer": 84, "storag": 84, "pro": 84, "tip": 84, "write": 84, "concurr": 84, "between": 84, "share": 84, "run": 84, "foreword": 84, "r7": 86, "discret": 86, "logsumexp": 86, "cornerston": 86, "stabl": 86, "handl": 86, "vector": 86, "paremet": 86, "integ": 86, "\u03b1": 86, "gamma": 86, "via": 86, "r8": 87, "discuss": 87, "hw": 87, "project": 87, "propos": 87, "r9": 88, "tutori": 89, "due": 90, "date": 90, "weekli": 90}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"Homework 1.1: First attempts at Bayesian generative modeling (70 pts)": [[0, "Homework-1.1:-First-attempts-at-Bayesian-generative-modeling-(70-pts)"]], "1. Intuitive generative modeling": [[1, "intuitive-generative-modeling"]], "BE/Bi 103 b: Statistical Inference in the Biological Sciences": [[2, "be-bi-103-b-statistical-inference-in-the-biological-sciences"]], "Useful links": [[2, "useful-links"]], "People": [[2, "people"]], "Lessons": [[2, null]], "Homework": [[2, null], [75, "homework"]], "Schedule": [[2, null]], "Policies": [[2, null]], "Resources": [[2, null]], "Previous editions of the course": [[2, "previous-editions-of-the-course"]], "E1. To be completed after lesson 5": [[3, "E1.-To-be-completed-after-lesson-5"]], "Exercise 1.1": [[3, "Exercise-1.1"]], "Exercise 1.2": [[3, "Exercise-1.2"]], "Exercise 1.3": [[3, "Exercise-1.3"]], "Exercise 1.4": [[3, "Exercise-1.4"]], "E2. To be completed after lesson 6": [[4, "E2.-To-be-completed-after-lesson-6"]], "Exercise 2.1": [[4, "Exercise-2.1"]], "Exercise 2.2": [[4, "Exercise-2.2"]], "Exercise 2.3": [[4, "Exercise-2.3"]], "Exercise 2.4": [[4, "Exercise-2.4"]], "Exercise 2.5": [[4, "Exercise-2.5"]], "E3. To be completed after lesson 10": [[5, "E3.-To-be-completed-after-lesson-10"]], "Exercise 3.1": [[5, "Exercise-3.1"]], "Exercise 3.2": [[5, "Exercise-3.2"]], "Exercise 3.3": [[5, "Exercise-3.3"]], "Exercise 3.4": [[5, "Exercise-3.4"]], "E4. To be completed after lesson 13": [[6, "E4.-To-be-completed-after-lesson-13"]], "Exercise 4.1": [[6, "Exercise-4.1"]], "Exercise 4.2": [[6, "Exercise-4.2"]], "Exercise 4.3": [[6, "Exercise-4.3"]], "Exercise 4.4": [[6, "Exercise-4.4"]], "E5. To be completed after lesson 16": [[7, "E5.-To-be-completed-after-lesson-16"]], "Exercise 5.1": [[7, "Exercise-5.1"]], "Exercise 5.2": [[7, "Exercise-5.2"]], "Exercise 5.3": [[7, "Exercise-5.3"]], "Exercise 5.4": [[7, "Exercise-5.4"]], "E6. To be completed after lesson 18": [[8, "E6.-To-be-completed-after-lesson-18"]], "Exercise 6.1": [[8, "Exercise-6.1"]], "Exercise 6.2": [[8, "Exercise-6.2"]], "Exercise 6.3": [[8, "Exercise-6.3"]], "Exercise 6.4": [[8, "Exercise-6.4"]], "E7. To be completed after lesson 20": [[9, "E7.-To-be-completed-after-lesson-20"]], "Exercise 7.1": [[9, "Exercise-7.1"]], "Exercise 7.2": [[9, "Exercise-7.2"]], "Exercise 7.3": [[9, "Exercise-7.3"]], "Exercise 7.4": [[9, "Exercise-7.4"]], "Exercise 7.5": [[9, "Exercise-7.5"]], "E8. To be completed after lesson 22": [[10, "E8.-To-be-completed-after-lesson-22"]], "Exercise 8.1": [[10, "Exercise-8.1"]], "Exercise 8.2": [[10, "Exercise-8.2"]], "Exercise 8.3": [[10, "Exercise-8.3"]], "E9. To be completed after lesson 25": [[11, "E9.-To-be-completed-after-lesson-25"]], "Exercise 9.1": [[11, "Exercise-9.1"]], "Exercise 9.2": [[11, "Exercise-9.2"]], "Exercise 9.3": [[11, "Exercise-9.3"]], "Exercise 9.4": [[11, "Exercise-9.4"]], "AWS setup and usage": [[12, "AWS-setup-and-usage"]], "1. Create an Amazon Web Services account": [[12, "1.-Create-an-Amazon-Web-Services-account"]], "2. Launch your instance": [[12, "2.-Launch-your-instance"]], "3. Connect to your instance": [[12, "3.-Connect-to-your-instance"]], "4. Launch JupyterLab": [[12, "4.-Launch-JupyterLab"]], "5. Copying results to and from AWS to your local machine": [[12, "5.-Copying-results-to-and-from-AWS-to-your-local-machine"]], "6. Exiting": [[12, "6.-Exiting"]], "7. Seriously. Stop your instances if you are not using them.": [[12, "7.-Seriously.-Stop-your-instances-if-you-are-not-using-them."]], "8. Using your instance again": [[12, "8.-Using-your-instance-again"]], "9. Terminate your instances after the class is over": [[12, "9.-Terminate-your-instances-after-the-class-is-over"]], "Using Google Colab": [[13, "Using-Google-Colab"]], "Watchouts when using Colab": [[13, "Watchouts-when-using-Colab"]], "Software in Colab": [[13, "Software-in-Colab"]], "A sample calculation": [[13, "A-sample-calculation"]], "Computing environment": [[13, "Computing-environment"], [15, "Computing-environment"], [27, "Computing-environment"], [28, "Computing-environment"], [29, "Computing-environment"], [31, "Computing-environment"], [32, "Computing-environment"], [33, "Computing-environment"], [42, "Computing-environment"], [43, "Computing-environment"], [44, "Computing-environment"], [45, "Computing-environment"], [46, "Computing-environment"], [48, "Computing-environment"], [49, "Computing-environment"], [50, "Computing-environment"], [52, "Computing-environment"], [53, "Computing-environment"], [55, "Computing-environment"], [57, "Computing-environment"], [60, "Computing-environment"], [65, "Computing-environment"], [66, "Computing-environment"], [67, "Computing-environment"], [68, "Computing-environment"], [69, "Computing-environment"], [71, "Computing-environment"], [72, "Computing-environment"], [86, "Computing-environment"]], "0. Setting up computing resources": [[14, "setting-up-computing-resources"]], "Configuring your machine": [[15, "Configuring-your-machine"]], "Installing Python packages": [[15, "Installing-Python-packages"]], "Stan installation": [[15, "Stan-installation"]], "Configuring a C++ toolchain for MacOS": [[15, "Configuring-a-C++-toolchain-for-MacOS"]], "Configuring a C++ toolchain for Windows": [[15, "Configuring-a-C++-toolchain-for-Windows"]], "Configuring a C++ toolchain for Linux": [[15, "Configuring-a-C++-toolchain-for-Linux"]], "Installing Stan with CmdStanPy": [[15, "Installing-Stan-with-CmdStanPy"]], "Checking your Stan installation": [[15, "Checking-your-Stan-installation"]], "Probability as the logic of science": [[16, "probability-as-the-logic-of-science"]], "What is statistical inference?": [[16, "what-is-statistical-inference"]], "The problem of probability": [[16, "the-problem-of-probability"]], "Frequentist probability.": [[16, "frequentist-probability"]], "Bayesian probability.": [[16, "bayesian-probability"]], "Desiderata for Bayesian probability": [[16, "desiderata-for-bayesian-probability"]], "The sum rule, the product rule, and conditional probability": [[16, "the-sum-rule-the-product-rule-and-conditional-probability"]], "Application to scientific measurement": [[16, "application-to-scientific-measurement"]], "Bayes\u2019s Theorem": [[16, "bayess-theorem"]], "The prior probability.": [[16, "the-prior-probability"]], "The likelihood.": [[16, "the-likelihood"]], "The evidence.": [[16, "the-evidence"]], "The posterior probability.": [[16, "the-posterior-probability"]], "Bayes\u2019s theorem as a model for learning": [[17, "bayes-s-theorem-as-a-model-for-learning"]], "Notation of parts of Bayes\u2019s Theorem": [[18, "notation-of-parts-of-bayess-theorem"]], "1. Probability and the logic of scientific reasoning": [[19, "probability-and-the-logic-of-scientific-reasoning"]], "Marginalization": [[20, "marginalization"]], "Probability distributions": [[21, "probability-distributions"]], "Joint and conditional distributions and Bayes\u2019s theorem for PDFs": [[21, "joint-and-conditional-distributions-and-bayess-theorem-for-pdfs"]], "Change of variables formula for continuous distributions": [[21, "change-of-variables-formula-for-continuous-distributions"]], "Generalization to multiple dimensions": [[21, "generalization-to-multiple-dimensions"]], "An example of change of variables": [[21, "an-example-of-change-of-variables"]], "Another example of change of variables: the Log-Normal distribution": [[21, "another-example-of-change-of-variables-the-log-normal-distribution"]], "Bayesian modeling example: parameter estimation from repeated measurements": [[22, "bayesian-modeling-example-parameter-estimation-from-repeated-measurements"]], "The likelihood": [[22, "the-likelihood"], [49, "The-likelihood"]], "The Normal distribution": [[22, "the-normal-distribution"]], "The likelihood revisited: and another parameter": [[22, "the-likelihood-revisited-and-another-parameter"]], "Choice of prior": [[22, "choice-of-prior"]], "Succinctly stating the model": [[22, "succinctly-stating-the-model"]], "Tasks of Bayesian modeling": [[23, "tasks-of-bayesian-modeling"]], "Model building": [[23, "model-building"]], "The role of the prior": [[23, "the-role-of-the-prior"]], "Making sense of the posterior": [[23, "making-sense-of-the-posterior"]], "Choosing likelihoods": [[24, "choosing-likelihoods"]], "Choosing priors": [[25, "choosing-priors"]], "Uniform priors": [[25, "uniform-priors"]], "Jeffreys priors": [[25, "jeffreys-priors"]], "Example Jeffreys priors": [[25, "example-jeffreys-priors"]], "Why not use Jeffreys priors?": [[25, "why-not-use-jeffreys-priors"]], "Weakly informative priors": [[25, "weakly-informative-priors"]], "Conjugate priors": [[25, "conjugate-priors"]], "The bet-the-farm method of specifying weakly informative priors": [[25, "the-bet-the-farm-method-of-specifying-weakly-informative-priors"]], "2. Introduction to Bayesian modeling": [[26, "introduction-to-bayesian-modeling"]], "3. Plotting posteriors": [[27, "3.-Plotting-posteriors"]], "The data set": [[27, "The-data-set"], [42, "The-data-set"], [49, "The-data-set"], [52, "The-data-set"]], "Models for spindle size": [[27, "Models-for-spindle-size"]], "Plotting the posterior for a single parameter": [[27, "Plotting-the-posterior-for-a-single-parameter"]], "Analytically marginalizing": [[27, "Analytically-marginalizing"]], "Computing and plotting the marginalized posterior": [[27, "Computing-and-plotting-the-marginalized-posterior"]], "Normalizing by numerical quadrature": [[27, "Normalizing-by-numerical-quadrature"]], "A prescription for plotting 1D posteriors": [[27, "A-prescription-for-plotting-1D-posteriors"]], "An analytical expression for the marginal posterior": [[27, "An-analytical-expression-for-the-marginal-posterior"]], "Plotting a 2D posterior": [[27, "Plotting-a-2D-posterior"]], "Aside: Speed of likelihood calculation": [[27, "Aside:-Speed-of-likelihood-calculation"]], "Computing the log of a 2D posterior": [[27, "Computing-the-log-of-a-2D-posterior"]], "4. Marginalization by numerical quadrature": [[28, "4.-Marginalization-by-numerical-quadrature"]], "The tubulin conservation model": [[28, "The-tubulin-conservation-model"], [33, "The-tubulin-conservation-model"], [50, "The-tubulin-conservation-model"]], "Analytical marginalization": [[28, "Analytical-marginalization"]], "Numerical marginalization": [[28, "Numerical-marginalization"]], "The curse of dimensionality and overcoming it": [[28, "The-curse-of-dimensionality-and-overcoming-it"]], "5. Conjugacy": [[29, "5.-Conjugacy"]], "The Beta-Binomial conjugate pair": [[29, "The-Beta-Binomial-conjugate-pair"]], "Finding the conjugate": [[29, "Finding-the-conjugate"]], "Plots of the posteriors": [[29, "Plots-of-the-posteriors"]], "Comments on conjugates": [[29, "Comments-on-conjugates"]], "6. Parameter estimation by optimization": [[30, "parameter-estimation-by-optimization"]], "Parameter estimation by optimization case study: Normal likelihood": [[31, "Parameter-estimation-by-optimization-case-study:-Normal-likelihood"]], "Exploratory data analysis": [[31, "Exploratory-data-analysis"]], "Independent size model": [[31, "Independent-size-model"]], "Estimation of the MAP parameters": [[31, "Estimation-of-the-MAP-parameters"]], "Normal approximation of the posterior": [[31, "Normal-approximation-of-the-posterior"]], "Credible intervals": [[31, "Credible-intervals"], [32, "Credible-intervals"]], "How good is the approximation?": [[31, "How-good-is-the-approximation?"]], "Bayesian approach to parameter estimation by optimization": [[32, "Bayesian-approach-to-parameter-estimation-by-optimization"]], "Summarizing the posterior near its maximum": [[32, "Summarizing-the-posterior-near-its-maximum"]], "Demonstration of the Normal approximation": [[32, "Demonstration-of-the-Normal-approximation"]], "Credible intervals may be skewed": [[32, "Credible-intervals-may-be-skewed"]], "Why use the MAP for parameter estimation?": [[32, "Why-use-the-MAP-for-parameter-estimation?"]], "Parameter estimation by optimization: A variate-covariate model": [[33, "Parameter-estimation-by-optimization:-A-variate-covariate-model"]], "Parameter estimation": [[33, "Parameter-estimation"]], "Checking the Normal approximation": [[33, "Checking-the-Normal-approximation"]], "Displaying the best fit line": [[33, "Displaying-the-best-fit-line"]], "Further reading on MCMC": [[35, "further-reading-on-mcmc"]], "7. Introduction to Markov chain Monte Carlo": [[36, "introduction-to-markov-chain-monte-carlo"]], "Random number generation": [[37, "random-number-generation"]], "The basic idea behind MCMC": [[37, "the-basic-idea-behind-mcmc"]], "Generating a transition kernel: The Metropolis-Hastings algorithm": [[38, "generating-a-transition-kernel-the-metropolis-hastings-algorithm"]], "The algorithm/kernel": [[38, "the-algorithm-kernel"]], "Detailed balance": [[38, "detailed-balance"]], "Choosing the transition kernel": [[38, "choosing-the-transition-kernel"]], "Warm-up": [[39, "warm-up"]], "Why MCMC?": [[40, "why-mcmc"]], "8. Introduction to MCMC with Stan": [[41, "introduction-to-mcmc-with-stan"]], "Parameter estimation with Markov chain Monte Carlo": [[42, "Parameter-estimation-with-Markov-chain-Monte-Carlo"]], "Stan: Our MCMC engine": [[42, "Stan:-Our-MCMC-engine"]], "ECDFs of mRNA counts": [[42, "ECDFs-of-mRNA-counts"], [65, "ECDFs-of-mRNA-counts"]], "Building a generative model": [[42, "Building-a-generative-model"], [49, "Building-a-generative-model"]], "Priors for burst size and inter-burst time": [[42, "Priors-for-burst-size-and-inter-burst-time"]], "Sampling the posterior": [[42, "Sampling-the-posterior"]], "Plots of the samples": [[42, "Plots-of-the-samples"]], "Marginalizing the posterior": [[42, "Marginalizing-the-posterior"]], "Analysis for all genes": [[42, "Analysis-for-all-genes"]], "Display of \u201cbest fit\u201d": [[42, "Display-of-%22best-fit%22"]], "\u201cHello, world\u201d \u2014Stan": [[43, "%22Hello,-world%22-\u2014Stan"]], "Basics of Stan programs": [[43, "Basics-of-Stan-programs"]], "Say hi, Stan": [[43, "Say-hi,-Stan"]], "Parsing output with ArviZ": [[43, "Parsing-output-with-ArviZ"]], "Direct sampling": [[43, "Direct-sampling"]], "Why are we using that?": [[43, "Why-are-we-using-that?"]], "Displaying your Stan code": [[43, "Displaying-your-Stan-code"]], "Saving samples": [[43, "Saving-samples"]], "Cleaning up the shrapnel": [[43, "Cleaning-up-the-shrapnel"]], "9. Mixture models and label switching with MCMC": [[44, "9.-Mixture-models-and-label-switching-with-MCMC"]], "Mixture models": [[44, "Mixture-models"]], "Coding up a mixture model": [[44, "Coding-up-a-mixture-model"]], "Parsing the output": [[44, "Parsing-the-output"]], "Plotting the samples": [[44, "Plotting-the-samples"]], "Label switching": [[44, "Label-switching"]], "Initializing walkers": [[44, "Initializing-walkers"]], "Conclusions": [[44, "Conclusions"], [63, "Conclusions"], [65, "Conclusions"], [66, "Conclusions"]], "10. Variate-covariate models with MCMC": [[45, "10.-Variate-covariate-models-with-MCMC"]], "Updated generative model": [[45, "Updated-generative-model"]], "Using Stan to sample": [[45, "Using-Stan-to-sample"]], "Display of MCMC samples": [[46, "Display-of-MCMC-samples"]], "Visualization with ArviZ": [[46, "Visualization-with-ArviZ"]], "The model and samples": [[46, "The-model-and-samples"]], "Examining traces": [[46, "Examining-traces"]], "Trace plots": [[46, "Trace-plots"]], "Trace plots with ArviZ": [[46, "Trace-plots-with-ArviZ"]], "Trace plots with bebi103": [[46, "Trace-plots-with-bebi103"]], "Interpetation of trace plots": [[46, "Interpetation-of-trace-plots"]], "Parallel coordinate plots": [[46, "Parallel-coordinate-plots"]], "Parallel coordinate plots with ArviZ": [[46, "Parallel-coordinate-plots-with-ArviZ"]], "Parallel coordinate plots with bebi103": [[46, "Parallel-coordinate-plots-with-bebi103"]], "Intepretation of parallel coordinate plots": [[46, "Intepretation-of-parallel-coordinate-plots"]], "Plots of marginalized distributions": [[46, "Plots-of-marginalized-distributions"]], "Plotting marginalized distributions of one parameter": [[46, "Plotting-marginalized-distributions-of-one-parameter"]], "Plotting marginalized distributions with ArviZ": [[46, "Plotting-marginalized-distributions-with-ArviZ"]], "Plotting marginalized distributions with iqplot": [[46, "Plotting-marginalized-distributions-with-iqplot"]], "Marginal posteriors of two parameters and corner plots": [[46, "Marginal-posteriors-of-two-parameters-and-corner-plots"]], "Pair plots with ArviZ": [[46, "Pair-plots-with-ArviZ"]], "Corner plots with bebi103": [[46, "Corner-plots-with-bebi103"]], "11. Display of MCMC results": [[47, "display-of-mcmc-results"]], "Reporting summaries of the posterior": [[48, "Reporting-summaries-of-the-posterior"]], "Reporting summaries of MCMC samples": [[48, "Reporting-summaries-of-MCMC-samples"]], "Some distributions to sample": [[48, "Some-distributions-to-sample"]], "Summarizing the \u201cMCMC\u201d results with error bars": [[48, "Summarizing-the-%22MCMC%22-results-with-error-bars"]], "Relative merits of each method": [[48, "Relative-merits-of-each-method"]], "How to display the summary in text.": [[48, "How-to-display-the-summary-in-text."]], "12. Model building with prior predictive checks": [[49, "12.-Model-building-with-prior-predictive-checks"]], "Model 1: Spindle size is independent of droplet size": [[49, "Model-1:-Spindle-size-is-independent-of-droplet-size"]], "The prior": [[49, "The-prior"]], "The prior, take 2": [[49, "The-prior,-take-2"]], "Prior predictive checks": [[49, "Prior-predictive-checks"], [49, "id1"]], "The prior, take 3": [[49, "The-prior,-take-3"]], "Prior predictive checks, take 2": [[49, "Prior-predictive-checks,-take-2"]], "Prior predictive checks with Stan": [[49, "Prior-predictive-checks-with-Stan"]], "Model 2: Spindle size dependent on total tubulin concentration": [[49, "Model-2:-Spindle-size-dependent-on-total-tubulin-concentration"]], "Indentifiability of parameters": [[49, "Indentifiability-of-parameters"]], "Limiting behavior": [[49, "Limiting-behavior"]], "Generative model": [[49, "Generative-model"]], "Checking model assumptions": [[49, "Checking-model-assumptions"]], "Is V_\\mathrm{s} / V_0 \\ll 1?": [[49, "Is-V_\\mathrm{s}-/-V_0-\\ll-1?"]], "Do all spindles have the same aspect ratio k?": [[49, "Do-all-spindles-have-the-same-aspect-ratio-k?"]], "13. Posterior predictive checks": [[50, "13.-Posterior-predictive-checks"]], "The independent size model": [[50, "The-independent-size-model"]], "Beware the summary statistic": [[50, "Beware-the-summary-statistic"]], "14. Collector\u2019s box of distributions": [[51, "collector-s-box-of-distributions"]], "Check out the Distribution Explorer": [[51, "check-out-the-distribution-explorer"]], "Choosing distributions": [[51, "choosing-distributions"]], "Starting simple and adding flexibility": [[51, "starting-simple-and-adding-flexibility"]], "Priors for variables with support on the set of positive real numbers": [[51, "priors-for-variables-with-support-on-the-set-of-positive-real-numbers"]], "15. MCMC diagnostics": [[52, "15.-MCMC-diagnostics"]], "The model": [[52, "The-model"]], "Diagnostics for any MCMC sampler": [[52, "Diagnostics-for-any-MCMC-sampler"]], "The Gelman-Rubin R-hat statistic": [[52, "The-Gelman-Rubin-R-hat-statistic"]], "Effective samples size": [[52, "Effective-samples-size"]], "Monte Carlo standard error": [[52, "Monte-Carlo-standard-error"]], "Diagnostics for HMC": [[52, "Diagnostics-for-HMC"]], "Divergences": [[52, "Divergences"]], "Tree depth": [[52, "Tree-depth"]], "E-BFMI": [[52, "E-BFMI"]], "Quickly checking the diagnostics": [[52, "Quickly-checking-the-diagnostics"]], "16. A diagnostics case study: Artificial funnel of hell": [[53, "16.-A-diagnostics-case-study:-Artificial-funnel-of-hell"]], "Sampling out of the funnel": [[53, "Sampling-out-of-the-funnel"]], "Conquering the Funnel of Hell": [[53, "Conquering-the-Funnel-of-Hell"]], "Adjusting adapt_delta": [[53, "Adjusting-adapt_delta"]], "Noncentering": [[53, "Noncentering"], [69, "Noncentering"]], "Hierarchical models feature a Funnel of Hell": [[53, "Hierarchical-models-feature-a-Funnel-of-Hell"]], "17. Model comparison": [[54, "model-comparison"]], "Metrics for model assessment": [[54, "metrics-for-model-assessment"]], "Posterior predictive checks": [[54, "posterior-predictive-checks"]], "Closeness metrics": [[54, "closeness-metrics"]], "Entropy and the Kullback-Leibler divergence": [[54, "entropy-and-the-kullback-leibler-divergence"]], "The expected log pointwise predictive density": [[54, "the-expected-log-pointwise-predictive-density"]], "The Watanabe-Akaike information criterion": [[54, "the-watanabe-akaike-information-criterion"]], "Leave-one-out estimates of elpd": [[54, "leave-one-out-estimates-of-elpd"]], "The Akaike weights": [[54, "the-akaike-weights"]], "Example model selection: regression": [[55, "Example-model-selection:-regression"]], "18. Model comparison in practice": [[56, "model-comparison-in-practice"]], "Model comparison in practice": [[57, "Model-comparison-in-practice"]], "An example model comparison": [[57, "An-example-model-comparison"]], "Computing the pointwise log likelihood": [[57, "Computing-the-pointwise-log-likelihood"]], "Computing the WAIC and LOO": [[57, "Computing-the-WAIC-and-LOO"]], "Calculations with the mixture model": [[57, "Calculations-with-the-mixture-model"]], "Computing the weights": [[57, "Computing-the-weights"]], "Choosing a hierarchical prior": [[58, "Choosing-a-hierarchical-prior"]], "Exchangeability": [[58, "Exchangeability"]], "Choice of the conditional distribution": [[58, "Choice-of-the-conditional-distribution"]], "Generalization of hierarchical models": [[59, "Generalization-of-hierarchical-models"]], "Implementation of a hierarchical model": [[60, "Implementation-of-a-hierarchical-model"]], "19. Hierarchical models": [[61, "hierarchical-models"]], "Modeling repeated experiments": [[62, "Modeling-repeated-experiments"]], "A model for reversals": [[62, "A-model-for-reversals"]], "Pooled data: identical parameters": [[62, "Pooled-data:-identical-parameters"]], "Independent parameters": [[62, "Independent-parameters"]], "The best of both worlds: A hierarchical model": [[62, "The-best-of-both-worlds:-A-hierarchical-model"]], "20. Implementation of hierarchical models": [[63, "20.-Implementation-of-hierarchical-models"]], "Hierarchical model structure": [[63, "Hierarchical-model-structure"]], "Coding up the hierarchical model in Stan": [[63, "Coding-up-the-hierarchical-model-in-Stan"]], "A quick aside: generating a data set": [[63, "A-quick-aside:-generating-a-data-set"]], "Generating input data for Stan": [[63, "Generating-input-data-for-Stan"]], "Drawing samples and checking diagnostics": [[63, "Drawing-samples-and-checking-diagnostics"]], "A noncentered parametrization": [[63, "A-noncentered-parametrization"]], "21. Principled analysis pipelines": [[64, "21.-Principled-analysis-pipelines"]], "Building a workflow": [[64, "Building-a-workflow"]], "References and terminology": [[64, "References-and-terminology"]], "Simulation-based calibration": [[64, "Simulation-based-calibration"]], "Diagnostics": [[64, "Diagnostics"]], "z-score": [[64, "z-score"]], "Shrinkage": [[64, "Shrinkage"]], "Shrinkage vs. z-score plot": [[64, "Shrinkage-vs.-z-score-plot"]], "Rank statistics": [[64, "Rank-statistics"]], "A rank statistic ECDF plot": [[64, "A-rank-statistic-ECDF-plot"]], "Rank statistic histograms": [[64, "Rank-statistic-histograms"]], "A full principled pipeline": [[64, "A-full-principled-pipeline"]], "22: Simulation based calibration and related checks in practice": [[65, "22:-Simulation-based-calibration-and-related-checks-in-practice"]], "The generative model": [[65, "The-generative-model"]], "Performing SBC": [[65, "Performing-SBC"]], "An adjusted prior": [[65, "An-adjusted-prior"]], "Sampling with our new model": [[65, "Sampling-with-our-new-model"]], "23. Introduction to Gaussian processes": [[66, "23.-Introduction-to-Gaussian-processes"]], "Predicting using posterior estimates": [[66, "Predicting-using-posterior-estimates"]], "An example data set": [[66, "An-example-data-set"]], "Processes and nonparametric Bayesian inference": [[66, "Processes-and-nonparametric-Bayesian-inference"]], "Gaussian processes with a finite number of points": [[66, "Gaussian-processes-with-a-finite-number-of-points"]], "The mean function and centering and scaling": [[66, "The-mean-function-and-centering-and-scaling"]], "The kernel and covariance matrix": [[66, "The-kernel-and-covariance-matrix"]], "Sampling out of a Gaussian process prior": [[66, "Sampling-out-of-a-Gaussian-process-prior"]], "Sampling out of a GP prior using Stan": [[66, "Sampling-out-of-a-GP-prior-using-Stan"]], "Sampling out of a GP prior using Numpy": [[66, "Sampling-out-of-a-GP-prior-using-Numpy"]], "Composing kernels": [[66, "Composing-kernels"]], "Inference with GPs": [[66, "Inference-with-GPs"]], "Normal likelihoods with Gaussian process priors": [[66, "Normal-likelihoods-with-Gaussian-process-priors"]], "The posterior predictive distribution of function values": [[66, "The-posterior-predictive-distribution-of-function-values"]], "Computing the parameters of the posterior predictive distribution": [[66, "Computing-the-parameters-of-the-posterior-predictive-distribution"]], "Plotting an analytical posterior": [[66, "Plotting-an-analytical-posterior"]], "Gaussian process hyperparameters by optimization": [[67, "Gaussian-process-hyperparameters-by-optimization"]], "Priors for hyperparameters": [[67, "Priors-for-hyperparameters"]], "Computing the MAP with SciPy": [[67, "Computing-the-MAP-with-SciPy"]], "Posterior predictive samples": [[67, "Posterior-predictive-samples"]], "Obtaining hyperpriors by optimizing with Stan": [[67, "Obtaining-hyperpriors-by-optimizing-with-Stan"]], "Calculating derivatives from data with GPs": [[68, "Calculating-derivatives-from-data-with-GPs"]], "Derivatives of GPs": [[68, "Derivatives-of-GPs"]], "Derivative of the squared exponential kernel": [[68, "Derivative-of-the-squared-exponential-kernel"]], "Derivatives of the Mat\u00e9rn kernel": [[68, "Derivatives-of-the-Mat\u00e9rn-kernel"]], "Expressions for the gradient and covariance of the gradient": [[68, "Expressions-for-the-gradient-and-covariance-of-the-gradient"]], "Derivatives of GPs in practice using optimization": [[68, "Derivatives-of-GPs-in-practice-using-optimization"]], "Derivatives with a Mat\u00e9rn kernel": [[68, "Derivatives-with-a-Mat\u00e9rn-kernel"]], "Sampling derivatives with Stan": [[68, "Sampling-derivatives-with-Stan"]], "Gaussian processes with non-Normal likelihoods": [[69, "Gaussian-processes-with-non-Normal-likelihoods"]], "Generating samples of latent variables using MCMC": [[69, "Generating-samples-of-latent-variables-using-MCMC"]], "A GP generative model": [[69, "A-GP-generative-model"]], "Sampling latent variables with Stan": [[69, "Sampling-latent-variables-with-Stan"]], "Sampling with a Poisson likelihood": [[69, "Sampling-with-a-Poisson-likelihood"]], "24. Implementation of Gaussian processes": [[70, "implementation-of-gaussian-processes"]], "MCMC with GPs with Normal likelihoods": [[71, "MCMC-with-GPs-with-Normal-likelihoods"]], "Hyperparameter estimation using MCMC": [[71, "Hyperparameter-estimation-using-MCMC"]], "Posterior predictive checks with GPs": [[71, "Posterior-predictive-checks-with-GPs"]], "Aside: Stan include files": [[71, "Aside:-Stan-include-files"]], "25. Variational Bayesian inference": [[72, "25.-Variational-Bayesian-inference"]], "The main ideas of variational inference": [[72, "The-main-ideas-of-variational-inference"]], "Choosing Q(\u03b8)": [[72, "Choosing-Q(\u03b8)"]], "Summary of VI algorithm": [[72, "Summary-of-VI-algorithm"]], "Automatic Differentiation Variational Inference and Stan": [[72, "Automatic-Differentiation-Variational-Inference-and-Stan"]], "Examples": [[72, "Examples"]], "Example 1: Spindle size as a function of volume": [[72, "Example-1:-Spindle-size-as-a-function-of-volume"]], "Example 2: A multilevel hierarchical model": [[72, "Example-2:-A-multilevel-hierarchical-model"]], "26: Wrap-up": [[73, "wrap-up"]], "Model 1": [[74, "Model-1"], [74, "id1"]], "Model 2": [[74, "Model-2"], [74, "id2"]], "Model 3": [[74, "Model-3"], [74, "id3"]], "They all give the same data!": [[74, "They-all-give-the-same-data!"]], "Conditional distributions": [[74, "Conditional-distributions"]], "Model 0": [[74, "Model-0"]], "Interventional distribution": [[74, "Interventional-distribution"]], "More complex example": [[74, "More-complex-example"]], "Meetings": [[75, "meetings"]], "Lab sessions": [[75, "lab-sessions"]], "Submission of assignments": [[75, "submission-of-assignments"]], "Lessons and lesson exercises": [[75, "lessons-and-lesson-exercises"]], "Grading": [[75, "grading"]], "Collaboration policy and Honor Code": [[75, "collaboration-policy-and-honor-code"]], "Course communications": [[75, "course-communications"]], "\u201cEdiquette\u201d": [[75, "ediquette"]], "R1: Review of probability": [[76, "r1-review-of-probability"]], "R2: Choosing priors and review of optimization": [[77, "r2-choosing-priors-and-review-of-optimization"], [78, "r2-choosing-priors-and-review-of-optimization"]], "R3: Just homework help": [[79, "r3-just-homework-help"]], "More details on Hamiltonian Monte Carlo": [[80, "More-details-on-Hamiltonian-Monte-Carlo"]], "The typical set": [[80, "The-typical-set"]], "Hamiltonians": [[80, "Hamiltonians"]], "Hamiltonian Monte Carlo": [[80, "Hamiltonian-Monte-Carlo"]], "Transition using HMC": [[80, "Transition-using-HMC"]], "Choosing Kinetic Energy (Euclidean-Gaussian)": [[80, "Choosing-Kinetic-Energy-(Euclidean-Gaussian)"]], "A short note on integration times": [[80, "A-short-note-on-integration-times"]], "Numerical integration and what happens in divergences": [[80, "Numerical-integration-and-what-happens-in-divergences"]], "Computing Environment": [[80, "Computing-Environment"]], "R4. Introduction to Hamiltonian Monte Carlo": [[81, "r4-introduction-to-hamiltonian-monte-carlo"]], "Overview of Hamiltonian Monte Carlo": [[82, "Overview-of-Hamiltonian-Monte-Carlo"]], "Notation": [[82, "Notation"]], "Motivating interest:": [[82, "Motivating-interest:"]], "Features of a high-dimensional space Q:": [[82, "Features-of-a-high-dimensional-space-Q:"]], "But the question then remains: how do we design an algorithm to sample the typical set?": [[82, "But-the-question-then-remains:-how-do-we-design-an-algorithm-to-sample-the-typical-set?"]], "So this all leads us to \u2026 \ud83c\udf89 Hamiltonian Monte Carlo! \ud83c\udf89": [[82, "So-this-all-leads-us-to-...-\ud83c\udf89-Hamiltonian-Monte-Carlo!-\ud83c\udf89"]], "The Ideal Hamiltonian Markov Transition": [[82, "The-Ideal-Hamiltonian-Markov-Transition"]], "Actual Implementation of Hamiltonian Markov Transition Considerations": [[82, "Actual-Implementation-of-Hamiltonian-Markov-Transition-Considerations"]], "(A) Optimizing Choice of Kinetic Energy K(q, p)": [[82, "(A)-Optimizing-Choice-of-Kinetic-Energy-K(q,-p)"]], "(B) Integration method": [[82, "(B)-Integration-method"]], "(C) Integration time": [[82, "(C)-Integration-time"]], "Concluding thoughts": [[82, "Concluding-thoughts"]], "R5: Bayesian model building": [[83, "R5:-Bayesian-model-building"]], "R6: MCMC using Caltech\u2019s HPC": [[84, "R6:-MCMC-using-Caltech's-HPC"], [85, "r6-mcmc-using-caltech-s-hpc"]], "What even is a supercomputer?": [[84, "What-even-is-a-supercomputer?"]], "How to use the Caltech HPCC?": [[84, "How-to-use-the-Caltech-HPCC?"]], "Obtaining access": [[84, "Obtaining-access"]], "Logging on": [[84, "Logging-on"]], "SLURM": [[84, "SLURM"]], "Transferring files": [[84, "Transferring-files"]], "Storage": [[84, "Storage"]], "Software": [[84, "Software"], [89, "software"]], "Support": [[84, "Support"]], "Pro-Tip for writing code on the HPCC": [[84, "Pro-Tip-for-writing-code-on-the-HPCC"]], "Concurrency with Python": [[84, "Concurrency-with-Python"]], "Independent processes": [[84, "Independent-processes"]], "Pooling between processes": [[84, "Pooling-between-processes"]], "Sharing state between processes": [[84, "Sharing-state-between-processes"]], "Communicating between processes": [[84, "Communicating-between-processes"]], "Running Stan on the HPCC": [[84, "Running-Stan-on-the-HPCC"]], "Foreword": [[84, "Foreword"]], "R7: Sampling discrete parameters with Stan": [[86, "R7:-Sampling-discrete-parameters-with-Stan"]], "Review of LogSumExp, the cornerstone of stable marginalization with discrete parameters": [[86, "Review-of-LogSumExp,-the-cornerstone-of-stable-marginalization-with-discrete-parameters"]], "Handling log probabilities of discrete valued vectors in Stan": [[86, "Handling-log-probabilities-of-discrete-valued-vectors-in-Stan"]], "Discrete paremeters in Stan: integer \u03b1 for gamma distribution": [[86, "Discrete-paremeters-in-Stan:-integer-\u03b1-for-gamma-distribution"]], "Take two: handling discrete parameters via marginalization": [[86, "Take-two:-handling-discrete-parameters-via-marginalization"]], "R8: Discussion of HW 10 project proposals": [[87, "r8-discussion-of-hw-10-project-proposals"]], "R9: Just homework help": [[88, "r9-just-homework-help"]], "Reading/tutorials": [[89, "reading-tutorials"]], "Schedule overview": [[90, "schedule-overview"]], "Homework due dates": [[90, "homework-due-dates"]], "Lesson exercise due dates": [[90, "lesson-exercise-due-dates"]], "Weekly schedule": [[90, "weekly-schedule"]]}, "indexentries": {}})