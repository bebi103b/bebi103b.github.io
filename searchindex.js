Search.setIndex({"docnames": ["homework/01/Untitled", "homework/01/hw1.1", "homework/01/index", "homework/02/hw2.1", "homework/02/hw2.2", "homework/02/index", "homework/03/hw3.1", "homework/03/hw3.2", "homework/03/index", "index", "lesson_exercises/exercise_01", "lesson_exercises/exercise_02", "lesson_exercises/exercise_03", "lesson_exercises/exercise_04", "lesson_exercises/exercise_05", "lesson_exercises/exercise_06", "lesson_exercises/exercise_07", "lesson_exercises/exercise_08", "lesson_exercises/exercise_09", "lessons/00/aws_setup", "lessons/00/colab", "lessons/00/index", "lessons/00/setup", "lessons/01/bayes_logic", "lessons/01/bayes_model_for_learning", "lessons/01/bayes_notation", "lessons/01/index", "lessons/01/marginalization", "lessons/01/probability_distributions", "lessons/02/bayesian_modeling_example", "lessons/02/bayesian_modeling_tasks", "lessons/02/choice_of_likelihood", "lessons/02/choice_of_prior", "lessons/02/index", "lessons/03/plotting_posteriors", "lessons/04/marginalization_by_numerical_quadrature", "lessons/05/conjugacy", "lessons/06/index", "lessons/06/normal_optimization", "lessons/06/optimization_basics", "lessons/06/variate_covariate_optimization", "lessons/07/Untitled", "lessons/07/further_reading", "lessons/07/index", "lessons/07/mcmc_idea", "lessons/07/metropolis_hastings", "lessons/07/warm_up", "lessons/07/why_mcmc", "lessons/08/index", "lessons/08/parameter_estimation_with_mcmc", "lessons/08/stan_hello_world", "lessons/09/mixture_model_stan", "lessons/10/variate_covariate_with_stan", "lessons/11/display_of_mcmc_samples", "lessons/11/index", "lessons/11/posterior_summaries", "lessons/12/prior_predictive_checks", "lessons/13/posterior_predictive_checks", "lessons/14/box_of_distributions", "lessons/15/mcmc_diagnostics", "lessons/16/funnel_of_hell", "lessons/17/model_comparison", "lessons/18/comparing_regressions", "lessons/18/index", "lessons/18/model_comparison", "lessons/19/choosing_a_hierarchical_prior", "lessons/19/generalization", "lessons/19/implementation", "lessons/19/index", "lessons/19/modeling_repeated_experiments", "lessons/20/hierarchical_implementation", "lessons/21/sbc", "lessons/22/sbc_in_practice", "lessons/23/intro_to_gps", "lessons/24/gp_hyperparams_by_optimization", "lessons/24/gps_and_derivatives", "lessons/24/gps_without_marginalization", "lessons/24/index", "lessons/24/mcmc_with_gps", "lessons/25/variational_inference", "lessons/26/wrapup", "policies", "recitations/01/probability_review", "recitations/02/choosing_priors", "recitations/02/index", "recitations/03/just_hw_help", "recitations/04/hmc", "recitations/04/index", "recitations/04/overview", "recitations/05/practice_model_building", "recitations/06/HPC", "recitations/06/intro_to_hpc", "recitations/07/sampling_discrete_parameters", "recitations/08/project_proposals", "recitations/09/just_hw_help", "resources", "schedule"], "filenames": ["homework/01/Untitled.ipynb", "homework/01/hw1.1.ipynb", "homework/01/index.rst", "homework/02/hw2.1.ipynb", "homework/02/hw2.2.ipynb", "homework/02/index.rst", "homework/03/hw3.1.ipynb", "homework/03/hw3.2.ipynb", "homework/03/index.rst", "index.rst", "lesson_exercises/exercise_01.ipynb", "lesson_exercises/exercise_02.ipynb", "lesson_exercises/exercise_03.ipynb", "lesson_exercises/exercise_04.ipynb", "lesson_exercises/exercise_05.ipynb", "lesson_exercises/exercise_06.ipynb", "lesson_exercises/exercise_07.ipynb", "lesson_exercises/exercise_08.ipynb", "lesson_exercises/exercise_09.ipynb", "lessons/00/aws_setup.ipynb", "lessons/00/colab.ipynb", "lessons/00/index.rst", "lessons/00/setup.ipynb", "lessons/01/bayes_logic.rst", "lessons/01/bayes_model_for_learning.rst", "lessons/01/bayes_notation.rst", "lessons/01/index.rst", "lessons/01/marginalization.rst", "lessons/01/probability_distributions.rst", "lessons/02/bayesian_modeling_example.rst", "lessons/02/bayesian_modeling_tasks.rst", "lessons/02/choice_of_likelihood.rst", "lessons/02/choice_of_prior.rst", "lessons/02/index.rst", "lessons/03/plotting_posteriors.ipynb", "lessons/04/marginalization_by_numerical_quadrature.ipynb", "lessons/05/conjugacy.ipynb", "lessons/06/index.rst", "lessons/06/normal_optimization.ipynb", "lessons/06/optimization_basics.ipynb", "lessons/06/variate_covariate_optimization.ipynb", "lessons/07/Untitled.ipynb", "lessons/07/further_reading.rst", "lessons/07/index.rst", "lessons/07/mcmc_idea.rst", "lessons/07/metropolis_hastings.rst", "lessons/07/warm_up.rst", "lessons/07/why_mcmc.rst", "lessons/08/index.rst", "lessons/08/parameter_estimation_with_mcmc.ipynb", "lessons/08/stan_hello_world.ipynb", "lessons/09/mixture_model_stan.ipynb", "lessons/10/variate_covariate_with_stan.ipynb", "lessons/11/display_of_mcmc_samples.ipynb", "lessons/11/index.rst", "lessons/11/posterior_summaries.ipynb", "lessons/12/prior_predictive_checks.ipynb", "lessons/13/posterior_predictive_checks.ipynb", "lessons/14/box_of_distributions.rst", "lessons/15/mcmc_diagnostics.ipynb", "lessons/16/funnel_of_hell.ipynb", "lessons/17/model_comparison.rst", "lessons/18/comparing_regressions.ipynb", "lessons/18/index.rst", "lessons/18/model_comparison.ipynb", "lessons/19/choosing_a_hierarchical_prior.ipynb", "lessons/19/generalization.ipynb", "lessons/19/implementation.ipynb", "lessons/19/index.rst", "lessons/19/modeling_repeated_experiments.ipynb", "lessons/20/hierarchical_implementation.ipynb", "lessons/21/sbc.ipynb", "lessons/22/sbc_in_practice.ipynb", "lessons/23/intro_to_gps.ipynb", "lessons/24/gp_hyperparams_by_optimization.ipynb", "lessons/24/gps_and_derivatives.ipynb", "lessons/24/gps_without_marginalization.ipynb", "lessons/24/index.rst", "lessons/24/mcmc_with_gps.ipynb", "lessons/25/variational_inference.ipynb", "lessons/26/wrapup.rst", "policies.rst", "recitations/01/probability_review.rst", "recitations/02/choosing_priors.rst", "recitations/02/index.rst", "recitations/03/just_hw_help.rst", "recitations/04/hmc.ipynb", "recitations/04/index.rst", "recitations/04/overview.ipynb", "recitations/05/practice_model_building.ipynb", "recitations/06/HPC.ipynb", "recitations/06/intro_to_hpc.rst", "recitations/07/sampling_discrete_parameters.ipynb", "recitations/08/project_proposals.rst", "recitations/09/just_hw_help.rst", "resources.rst", "schedule.rst"], "titles": ["&lt;no title&gt;", "Homework 1.1: First attempts at Bayesian generative modeling (70 pts)", "1. Intuitive generative modeling", "Homework 2.1: Overwhelming a prior (45 pts)", "Homework 2.2: Exponential conjugate prior (55 pts)", "2. Analytical and graphical methods for analysis of the posterior", "Homework 3.1: Least squares (20 pts)", "Homework 3.2: MAP estimates and zero-inflation for Drop-Seq controls (80 pts)", "3. Maximum a posteriori parameter estimation", "BE/Bi 103 b: Statistical Inference in the Biological Sciences", "E1. To be completed after lesson 5", "E2. To be completed after lesson 6", "E3. To be completed after lesson 10", "E4. To be completed after lesson 13", "E5. To be completed after lesson 16", "E6. To be completed after lesson 18", "E7. To be completed after lesson 20", "E8. To be completed after lesson 22", "E9. To be completed after lesson 25", "AWS setup and usage", "Using Google Colab", "0. Setting up computing resources", "Configuring your machine", "Probability as the logic of science", "Bayes\u2019s theorem as a model for learning", "Notation of parts of Bayes\u2019s Theorem", "1. Probability and the logic of scientific reasoning", "Marginalization", "Probability distributions", "Bayesian modeling example: parameter estimation from repeated measurements", "Tasks of Bayesian modeling", "Choosing likelihoods", "Choosing priors", "2. Introduction to Bayesian modeling", "3. Plotting posteriors", "4. Marginalization by numerical quadrature", "5. Conjugacy", "6. Parameter estimation by optimization", "Parameter estimation by optimization case study: Normal likelihood", "Bayesian approach to parameter estimation by optimization", "Parameter estimation by optimization: A variate-covariate model", "&lt;no title&gt;", "Further reading on MCMC", "7. Introduction to Markov chain Monte Carlo", "Random number generation", "Generating a transition kernel: The Metropolis-Hastings algorithm", "Warm-up", "Why MCMC?", "8. Introduction to MCMC with Stan", "Parameter estimation with Markov chain Monte Carlo", "\u201cHello, world\u201d \u2014Stan", "9. Mixture models and label switching with MCMC", "10. Variate-covariate models with MCMC", "Display of MCMC samples", "11. Display of MCMC results", "Reporting summaries of the posterior", "12. Model building with prior predictive checks", "13. Posterior predictive checks", "14. Collector\u2019s box of distributions", "15. MCMC diagnostics", "16. A diagnostics case study: Artificial funnel of hell", "17. Model comparison", "Example model selection: regression", "18. Model comparison in practice", "Model comparison in practice", "Choosing a hierarchical prior", "Generalization of hierarchical models", "Implementation of a hierarchical model", "19. Hierarchical models", "Modeling repeated experiments", "20. Implementation of hierarchical models", "21. Principled analysis pipelines", "22: Simulation based calibration and related checks in practice", "23. Introduction to Gaussian processes", "Gaussian process hyperparameters by optimization", "Calculating derivatives from data with GPs", "Gaussian processes with non-Normal likelihoods", "24. Implementation of Gaussian processes", "MCMC with GPs with Normal likelihoods", "25. Variational Bayesian inference", "26: Wrap-up", "Meetings", "R1: Review of probability", "R2: Choosing priors and review of optimization", "R2: Choosing priors and review of optimization", "R3: Just homework help", "More details on Hamiltonian Monte Carlo", "R4. Introduction to Hamiltonian Monte Carlo", "Overview of Hamiltonian Monte Carlo", "R5: Bayesian model building", "R6: MCMC using Caltech\u2019s HPC", "R6: MCMC using Caltech\u2019s HPC", "R7: Sampling discrete parameters with Stan", "R8: Discussion of HW 10 project proposals", "R9: Just homework help", "Software", "Schedule overview"], "terms": {"begin": [0, 3, 6, 7, 19, 23, 24, 25, 27, 28, 29, 30, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 86, 88, 90, 92], "align": [0, 3, 6, 7, 23, 24, 25, 27, 28, 29, 30, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 86, 88, 90, 92], "rho": [0, 58, 73, 74, 75, 76, 78], "sim": [0, 3, 6, 7, 29, 32, 34, 35, 36, 38, 40, 49, 51, 52, 53, 56, 57, 58, 59, 60, 62, 65, 67, 69, 70, 72, 73, 74, 75, 76, 78, 79, 88, 90, 92], "text": [0, 3, 7, 22, 23, 28, 29, 32, 34, 35, 36, 38, 40, 46, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67, 69, 70, 72, 73, 74, 75, 76, 78, 79, 81, 86, 90, 92], "norm": [0, 3, 6, 29, 32, 34, 38, 39, 40, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 62, 70, 72, 73, 75, 76, 79, 86], "1": [0, 4, 5, 7, 8, 9, 20, 22, 23, 27, 28, 29, 30, 32, 34, 35, 36, 38, 39, 40, 41, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 82, 86, 88, 89, 90, 92, 96], "050": 0, "0": [0, 1, 7, 9, 19, 20, 22, 32, 34, 35, 36, 38, 39, 40, 41, 44, 45, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 86, 88, 90, 92, 96], "2296": 0, "1em": [0, 3, 29, 32, 34, 35, 36, 38, 40, 45, 49, 51, 52, 53, 56, 57, 59, 60, 62, 64, 65, 67, 69, 70, 72, 73, 74, 75, 76, 78, 79, 88, 90, 92], "v": [0, 20, 22, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 88, 92], "mu_v": 0, "sigma_v": [0, 34], "m": [0, 32, 51, 56, 61, 70, 73, 74, 75, 76, 78, 79, 86, 88, 90, 92, 96], "sigma_m": 0, "ell": [0, 32, 34, 35, 38, 40, 52, 53, 56, 57, 62, 79], "3": [0, 9, 20, 22, 23, 28, 32, 35, 36, 38, 39, 40, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 85, 86, 88, 89, 90, 92, 96], "sigma_": [0, 29, 32, 39, 71, 73], "end": [0, 3, 6, 7, 22, 23, 24, 25, 27, 28, 29, 30, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 90, 92], "import": [0, 3, 4, 7, 12, 13, 16, 20, 22, 23, 28, 29, 31, 34, 35, 36, 38, 39, 40, 41, 44, 45, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 90, 92], "numpi": [0, 3, 20, 22, 34, 35, 36, 38, 39, 40, 41, 44, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 74, 75, 76, 78, 79, 86, 90, 92], "np": [0, 3, 20, 22, 34, 35, 36, 38, 39, 40, 41, 44, 49, 50, 51, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92], "bokeh": [0, 20, 22, 34, 35, 36, 38, 39, 40, 41, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92], "io": [0, 20, 22, 34, 35, 36, 38, 39, 40, 41, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92], "plot": [0, 1, 3, 4, 7, 9, 13, 20, 22, 30, 32, 35, 38, 39, 40, 41, 44, 47, 50, 52, 55, 56, 57, 59, 60, 61, 62, 64, 67, 70, 72, 74, 75, 76, 78, 79, 86, 88, 90, 92, 96], "output_notebook": [0, 20, 22, 34, 35, 36, 38, 39, 40, 41, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92], "load": [0, 3, 19, 20, 22, 34, 35, 36, 38, 39, 40, 41, 44, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92], "bokehj": [0, 20, 22, 34, 35, 36, 38, 39, 40, 41, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 92], "19": [0, 9, 34, 39, 49, 50, 51, 56, 59, 64, 72, 73, 75, 76, 79, 92, 96], "rng": [0, 41, 50, 55, 56, 74, 76, 92], "random": [0, 23, 28, 41, 43, 50, 51, 55, 56, 58, 59, 60, 72, 73, 74, 75, 76, 79, 86, 88, 90, 92], "default_rng": [0, 41, 50, 55, 56, 73, 74, 76, 92], "n": [0, 6, 28, 29, 34, 35, 36, 44, 47, 49, 51, 52, 53, 56, 57, 59, 61, 62, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 86, 88, 89, 90, 92], "50000": 0, "001": [0, 59, 90], "sigma_l": 0, "normal": [0, 3, 6, 7, 11, 20, 22, 30, 31, 32, 35, 36, 37, 44, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 64, 65, 67, 70, 72, 74, 75, 77, 79, 86, 90, 92], "size": [0, 29, 32, 35, 40, 41, 50, 51, 52, 53, 55, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 86, 88, 90, 92], "cbrt": [0, 35, 40, 52, 53, 56, 57, 62, 79], "20": [0, 3, 8, 9, 19, 20, 22, 29, 34, 38, 39, 40, 49, 50, 51, 56, 57, 59, 62, 64, 67, 72, 73, 74, 75, 76, 78, 79, 81, 92, 96], "p": [0, 7, 20, 22, 23, 25, 28, 34, 35, 36, 38, 39, 40, 41, 44, 45, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92], "figur": [0, 20, 22, 23, 28, 34, 35, 36, 38, 39, 40, 41, 49, 52, 53, 56, 60, 70, 72, 73, 74, 75, 76, 79, 86, 88, 92], "frame_width": [0, 20, 22, 34, 35, 36, 38, 39, 40, 41, 49, 51, 52, 53, 55, 56, 67, 72, 73, 74, 75, 76, 79, 86, 92], "200": [0, 3, 34, 35, 36, 38, 39, 40, 41, 49, 51, 52, 53, 55, 56, 57, 62, 72, 73, 79, 92], "frame_height": [0, 20, 22, 34, 35, 36, 38, 39, 40, 41, 49, 51, 52, 53, 55, 56, 72, 73, 74, 75, 76, 79, 86, 92], "x_axis_label": [0, 20, 22, 34, 35, 36, 38, 39, 40, 41, 49, 51, 52, 53, 55, 56, 57, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 79, 86, 92], "mass": [0, 1, 7, 28, 32, 38, 51, 55, 58, 60, 64, 71, 72, 73, 81, 86, 88], "jb": 0, "unit": [0, 20, 29, 32, 38, 49, 50, 52, 56, 61, 70, 73, 76, 88], "y_axis_label": [0, 20, 22, 34, 35, 36, 38, 39, 40, 41, 49, 52, 53, 55, 56, 57, 60, 62, 67, 70, 72, 73, 74, 75, 76, 79, 86, 92], "length": [0, 1, 29, 31, 32, 34, 35, 38, 40, 49, 50, 51, 52, 53, 56, 57, 58, 59, 62, 64, 71, 73, 74, 76, 79, 86, 90], "scatter": [0, 20, 22, 34, 35, 38, 40, 49, 51, 52, 53, 55, 56, 60, 70, 72, 73, 74, 75, 76, 79, 86], "2": [0, 6, 8, 9, 20, 22, 23, 28, 29, 32, 34, 35, 36, 38, 39, 40, 41, 44, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 81, 83, 86, 88, 89, 90, 92, 93, 96], "alpha": [0, 20, 22, 34, 35, 36, 38, 39, 40, 41, 44, 45, 49, 51, 52, 53, 56, 58, 59, 60, 64, 65, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92], "show": [0, 4, 6, 19, 20, 22, 32, 34, 35, 36, 38, 39, 40, 41, 45, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 81, 86, 90, 92], "collard": 1, "cowork": [1, 7, 46, 56, 64, 71, 75, 79], "did": [1, 10, 22, 23, 24, 31, 32, 34, 35, 38, 40, 49, 50, 52, 53, 56, 57, 60, 61, 62, 64, 65, 67, 69, 71, 72, 73, 74, 81, 88, 89, 93], "simpl": [1, 23, 29, 30, 34, 36, 39, 46, 50, 51, 55, 60, 61, 65, 71, 72, 73, 74, 76, 78, 79, 81, 86, 88, 90], "experi": [1, 3, 7, 16, 23, 24, 28, 30, 31, 32, 34, 36, 49, 56, 58, 59, 61, 65, 66, 67, 68, 70, 71, 72, 73, 75, 79, 88, 89, 90, 92], "thei": [1, 3, 6, 23, 29, 32, 34, 36, 38, 39, 40, 49, 50, 51, 52, 53, 56, 59, 60, 61, 64, 70, 71, 73, 75, 76, 79, 81, 86, 88, 89, 90, 92], "collect": [1, 47, 49, 50, 57, 89], "sampl": [1, 12, 14, 15, 19, 22, 28, 30, 35, 40, 44, 45, 46, 47, 54, 56, 57, 61, 62, 64, 65, 66, 67, 71, 78, 79, 86, 90, 96], "carrion": 1, "beetl": 1, "feed": [1, 92], "decai": [1, 34, 56, 72], "anim": [1, 86, 92], "matter": [1, 32, 47, 66, 81], "measur": [1, 3, 6, 7, 25, 28, 30, 31, 32, 33, 34, 35, 38, 49, 50, 56, 57, 58, 59, 61, 62, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 79, 86, 89, 92], "morpholog": 1, "featur": [1, 34, 38, 50, 58, 59, 61, 65, 66, 72, 73, 79, 82, 83, 90, 91, 93], "variou": [1, 7, 30, 44, 50, 53, 55, 73, 75, 90, 92, 95], "speci": [1, 32], "from": [1, 3, 4, 6, 7, 20, 22, 23, 24, 27, 28, 30, 32, 33, 34, 36, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 86, 88, 89, 90, 92], "differ": [1, 3, 19, 20, 23, 32, 34, 38, 39, 49, 51, 55, 56, 57, 60, 61, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 79, 81, 86, 88, 89, 90, 92], "site": [1, 4, 74, 75], "time": [1, 6, 19, 20, 21, 23, 29, 31, 34, 35, 39, 45, 46, 50, 51, 52, 55, 56, 58, 61, 65, 69, 71, 72, 73, 74, 75, 76, 79, 81, 89, 90, 92, 95, 96], "year": [1, 19, 32, 45, 69], "imagin": [1, 6, 28, 46, 49, 58, 60, 61, 66, 69, 72, 73, 75, 86, 88], "you": [1, 3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 29, 30, 31, 32, 34, 36, 38, 39, 40, 42, 44, 45, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 64, 66, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92, 95], "ar": [1, 3, 4, 6, 7, 9, 11, 13, 14, 15, 18, 20, 21, 22, 23, 25, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92], "cabin": 1, "main": [1, 32, 38, 39, 44, 49, 50, 53, 58, 71, 76, 88, 90, 95], "There": [1, 7, 19, 20, 21, 22, 23, 29, 32, 36, 45, 46, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 62, 64, 70, 71, 73, 75, 76, 79, 81, 85, 88, 90, 92, 94, 95], "also": [1, 7, 9, 19, 20, 21, 23, 24, 25, 27, 28, 29, 30, 32, 34, 35, 36, 38, 39, 44, 45, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 89, 90, 92, 95], "plenti": [1, 19, 59, 64], "area": [1, 35, 59, 72, 86, 92], "which": [1, 4, 6, 7, 19, 20, 21, 22, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92], "stai": [1, 51, 86], "so": [1, 3, 16, 19, 20, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 89, 90, 92], "curiou": 1, "look": [1, 4, 7, 19, 32, 34, 36, 38, 39, 40, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 90, 92], "your": [1, 3, 4, 9, 16, 17, 20, 21, 23, 31, 32, 34, 38, 39, 40, 45, 51, 56, 57, 58, 59, 60, 61, 70, 71, 72, 73, 74, 78, 79, 81, 86, 88, 89, 90], "plan": [1, 92], "set": [1, 3, 4, 6, 7, 9, 11, 16, 19, 20, 22, 23, 24, 25, 28, 30, 32, 35, 38, 39, 40, 45, 47, 50, 51, 52, 53, 57, 61, 62, 64, 65, 66, 67, 69, 71, 72, 74, 75, 76, 78, 79, 81, 89, 90, 92], "up": [1, 4, 7, 9, 12, 19, 20, 22, 29, 30, 32, 34, 35, 38, 40, 43, 44, 49, 56, 57, 58, 59, 60, 62, 66, 69, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 90, 92, 96], "trap": 1, "specimen": 1, "given": [1, 7, 19, 23, 25, 28, 29, 30, 32, 34, 36, 39, 44, 47, 49, 51, 56, 59, 61, 64, 67, 69, 70, 73, 74, 75, 76, 78, 79, 80, 81, 86, 88, 89, 92], "For": [1, 3, 7, 19, 20, 23, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 42, 44, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 69, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 90, 92], "each": [1, 3, 4, 7, 10, 15, 19, 20, 23, 29, 34, 35, 36, 38, 39, 44, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 61, 64, 65, 67, 69, 70, 71, 72, 73, 76, 78, 79, 81, 86, 88, 89, 90, 92, 96], "its": [1, 6, 7, 23, 29, 32, 34, 35, 36, 38, 49, 50, 51, 52, 55, 56, 58, 60, 61, 65, 67, 72, 73, 74, 75, 79, 81, 86, 90, 92, 95], "elytra": 1, "As": [1, 3, 7, 19, 20, 22, 23, 28, 29, 30, 32, 34, 35, 36, 39, 44, 45, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 81, 86, 88, 90, 92], "we": [1, 3, 4, 6, 7, 9, 10, 11, 15, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 86, 89, 90, 92], "learn": [1, 9, 21, 23, 26, 30, 36, 38, 39, 49, 50, 51, 53, 56, 57, 59, 61, 69, 70, 71, 73, 74, 75, 90], "class": [1, 3, 9, 20, 22, 25, 35, 45, 58, 73, 79, 81, 86, 90, 92, 95, 96], "prior": [1, 5, 6, 7, 9, 10, 11, 13, 17, 24, 25, 27, 31, 33, 34, 35, 36, 38, 39, 40, 50, 51, 52, 57, 59, 61, 64, 66, 67, 68, 69, 70, 71, 75, 76, 78, 79, 81, 88, 89, 90, 92, 96], "perform": [1, 7, 11, 17, 19, 21, 30, 31, 32, 34, 35, 38, 45, 47, 49, 50, 51, 52, 55, 56, 57, 59, 61, 64, 67, 70, 71, 73, 74, 75, 76, 78, 79, 81, 86, 88, 90, 92], "an": [1, 4, 7, 20, 21, 22, 23, 24, 25, 27, 29, 30, 31, 32, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 65, 67, 69, 70, 71, 74, 75, 76, 79, 81, 86, 89, 90, 92], "i": [1, 3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 82, 85, 86, 88, 89, 92, 94, 95, 96], "us": [1, 3, 4, 7, 11, 12, 13, 14, 15, 16, 18, 21, 22, 23, 25, 27, 28, 29, 30, 31, 34, 35, 36, 38, 40, 44, 45, 46, 47, 49, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 74, 79, 81, 88, 89, 92, 95], "think": [1, 6, 7, 23, 29, 30, 32, 38, 40, 44, 50, 51, 55, 56, 59, 61, 64, 70, 73, 74, 76, 86, 88, 92], "about": [1, 7, 19, 20, 23, 24, 25, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 61, 64, 70, 71, 72, 73, 74, 75, 76, 79, 81, 86, 88, 89, 90, 92, 93, 95], "what": [1, 3, 6, 7, 10, 11, 12, 15, 16, 17, 18, 19, 20, 25, 29, 30, 32, 34, 35, 40, 44, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 64, 70, 71, 72, 73, 74, 75, 79, 81, 88, 89, 92], "kind": [1, 23, 45, 51, 53, 56, 59, 61, 72, 73, 74, 75, 92], "data": [1, 3, 4, 6, 7, 9, 16, 19, 20, 22, 23, 24, 25, 28, 29, 30, 31, 32, 35, 36, 39, 40, 46, 47, 50, 51, 52, 53, 55, 57, 58, 61, 62, 64, 65, 66, 67, 71, 72, 74, 76, 77, 78, 79, 81, 89, 90, 92, 95], "might": [1, 7, 19, 20, 22, 29, 30, 31, 32, 34, 36, 44, 47, 50, 51, 53, 55, 56, 58, 60, 61, 65, 71, 72, 73, 74, 78, 79, 86, 88, 89, 90, 92], "expect": [1, 6, 7, 22, 23, 29, 30, 32, 34, 36, 38, 40, 47, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 64, 70, 71, 72, 73, 76, 79, 81, 86, 88, 92], "observ": [1, 7, 23, 30, 36, 57, 58, 61, 64, 69, 73, 75, 76, 79, 89], "thi": [1, 3, 4, 6, 7, 9, 14, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 89, 90, 92, 95, 96], "involv": [1, 7, 19, 23, 29, 30, 32, 35, 39, 49, 53, 56, 59, 61, 66, 73, 78, 88, 90], "propos": [1, 7, 45, 46, 56, 59, 60, 61, 71, 86, 89], "draw": [1, 32, 44, 49, 50, 51, 55, 56, 57, 59, 60, 61, 62, 64, 67, 71, 72, 73, 74, 75, 76, 78, 79, 86, 92], "befor": [1, 20, 23, 29, 30, 32, 34, 35, 36, 40, 49, 50, 51, 56, 57, 60, 61, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 90, 92, 96], "proceed": [1, 57, 60, 75, 79], "do": [1, 3, 6, 7, 10, 11, 13, 17, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 89, 91, 92], "want": [1, 10, 19, 20, 23, 28, 34, 35, 36, 38, 44, 45, 47, 49, 50, 51, 53, 56, 57, 58, 59, 61, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92], "clarifi": 1, "purpos": [1, 19, 29, 49, 50, 51, 56, 58, 59, 64, 74, 86], "problem": [1, 3, 4, 6, 7, 14, 20, 21, 25, 28, 30, 32, 34, 35, 38, 39, 40, 44, 45, 51, 53, 55, 56, 59, 60, 61, 66, 69, 70, 71, 72, 74, 75, 76, 79, 81, 86, 88, 89, 90, 92], "address": [1, 19, 59, 70, 71, 73, 90], "question": [1, 10, 11, 12, 13, 14, 15, 16, 17, 18, 57, 58, 59, 61, 71, 81], "mai": [1, 4, 6, 7, 11, 12, 13, 14, 15, 19, 20, 21, 22, 23, 25, 28, 29, 30, 32, 38, 44, 47, 49, 50, 51, 55, 56, 57, 58, 59, 60, 61, 64, 65, 69, 70, 71, 73, 74, 76, 78, 79, 81, 88, 89, 92], "my": [1, 10, 22, 23, 28, 29, 32, 38, 45, 53, 55, 72, 79, 86, 88, 90, 92], "formal": [1, 23, 30, 56, 61, 70], "procedur": [1, 6, 31, 32, 35, 40, 56, 57, 61, 71, 72, 75, 79, 92], "build": [1, 3, 9, 31, 32, 50, 52, 58, 72, 73, 75, 78, 81, 92, 96], "The": [1, 3, 4, 6, 7, 19, 20, 21, 22, 25, 28, 31, 38, 39, 43, 50, 51, 52, 55, 58, 60, 62, 64, 65, 66, 67, 70, 71, 74, 75, 76, 78, 80, 81, 89, 90, 92, 95, 96], "concept": [1, 28, 44, 79, 81, 86, 88, 90, 92], "though": [1, 19, 20, 22, 28, 29, 30, 32, 34, 35, 38, 39, 40, 45, 46, 50, 53, 55, 56, 57, 58, 59, 61, 62, 64, 69, 70, 71, 72, 73, 74, 78, 79, 81, 88, 89, 92], "fairli": [1, 40, 51, 92], "intuit": [1, 9, 23, 32, 36, 56, 61, 72, 86, 88, 96], "At": [1, 19, 30, 32, 50, 73, 86, 92], "point": [1, 6, 7, 10, 11, 23, 32, 35, 38, 40, 44, 49, 50, 51, 52, 53, 56, 57, 58, 59, 61, 62, 64, 70, 71, 74, 75, 76, 78, 79, 81, 86, 88, 92], "re": [1, 4, 29, 36, 38, 40, 44, 49, 53, 55, 59, 60, 69, 73, 74, 75, 76, 88, 92], "ask": [1, 29, 56, 61, 81, 88], "how": [1, 3, 4, 7, 10, 11, 14, 19, 21, 22, 23, 24, 28, 29, 30, 32, 34, 36, 39, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 79, 81, 86, 89, 91, 92, 95], "right": [1, 19, 20, 23, 28, 29, 32, 34, 35, 39, 40, 44, 45, 47, 51, 52, 53, 56, 57, 60, 61, 62, 64, 65, 71, 73, 74, 75, 79, 81, 86, 88, 89, 92], "now": [1, 3, 6, 7, 19, 23, 24, 27, 28, 29, 32, 34, 35, 36, 38, 39, 40, 44, 47, 49, 50, 51, 52, 53, 56, 57, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 86, 88, 90, 92], "concern": [1, 19, 30, 49], "some": [1, 3, 6, 7, 17, 19, 20, 21, 22, 23, 28, 29, 30, 32, 39, 47, 49, 50, 51, 52, 53, 56, 58, 59, 60, 61, 62, 64, 67, 69, 70, 71, 72, 73, 74, 76, 78, 79, 81, 86, 88, 89, 90, 92, 95], "definit": [1, 23, 28, 29, 32, 34, 38, 39, 52, 58, 61, 65, 69, 71, 73, 75, 76, 78, 79, 86, 88, 90, 92], "soon": [1, 32, 53], "like": [1, 4, 6, 19, 20, 23, 28, 29, 32, 34, 36, 39, 40, 46, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 64, 65, 69, 70, 71, 72, 73, 75, 76, 79, 81, 86, 88, 89, 90, 92], "likelihood": [1, 3, 4, 6, 7, 10, 11, 15, 25, 27, 30, 32, 33, 35, 36, 37, 39, 40, 49, 51, 52, 57, 58, 59, 61, 62, 66, 67, 69, 71, 72, 74, 75, 77, 79, 89, 90, 92], "function": [1, 4, 20, 22, 23, 25, 28, 29, 30, 32, 34, 35, 36, 38, 39, 40, 44, 47, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 64, 70, 72, 74, 75, 76, 78, 81, 86, 88, 90, 92, 95], "last": [1, 7, 10, 22, 23, 28, 45, 49, 50, 57, 59, 67, 74, 75, 80, 86, 88, 90, 92], "term": [1, 7, 11, 20, 21, 22, 23, 28, 29, 30, 32, 34, 38, 39, 45, 49, 50, 51, 56, 59, 61, 71, 73, 79, 80, 81, 86, 88, 90, 92, 95], "rather": [1, 28, 30, 34, 39, 49, 50, 56, 59, 62, 64, 73, 74, 75, 79, 86], "just": [1, 7, 20, 24, 28, 29, 30, 32, 34, 35, 36, 38, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 66, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 90, 92], "yourself": [1, 31, 34, 36, 38, 42, 70, 72], "when": [1, 3, 6, 11, 15, 16, 17, 19, 22, 23, 29, 30, 31, 32, 34, 35, 36, 40, 44, 46, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 69, 71, 72, 73, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92], "thing": [1, 20, 23, 29, 30, 34, 47, 49, 50, 53, 55, 73, 76, 86, 88, 89, 90, 92], "later": [1, 21, 32, 34, 35, 46, 47, 53, 56, 59], "suspect": [1, 32, 65, 74, 76], "see": [1, 3, 6, 7, 19, 22, 27, 30, 32, 34, 36, 38, 39, 40, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 62, 64, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 90, 92], "close": [1, 30, 32, 34, 38, 39, 40, 52, 57, 58, 60, 70, 71, 72, 73, 74, 76, 79, 86, 88], "match": [1, 29, 31, 32, 34, 36, 56, 58, 62, 70, 72, 92], "That": [1, 3, 7, 19, 20, 23, 24, 28, 29, 30, 32, 34, 36, 38, 49, 51, 56, 58, 59, 60, 61, 64, 69, 70, 71, 72, 73, 74, 79, 81, 86, 92], "said": [1, 23, 32, 36, 44, 45, 49, 50, 56, 65, 86], "most": [1, 3, 7, 19, 20, 22, 30, 32, 34, 35, 38, 39, 40, 45, 46, 47, 49, 50, 53, 55, 56, 58, 59, 61, 64, 65, 67, 70, 72, 73, 74, 79, 81, 86, 88, 90, 92], "take": [1, 3, 6, 7, 9, 17, 19, 20, 21, 22, 23, 29, 30, 32, 34, 38, 40, 44, 45, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 64, 65, 70, 72, 73, 76, 79, 86, 88, 89, 90], "approach": [1, 6, 7, 9, 17, 21, 22, 23, 29, 30, 32, 34, 36, 37, 38, 44, 45, 51, 52, 55, 57, 58, 59, 60, 64, 69, 71, 72, 73, 74, 79, 81, 88, 89, 92, 95], "develop": [1, 9, 32, 56, 79], "cours": [1, 3, 7, 19, 20, 21, 23, 28, 29, 30, 32, 34, 39, 50, 51, 56, 59, 61, 65, 66, 72, 73, 76, 79, 86, 90, 96], "make": [1, 4, 7, 10, 19, 20, 22, 23, 28, 29, 32, 34, 35, 36, 38, 39, 40, 47, 49, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 69, 70, 71, 72, 73, 74, 75, 76, 79, 81, 86, 88, 89, 90, 92], "mistak": 1, "ok": [1, 52, 57, 64, 70, 71, 73, 79, 92], "go": [1, 9, 19, 21, 23, 25, 30, 32, 34, 35, 39, 45, 46, 50, 51, 53, 55, 56, 57, 58, 59, 61, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 92], "grade": [1, 9], "detail": [1, 3, 7, 9, 36, 38, 42, 46, 51, 53, 59, 61, 64, 73, 75, 79, 81, 87, 88], "implement": [1, 9, 20, 22, 34, 35, 36, 38, 39, 40, 44, 45, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 64, 68, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92, 96], "our": [1, 3, 6, 19, 20, 22, 23, 24, 28, 29, 30, 31, 32, 34, 36, 38, 40, 44, 45, 47, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 73, 74, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92, 95], "get": [1, 7, 19, 20, 21, 23, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 53, 56, 57, 58, 59, 60, 61, 64, 69, 70, 71, 72, 73, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92], "defin": [1, 6, 7, 23, 25, 28, 29, 30, 32, 34, 38, 39, 40, 44, 45, 49, 50, 52, 55, 56, 58, 61, 66, 67, 69, 70, 71, 73, 74, 75, 76, 79, 81, 86, 88, 90, 92], "probabl": [1, 3, 7, 9, 12, 19, 20, 25, 27, 29, 30, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 64, 65, 67, 69, 71, 72, 73, 74, 75, 79, 86, 88, 89, 96], "distribut": [1, 3, 4, 6, 7, 9, 10, 11, 12, 14, 15, 23, 24, 26, 27, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 52, 56, 59, 60, 61, 62, 64, 66, 67, 69, 70, 71, 72, 74, 75, 76, 78, 79, 81, 86, 88, 90, 95, 96], "describ": [1, 7, 15, 16, 17, 18, 23, 24, 25, 28, 29, 30, 31, 32, 36, 38, 39, 47, 49, 50, 55, 57, 58, 61, 64, 66, 69, 71, 73, 74, 75, 79, 81, 86, 88, 89, 92], "b": [1, 3, 4, 6, 7, 12, 23, 28, 32, 36, 38, 39, 49, 50, 51, 56, 59, 61, 64, 71, 72, 86, 89, 90, 92], "sai": [1, 3, 6, 7, 10, 11, 19, 23, 24, 28, 29, 30, 32, 34, 35, 45, 46, 47, 53, 56, 57, 59, 61, 69, 71, 73, 76, 78, 81, 86, 92], "40": [1, 34, 35, 40, 49, 51, 56, 67, 70, 76, 79, 92], "would": [1, 7, 19, 25, 29, 31, 32, 34, 35, 38, 39, 40, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 62, 64, 65, 67, 71, 72, 73, 74, 76, 78, 79, 86, 88, 89, 90, 92], "out": [1, 7, 12, 13, 19, 20, 23, 29, 30, 32, 34, 35, 36, 38, 40, 42, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 59, 62, 64, 65, 66, 69, 70, 71, 72, 74, 75, 76, 78, 79, 81, 86, 88, 90, 92], "respons": [1, 9, 72], "part": [1, 7, 19, 26, 28, 31, 32, 34, 39, 40, 46, 50, 51, 57, 73, 75, 81, 90], "unfortun": [1, 35, 44, 79, 88], "know": [1, 23, 24, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 46, 47, 51, 52, 55, 56, 58, 60, 61, 64, 71, 73, 75, 81, 86, 88, 89, 92], "paramet": [1, 3, 4, 6, 7, 9, 11, 20, 22, 23, 24, 25, 27, 28, 30, 32, 33, 35, 36, 44, 45, 46, 47, 48, 50, 51, 52, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 74, 75, 76, 78, 79, 86, 88, 89, 90, 96], "valu": [1, 6, 7, 23, 24, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 64, 67, 69, 70, 71, 72, 74, 75, 76, 78, 79, 86, 88, 89, 90], "chose": [1, 31, 32, 35, 40, 57, 65, 74, 76, 86, 89, 92], "In": [1, 3, 6, 7, 9, 19, 20, 21, 22, 23, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 45, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92], "fact": [1, 20, 23, 30, 32, 34, 35, 36, 38, 39, 49, 56, 59, 60, 61, 72, 76, 79, 86, 90], "ahead": [1, 24, 50, 58, 59, 61, 72, 78, 81, 96], "write": [1, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 22, 23, 25, 28, 29, 30, 32, 34, 35, 36, 38, 39, 40, 45, 47, 50, 51, 56, 58, 61, 69, 70, 73, 75, 76, 79, 81, 86, 88, 89, 92, 95], "down": [1, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 25, 29, 30, 32, 34, 35, 36, 39, 40, 47, 56, 58, 60, 61, 70, 73, 86], "context": [1, 6, 16, 25, 29, 30, 32, 34, 40, 49, 56, 59, 73, 86, 90], "full": [1, 18, 19, 20, 30, 38, 39, 40, 55, 58, 74, 79, 81, 89], "specif": [1, 7, 20, 23, 29, 34, 39, 44, 50, 53, 56, 59, 61, 64, 65, 69, 70, 71, 73, 74, 75, 76, 78, 79, 81, 88, 90], "c": [1, 3, 4, 6, 7, 19, 23, 29, 31, 32, 50, 58, 59, 69, 73, 79], "To": [1, 3, 7, 9, 19, 20, 22, 23, 25, 27, 29, 32, 34, 35, 38, 39, 40, 42, 44, 45, 47, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 64, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92], "one": [1, 3, 7, 19, 20, 22, 23, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 49, 50, 51, 52, 55, 56, 57, 58, 59, 64, 65, 69, 71, 72, 73, 76, 78, 79, 81, 86, 88, 89, 90, 92], "follow": [1, 3, 7, 10, 19, 20, 21, 22, 23, 25, 32, 34, 35, 40, 44, 47, 49, 50, 51, 52, 53, 56, 57, 58, 59, 62, 70, 71, 72, 73, 74, 75, 76, 78, 81, 86, 88, 89, 90, 92], "construct": [1, 10, 23, 30, 34, 35, 38, 49, 51, 53, 56, 57, 70, 71, 72, 73, 74, 75, 76, 81, 88, 90, 92], "those": [1, 19, 20, 25, 29, 32, 34, 35, 46, 47, 50, 51, 56, 57, 60, 61, 70, 71, 72, 73, 74, 78, 79, 88], "parametr": [1, 29, 32, 36, 49, 55, 56, 59, 60, 61, 65, 72, 73, 74, 76, 79, 88], "can": [1, 4, 7, 14, 15, 16, 19, 20, 21, 22, 23, 25, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92, 95], "mani": [1, 3, 19, 20, 22, 27, 29, 31, 32, 36, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 55, 56, 58, 59, 60, 67, 70, 73, 74, 76, 79, 81, 86, 88, 89, 90, 92, 95], "them": [1, 7, 9, 23, 32, 34, 36, 44, 45, 46, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 62, 67, 70, 71, 73, 74, 75, 81, 86, 90, 92, 95], "should": [1, 4, 6, 7, 19, 20, 22, 23, 28, 29, 31, 32, 34, 35, 36, 38, 40, 42, 44, 49, 50, 51, 56, 57, 58, 59, 60, 61, 62, 64, 70, 71, 72, 73, 74, 76, 79, 81, 86, 88, 90, 92], "carefulli": [1, 3, 23, 28, 52, 56, 64, 70, 74, 81], "best": [1, 6, 7, 13, 19, 20, 32, 36, 52, 55, 57, 61, 62, 64, 73, 79, 81, 86, 95], "clear": [1, 23, 35, 36, 39, 47, 51, 58, 62, 73, 75, 81, 86, 88, 89, 92, 95], "come": [1, 3, 7, 19, 29, 30, 32, 34, 36, 40, 44, 47, 49, 50, 51, 52, 56, 58, 60, 64, 65, 66, 70, 71, 72, 73, 74, 86, 88, 89, 92], "doe": [1, 3, 4, 12, 13, 17, 19, 20, 23, 28, 29, 31, 32, 34, 38, 40, 45, 49, 50, 51, 55, 56, 59, 60, 61, 64, 70, 72, 73, 74, 76, 78, 79, 81, 82, 86, 88, 90, 91, 92], "jibe": 1, "If": [1, 7, 9, 13, 14, 16, 19, 20, 22, 23, 28, 29, 30, 32, 34, 35, 36, 39, 40, 44, 45, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 65, 70, 71, 72, 73, 75, 76, 79, 81, 86, 88, 89, 90, 92], "have": [1, 3, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 34, 35, 36, 38, 39, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92, 95], "ani": [1, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 23, 29, 30, 32, 34, 36, 38, 39, 40, 44, 45, 47, 49, 50, 51, 55, 56, 58, 60, 61, 65, 69, 70, 71, 72, 73, 78, 79, 81, 82, 86, 88, 90, 91, 92, 93], "idea": [1, 7, 12, 18, 23, 31, 32, 36, 43, 49, 51, 55, 56, 59, 61, 62, 64, 71, 73, 86, 88], "why": [1, 3, 4, 7, 10, 11, 12, 13, 14, 15, 16, 28, 34, 43, 51, 53, 64, 70, 72, 79, 81, 86, 88, 89, 90, 92], "d": [1, 4, 6, 7, 19, 22, 28, 29, 30, 32, 34, 35, 38, 39, 40, 44, 45, 47, 52, 53, 56, 57, 60, 61, 62, 64, 71, 73, 75, 79, 86, 88], "until": [1, 71, 86, 90], "through": [1, 9, 19, 20, 21, 29, 32, 36, 39, 40, 47, 51, 53, 61, 70, 72, 73, 74, 75, 81, 86, 88, 90], "complet": [1, 9, 19, 22, 29, 34, 35, 36, 38, 40, 47, 50, 52, 56, 59, 65, 70, 71, 72, 73, 74, 78, 79, 81, 86, 88, 90], "access": [1, 7, 19, 30, 44, 49, 50, 51, 55, 59, 81], "here": [1, 4, 7, 19, 23, 28, 29, 30, 32, 34, 38, 40, 44, 45, 46, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 64, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 86, 88, 90, 92], "extract": [1, 38, 40, 50, 56, 74, 75, 79, 90], "made": [1, 6, 14, 19, 34, 49, 56, 58, 81, 86, 95], "nicrophoru": 1, "orbicolli": 1, "locat": [1, 3, 14, 19, 29, 32, 36, 38, 50, 52, 58, 60, 67, 70, 74, 81, 86, 90, 92], "10": [1, 4, 9, 20, 22, 29, 32, 34, 35, 36, 38, 39, 40, 44, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92, 96], "fall": [1, 55, 72, 73, 86, 88], "within": [1, 3, 19, 32, 46, 49, 51, 52, 56, 57, 59, 61, 72, 81, 88, 90], "homework": [2, 5, 8, 19, 20, 30, 32, 58, 69, 93], "first": [2, 3, 4, 7, 19, 20, 23, 24, 28, 29, 30, 32, 34, 35, 36, 38, 40, 44, 45, 46, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 69, 70, 71, 72, 73, 74, 75, 76, 79, 81, 86, 88, 89, 90, 92], "attempt": [2, 7, 10, 32, 55, 60, 61, 79, 81], "bayesian": [2, 6, 9, 25, 31, 32, 34, 35, 37, 38, 44, 46, 47, 49, 50, 55, 56, 59, 61, 71, 72, 86, 88, 95, 96], "70": [2, 55, 57, 59, 62, 70, 79], "pt": [2, 5, 8], "continu": [3, 23, 30, 32, 35, 39, 40, 44, 45, 47, 51, 53, 58, 61, 64, 71, 72, 73, 79, 86, 90, 92], "choos": [3, 19, 29, 30, 33, 34, 35, 36, 38, 40, 44, 46, 47, 49, 51, 52, 55, 56, 57, 60, 61, 68, 69, 73, 74, 75, 76, 81, 88], "gener": [3, 6, 7, 9, 10, 13, 20, 23, 25, 29, 30, 31, 32, 34, 35, 38, 39, 40, 43, 46, 47, 50, 51, 53, 55, 57, 58, 59, 60, 61, 62, 64, 68, 69, 71, 73, 74, 75, 78, 79, 81, 86, 88, 89, 90, 92], "model": [3, 4, 6, 7, 9, 10, 12, 13, 16, 17, 20, 22, 23, 25, 26, 28, 31, 32, 36, 37, 39, 44, 47, 50, 55, 58, 65, 71, 73, 74, 75, 78, 81, 86, 88, 90, 92, 95, 96], "nonetheless": [3, 20, 23, 32, 38, 49, 56, 58, 59, 72, 73, 78, 79], "estim": [3, 6, 9, 11, 20, 22, 23, 25, 30, 32, 33, 34, 36, 44, 45, 48, 52, 53, 56, 58, 59, 64, 67, 69, 70, 71, 72, 74, 75, 79, 88, 89, 92, 96], "where": [3, 6, 7, 19, 20, 23, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 44, 46, 47, 49, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 64, 65, 70, 71, 73, 74, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92], "contribut": [3, 29, 51, 64, 79, 86, 88], "exact": [3, 34, 38, 79, 86, 88], "constraint": [3, 56, 74, 90], "less": [3, 14, 28, 32, 34, 44, 49, 56, 59, 64, 71, 72, 88, 90, 92], "explor": [3, 7, 9, 23, 30, 31, 32, 34, 36, 38, 50, 53, 56, 57, 60, 70, 73, 86, 88, 90, 92, 95], "computation": [3, 19, 39, 61, 79, 90], "work": [3, 16, 19, 20, 21, 22, 23, 29, 32, 34, 35, 38, 39, 42, 45, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 78, 81, 86, 88, 89, 90, 92, 96], "david": [3, 79], "prober": 3, "": [3, 4, 9, 13, 19, 20, 21, 22, 26, 27, 29, 30, 32, 34, 35, 38, 39, 42, 44, 45, 46, 49, 50, 51, 52, 53, 55, 57, 59, 60, 61, 62, 64, 66, 67, 69, 70, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 92, 95, 96], "lab": [3, 9, 19, 49, 72, 89, 90, 96], "monitor": 3, "activ": [3, 19, 46, 49, 72, 73, 81, 90], "zebrafish": 3, "larva": 3, "genotyp": 3, "effort": [3, 71], "understand": [3, 6, 9, 23, 29, 36, 38, 44, 47, 51, 56, 64, 70, 73, 79, 81, 86], "sleep": 3, "control": [3, 8, 19, 50, 52, 56, 89], "publish": [3, 4, 49, 59, 79], "gandhi": 3, "et": [3, 7, 36, 38, 40, 49, 52, 53, 56, 57, 59, 62, 71, 75, 76, 79, 95], "al": [3, 7, 36, 38, 40, 49, 52, 53, 56, 57, 59, 62, 71, 75, 76, 79, 92, 95], "2015": [3, 67, 69], "minut": [3, 7, 20, 22, 23, 29, 40, 49, 72, 89], "17": [3, 9, 19, 34, 40, 49, 50, 51, 56, 57, 59, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 90, 92, 96], "fish": [3, 59, 64, 72, 73, 76, 90], "had": [3, 29, 32, 40, 52, 56, 59, 60, 62, 65, 72, 78, 81, 86, 92], "over": [3, 9, 23, 27, 32, 34, 35, 36, 40, 45, 46, 47, 51, 56, 61, 64, 69, 71, 72, 73, 75, 76, 79, 81, 86, 88, 90, 92], "nine": 3, "hour": [3, 19, 20, 21, 22, 49, 81, 90, 96], "third": [3, 34, 51, 57, 81], "night": 3, "result": [3, 7, 9, 23, 30, 31, 32, 34, 35, 38, 39, 40, 45, 49, 50, 51, 53, 56, 57, 59, 64, 67, 69, 70, 71, 72, 73, 74, 75, 76, 79, 81, 86, 88, 90, 92, 95], "easili": [3, 19, 34, 45, 49, 50, 56, 66, 73, 79, 86, 88], "directli": [3, 19, 23, 29, 32, 34, 38, 39, 47, 49, 50, 51, 52, 53, 56, 61, 62, 64, 69, 71, 73, 75, 79, 88], "arrai": [3, 4, 29, 34, 35, 38, 40, 49, 50, 51, 52, 53, 55, 56, 57, 59, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 90, 92], "variabl": [3, 6, 23, 27, 29, 32, 34, 35, 38, 45, 49, 50, 51, 52, 53, 56, 57, 59, 60, 64, 66, 69, 70, 71, 72, 73, 74, 75, 78, 79, 86, 90, 92], "call": [3, 19, 22, 23, 27, 28, 29, 30, 32, 34, 44, 46, 49, 50, 51, 53, 56, 60, 61, 62, 69, 70, 73, 76, 78, 79, 86, 88, 90, 92], "y": [3, 6, 7, 20, 22, 23, 25, 27, 28, 29, 30, 32, 34, 35, 38, 39, 40, 41, 44, 47, 49, 50, 51, 52, 53, 55, 56, 58, 61, 64, 66, 70, 71, 72, 73, 74, 75, 76, 78, 79, 86, 92], "190": [3, 36, 79, 92], "249": 3, "232": 3, "319": [3, 49], "104": 3, "93": [3, 51, 64], "233": 3, "287": 3, "49": [3, 34, 51, 90], "311": [3, 49], "225": 3, "243": [3, 51], "113": [3, 19, 79], "133": 3, "179": [3, 51, 79, 90], "drawn": [3, 49, 51, 56, 61, 71, 73, 79, 92], "mu": [3, 7, 20, 22, 28, 29, 32, 34, 39, 40, 55, 56, 57, 58, 60, 62, 73, 79, 92], "scale": [3, 29, 32, 34, 38, 39, 40, 41, 49, 50, 52, 53, 56, 58, 61, 62, 64, 70, 72, 74, 75, 76, 78, 86, 88, 90], "sigma": [3, 6, 20, 22, 23, 28, 29, 32, 34, 35, 38, 39, 40, 52, 53, 55, 56, 57, 58, 60, 62, 70, 73, 74, 75, 76, 78, 79, 88], "y_i": [3, 6, 28, 29, 38, 61, 64, 73, 76], "mid": [3, 23, 24, 25, 27, 28, 29, 30, 32, 34, 35, 36, 38, 39, 40, 44, 45, 47, 49, 50, 51, 52, 53, 56, 58, 60, 61, 64, 65, 66, 69, 71, 73, 74, 75, 76, 78, 79, 86], "foral": [3, 6, 7, 29, 34, 35, 38, 40, 49, 51, 52, 53, 56, 57, 59, 62, 65, 67, 72, 73, 75, 76, 79, 90, 92], "task": [3, 23, 32, 33, 38, 57, 62, 81, 86, 88, 90], "posterior": [3, 4, 9, 10, 11, 13, 15, 17, 20, 22, 24, 25, 27, 29, 32, 35, 40, 44, 45, 47, 50, 51, 52, 54, 56, 58, 59, 60, 62, 64, 65, 66, 67, 69, 70, 71, 72, 75, 76, 79, 86, 88, 90, 92, 96], "g": [3, 19, 20, 23, 24, 25, 27, 28, 29, 30, 32, 34, 35, 36, 38, 39, 40, 44, 47, 49, 50, 51, 56, 58, 61, 65, 66, 67, 69, 71, 72, 73, 75, 79, 81, 86, 92], "improp": [3, 32, 34, 35], "uninform": 3, "becaus": [3, 7, 19, 20, 21, 23, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 45, 49, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 90, 92], "veri": [3, 7, 23, 28, 29, 30, 32, 34, 36, 38, 39, 40, 45, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 70, 72, 73, 74, 75, 76, 78, 79, 86, 88, 90, 92], "broad": [3, 29, 30, 32, 34, 38, 56, 61, 72, 73, 81, 92, 96], "infinit": [3, 32, 49, 73, 88], "even": [3, 7, 23, 29, 30, 32, 34, 50, 51, 55, 56, 59, 61, 70, 72, 73, 78, 81, 86, 88, 92], "normaliz": [3, 32], "constant": [3, 6, 29, 32, 34, 35, 38, 56, 65, 73, 74, 76, 78, 79, 92], "Of": [3, 7, 29, 36, 65, 73], "both": [3, 23, 28, 34, 40, 49, 50, 56, 57, 59, 61, 62, 64, 72, 73, 75, 81, 86, 88, 90, 92], "assum": [3, 4, 6, 7, 19, 22, 29, 32, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 56, 58, 61, 64, 65, 66, 69, 70, 73, 75, 79, 86, 89, 92], "nonneg": [3, 32], "again": [3, 20, 22, 23, 28, 29, 30, 34, 35, 38, 39, 40, 45, 47, 49, 51, 53, 56, 57, 59, 61, 64, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 86, 92], "150": [3, 49, 51, 53, 79], "min": [3, 32, 41, 45, 56, 73, 74, 75, 76, 78, 90], "effect": [3, 14, 20, 22, 23, 30, 32, 38, 44, 49, 53, 58, 60, 62, 64, 65, 67, 69, 70, 72, 73, 75, 76, 78, 79, 81, 86, 88, 92], "oppos": [3, 35, 56, 81, 88, 90], "uniform": [3, 6, 34, 35, 36, 41, 44, 51, 52, 67, 71, 88], "comment": [3, 7, 18, 50, 73, 81, 90], "download": [4, 7, 19, 20, 34, 35, 38, 40, 49, 51, 52, 53, 56, 57, 59, 62, 64, 72, 73, 74, 75, 76, 78, 86, 92], "wa": [4, 7, 23, 32, 34, 36, 38, 40, 44, 45, 49, 50, 53, 56, 58, 59, 61, 70, 72, 73, 76, 78, 79, 86, 88, 90, 92, 93], "motiv": [4, 28, 36], "discuss": [4, 6, 7, 9, 20, 22, 23, 28, 30, 32, 34, 39, 40, 44, 46, 47, 49, 51, 53, 56, 57, 59, 64, 66, 71, 73, 74, 81, 86, 95], "section": [4, 20, 21, 22, 23, 28, 39, 50, 59, 60, 73, 81, 86, 90, 92], "holm": 4, "huber": 4, "book": [4, 23, 28, 36, 46, 95], "gamma": [4, 35, 36, 39, 40, 41, 44, 51, 52, 53, 56, 57, 58, 62, 65, 72, 73, 74, 75, 76, 79, 90], "updat": [4, 19, 24, 30, 32, 36, 38, 51, 56, 58, 70, 71, 72, 75, 79, 86], "welcom": 4, "wikipedia": [4, 36, 59], "tabl": [4, 36, 50, 56, 89, 92], "check": [4, 7, 9, 13, 15, 16, 17, 19, 20, 36, 42, 49, 50, 51, 52, 60, 62, 64, 67, 71, 73, 75, 76, 79, 81, 86, 89, 90, 92, 96], "answer": [4, 14, 50, 57, 58, 59, 61, 81, 89, 90, 92], "actual": [4, 30, 32, 34, 36, 39, 47, 49, 56, 57, 61, 64, 67, 69, 71, 72, 73, 75, 76, 78, 86, 90, 92], "proof": [4, 28, 75], "sequenc": [4, 7, 86], "chromosom": 4, "dna": [4, 32, 49], "e": [4, 7, 19, 20, 22, 23, 28, 30, 32, 34, 35, 39, 44, 49, 51, 56, 58, 60, 61, 62, 64, 65, 67, 69, 70, 72, 73, 75, 76, 78, 79, 81, 88, 90, 92], "coli": [4, 32, 70, 75], "strain": [4, 69], "atcc": 4, "baa": 4, "196": [4, 79], "fasta": 4, "format": [4, 16, 22, 38, 40, 50, 56, 67, 74, 75, 86], "resist": 4, "multipl": [4, 21, 39, 50, 59, 61, 78, 79, 86, 88, 90, 92], "drug": 4, "studi": [4, 9, 23, 30, 37, 49, 51, 52, 56, 69, 70, 73, 76, 79, 89, 92, 95], "antibiot": 4, "paper": [4, 7, 29, 30, 36, 46, 49, 50, 51, 59, 60, 61, 64, 71, 72, 73, 75, 79, 86, 88, 89, 92], "read": [4, 7, 9, 20, 29, 31, 38, 43, 44, 46, 50, 51, 58, 59, 61, 64, 69, 70, 71, 72, 79, 86, 89, 90, 96], "singl": [4, 7, 24, 27, 28, 29, 31, 32, 36, 39, 49, 51, 53, 55, 57, 58, 59, 61, 64, 69, 70, 75, 76, 81, 89, 90, 92], "string": [4, 50, 70, 90], "below": [4, 9, 20, 22, 23, 28, 36, 40, 44, 50, 51, 52, 53, 55, 56, 57, 59, 60, 64, 70, 71, 73, 75, 78, 81, 86, 88, 90, 92], "def": [4, 34, 35, 38, 40, 49, 55, 73, 74, 75, 76, 78, 79, 86, 90], "read_fasta_single_record": 4, "filenam": [4, 50, 81], "file": [4, 7, 19, 50, 56, 75, 79, 81], "contain": [4, 23, 28, 32, 35, 36, 39, 47, 49, 50, 51, 53, 55, 56, 58, 64, 65, 69, 70, 73, 76, 78, 79, 81, 86, 88, 90, 95], "line": [4, 13, 19, 22, 29, 32, 34, 35, 36, 38, 39, 41, 49, 50, 51, 52, 53, 55, 56, 72, 73, 74, 75, 76, 78, 86, 88, 90, 92], "descriptor": 4, "all": [4, 6, 7, 9, 19, 20, 23, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 45, 47, 50, 51, 52, 53, 55, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 90, 92], "subsequ": [4, 30, 58, 73, 78, 92], "open": [4, 19, 20, 22, 79, 90], "r": [4, 22, 23, 45, 46, 50, 60, 70, 79, 88, 90], "f": [4, 7, 20, 22, 24, 25, 27, 28, 29, 30, 32, 34, 36, 38, 39, 41, 44, 49, 51, 56, 58, 61, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 78, 79, 86, 88, 89, 90, 92], "readlin": 4, "rstrip": 4, "strip": [4, 70, 72, 76, 79, 81], "whitespac": 4, "seq": [4, 8], "while": [4, 19, 32, 34, 35, 36, 38, 45, 46, 49, 50, 51, 53, 56, 59, 61, 71, 73, 74, 76, 79, 81, 86, 88, 90, 92], "return": [4, 9, 28, 34, 35, 38, 39, 40, 44, 46, 49, 50, 51, 52, 53, 56, 57, 62, 64, 73, 74, 75, 76, 78, 79, 86, 88, 90, 92], "find": [4, 6, 7, 10, 11, 19, 20, 27, 29, 30, 31, 32, 34, 35, 38, 39, 40, 51, 55, 56, 58, 61, 64, 71, 73, 74, 75, 78, 79, 81, 86, 88, 90, 95], "index": [4, 7, 47, 49, 50, 51, 56, 57, 59, 64, 70, 76, 79], "shine": 4, "delgarno": 4, "motif": 4, "initi": [4, 19, 35, 36, 38, 40, 56, 58, 64, 74, 75, 86, 88, 92], "protein": [4, 56, 89, 92], "synthesi": 4, "aggaggt": 4, "recognit": 4, "recognition_sites_with_r": 4, "recog_seq": 4, "indic": [4, 10, 38, 51, 53, 56, 58, 59, 60, 62, 64, 65, 67, 70, 71, 72, 73, 75, 76, 78, 81, 86, 92], "findit": 4, "append": [4, 49, 55, 56, 76, 90], "start": [4, 19, 22, 23, 30, 32, 34, 35, 38, 40, 46, 49, 50, 51, 52, 53, 55, 56, 59, 60, 64, 70, 71, 73, 74, 75, 76, 86, 88, 89, 90, 92], "store": [4, 19, 34, 35, 50, 55, 56, 57, 59, 64, 74, 92], "number": [4, 7, 14, 19, 20, 22, 23, 28, 29, 30, 32, 34, 36, 43, 47, 49, 50, 51, 53, 55, 56, 57, 59, 61, 64, 67, 69, 70, 71, 72, 76, 78, 79, 81, 86, 88, 89, 90, 92], "base": [4, 9, 17, 19, 20, 23, 29, 30, 32, 49, 50, 51, 55, 56, 58, 59, 61, 62, 73, 74, 79, 86, 89, 90, 92, 95, 96], "between": [4, 6, 23, 28, 30, 31, 32, 35, 40, 46, 49, 51, 52, 53, 56, 58, 59, 61, 62, 64, 65, 70, 71, 72, 73, 76, 79, 82, 86, 88, 89, 92, 93], "occurr": [4, 23], "distanc": [4, 32, 58, 79, 86], "explain": [4, 12, 14, 16, 75, 81, 89], "reason": [4, 7, 9, 23, 29, 32, 34, 38, 39, 49, 51, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 90, 92, 95], "exploratori": [4, 7], "ecdf": [4, 47, 50, 51, 52, 53, 56, 57, 59, 62, 67, 79, 92], "inter": 4, "comput": [4, 7, 9, 10, 11, 15, 19, 23, 27, 28, 29, 30, 32, 44, 45, 46, 47, 61, 66, 69, 70, 71, 88, 90], "rate": [4, 28, 45, 56, 73, 74, 75, 78, 89, 92], "invers": [4, 32, 38, 39, 44, 49, 51, 58, 73, 74, 76, 86], "characterist": [4, 38, 56, 75], "overwhelm": [5, 67, 88], "45": [5, 35, 36, 51, 55, 76], "exponenti": [5, 28, 31, 34, 35, 39, 40, 44, 55, 58, 61, 73, 74, 76, 78, 86, 88, 92], "conjug": [5, 10, 73], "55": [5, 49, 70, 76], "heard": [6, 23], "fit": [6, 13, 19, 23, 52, 56, 69, 73, 76, 95], "variat": [6, 9, 18, 29, 30, 34, 35, 37, 50, 53, 56, 69, 73, 76, 90, 96], "covari": [6, 9, 29, 37, 38, 39, 53, 58, 74, 76, 78, 79, 86, 88, 96], "minim": [6, 34, 38, 39, 40, 50, 56, 74, 75, 79, 81, 86], "sum": [6, 27, 28, 30, 34, 35, 38, 40, 44, 45, 51, 55, 56, 58, 59, 61, 67, 79, 86, 88, 92], "residu": 6, "pars": [6, 72, 73, 95], "mean": [6, 11, 12, 13, 17, 18, 19, 20, 22, 23, 29, 31, 32, 34, 38, 40, 44, 46, 47, 49, 50, 51, 55, 56, 58, 59, 60, 61, 64, 65, 69, 70, 71, 72, 74, 75, 76, 78, 79, 81, 86, 88, 90, 92], "x": [6, 23, 25, 28, 34, 35, 38, 39, 40, 41, 49, 50, 51, 52, 53, 55, 56, 60, 72, 73, 74, 75, 76, 78, 79, 86, 90], "independ": [6, 14, 18, 29, 31, 32, 34, 35, 40, 44, 51, 52, 58, 59, 60, 61, 62, 64, 65, 67, 70, 73, 79, 86, 92], "known": [6, 23, 29, 30, 31, 32, 35, 36, 39, 44, 46, 55, 56, 58, 61, 64, 71, 73, 89, 90, 92], "essenti": [6, 15, 29, 50, 59, 70, 81, 88, 90], "exactli": [6, 23, 29, 36, 51, 56, 58, 64, 73, 74, 75, 79, 86, 92], "could": [6, 21, 28, 29, 32, 34, 35, 38, 40, 45, 47, 49, 51, 52, 55, 56, 57, 58, 60, 61, 65, 69, 70, 72, 73, 76, 78, 79, 86, 88, 90, 92], "someth": [6, 19, 23, 34, 36, 56, 61, 69, 71, 73, 81, 86, 88, 90], "depend": [6, 20, 29, 31, 34, 35, 36, 39, 44, 45, 49, 51, 57, 62, 66, 69, 72, 73, 79, 86, 89, 90, 92], "ha": [6, 7, 11, 19, 22, 23, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 44, 45, 46, 49, 50, 51, 53, 56, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 76, 78, 79, 81, 86, 88, 89, 90, 92, 95], "stochast": [6, 56, 73, 79, 88, 92], "nois": [6, 23, 29, 75], "deriv": [6, 23, 28, 31, 32, 34, 38, 39, 44, 56, 58, 61, 71, 73, 77, 79, 86, 88], "theoret": [6, 7, 29, 30, 35, 36, 40, 49, 51, 56, 58, 72, 73, 74, 81, 88], "relat": [6, 7, 9, 17, 28, 29, 32, 38, 39, 44, 56, 60, 61, 71, 73, 81, 88, 90], "written": [6, 22, 23, 25, 30, 32, 34, 35, 49, 50, 51, 56, 61, 65, 69, 76, 81, 82, 86, 90, 91, 92, 93], "f_y": [6, 28], "phi": [6, 7, 32, 34, 35, 38, 40, 52, 53, 56, 57, 62, 65, 66, 67, 69, 76, 79, 88, 92], "wish": [6, 28, 29, 30, 34, 35, 44, 49, 50, 51, 52, 55, 56, 58, 60, 61, 70, 71, 73, 79, 81, 89], "determin": [6, 7, 28, 32, 36, 51, 56, 58, 59, 61, 64, 67, 70, 73, 74, 86, 90, 92], "infer": [6, 18, 19, 21, 25, 30, 32, 34, 35, 38, 39, 50, 51, 56, 59, 61, 67, 71, 72, 74, 75, 76, 95, 96], "x_1": [6, 28, 58, 75], "y_1": [6, 24, 28, 29, 38, 61, 64], "x_2": [6, 28, 58, 75], "y_2": [6, 24, 28, 29, 38, 61, 64], "ldot": [6, 28, 29, 44, 47, 58, 61, 64, 65, 69, 70, 73, 74], "x_n": 6, "y_n": [6, 29, 61, 64], "mathrm": [6, 28, 29, 30, 32, 34, 35, 39, 44, 45, 47, 59, 60, 61, 64, 71, 73, 74, 75, 76, 78, 86, 88, 92], "x_i": [6, 34, 58, 73, 75, 92], "sigma_i": [6, 29, 56, 57, 62, 73, 79], "A": [6, 7, 9, 23, 25, 28, 29, 31, 32, 37, 39, 44, 50, 51, 53, 55, 57, 59, 61, 65, 72, 73, 75, 81, 89, 90, 92, 95], "r_i": 6, "frac": [6, 23, 24, 25, 27, 28, 29, 30, 32, 34, 35, 36, 39, 40, 45, 46, 47, 51, 52, 53, 56, 57, 59, 60, 61, 62, 64, 65, 66, 69, 71, 73, 75, 79, 86, 88], "sum_": [6, 27, 29, 34, 35, 47, 61, 64, 69, 79, 92], "equival": [6, 23, 28, 32, 34, 51, 56, 58, 60, 76, 79, 88, 92], "map": [6, 8, 11, 40, 51, 55, 67, 73, 75, 78, 88, 90], "abov": [6, 7, 19, 20, 24, 29, 32, 34, 35, 44, 49, 51, 53, 56, 57, 60, 64, 69, 70, 71, 73, 75, 78, 79, 86, 88, 90, 92], "note": [6, 7, 19, 22, 23, 25, 28, 30, 32, 34, 35, 36, 38, 39, 40, 45, 47, 49, 50, 51, 52, 56, 57, 58, 59, 60, 61, 62, 64, 65, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 88, 89, 90, 92], "taken": [6, 19, 30, 44, 47, 50, 59, 60, 86], "homoscedast": [6, 40, 52, 73, 74, 75], "error": [6, 29, 34, 49, 51, 56, 58, 64, 69, 72, 73, 74, 75, 81, 86, 88, 90], "further": [6, 13, 23, 34, 43, 56, 61, 70, 72, 73, 79], "whose": [6, 23, 44], "still": [6, 15, 29, 32, 39, 45, 49, 53, 55, 56, 57, 58, 60, 61, 64, 70, 72, 73, 79, 86, 90, 92], "need": [6, 7, 14, 19, 20, 21, 22, 23, 28, 29, 30, 31, 34, 35, 38, 40, 44, 45, 46, 47, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 61, 64, 65, 69, 70, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92], "consid": [6, 7, 23, 29, 30, 32, 34, 35, 38, 39, 40, 45, 49, 51, 53, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 88, 92], "assumpt": [6, 61, 64, 69], "often": [6, 7, 20, 23, 28, 29, 30, 32, 34, 39, 44, 47, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 69, 72, 73, 75, 81, 90, 92], "done": [6, 19, 23, 29, 30, 38, 49, 50, 51, 53, 56, 61, 64, 69, 70, 73, 76, 78, 86, 88, 90, 92], "issu": [6, 7, 28, 29, 30, 32, 34, 53, 55, 56, 60, 70, 72, 73, 90], "inspir": 7, "valentin": 7, "svensson": 7, "blog": [7, 51, 73, 81, 92], "post": [7, 34, 35, 51, 71, 73, 75, 78, 81, 92], "viewabl": 7, "cell": [7, 20, 29, 32, 40, 49, 51, 52, 56, 59, 64, 70, 72, 73, 75, 76, 81, 86, 89, 90], "rna": [7, 49, 64, 72, 73, 90], "scrna": 7, "technologi": 7, "more": [7, 19, 20, 23, 24, 28, 29, 30, 32, 34, 35, 36, 38, 40, 42, 45, 46, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 87, 88, 90, 92], "common": [7, 23, 32, 53, 61, 65, 73], "It": [7, 19, 20, 22, 23, 28, 29, 31, 32, 34, 35, 36, 38, 39, 40, 44, 45, 47, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 62, 64, 70, 71, 72, 73, 74, 75, 76, 78, 81, 82, 86, 88, 92, 93], "enabl": [7, 20, 36, 39, 49, 50, 52, 53, 56, 57, 59, 74, 76, 90], "research": [7, 20, 23, 29, 30, 32, 40, 55, 81, 90, 95], "count": [7, 51, 58, 59, 64, 73, 76, 89, 92], "mrna": [7, 51, 59, 64, 76], "transcript": [7, 49, 51, 59, 64, 72, 73, 76], "gene": [7, 51, 58, 59, 64, 70, 72, 73, 76, 90], "techniqu": [7, 9, 32, 44, 49, 50, 53, 59, 61, 64, 71, 75, 79, 88], "usual": [7, 14, 20, 23, 34, 40, 50, 52, 56, 58, 59, 61, 64, 67, 71, 73, 74, 75, 76, 86, 90, 92], "individu": [7, 31, 35, 56, 64, 67, 70, 88, 92], "encas": [7, 78], "droplet": [7, 34, 35, 38, 40, 52, 53, 57, 62, 79], "microfluid": 7, "devic": 7, "importantli": [7, 20, 28, 29, 30, 36, 40, 44, 45, 47, 49, 51, 56, 59, 61, 64, 70, 71, 72, 73, 76, 79], "cdna": 7, "barcod": 7, "molecul": [7, 31, 49, 56, 58, 59, 76], "identif": 7, "output": [7, 19, 40, 49, 56, 61, 64, 70, 74, 79, 90], "matrix": [7, 28, 29, 32, 38, 39, 40, 51, 58, 64, 74, 75, 76, 78, 86, 88, 90], "row": [7, 49, 50, 55, 56, 57, 70, 73, 79, 86], "correspond": [7, 19, 23, 28, 49, 51, 70, 73, 75, 76, 79, 86, 92], "column": [7, 49, 50, 51, 53, 55, 56, 57, 59, 70, 72, 79, 90], "entri": [7, 29, 32, 39, 51, 58, 70, 73, 74, 76, 79, 81, 90], "integ": [7, 28, 44, 49, 51, 58, 90], "process": [7, 9, 19, 20, 23, 27, 29, 30, 31, 44, 49, 50, 56, 57, 58, 60, 61, 71, 75, 78, 88, 89, 92], "worth": [7, 31, 73, 75, 86, 90], "analysi": [7, 9, 17, 23, 30, 32, 34, 40, 46, 47, 50, 51, 52, 56, 72, 73, 75, 76, 79, 81, 89, 90, 95], "tool": [7, 9, 22, 23, 38, 40, 61, 81, 89, 95], "kalisto": 7, "fulli": [7, 23, 29, 30, 57, 73, 79, 89, 92], "saw": [7, 28, 30, 51, 53, 72, 75, 79], "smfish": [7, 49, 51, 59], "abund": 7, "neg": [7, 29, 32, 34, 38, 39, 40, 49, 51, 56, 58, 59, 64, 72, 74, 79, 86, 90, 92], "binomi": [7, 32, 49, 51, 59, 64, 67, 69, 72, 86, 90, 92], "under": [7, 19, 23, 32, 34, 35, 39, 51, 56, 57, 59, 67, 69, 71, 81, 88, 90, 92], "bursti": [7, 49, 51, 59, 73, 76], "express": [7, 23, 24, 27, 29, 35, 36, 38, 39, 47, 49, 51, 52, 56, 58, 59, 60, 61, 65, 69, 70, 71, 73, 76, 79, 90, 92], "absenc": [7, 44, 59, 73], "zheng": 7, "inject": [7, 23, 60], "ercc": 7, "extern": [7, 30], "consortium": 7, "spike": 7, "solut": [7, 9, 73, 78, 79, 81, 86, 88, 90], "thu": [7, 23, 24, 28, 32, 36, 38, 45, 52, 56, 58, 60, 61, 64, 69, 70, 72, 73, 74, 76, 79, 81, 88], "confound": [7, 29], "absent": 7, "poisson": [7, 31, 58, 73, 92], "turn": [7, 23, 29, 34, 49, 50, 51, 60, 61, 62, 66, 67, 72, 81, 86, 88], "hi": [7, 32, 36, 42, 46, 53], "link": [7, 28, 53, 76, 90, 95], "caus": [7, 19, 51, 60, 70], "constern": 7, "among": [7, 19, 27, 32, 56, 79, 81], "commun": [7, 9, 20, 49, 92], "explan": [7, 59, 86, 92, 95], "unknown": [7, 30, 56, 61, 73], "captur": [7, 29, 32, 34, 57, 58, 62, 69, 70, 71, 72, 73, 74, 76, 79, 92], "flexibl": [7, 61, 62, 64, 71, 79], "than": [7, 14, 19, 23, 28, 29, 30, 32, 34, 36, 38, 39, 40, 44, 46, 49, 50, 51, 55, 56, 58, 59, 61, 64, 65, 67, 69, 71, 72, 73, 75, 79, 81, 86, 88, 90, 92], "limit": [7, 20, 23, 29, 31, 32, 44, 45, 46, 50, 58, 59, 62, 71, 73, 75, 88, 90, 92], "understood": [7, 30, 56, 61], "formul": [7, 23, 86, 92], "http": [7, 19, 20, 34, 38, 49, 59, 81, 86, 92], "s3": [7, 20, 34, 38, 49, 81, 90, 92], "amazonaw": [7, 20, 34, 38, 49, 81, 92], "com": [7, 19, 20, 34, 38, 49, 81, 86, 90, 92], "bebi103": [7, 19, 20, 22, 34, 35, 38, 39, 40, 49, 50, 51, 52, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 81, 90, 92, 95], "caltech": [7, 9, 19, 20, 21, 34, 38, 49, 81, 92], "edu": [7, 9, 20, 34, 38, 49, 81, 90, 92], "zheng_gemcode_control": 7, "csv": [7, 19, 34, 35, 38, 40, 49, 50, 51, 52, 53, 56, 57, 59, 62, 64, 72, 73, 74, 75, 76, 78, 79, 81, 90], "presum": [7, 89], "raw": 7, "deposit": [7, 50], "short": [7, 60, 75, 90], "archiv": 7, "srp073767": 7, "avail": [7, 19, 20, 32, 34, 49, 50, 55, 56, 57, 59, 62, 72, 78, 81, 90, 95], "figshar": 7, "licens": 7, "cc": 7, "BY": 7, "4": [7, 9, 20, 22, 28, 32, 34, 36, 38, 39, 40, 45, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 89, 90, 92, 96], "addition": [7, 71, 81], "inform": [7, 11, 19, 20, 23, 24, 28, 34, 35, 36, 38, 40, 50, 52, 55, 56, 57, 59, 62, 64, 65, 70, 71, 72, 79, 86, 88, 90, 92, 96], "concentr": [7, 65, 71, 73, 86, 88], "mix": [7, 59, 60, 64, 70, 75, 92], "obtain": [7, 23, 30, 34, 35, 49, 50, 53, 55, 59, 61, 71, 75, 78, 79, 86], "thermo": 7, "fisher": [7, 32], "were": [7, 23, 25, 32, 35, 39, 44, 49, 50, 53, 56, 57, 58, 59, 61, 64, 67, 70, 71, 72, 73, 76, 79, 90, 92], "dilut": 7, "50": [7, 29, 32, 34, 35, 38, 39, 40, 41, 44, 52, 53, 55, 56, 57, 62, 67, 70, 72, 76, 79, 81, 92], "fold": [7, 23, 38], "eas": [7, 30, 32, 73, 79], "although": [7, 61, 86, 88, 92], "strictli": [7, 32, 56, 58, 78, 90], "refer": [7, 19, 23, 29, 32, 39, 50, 51, 52, 55, 59, 61, 73, 75, 79, 81, 88, 92, 95], "obviou": [7, 28, 29, 30, 56, 62, 64, 70, 71, 86], "deviat": [7, 29, 55, 56, 58, 59, 70, 71, 72, 73, 74, 75, 86], "being": [7, 12, 17, 20, 32, 34, 36, 49, 50, 52, 56, 58, 59, 61, 70, 73, 76, 78, 79, 81, 88], "sure": [7, 19, 22, 29, 32, 34, 38, 44, 49, 53, 56, 57, 58, 59, 61, 64, 70, 71, 72, 74, 78, 79, 81, 86, 89, 90, 92], "strang": [7, 36, 47, 56, 73, 92], "specul": 7, "hint": 7, "obvious": [7, 56], "inconsist": [7, 32], "onli": [7, 19, 20, 23, 29, 30, 32, 34, 36, 38, 40, 44, 45, 47, 51, 53, 56, 58, 59, 61, 69, 70, 72, 73, 75, 78, 79, 81, 86, 89, 90, 92], "behavior": [7, 59, 60, 62, 64, 67, 70, 72, 73, 75, 76, 78, 92], "calcul": [7, 19, 21, 23, 29, 30, 32, 35, 36, 38, 40, 49, 50, 55, 56, 58, 59, 61, 62, 71, 72, 73, 77, 78, 79, 81, 88, 90, 91, 92], "quick": [7, 19, 20, 34, 38, 40, 49, 52, 53, 56, 57, 59, 60, 61, 64, 72, 73, 76, 79, 92, 95], "graphic": [7, 9, 13, 15, 39, 44, 56, 60, 70, 71, 81, 90], "verif": [7, 56], "inde": [7, 15, 28, 29, 30, 49, 50, 51, 56, 73, 78], "principl": [7, 9, 17, 32, 56, 58, 61, 72, 73, 88, 89, 96], "wai": [7, 22, 23, 24, 30, 32, 34, 35, 45, 46, 49, 51, 53, 55, 56, 58, 59, 60, 61, 62, 64, 65, 69, 70, 73, 75, 76, 79, 81, 86, 88, 90, 92], "week": [7, 40, 57, 81, 96], "dirti": 7, "credibl": [7, 11, 40, 52, 53, 55, 67, 73, 74, 75, 78], "interv": [7, 11, 32, 36, 40, 44, 50, 51, 52, 53, 55, 58, 66, 67, 71, 72, 73, 74, 75, 78, 86, 89], "local": [7, 11, 20, 22, 30, 35, 38, 39, 73, 90], "notic": [7, 19, 32, 40, 49, 50, 51, 79, 90, 92], "sourc": [7, 19, 34, 35, 38, 40, 52, 53, 56, 72, 73, 74, 76, 79, 81, 90], "commonli": [7, 30, 32, 46, 50, 53, 55, 59, 75, 78, 90], "occur": 7, "typic": [7, 20, 29, 30, 32, 36, 40, 49, 51, 52, 56, 58, 59, 65, 70, 71, 72, 73], "nonzero": [7, 28, 29, 38], "let": [7, 19, 23, 24, 27, 29, 32, 34, 35, 38, 39, 46, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 64, 67, 69, 70, 72, 73, 75, 76, 78, 79, 81, 86, 88, 92], "case": [7, 9, 19, 27, 28, 29, 30, 31, 32, 34, 35, 37, 39, 40, 44, 45, 47, 49, 50, 51, 52, 55, 56, 57, 58, 59, 61, 64, 65, 66, 69, 70, 71, 72, 73, 74, 75, 79, 81, 86, 88, 90, 92, 95], "detect": [7, 59], "due": [7, 9, 20, 23, 32, 56, 61, 75, 81, 86, 90, 92], "unspecifi": 7, "includ": [7, 9, 19, 20, 21, 22, 23, 28, 30, 32, 38, 39, 44, 47, 49, 50, 51, 53, 55, 56, 57, 59, 61, 62, 64, 70, 71, 72, 73, 75, 79, 81, 86, 88, 89, 90, 92], "Then": [7, 23, 24, 27, 29, 32, 34, 45, 47, 50, 52, 60, 61, 71, 73, 86, 90, 92], "accord": [7, 22, 35, 39, 46, 51, 52, 53, 59, 69, 75, 76], "version": [7, 19, 20, 22, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92], "mixtur": [7, 9, 55, 96], "delta_": [7, 73, 75], "0y": 7, "otherwis": [7, 45, 46, 50, 71, 79, 88], "investig": [7, 24, 35, 36, 45, 49, 56, 59, 60, 61, 67, 69], "whether": [7, 59, 72, 74, 76, 81], "rel": [7, 19, 20, 23, 29, 61, 64, 71, 88], "similar": [7, 28, 34, 36, 50, 51, 52, 56, 57, 61, 62, 70, 81, 89, 90, 92], "versu": [7, 34, 38, 53, 56, 57, 62, 70, 72, 73], "fraction": [7, 34, 56, 59, 88], "stand": [7, 86], "technic": [7, 30, 86, 90], "quantifi": [7, 23, 61, 74, 79, 88, 92], "well": [7, 19, 20, 22, 29, 30, 31, 32, 34, 38, 39, 40, 47, 50, 51, 53, 57, 61, 64, 65, 69, 72, 73, 74, 75, 86, 88, 92], "other": [7, 21, 22, 23, 25, 28, 29, 30, 32, 34, 35, 38, 39, 44, 47, 49, 50, 51, 52, 53, 56, 59, 61, 65, 67, 69, 70, 71, 73, 78, 79, 81, 86, 89, 90, 92, 95], "With": [7, 29, 32, 49, 50, 52, 56, 57, 64, 65, 72, 75, 88, 92], "mind": [7, 23, 28, 29, 50, 59, 70, 73, 74, 90], "new": [7, 19, 23, 28, 30, 32, 34, 49, 50, 51, 56, 57, 58, 61, 73, 74, 86, 88, 90, 95], "wherein": 7, "mu_i": [7, 29, 40, 52, 53, 56, 57, 58, 62, 73, 75, 79], "share": [7, 9, 19, 32], "j": [7, 20, 22, 27, 32, 34, 35, 38, 40, 61, 79, 90, 92], "y_": [7, 61], "ij": [7, 29, 32, 39, 73, 75], "negbinom": [7, 49, 51, 59, 72, 90], "trickier": [7, 55, 74], "optim": [7, 9, 11, 30, 34, 35, 45, 49, 50, 64, 76, 77, 78, 79, 86, 90, 96], "solv": [7, 39, 56, 73, 86, 88], "big": [7, 32, 40, 49, 55, 56, 70, 79], "report": [7, 38, 39, 40, 49, 51, 54, 59, 61, 69, 70, 71, 89], "hessian": [7, 32, 38, 39, 40], "sever": [7, 20, 21, 22, 32, 34, 35, 38, 40, 46, 55, 60, 72], "smooth": [7, 34, 57, 61, 64, 73, 75], "curv": [7, 34, 35, 40, 52, 56, 57, 73, 75, 86], "overlai": [7, 38, 41, 57, 60, 74, 76], "light": [7, 29, 30, 32, 56, 58, 69], "least": [8, 23, 35, 38, 39, 59, 72, 73, 79, 81, 88, 90, 92], "squar": [8, 29, 32, 73, 74, 76, 78, 86, 90], "zero": [8, 28, 29, 32, 34, 35, 38, 39, 40, 44, 49, 50, 51, 52, 56, 58, 60, 69, 70, 71, 72, 73, 74, 76, 79, 86, 92], "inflat": 8, "drop": [8, 52, 56, 73], "80": [8, 56, 67, 79], "prequel": [9, 34], "pipelin": [9, 56, 72], "organ": [9, 49, 64, 70], "preserv": [9, 58, 88], "displai": [9, 51, 56, 59, 60, 73, 75, 79, 81, 96], "quantit": [9, 23, 56, 57], "basic": [9, 12, 18, 43, 49, 53, 79, 86, 88, 90, 92], "resampl": [9, 50, 88], "method": [9, 20, 23, 30, 31, 34, 35, 38, 39, 40, 46, 49, 50, 51, 52, 53, 56, 57, 59, 61, 64, 70, 71, 74, 75, 79, 86, 90], "frequentist": [9, 32, 39, 50], "deeper": [9, 70], "mostli": [9, 32, 40, 71, 72, 88], "comparison": [9, 56, 57, 60, 62, 76, 79, 92, 96], "hierarch": [9, 16, 22, 30, 32, 56, 58, 73, 76, 96], "markov": [9, 12, 30, 32, 35, 39, 42, 44, 47, 48, 50, 56, 57, 59, 71, 78, 96], "chain": [9, 12, 14, 30, 32, 35, 39, 42, 44, 45, 46, 47, 48, 50, 51, 52, 53, 56, 57, 59, 60, 62, 64, 66, 69, 70, 71, 72, 73, 75, 76, 78, 86, 88, 90, 92, 96], "mont": [9, 12, 30, 32, 35, 39, 42, 45, 47, 48, 50, 56, 57, 71, 78, 92, 96], "carlo": [9, 12, 30, 32, 35, 39, 42, 45, 47, 48, 50, 56, 57, 71, 78, 92, 96], "workflow": [9, 30, 56, 81, 90, 96], "topic": [9, 32, 42, 59, 65, 73, 86, 90], "real": [9, 20, 22, 23, 28, 32, 39, 49, 50, 51, 52, 53, 56, 57, 59, 60, 62, 64, 65, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 90, 92], "enrol": 9, "pleas": [9, 16, 32, 36, 71, 73, 81], "ed": [9, 81, 95], "canva": [9, 81], "assign": [9, 23, 28, 32, 50, 51, 56, 88, 90], "submiss": [9, 90], "password": [9, 90], "protect": [9, 64, 74, 75], "instructor": [9, 81, 96], "justin": [9, 90], "boi": [9, 50, 74, 75, 90], "dot": [9, 51, 86, 89], "ta": [9, 81, 82, 88, 93, 96], "kayla": 9, "jackson": 9, "logic": [9, 28, 53, 61, 73, 90, 95, 96], "scientif": [9, 20, 90, 95, 96], "introduct": [9, 42, 50, 59, 86, 92, 96], "margin": [9, 10, 23, 26, 28, 29, 30, 38, 39, 40, 45, 47, 51, 52, 55, 58, 67, 71, 73, 74, 76, 78, 79, 88, 96], "numer": [9, 30, 38, 39, 40, 51, 61, 69, 73, 74, 78, 88, 90, 92], "quadratur": [9, 40], "5": [9, 20, 22, 28, 29, 32, 34, 35, 38, 39, 40, 41, 44, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 60, 62, 64, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 89, 90, 92, 96], "conjugaci": [9, 35, 73, 96], "e1": 9, "after": [9, 22, 23, 29, 30, 35, 36, 40, 44, 49, 50, 56, 57, 59, 61, 71, 72, 76, 78, 79, 81, 86, 88, 89, 92], "6": [9, 28, 34, 35, 38, 39, 40, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 90, 91, 92, 96], "e2": 9, "7": [9, 20, 22, 32, 34, 35, 38, 40, 41, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 90, 92, 96], "8": [9, 20, 22, 34, 35, 36, 38, 39, 40, 41, 49, 50, 51, 52, 55, 56, 57, 59, 60, 62, 64, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 90, 92, 93, 96], "mcmc": [9, 14, 16, 19, 30, 32, 43, 45, 46, 50, 56, 57, 60, 61, 64, 67, 71, 72, 73, 77, 79, 86, 88, 92, 95, 96], "stan": [9, 19, 20, 32, 42, 45, 46, 51, 53, 57, 58, 59, 60, 62, 64, 66, 67, 71, 72, 81, 88, 95, 96], "9": [9, 20, 22, 34, 35, 38, 40, 49, 50, 56, 57, 59, 60, 62, 64, 67, 69, 70, 72, 73, 74, 75, 76, 78, 79, 81, 86, 90, 92, 94, 96], "label": [9, 61, 64, 65, 70, 86, 89, 92, 96], "switch": [9, 64, 65, 96], "e3": 9, "11": [9, 20, 22, 34, 35, 36, 38, 39, 40, 49, 50, 51, 53, 56, 57, 58, 59, 60, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92, 96], "12": [9, 20, 22, 34, 35, 38, 40, 49, 50, 51, 52, 53, 55, 57, 58, 59, 60, 62, 64, 67, 69, 70, 72, 73, 74, 75, 76, 78, 79, 90, 92, 96], "predict": [9, 13, 15, 17, 23, 40, 49, 50, 52, 58, 62, 64, 67, 71, 72, 75, 79, 89, 90, 92, 96], "13": [9, 34, 35, 38, 40, 49, 50, 51, 52, 53, 55, 56, 59, 60, 62, 64, 70, 72, 73, 74, 75, 76, 79, 90, 92, 96], "e4": 9, "14": [9, 34, 35, 38, 40, 49, 50, 51, 53, 56, 57, 59, 60, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 90, 92, 96], "collector": [9, 96], "box": [9, 23, 44, 88, 96], "15": [9, 20, 22, 34, 35, 36, 38, 39, 40, 49, 50, 51, 55, 56, 57, 60, 64, 67, 70, 72, 73, 74, 75, 76, 79, 86, 90, 92, 96], "diagnost": [9, 14, 16, 46, 51, 53, 62, 64, 67, 72, 73, 75, 76, 78, 88, 92, 96], "16": [9, 20, 22, 34, 40, 49, 50, 51, 53, 56, 57, 59, 64, 70, 72, 73, 74, 75, 76, 79, 86, 90, 92, 96], "artifici": [9, 55], "funnel": [9, 70, 76, 79, 88, 96], "hell": [9, 96], "e5": 9, "18": [9, 20, 22, 34, 49, 50, 51, 52, 55, 56, 57, 59, 62, 64, 67, 69, 70, 72, 73, 75, 76, 79, 86, 92, 96], "practic": [9, 23, 29, 32, 44, 51, 58, 59, 61, 73, 81, 86, 88, 90, 96], "e6": 9, "e7": 9, "21": [9, 34, 35, 38, 40, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 62, 64, 70, 72, 73, 79, 92, 96], "22": [9, 56, 58, 64, 70, 73, 76, 79, 90, 92, 96], "simul": [9, 17, 19, 56, 90, 92, 96], "calibr": [9, 17, 19, 56, 90, 96], "e8": 9, "23": [9, 51, 53, 56, 70, 72, 79, 92], "gaussian": [9, 18, 29, 35, 66, 75, 78, 79, 88], "24": [9, 51, 53, 56, 72, 78, 79, 81, 92, 96], "25": [9, 20, 22, 34, 35, 38, 40, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 70, 72, 73, 74, 75, 76, 78, 90, 92, 96], "e9": 9, "26": [9, 20, 22, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 92, 96], "wrap": [9, 96], "analyt": [9, 30, 32, 36, 39, 40, 47, 52, 60, 76, 79, 88], "maximum": [9, 32, 34, 38, 53, 58, 59, 60, 62, 64, 67, 70, 72, 73, 75, 76, 78, 89, 90, 92], "posteriori": [9, 36, 39, 74], "overview": [9, 87, 90], "date": [9, 81], "exercis": [9, 19, 34, 55, 56, 64], "weekli": [9, 81], "meet": 9, "session": [9, 19, 20, 50, 85, 94], "collabor": [9, 20], "honor": 9, "code": [9, 19, 20, 22, 29, 34, 35, 38, 40, 49, 52, 53, 55, 56, 57, 59, 60, 62, 64, 72, 73, 74, 75, 76, 78, 79, 92], "ediquett": 9, "softwar": [9, 19, 45], "tutori": [9, 60, 64, 90], "winter": 9, "2024": [9, 20, 49, 50, 51, 64], "2022": 9, "2021": [9, 59], "2020": [9, 46], "statement": [10, 51, 52, 56, 73, 78], "sens": [10, 23, 28, 29, 32, 34, 35, 36, 39, 40, 56, 61, 69, 71, 72, 73, 88, 89, 92], "curs": [10, 30, 34], "dimension": [10, 29, 30, 32, 34, 50, 51, 53, 57, 64, 73, 78, 86], "appear": [10, 19, 20, 34, 56, 79, 89], "few": [10, 21, 30, 32, 34, 36, 40, 46, 49, 50, 51, 52, 55, 56, 59, 61, 62, 64, 70, 71, 72, 73, 76, 79, 90, 92], "confus": [10, 11, 72, 73, 81], "approxim": [11, 29, 30, 35, 44, 47, 49, 53, 55, 56, 58, 59, 60, 61, 64, 66, 70, 73, 75, 79, 86, 89, 92], "possibli": [11, 47, 53, 70, 71, 73, 92], "multivari": [11, 29, 30, 32, 39, 40, 58, 73, 76, 86, 88], "stori": [11, 29, 31, 32, 36, 51, 58, 86, 92], "meant": [11, 19, 51, 71, 88], "weakli": [11, 38, 52, 56, 65, 69, 70], "off": [11, 29, 34, 38, 50, 52, 58, 60, 69, 72, 73, 75, 86, 88], "true": [11, 22, 23, 32, 34, 49, 50, 51, 52, 53, 55, 56, 60, 61, 62, 64, 67, 70, 71, 72, 73, 78, 79, 86, 90, 92], "word": [12, 15, 18, 23, 30, 44, 49, 52, 56, 61, 69, 71, 73, 90], "abl": [12, 35, 40, 44, 47, 49, 53, 56, 59, 61, 70, 72, 73, 81, 88, 89, 90, 92], "behind": [12, 18, 29, 36, 43, 49, 61, 64, 79, 81], "warm": [12, 43, 49, 59, 86, 88], "sampler": [12, 14, 42, 45, 46, 49, 50, 51, 53, 57, 60, 62, 70, 71, 86, 92], "nonidentifi": [12, 51], "contend": 13, "suffici": [13, 29, 34, 44, 45, 74], "assess": [13, 32, 38, 49, 51, 56, 58, 64, 71], "better": [13, 32, 44, 51, 53, 57, 61, 62, 64, 70, 72, 73, 76, 79, 81], "agre": [13, 23, 32, 59, 61], "good": [13, 29, 34, 35, 39, 40, 46, 49, 50, 51, 52, 53, 56, 57, 58, 59, 60, 61, 62, 64, 65, 70, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 90, 92, 95], "total": [14, 19, 38, 40, 55, 57, 59, 61, 62, 69, 70, 72, 73, 79, 81, 86, 88, 90, 92], "diverg": [14, 32, 50, 51, 60, 62, 64, 67, 70, 72, 73, 75, 76, 78, 79, 88, 92], "diagnos": [14, 53, 60, 70, 71, 72], "potenti": [14, 53, 86, 88, 92], "ever": [14, 19, 60, 79, 86], "guarante": [14, 22, 32, 38, 39, 51, 59, 79], "properli": [14, 34, 49, 50, 52, 53, 59, 60, 70, 71, 72, 75, 81, 92], "finit": [14, 44, 49, 75, 88], "step": [14, 19, 22, 23, 30, 34, 38, 40, 44, 45, 46, 50, 53, 56, 57, 59, 60, 61, 66, 70, 71, 73, 76, 79, 86, 88, 90, 92], "ye": [14, 50, 57], "stop": [14, 56, 64, 71, 79, 88], "underscor": [14, 51, 61], "extens": [14, 51, 86, 90], "pointwis": [15, 62, 92], "log": [15, 19, 20, 32, 35, 38, 39, 40, 49, 51, 55, 56, 57, 58, 60, 62, 70, 72, 74, 75, 79, 86, 88], "necessari": [15, 19, 20, 34, 45, 46, 47, 51, 55, 58, 59, 70, 76, 81], "waic": [15, 61], "loo": [15, 61, 62], "tidi": [16, 53, 70], "encount": [16, 28, 32, 34, 39, 50, 59, 72, 73, 74, 75, 76, 86, 89, 92], "structur": [16, 23, 35, 50, 51, 58, 76, 79, 81, 88, 90], "own": [16, 19, 20, 21, 22, 23, 50, 73, 75, 79, 81, 88, 90], "briefli": [16, 50, 53, 86], "situat": [16, 32, 64, 65, 92], "exchang": 16, "thoroughli": [16, 79], "especi": [16, 36, 38, 51, 55, 64, 81, 86, 90, 95], "addit": [16, 17, 18, 20, 30, 34, 51, 61, 67, 79, 88, 90, 92], "z": [17, 23, 72, 73, 75, 78], "score": [17, 72], "help": [17, 19, 24, 25, 34, 53, 56, 57, 58, 59, 60, 62, 71, 73, 81, 88, 90, 92, 96], "verifi": [17, 20, 22, 50, 57, 71, 74, 81], "shrinkag": [17, 72], "rank": [17, 18, 55, 59, 60, 62, 64, 70, 72, 79, 86, 92], "statist": [17, 19, 21, 22, 29, 46, 47, 50, 51, 55, 56, 58, 61, 70, 72, 73, 79, 86, 92, 95], "possibl": [17, 22, 23, 27, 29, 31, 32, 44, 50, 51, 52, 53, 55, 56, 61, 70, 71, 72, 73, 79, 86, 88, 90, 92], "pitfal": 17, "By": [17, 24, 29, 32, 47, 53, 59, 64, 71, 73, 86], "cautiou": 17, "sbc": [17, 19, 56, 71, 90], "analys": [17, 20, 30, 71, 90], "elbo": [18, 79], "advantag": [18, 21, 22, 32, 36, 55, 56, 61, 69, 73, 88, 92], "disadvantag": [18, 21, 36], "field": [18, 79, 86, 88, 89], "famili": [18, 30, 73, 79, 88], "run": [19, 20, 21, 22, 23, 34, 40, 49, 50, 51, 56, 59, 60, 70, 71, 72, 76, 79, 81, 88, 92], "power": [19, 22, 47, 49, 50, 51, 59, 61, 71, 73, 86, 90], "instal": [19, 20, 49, 50, 90, 92], "suffic": [19, 38, 56], "serv": [19, 23, 24, 36, 49, 56, 67, 73, 74, 86], "expans": [19, 39], "resourc": [19, 20, 22, 39, 81, 90], "option": [19, 34, 38, 53, 56, 81, 88, 90], "googl": [19, 21, 22, 49, 50, 81, 92], "cloud": [19, 20, 21, 22], "platform": [19, 20], "microsoft": [19, 20, 21], "azur": [19, 21], "high": [19, 21, 29, 32, 39, 46, 53, 59, 60, 73, 74, 75, 86, 90], "center": [19, 32, 39, 51, 55, 56, 60, 70, 74, 75, 76, 78, 86, 92], "lesson": [19, 21, 22, 30, 32, 34, 35, 38, 39, 49, 50, 51, 52, 53, 56, 57, 59, 60, 62, 64, 66, 69, 70, 71, 72, 73, 74, 75, 76, 78, 79, 90], "lot": [19, 23, 34, 49, 50, 53, 57, 58, 61, 62, 70, 73, 76, 92], "onc": [19, 20, 46, 50, 57, 73, 86, 88, 90, 92], "much": [19, 20, 22, 23, 28, 29, 30, 34, 35, 38, 39, 40, 45, 47, 50, 51, 55, 56, 57, 58, 59, 60, 61, 62, 64, 70, 71, 72, 73, 74, 75, 76, 79, 81, 86, 88, 92], "next": [19, 20, 23, 24, 32, 34, 35, 38, 39, 40, 44, 45, 50, 56, 57, 58, 67, 69, 73, 74, 79, 86, 88, 92], "spin": [19, 92], "outlin": [19, 46, 64, 75, 81, 88], "alreadi": [19, 20, 22, 24, 28, 30, 38, 39, 40, 44, 49, 51, 53, 56, 61, 73, 75, 76, 79, 88, 90], "cost": [19, 71], "100": [19, 23, 32, 34, 38, 39, 40, 49, 56, 60, 64, 70, 72, 73, 79, 81, 86, 90, 92, 96], "four": [19, 32, 49, 50, 53, 56, 57, 59, 66, 70, 71, 88], "core": [19, 20, 21, 50, 72, 90], "entir": [19, 32, 38, 56, 58, 70, 75, 81, 85, 86, 89, 90, 94], "consol": [19, 90], "click": [19, 20, 60], "button": 19, "upper": [19, 32, 39, 51, 52, 55, 56, 57, 59, 62, 64, 67, 73, 74, 75, 79, 92], "page": [19, 20, 36, 47, 81, 90, 96], "imag": [19, 34, 35, 50, 56, 58, 60, 76, 86, 89, 92], "ami": 19, "pre": [19, 20, 73, 81, 90], "oregon": [19, 50], "u": [19, 23, 24, 25, 27, 30, 34, 35, 38, 39, 40, 41, 47, 49, 50, 56, 57, 60, 61, 62, 64, 67, 70, 72, 73, 75, 81, 86, 90, 92], "west": 19, "Be": [19, 30, 70], "select": [19, 22, 35, 51, 53, 58, 63, 70, 79, 81, 92], "region": [19, 34, 39, 40, 46, 50, 53, 55, 56, 59, 60, 73, 86, 88], "top": [19, 20, 56, 67, 81], "corner": [19, 51, 52, 55, 57, 60, 62, 64, 67, 70, 72, 73, 75, 76, 78, 79, 86, 92], "same": [19, 20, 23, 24, 28, 29, 32, 35, 36, 38, 40, 45, 49, 50, 51, 53, 57, 59, 60, 61, 64, 65, 70, 71, 72, 73, 74, 75, 76, 79, 86, 88, 89, 92], "throughout": [19, 22, 29, 39, 56, 81, 92, 95], "sinc": [19, 23, 29, 32, 34, 35, 38, 39, 40, 44, 45, 49, 50, 51, 52, 55, 56, 57, 59, 60, 61, 62, 64, 65, 71, 72, 73, 74, 75, 76, 78, 79, 81, 86, 92], "physic": [19, 23, 30, 34, 35, 40, 52, 56, 73, 86, 88, 95], "live": [19, 72, 90], "ec2": 19, "pulldown": [19, 81], "menu": [19, 81], "left": [19, 23, 28, 29, 32, 34, 35, 39, 40, 45, 47, 49, 51, 52, 53, 56, 57, 60, 61, 62, 64, 65, 69, 71, 73, 75, 79, 81, 86, 88, 90, 92], "screen": [19, 49, 53, 81], "pane": 19, "default": [19, 20, 30, 50, 51, 53, 59, 60, 64, 73, 79, 90], "me": [19, 23, 30, 32, 55, 56, 61, 90], "instead": [19, 22, 28, 32, 34, 35, 38, 39, 40, 44, 51, 53, 55, 56, 57, 58, 60, 61, 64, 69, 72, 73, 74, 75, 76, 79, 81, 86, 88, 90, 92], "public": 19, "search": [19, 78, 81], "doubl": [19, 44, 51, 76, 88], "list": [19, 51, 55, 58, 65, 72, 73, 81, 89, 90, 92], "request": [19, 20, 49, 89, 90, 92], "spot": 19, "save": [19, 56, 90, 92], "monei": [19, 23], "lose": [19, 65, 79, 92], "whatev": [19, 73, 90], "name": [19, 23, 29, 31, 32, 44, 49, 50, 51, 52, 53, 55, 56, 58, 59, 60, 61, 62, 64, 81, 90, 92], "tag": [19, 92], "give": [19, 24, 27, 30, 32, 34, 35, 38, 40, 45, 49, 50, 51, 53, 55, 56, 59, 61, 64, 66, 70, 71, 72, 73, 74, 75, 79, 81, 86, 88, 89, 90, 92, 95], "recommend": [19, 20, 42, 59, 79, 86, 90], "back": [19, 69, 71, 72, 73, 79, 81, 86, 88, 90, 92], "simpli": [19, 20, 30, 32, 36, 40, 46, 47, 49, 51, 53, 57, 58, 61, 67, 86, 88, 90, 92], "mine": 19, "skip": [19, 22, 59, 73, 88], "applic": [19, 29, 32, 45, 61, 73, 74, 86, 92], "o": [19, 20, 34, 35, 38, 40, 49, 50, 51, 52, 53, 56, 57, 59, 62, 64, 72, 73, 74, 75, 76, 78, 79, 81, 90, 92], "type": [19, 32, 49, 50, 51, 52, 53, 72, 75, 86, 88, 90, 92], "choic": [19, 32, 36, 40, 53, 55, 57, 58, 69, 73, 74, 79, 81, 86, 92], "c5": 19, "xlarg": 19, "intens": [19, 29, 39, 70, 90], "2xlarg": 19, "larger": [19, 56, 58, 60, 70, 73, 76, 86, 88, 90, 92], "kei": [19, 49, 56, 64, 73, 86], "pair": [19, 23, 30, 34, 35, 51, 56, 73, 79], "login": [19, 90], "pop": 19, "window": [19, 81], "enter": [19, 86], "bebi103_aws_keypair": 19, "fine": [19, 20, 53, 57, 62, 78, 81], "leav": [19, 21, 32, 50, 53, 64, 73, 74, 92], "radio": 19, "NOT": 19, "repeat": [19, 23, 28, 31, 33, 49, 53, 56, 57, 58, 68, 73, 76], "git": [19, 50], "repositori": 19, "anyth": [19, 20, 23, 32, 61, 70, 71, 86, 88, 92], "dropbox": [19, 50], "never": [19, 29, 34, 44, 45, 46, 50, 59, 64, 73, 79], "internet": [19, 21, 90], "reus": 19, "forward": [19, 23, 25, 35, 56, 61, 73, 78, 86, 88], "network": 19, "allow": [19, 20, 39, 44, 45, 47, 49, 51, 52, 56, 57, 59, 60, 62, 64, 67, 73, 75, 76, 78, 79, 81, 86, 88, 90, 92], "ssh": [19, 90], "traffic": 19, "anywher": [19, 49, 72, 81, 95], "everyth": [19, 23, 50, 53, 56, 59, 62, 64, 70, 72, 73, 76, 78], "els": [19, 20, 49, 50, 64, 81, 92], "secur": 19, "ip": 19, "prove": [19, 27, 29, 34, 73, 90], "inconveni": 19, "home": [19, 78, 90], "campu": [19, 90], "configur": [19, 21, 90], "storag": [19, 20, 92], "30": [19, 34, 35, 41, 56, 57, 62, 79, 81, 90, 92, 96], "gib": 19, "gp2": 19, "root": [19, 32, 70, 90], "volum": [19, 34, 56, 86, 88, 90], "enough": [19, 20, 32, 34, 40, 44, 51, 56, 59, 73, 88], "rest": [19, 20, 29, 30, 49, 59, 72, 86, 90], "bottom": [19, 60, 70], "summari": [19, 32, 34, 54, 59, 72, 73], "view": [19, 30, 51, 72, 86, 90], "dashboard": [19, 56], "state": [19, 23, 28, 30, 32, 44, 45, 49, 51, 55, 59, 62, 73, 75, 79, 88, 92], "statu": 19, "readi": [19, 38, 59, 74, 75, 76, 92], "protocol": 19, "instruct": [19, 21, 22, 23, 35, 50, 56, 70, 81], "maco": 19, "linux": [19, 90], "bash": [19, 90], "zsh": 19, "accomplish": [19, 40, 47, 50, 51, 55, 59, 64, 73, 74, 76, 88, 92], "gitbash": 19, "identifi": [19, 30, 34, 35, 36, 39, 49, 51, 56, 59, 61, 71, 72, 73, 81, 86, 88], "put": [19, 32, 50, 52, 53, 56, 58, 59, 65, 71, 72, 73, 75, 86, 89, 90], "keypair": 19, "directori": [19, 20, 50, 78, 81, 90], "key_pair": 19, "pem": 19, "chang": [19, 20, 32, 49, 51, 56, 59, 60, 61, 69, 71, 75, 76, 79, 81, 86, 88, 90, 92, 96], "permiss": 19, "chmod": 19, "400": [19, 36, 39, 41, 59, 60, 70, 79, 86, 92], "clink": 19, "webpag": 19, "ipv4": 19, "54": [19, 51, 59, 67, 69, 70, 79], "92": [19, 64, 79], "67": 19, "command": [19, 22, 50, 86, 90], "user": [19, 50, 74, 75, 88, 90], "avoid": [19, 20, 29, 34, 35, 38, 49, 70, 72, 73, 76, 81, 86], "add": [19, 23, 40, 50, 51, 55, 57, 60, 61, 62, 65, 73, 74, 75, 76, 78, 81, 86, 89, 90, 92], "profil": [19, 79, 90], "echo": [19, 90], "k": [19, 40, 44, 45, 55, 64, 65, 67, 69, 70, 73, 74, 75, 76, 78, 79, 86], "zshrc": 19, "environ": [19, 90], "world": [19, 48], "oyster": 19, "exampl": [19, 23, 25, 30, 31, 33, 34, 35, 36, 38, 39, 44, 46, 47, 49, 51, 53, 55, 56, 58, 59, 61, 63, 65, 66, 69, 70, 72, 75, 76, 78, 81, 86, 90, 92], "clone": 19, "keep": [19, 23, 25, 34, 46, 50, 56, 58, 59, 60, 64, 70, 74, 76, 79, 88, 90], "github": [19, 20, 49, 90, 92], "my_user_nam": 19, "my_favorite_repositori": 19, "folder": [19, 50, 79, 86], "appropri": [19, 23, 49, 51, 55, 56, 59, 70, 73, 81, 86], "path": [19, 20, 34, 35, 38, 40, 49, 51, 52, 53, 56, 57, 59, 62, 64, 72, 73, 74, 75, 76, 78, 79, 81, 86, 90], "ipynb": [19, 81], "whenev": 19, "ad": [19, 30, 51, 53, 64, 73, 74, 78, 90], "bebi103_upd": 19, "ing": 19, "document": [19, 22, 38, 49, 50, 71, 78, 79, 81, 90, 95], "edit": [19, 20, 81, 90], "manag": [19, 49, 50, 60, 90], "push": [19, 72, 74, 76, 88], "pull": [19, 34, 35, 38, 40, 52, 53, 56, 59, 72, 79, 88, 92], "execut": [19, 20, 50, 52, 90], "jupyt": [19, 20, 22, 50, 56, 81, 86, 90], "browser": [19, 20, 72, 90], "server": [19, 90], "runtim": 19, "jpserver": 19, "30060": 19, "html": [19, 20, 56, 81], "Or": [19, 58, 73], "past": [19, 59, 78], "url": 19, "localhost": 19, "8888": 19, "token": 19, "e52184f06c9fb0f9ceea176b1d51d9cb36c72a019e688f": 19, "127": 19, "order": [19, 20, 23, 30, 32, 34, 35, 39, 44, 49, 50, 55, 56, 57, 58, 59, 61, 64, 70, 71, 72, 73, 75, 81, 86, 90, 92], "socket": 19, "anoth": [19, 24, 35, 36, 44, 50, 51, 53, 56, 58, 59, 60, 61, 64, 65, 70, 73, 86, 92, 95], "l": [19, 34, 35, 38, 40, 52, 56, 71, 73, 76, 79, 81], "8000": 19, "port": [19, 90], "got": [19, 24, 34, 49, 55, 59, 60, 61, 73, 74, 79, 86, 90, 92], "8889": 19, "substitut": [19, 30, 34, 61, 69, 73, 79], "8001": 19, "90": [19, 29, 56, 67, 70, 79], "direct": [19, 36, 73, 88], "specifi": [19, 29, 30, 34, 35, 38, 49, 50, 51, 52, 53, 56, 57, 58, 64, 65, 70, 73, 74, 79, 88, 90], "8890": 19, "notebook": [19, 20, 22, 49, 50, 56, 72, 81, 86, 88, 90, 92], "move": [19, 32, 45, 56, 59, 60, 72, 88, 90], "commit": 19, "intermedi": [19, 40, 56, 92], "scp": [19, 90], "yet": [19, 22, 32, 57, 73, 76, 81, 92], "my_fil": 19, "transfer": [19, 92], "colon": 19, "rememb": [19, 29, 30, 32, 34, 49, 50, 52, 56, 61, 64, 73, 74, 79], "second": [19, 22, 30, 32, 34, 35, 38, 39, 40, 49, 50, 53, 56, 57, 58, 64, 69, 71, 72, 73, 75, 79, 81, 90, 92], "argument": [19, 32, 34, 38, 40, 51, 52, 74, 78, 90], "similarli": [19, 23, 28, 40, 61, 73, 92], "upload": 19, "txt": [19, 50], "finish": [19, 50, 90, 92], "shut": 19, "shutdown": 19, "prompt": [19, 22, 88, 90], "hard": [19, 29, 38, 56, 70, 75, 76], "press": [19, 28, 40], "ctrl": 19, "unless": [19, 46, 50, 55, 79], "realli": [19, 23, 29, 30, 32, 34, 35, 38, 56, 58, 60, 61, 64, 71, 72, 73, 75, 76, 79, 81, 88, 92], "rid": 19, "charg": 19, "rack": 19, "massiv": 19, "bill": 19, "idl": [19, 20], "minor": [19, 56], "pain": 19, "wait": [19, 23, 29, 36, 73, 90], "forget": [19, 90], "pocketbook": 19, "easier": [19, 23, 29, 30, 34, 38, 51, 55, 61, 73, 74, 88], "navig": [19, 20], "either": [19, 20, 22, 34, 35, 49, 53, 56, 58, 59, 88, 90], "via": [19, 20, 31, 36, 49, 50, 70, 73, 81], "spun": 19, "fire": [19, 20], "per": [19, 32, 34, 49, 56, 58, 60, 64, 70, 72, 73, 79, 86, 90, 92], "eb": 19, "etc": [19, 20, 23, 29, 30, 50, 66, 69, 73, 78, 79, 81, 90], "intact": 19, "free": [19, 20, 21, 57, 61, 70, 74, 79, 81, 86], "tier": [19, 20], "expir": 19, "promo": 19, "These": [19, 20, 23, 34, 45, 49, 50, 51, 53, 56, 59, 67, 70, 72, 73, 78, 81, 86, 90, 92], "wipe": 19, "provid": [20, 28, 29, 34, 38, 39, 40, 44, 49, 50, 51, 59, 61, 64, 70, 71, 73, 74, 75, 81, 90, 95], "conveni": [20, 29, 32, 34, 38, 39, 40, 44, 47, 49, 50, 51, 53, 55, 56, 57, 59, 61, 64, 66, 70, 73, 75, 76, 78, 86, 88], "must": [20, 23, 28, 29, 34, 36, 38, 39, 49, 50, 52, 64, 71, 73, 76, 79, 81, 88, 90, 92, 96], "account": [20, 49, 59, 81, 90, 92], "student": [20, 34, 58, 69, 81, 82, 93, 95], "employe": 20, "suit": 20, "person": [20, 55, 90], "gmail": 20, "youtub": [20, 95], "facilit": [20, 31, 78, 90], "teammat": [20, 81], "staff": [20, 81], "machin": [20, 21, 50, 61, 72, 73, 90], "annoi": [20, 21, 50], "trick": [20, 30, 34, 45, 51, 70, 86, 92], "safari": 20, "edg": [20, 86], "web": 20, "brows": 20, "test": [20, 23, 57, 61, 71, 72, 79, 90, 92], "chrome": 20, "firefox": 20, "jupyterlab": [20, 22, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 92], "support": [20, 79], "three": [20, 29, 34, 40, 51, 52, 53, 55, 57, 58, 59, 61, 64, 66, 67, 69, 71, 81, 90], "launch": [20, 51], "altern": [20, 38, 49, 58, 60, 61, 69, 86, 88, 90], "badg": 20, "content": [20, 31, 50, 51, 56, 58, 73, 75, 78, 79], "virtual": [20, 90], "two": [20, 21, 22, 23, 29, 30, 32, 34, 35, 36, 38, 40, 45, 49, 50, 51, 55, 56, 57, 58, 59, 61, 62, 64, 65, 66, 69, 70, 71, 72, 73, 78, 79, 80, 86, 88, 89, 90], "cpu": [20, 90], "gb": 20, "vari": [20, 22, 23, 29, 38, 53, 56, 69, 70, 73, 74, 76, 79, 86, 88], "ram": [20, 50], "gpu": [20, 90], "tpu": 20, "tensor": 20, "too": [20, 23, 29, 32, 34, 35, 45, 55, 58, 59, 60, 71, 72, 73, 74, 76, 79, 81, 86, 88], "long": [20, 23, 32, 45, 46, 50, 55, 58, 59, 65, 75, 76, 86, 88, 89, 92], "disconnect": [20, 21], "timeout": 20, "almost": [20, 28, 29, 30, 32, 34, 38, 40, 44, 46, 47, 49, 51, 58, 64, 72, 73, 74, 81], "alwai": [20, 22, 23, 29, 32, 34, 38, 40, 44, 47, 49, 51, 55, 56, 58, 64, 65, 73, 79, 81, 86, 92], "effici": [20, 56, 59, 78, 88, 90], "exce": 20, "present": [20, 23, 34, 38, 50, 51, 53, 56, 60, 62, 70, 71, 74, 75, 78, 81, 88, 91], "place": [20, 38, 55, 56, 75, 76, 81, 88], "offer": [20, 34, 38, 45, 53, 59, 61, 64, 90, 92], "longer": [20, 32, 35, 49, 51, 56, 65, 74, 78, 86, 88], "pro": [20, 21], "howev": [20, 32, 34, 36, 39, 40, 47, 49, 51, 56, 57, 58, 59, 60, 61, 64, 71, 73, 74, 75, 81, 86, 88, 89, 90, 92], "encourag": [20, 70, 71, 73, 81], "app": [20, 86], "python": [20, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 81, 86, 92, 95], "callback": [20, 56], "instanc": [20, 21, 34, 49, 50, 56], "major": [20, 32, 34, 38, 40, 56, 71], "burden": 20, "circumv": 20, "upgrad": [20, 21, 49, 92], "faq": 20, "latest": 20, "januari": [20, 96], "wherea": [20, 39, 88], "anaconda": 20, "preinstal": 20, "variant": [20, 64], "thereof": [20, 61, 64, 81], "affect": [20, 32, 36, 39, 72, 73], "cmdstanpi": [20, 49, 50, 51, 52, 53, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 90, 92, 95], "install_cmdstan": [20, 22, 49, 92], "setup": [20, 21, 49, 58, 75, 92], "sy": [20, 49, 81, 92], "subprocess": [20, 29, 49, 92], "modul": [20, 38, 44, 49, 53, 56, 73, 81, 90, 92], "cmd": [20, 49, 92], "pip": [20, 49, 90, 92], "polar": [20, 34, 35, 38, 40, 49, 51, 52, 53, 55, 56, 57, 59, 62, 64, 70, 72, 73, 74, 75, 76, 78, 79], "iqplot": [20, 49, 50, 51, 52, 55, 56, 59, 67, 70, 72, 76, 79, 92], "colorcet": [20, 49, 50, 92], "datashad": [20, 49], "arviz": [20, 22, 49, 51, 52, 55, 56, 57, 59, 60, 61, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 90, 92, 95], "watermark": [20, 22, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 92], "popen": [20, 49, 92], "split": [20, 23, 30, 49, 51, 56, 61, 90, 92], "stdout": [20, 49, 50, 90, 92], "pipe": [20, 49, 92], "stderr": [20, 49, 90, 92], "data_path": [20, 34, 35, 38, 40, 49, 51, 52, 53, 56, 57, 59, 62, 64, 72, 73, 74, 75, 76, 78, 79, 81, 92], "ensur": [20, 29, 46, 51, 59, 60, 71, 76, 78, 81, 88, 92], "recent": [20, 70, 81, 90], "cmdstan": [20, 22, 49, 50, 51, 52, 53, 56, 57, 59, 60, 62, 64, 70, 72, 73, 74, 75, 76, 78, 79, 92], "drawback": [20, 39, 53, 55], "built": [20, 34, 38, 44, 50, 51, 56, 59, 64, 67, 70, 73, 78, 92], "binari": 20, "shutil": [20, 49, 92], "urllib": [20, 49, 92], "latest_vers": [20, 49, 92], "cmdstan_vers": [20, 22, 49, 50, 51, 52, 53, 56, 57, 59, 60, 62, 64, 70, 72, 73, 74, 75, 76, 78, 79, 92], "cmdstan_url": [20, 49, 92], "dev": [20, 34, 49, 92], "releas": [20, 49, 53, 92], "fname": [20, 49, 79, 92], "tgz": [20, 49, 92], "urlretriev": [20, 49, 92], "unpack_arch": [20, 49, 92], "faster": [20, 32, 34, 39, 49, 56, 58, 72, 81, 90], "mode": [20, 39, 50, 51, 55, 88], "fetch": [20, 78], "aw": [20, 21, 50], "hidden": 20, "render": [20, 41, 53, 56, 81, 86], "clutter": [20, 29, 49, 50], "collab": 20, "az": [20, 22, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 90, 92], "schools_data": [20, 22], "28": [20, 22, 51, 56, 72, 76, 79, 92, 96], "schools_cod": [20, 22], "int": [20, 22, 28, 29, 30, 32, 34, 44, 45, 47, 49, 51, 52, 53, 56, 57, 59, 60, 61, 62, 64, 67, 70, 71, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92], "lower": [20, 22, 23, 32, 39, 49, 51, 52, 53, 55, 56, 57, 59, 60, 61, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 88, 90, 92], "school": [20, 22], "vector": [20, 22, 51, 56, 64, 70, 73, 74, 75, 76, 78, 79, 86, 88], "treatment": [20, 22, 39, 40, 52, 71], "tau": [20, 22, 32, 70, 79], "eta": [20, 22, 79], "transform": [20, 22, 23, 28, 32, 44, 49, 50, 51, 52, 53, 57, 58, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92], "theta": [20, 22, 23, 24, 25, 27, 28, 30, 32, 34, 36, 38, 39, 44, 45, 47, 50, 51, 56, 58, 60, 61, 64, 65, 66, 67, 69, 70, 71, 76, 79, 86, 92], "w": [20, 22, 30, 51, 56, 64, 70, 79, 88, 90, 96], "disable_log": [20, 22, 49, 51, 52, 53, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 90, 92], "sm": [20, 22, 49, 50, 51, 52, 53, 57, 59, 60, 64, 67, 72, 74, 75, 76, 78, 79, 81, 90, 92], "cmdstanmodel": [20, 22, 49, 50, 51, 52, 53, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 81, 90, 92], "stan_fil": [20, 22, 49, 50, 51, 52, 53, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 90, 92], "output_dir": [20, 22, 90], "show_progress": [20, 22, 49, 50, 56, 79, 90, 92], "fals": [20, 22, 40, 49, 50, 51, 53, 55, 56, 59, 62, 64, 70, 72, 73, 74, 75, 79, 86, 90, 92], "from_cmdstanpi": [20, 22, 49, 50, 51, 52, 53, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 75, 76, 78, 79, 90, 92], "clean_cmdstan": [20, 22, 49, 50, 51, 52, 53, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 92], "250": [20, 22, 34, 35, 38, 40, 49, 52, 53, 55, 56, 57, 62, 72, 73, 74, 75, 76, 78, 79], "\u03bc": [20, 22, 34], "\u03c4": [20, 22, 70, 79], "ravel": [20, 22, 49, 50, 92], "load_ext": [20, 22, 34, 35, 36, 38, 39, 40, 41, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 92], "cpython": [20, 22, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 92], "ipython": [20, 22, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 55, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 86, 92], "27": [20, 22, 49, 51, 53, 56, 70, 72, 74, 75, 76, 78, 79, 92, 96], "requir": [21, 23, 30, 44, 47, 49, 56, 59, 61, 72, 79, 81, 86, 88, 89, 90], "signific": [21, 45, 56, 73, 90], "prefer": [21, 23, 32, 52, 53, 56, 61, 64, 90, 92], "connect": [21, 23, 61, 62, 86, 90], "larg": [21, 23, 29, 32, 34, 35, 47, 49, 52, 56, 59, 60, 61, 70, 72, 73, 74, 76, 79, 81, 86, 90, 92], "loud": 21, "hot": 21, "unavail": [21, 34], "dure": [21, 46, 49, 56, 81], "colab": [21, 22, 49, 50, 81, 92], "pretti": [21, 32, 36, 44, 47, 51, 53, 56, 61, 72, 73, 88, 90, 92], "fast": [21, 38, 56, 61, 70], "biggest": [21, 90], "interact": [21, 50, 56, 58, 89, 90], "babysit": 21, "commerci": 21, "servic": [21, 30, 90], "hpc": 21, "oper": [22, 32, 49, 51, 73, 75, 88, 90, 92], "BE": [22, 80], "bi": [22, 53, 69, 80], "103": [22, 80], "probabilist": [22, 23, 28, 29, 32, 49, 50, 88], "program": [22, 29, 49, 52, 78, 90], "languag": [22, 29, 49, 50, 81, 92], "translat": [22, 50, 88], "parser": 22, "compil": [22, 49, 50, 51, 56, 57, 59, 60, 62, 64, 67, 72, 73, 74, 75, 76, 78, 79, 81, 90, 92], "interfac": [22, 49, 50, 79, 95], "wide": [22, 29, 32, 34, 45, 46, 61, 72, 73, 75, 90], "rstan": 22, "pystan": [22, 50], "respect": [22, 29, 32, 34, 40, 50, 51, 53, 55, 60, 61, 64, 65, 67, 70, 73, 75, 78, 79, 81], "simpler": [22, 56, 58, 74, 92], "becom": [22, 23, 24, 30, 32, 34, 35, 40, 47, 51, 56, 58, 61, 86, 88, 89, 92], "appar": [22, 70, 75, 92], "whichev": 22, "tricki": [22, 34, 64, 73], "system": [22, 29, 50, 61, 69, 73, 86, 88, 90], "troubleshoot": 22, "worri": [22, 44, 55, 92], "troubl": [22, 56, 59, 60, 81], "On": [22, 58, 69, 86, 92], "xcode": 22, "previous": [22, 53, 59, 79, 90], "One": [22, 28, 29, 30, 34, 44, 55, 56, 70, 79, 86, 88, 90, 92], "mingw": 22, "conda": [22, 90], "libpython": 22, "m2w64": 22, "msys2": 22, "util": [22, 28, 32, 36, 88, 90, 95], "raspberri": 22, "pi": [22, 25, 27, 28, 29, 30, 32, 34, 39, 53, 56, 57, 60, 62, 64, 67, 71, 73, 76, 79, 86, 88, 90, 92], "took": [22, 34, 36, 40, 45, 59, 61, 69, 79], "appreci": 22, "nifti": [22, 92], "demonstr": [22, 29, 32, 36, 50, 51, 55, 56, 64, 67, 73, 76, 78, 81, 88, 90], "trivial": [22, 23, 47, 50, 57, 86, 90], "feat": 22, "warn": [22, 39, 49, 60, 62, 64, 72], "print": [22, 34, 38, 40, 49, 50, 51, 52, 53, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 81, 86, 90, 92], "36": [22, 34, 35, 38, 51, 62, 74, 75, 76, 78, 79, 92], "thought": [23, 36, 38, 81], "inquiri": 23, "visit": [23, 34, 46], "refresh": [23, 61, 72, 79, 86], "sketch": [23, 29, 32], "cycl": 23, "itself": [23, 56, 61, 64, 70, 74, 88], "natur": [23, 29, 49, 56, 58, 61, 64, 92], "mileston": 23, "along": [23, 32, 46, 49, 50, 53, 58, 59, 62, 86, 88, 90], "arrow": 23, "orang": [23, 34, 36, 38, 40, 49, 51, 60, 70, 72, 73, 74, 75, 76, 78, 79, 86], "adapt": [23, 49, 50, 72, 79], "fig": [23, 71], "gregori": [23, 95], "cambridg": [23, 28], "2005": 23, "hypothesi": [23, 24, 27, 30], "invent": 23, "refin": [23, 29], "stage": [23, 29, 56], "hypothes": [23, 25, 27, 28], "theori": [23, 39, 49, 64], "pursu": 23, "innov": 23, "sometim": [23, 38, 51, 56, 58, 61, 79, 89, 90], "geniu": 23, "deduct": [23, 81], "deduc": 23, "experiment": [23, 56, 69, 70, 79, 92], "seri": [23, 35, 36, 55, 71, 73, 89, 92, 95], "strong": [23, 49, 51, 59, 73, 76, 79, 92], "syllog": 23, "therefor": [23, 27, 29, 31, 32, 34, 35, 36, 38, 39, 40, 49, 50, 52, 56, 58, 59, 61, 64, 72, 73, 75, 76, 79, 81, 86, 89], "plausibl": [23, 29, 30], "perhap": [23, 30, 32, 36, 56, 58, 59, 64, 69, 73, 88], "familiar": [23, 31, 50, 51, 56, 58, 72, 73, 86, 92], "talk": [23, 28, 29, 32, 36, 44, 53, 59, 71], "bullet": 23, "But": [23, 29, 32, 35, 38, 39, 44, 45, 47, 49, 50, 52, 55, 58, 59, 61, 72, 73, 74, 79], "knowledg": [23, 24, 29, 30, 32, 36, 45, 52, 56, 58, 61, 71, 74, 86], "design": [23, 56, 70, 89, 92], "Not": [23, 50, 56, 70, 72], "necessarili": [23, 32, 38, 49, 55, 56, 59, 61, 92], "weak": [23, 32, 88], "wastewat": 23, "hydraul": 23, "fractur": 23, "frack": 23, "lead": [23, 30, 32, 39, 49, 51, 56, 60, 64, 76, 86], "greater": [23, 56, 58, 59], "earthquak": 23, "frequenc": [23, 49, 51, 56, 59, 72], "oklahoma": 23, "increas": [23, 34, 56, 70, 72, 73, 86, 88, 90, 92], "2010": 23, "becam": 23, "busi": [23, 92], "obeserv": 23, "role": 23, "crucial": [23, 51, 59, 60, 61, 86], "t": [23, 28, 29, 32, 34, 38, 39, 44, 45, 50, 55, 56, 58, 59, 60, 61, 64, 70, 71, 72, 73, 74, 75, 76, 78, 79, 86, 88, 89, 90, 92], "jayn": [23, 28], "domin": [23, 34, 64, 67, 72], "interpret": [23, 24, 28, 30, 39, 55, 57, 61, 73, 90], "repres": [23, 49, 53, 67, 71, 73, 88, 92], "ident": [23, 28, 29, 38, 49, 59, 64, 92], "repetit": 23, "hypothet": [23, 92], "event": [23, 28, 31, 32, 45, 58, 59, 61], "restrict": [23, 36, 73, 79], "proposit": [23, 30], "quantiti": [23, 25, 28, 29, 30, 32, 34, 50, 56, 57, 58, 61, 62, 64, 72, 73, 75, 76, 78, 79, 88, 90, 92], "meaningfulli": 23, "degre": [23, 49], "belief": [23, 49], "fight": 23, "peopl": 23, "who": [23, 81], "appli": [23, 24, 27, 28, 30, 49, 59, 60, 61, 65, 70, 73, 75, 79, 81, 86, 88, 90, 92], "valid": [23, 61, 64, 78], "exclus": 23, "great": [23, 31, 32, 46, 75, 90, 92, 95], "opinion": [23, 45, 53, 92], "proce": [23, 34, 35, 39, 40, 64, 71, 74, 76, 78, 79], "conceptu": [23, 25, 32, 36, 42, 86], "cleaner": 23, "certainti": 23, "convers": [23, 28, 56, 61, 81], "fix": [23, 34, 49, 50, 51, 53, 59, 73, 74, 86, 92], "convert": [23, 32, 44, 49, 50, 51, 53, 56, 57, 58, 59, 61, 64, 70, 73, 75, 78, 79, 86], "1946": 23, "cox": 23, "laid": [23, 30, 36, 46, 50, 53, 59, 72, 78], "desir": [23, 46, 61, 73, 90], "properti": [23, 30, 44, 46, 47, 73, 76, 79, 88], "expand": [23, 51, 88, 90], "1970": [23, 92], "ration": 23, "suppli": 23, "rise": [23, 89], "monoton": [23, 38, 61], "manner": 23, "consist": [23, 28, 32, 36, 47, 50, 59, 71, 72, 74, 81, 86], "proprieti": 23, "relev": [23, 32, 34, 38, 39, 40, 55], "satisfi": [23, 44, 45, 46, 47, 59, 60, 61, 71, 88], "paus": [23, 29, 30, 34, 51, 52, 61, 88], "without": [23, 28, 30, 31, 32, 36, 40, 46, 50, 60, 61, 73, 75, 81, 86, 90, 92], "chapter": 23, "uniti": [23, 45, 59, 71, 72, 73], "except": [23, 49, 50, 56, 76, 81, 88, 92], "complement": 23, "interest": [23, 29, 31, 34, 36, 40, 45, 47, 49, 50, 51, 53, 58, 59, 61, 67, 70, 73, 86, 89, 92], "happen": [23, 29, 39, 56, 57, 59, 60, 61, 73, 81, 90], "denot": [23, 25, 28, 30, 32, 39, 59, 61, 73, 86, 88], "notion": [23, 32, 61, 88], "bit": [23, 25, 28, 29, 32, 34, 36, 38, 44, 46, 51, 55, 56, 60, 61, 70, 71, 74, 75, 88, 90, 92], "abstract": 23, "bring": [23, 32, 58, 61, 73, 92], "realm": [23, 61, 92], "ll": [23, 35, 40, 49, 50, 55, 57, 58, 59, 60, 62, 64, 71, 72, 75, 76, 79, 86, 90], "been": [23, 28, 30, 40, 56, 61, 74, 76, 79, 90], "rewrit": [23, 56, 69], "explicitli": [23, 29, 34, 45, 50, 51, 61, 65, 73, 76, 81, 92], "henceforth": [23, 73], "vacuum": 23, "ahoi": 23, "pictur": [23, 34, 35, 52, 53, 59, 73, 90], "cannot": [23, 28, 32, 34, 35, 36, 40, 45, 47, 49, 51, 53, 56, 57, 58, 60, 61, 62, 70, 73, 75, 76, 79, 86], "perspect": [23, 86, 88], "analyz": [23, 30, 49, 62, 70, 71, 81, 89], "commut": 23, "side": [23, 28, 34, 40, 71, 73, 89, 92], "seemingli": [23, 49], "equal": [23, 32, 39, 45, 61, 71, 79, 89], "rearrang": [23, 79, 92], "far": [23, 28, 30, 38, 39, 44, 49, 56, 60, 64, 71, 74, 76, 81, 90], "goal": [23, 30, 34, 36, 38, 39, 44, 47, 61, 76, 79], "hand": [23, 28, 34, 38, 49, 52, 55, 57, 69, 71, 75, 81, 86, 88, 92], "item": [23, 51, 55, 86, 90, 92], "believ": [23, 32, 38, 65, 90], "acquir": [23, 24, 36, 49, 50, 74, 76], "instrument": [23, 65], "constitut": [23, 61], "bulk": [23, 35, 56], "algebra": [23, 34, 73, 78], "outcom": [23, 28, 31, 32, 61, 69, 70, 86], "cute": 23, "acronym": 23, "feel": [23, 32, 36, 49, 52, 81, 86], "try": [23, 29, 30, 32, 36, 51, 56, 58, 59, 60, 64, 69, 70, 76, 79, 81, 88, 90, 92], "head": [23, 35, 51, 53, 70, 72, 79, 86], "around": [23, 34, 35, 38, 45, 51, 53, 56, 58, 61, 70, 71, 76, 86, 88, 92], "plug": [24, 29, 61], "product": [24, 29, 30, 32, 34, 51, 56, 69, 73, 79, 81, 88, 92], "rule": [24, 27, 32, 35, 45, 46, 57, 59, 62, 71, 81], "denomin": 24, "insert": [24, 36, 56, 71], "equat": [24, 29, 44, 61, 69, 71, 81, 86, 88, 92], "yield": [24, 51, 71, 73, 92], "gave": [24, 50, 72], "combin": [24, 51, 56, 64, 90, 92], "acquisit": [24, 58], "constantli": 24, "symbol": [25, 29, 73, 88], "overload": 25, "aid": 25, "convent": [25, 78], "densiti": [25, 28, 29, 32, 34, 35, 38, 39, 45, 47, 49, 52, 53, 55, 56, 60, 64, 73, 75, 79, 86, 88], "non": [25, 49, 51, 58, 60, 73, 77], "evid": [25, 27, 29, 30, 51, 58, 79, 86, 92], "joint": [25, 27, 30, 34, 45, 56, 60, 71, 73, 79, 86, 88, 92], "speak": [25, 30, 58, 59, 73, 88], "track": [25, 46, 59, 70, 79], "scienc": [26, 28, 38, 40, 52, 53, 56, 62, 73, 95], "notat": [26, 28, 29, 34, 44, 61, 73, 75], "bay": [26, 27, 29, 30, 36, 59, 61, 66, 69, 73, 79, 92], "theorem": [26, 27, 29, 30, 31, 36, 61, 66, 69, 71, 73, 86, 88, 92], "mention": [27, 32, 49, 60, 64, 69, 90], "theta_i": [27, 32, 39, 44, 45, 47, 65, 67, 69, 71, 79], "particular": [27, 32, 35, 47, 49, 50, 51, 53, 55, 57, 59, 60, 67, 73, 74, 88, 92], "theta_j": [27, 32, 38, 39, 79], "c_j": [27, 73], "nonumb": [27, 29, 45, 61], "ne": [27, 61, 73, 76], "sum_i": [27, 28, 38, 61, 73, 86], "elimin": [27, 88], "lectur": [28, 30, 32, 42, 46, 49, 53, 61, 64, 71, 80, 81, 96], "verbatim": 28, "space": [28, 32, 34, 44, 45, 46, 52, 53, 55, 57, 59, 70, 71, 86, 90, 92], "introduc": [28, 32, 50, 51, 56, 73, 74, 79, 86, 88], "deal": [28, 32, 45, 51, 59, 70, 72, 88, 92], "discret": [28, 30, 32, 44, 45, 51, 58, 64, 73, 86, 88], "notation": 28, "le": [28, 34, 35, 40, 56, 73], "cumul": [28, 39], "cdf": [28, 38, 39, 41, 44, 47, 49, 51, 53, 58, 67], "shown": [28, 32, 35, 38, 44, 45, 56, 61, 71, 73, 86], "panel": 28, "height": [28, 34, 60, 70, 86], "men": 28, "centimet": 28, "countri": 28, "ly": [28, 74, 75, 78], "y_0": 28, "int_": [28, 86], "satisfact": 28, "axiom": [28, 86], "infti": [28, 29, 32, 34, 35, 38, 58, 73], "necessit": [28, 65], "pmf": [28, 31, 36, 51, 90, 92], "unlik": [28, 29, 40, 51, 56, 58, 60, 64, 70, 86, 92], "roll": 28, "fair": 28, "die": [28, 75], "seen": [28, 30, 34, 36, 44, 49, 51, 55, 57, 59, 62, 66, 73, 75, 78, 86], "hold": [28, 44, 45, 51, 56, 71, 73], "immedi": [28, 36, 47, 50, 56, 60, 70, 72], "consequ": 28, "conjectur": [28, 73], "final": [28, 35, 40, 47, 49, 61, 64, 70, 71, 72, 73, 74, 76, 79, 81, 88, 96], "f_x": 28, "subscript": [28, 47, 61, 70], "enforc": [28, 51], "mathbf": [28, 49, 73, 74, 75, 76, 78, 86], "partial": [28, 32, 39, 75, 86, 88], "factor": [28, 29, 34, 65, 66, 73, 79, 90], "jacobian": 28, "absolut": [28, 60, 86], "jacobi": [28, 32], "pmatrix": [28, 32, 36, 73, 86], "cdot": [28, 29, 32, 38, 39, 47, 58, 69, 73, 75, 76, 86, 88, 92], "vdot": [28, 32], "ddot": [28, 32], "beta": [28, 39, 40, 41, 44, 49, 51, 52, 53, 56, 57, 58, 59, 62, 64, 65, 66, 67, 69, 72, 73, 75, 79, 88, 90, 92], "rescal": [28, 86], "accordingli": [28, 79], "sqrt": [28, 29, 32, 34, 38, 39, 40, 60, 73, 74, 75, 86, 88, 90], "ln": [28, 32, 34, 38, 39, 44, 51, 56, 57, 61, 62, 64, 73, 74, 76, 78, 79, 92], "subtl": [28, 32], "univers": [28, 69], "2003": 28, "subtleti": [28, 61], "simplest": [29, 35, 47, 53, 90], "beak": [29, 64], "depth": [29, 34, 60, 62, 64, 67, 70, 72, 73, 75, 76, 78, 92], "finch": [29, 64], "fluoresc": [29, 49, 70, 89, 92], "abound": 29, "concret": [29, 30, 32, 61, 70, 73, 92], "elegan": [29, 31, 32, 58, 69], "egg": [29, 31, 32, 36, 38, 52, 58], "equiv": [29, 32, 56, 61, 70, 73], "ambigu": [29, 61], "sharpen": 29, "low": [29, 32, 40, 46, 51, 53, 70, 73, 74, 75, 88, 92], "codifi": [29, 30, 32, 52, 61], "everi": [29, 32, 35, 38, 39, 45, 51, 52, 56, 57, 74, 76, 81, 86, 88, 90, 92], "prod_": [29, 34, 61, 65, 92], "delta": [29, 30, 61, 75, 76, 78], "dirac": [29, 30, 61], "shall": [29, 34, 73], "heavi": [29, 55, 58, 74, 88, 90, 92], "univari": [29, 53, 57, 58, 76, 78], "pdf": [29, 31, 32, 34, 35, 36, 38, 39, 40, 47, 49, 53, 55, 56, 72, 74, 81, 88], "exp": [29, 34, 35, 38, 39, 40, 51, 60, 61, 64, 73, 74, 75, 76, 78, 86, 92], "standard": [29, 30, 50, 55, 56, 64, 70, 71, 72, 73, 74, 75, 81, 88], "varianc": [29, 31, 38, 46, 50, 56, 58, 59, 60, 61, 70, 71, 72, 73, 75, 88], "confusingli": 29, "literatur": [29, 81], "central": [29, 31, 39, 53, 55, 88, 90], "emerg": 29, "tend": [29, 32, 38, 51, 59, 60, 61, 64, 67, 71, 73, 75], "none": [29, 31, 41, 49, 56, 58, 62, 72, 90], "broadli": 29, "mathsf": [29, 32, 38, 39, 58, 73, 74, 75, 76, 78, 79, 86], "boldsymbol": [29, 73, 74, 75, 76, 78, 79], "det": [29, 32, 86], "mu_1": 29, "mu_2": [29, 55], "mu_n": 29, "symmetr": [29, 39, 71, 73, 79], "posit": [29, 32, 34, 35, 38, 39, 44, 45, 46, 49, 56, 64, 65, 70, 73, 74, 75, 76, 78, 79, 86, 88], "diagon": [29, 38, 39, 51, 72, 73, 74, 76, 78, 79], "y_j": 29, "correl": [29, 49, 51, 59, 73, 86, 88], "anticorrel": [29, 53], "reduc": [29, 62, 90], "2_i": 29, "multi": [29, 55, 78, 92], "decid": [29, 32, 56, 76, 81, 89, 92], "spread": [29, 72, 76, 90], "sought": 29, "beyond": [29, 32, 34, 61, 72, 75, 81], "int_0": [29, 32, 34, 35], "current": [29, 32, 34, 45, 53, 61, 88, 92], "guess": [29, 32, 35, 38, 40, 74, 75, 86], "\u00b5m": [29, 32, 34, 35, 38, 40, 52, 53, 56, 57, 58, 62, 79], "mu_": [29, 32], "tini": [29, 39, 60], "five": [29, 66, 71, 72], "ten": [29, 32, 58, 89], "micron": [29, 32, 38, 52], "unphys": [29, 56, 72], "mathemat": [29, 32, 34, 35, 36, 38, 56, 58, 61, 73, 79, 81, 88, 90], "disallow": 29, "roughli": [29, 30, 71, 89, 92], "piec": [29, 38], "cover": [29, 32, 45, 62, 90], "exclud": 29, "unreason": [29, 73], "brace": [29, 50, 51, 52, 56], "oh": [29, 92], "mess": [29, 61], "challeng": [29, 30, 31, 32, 36, 51, 70, 73, 90], "easi": [29, 30, 36, 39, 51, 55, 56, 60, 79, 86, 90, 92], "shorthand": [29, 44], "integr": [29, 30, 32, 34, 35, 36, 40, 44, 45, 47, 60, 61, 71, 79, 92, 96], "omit": [29, 61], "english": [29, 71], "self": [29, 71, 72], "nasti": [29, 36, 47], "am": [29, 38, 47, 51, 58, 61, 64, 67, 81, 90, 92, 96], "nor": [29, 32, 38, 55, 64, 73, 74, 90], "maintain": [29, 32], "focu": [29, 30, 34, 44, 49, 51, 56, 73], "loos": [30, 59, 61, 88], "explicit": [30, 56, 73], "unambigu": [30, 51, 56], "descript": [30, 49, 59, 71, 72, 88, 92], "prescrib": [30, 56, 58], "asid": [30, 59], "philosoph": 30, "gelman": [30, 44, 46, 61, 64, 95], "simpson": [30, 53], "betancourt": [30, 42, 51, 57, 59, 60, 71, 86, 88, 95], "clearli": [30, 34, 36, 49, 51, 57, 60, 64, 67, 70, 72, 79, 81, 89, 92], "dilemma": 30, "2017": [30, 67, 69, 79, 86], "apt": [30, 49], "titl": [30, 49, 55, 56, 86, 92], "emphasi": [30, 55, 74], "sort": [30, 36, 56, 62, 90], "liter": 30, "social": 30, "intervent": 30, "he": [30, 32, 38, 40, 61, 92], "she": 30, "pattern": [30, 70], "gather": 30, "form": [30, 32, 36, 39, 51, 53, 56, 61, 65, 73, 76, 79, 81, 86, 88, 89, 92], "latter": [30, 51, 61, 71, 90], "destin": 30, "previou": [30, 31, 38, 39, 40, 51, 52, 53, 57, 59, 62, 64, 70, 71, 72, 74, 76, 78, 81, 88, 92], "complic": [30, 32, 50, 86, 88], "grow": [30, 32, 34, 56, 70, 73, 88], "manifest": [30, 51], "heart": [30, 73], "langl": [30, 47, 71, 86], "xi": [30, 58, 66, 73, 78], "rangl": [30, 47, 86], "replac": [30, 44, 45, 70, 73, 75, 78, 79, 86, 92], "theta_1": [30, 32, 38, 65, 69, 70, 79], "theta_2": [30, 32, 38, 65, 69, 70, 79], "conjagaci": 30, "maxim": [30, 32, 34, 38, 39, 55, 74, 79, 92], "automat": [30, 34, 51, 56, 59, 60, 86, 90], "earlier": [30, 32, 51, 86], "resort": [30, 88], "candid": [30, 45], "nice": [30, 44, 49, 53, 55, 57, 71, 73, 75, 78, 92, 95], "therebi": [30, 32, 36], "enorm": 31, "amount": [31, 32, 38, 56, 58, 61, 62, 90], "bind": [31, 89, 92], "ligand": [31, 89, 92], "receptor": [31, 89, 92], "record": 31, "memori": [31, 44, 90], "arriv": [31, 44, 46, 79, 92], "exist": [31, 39, 44, 56, 88], "invest": 31, "greatli": [31, 73, 88, 90], "felt": 32, "heat": 32, "framework": [32, 88], "invalid": [32, 49, 74, 75, 86], "bia": [32, 49, 71, 73], "entropi": [32, 79], "bernardo": 32, "eventu": [32, 44, 88, 92], "advoc": 32, "insuffici": 32, "old": [32, 36, 92], "flat": [32, 40, 61], "quit": [32, 51, 56, 58, 61, 64, 71, 73, 78, 81, 86, 88, 90, 92], "summar": [32, 38, 53], "Such": [32, 51, 71], "encod": [32, 52, 79], "machineri": [32, 49], "remedi": 32, "bound": [32, 34, 35, 38, 39, 49, 51, 52, 53, 55, 56, 59, 73, 74, 75, 79, 90], "outsid": [32, 50, 56, 61, 62, 71, 81, 86, 88], "small": [32, 34, 51, 56, 58, 59, 60, 70, 72, 73, 74, 75, 76, 78, 79, 81, 86, 88, 92], "epsilon": [32, 88], "speed": [32, 39, 55, 58, 76, 79, 86, 90], "kinesin": [32, 58], "motor": [32, 56, 58], "noth": [32, 50, 56, 72], "goe": [32, 40, 44, 56, 75, 88, 92], "absurd": 32, "primari": [32, 34, 55, 95], "critic": [32, 36, 56], "contemporari": 32, "illustr": [32, 44, 51, 55, 64, 73, 86, 92], "resolut": 32, "earli": [32, 74, 75], "patholog": [32, 59, 60, 62, 64, 67, 70, 71, 72, 73, 75, 76, 78, 88, 92], "bad": [32, 49, 56, 57, 62, 64, 76, 92], "subject": [32, 59, 61, 79, 90, 96], "debat": 32, "complain": 32, "chosen": [32, 51, 55, 56, 57, 70, 73, 86], "recal": [32, 34, 39, 40, 50, 59, 61, 64, 72, 75, 92], "formula": [32, 60], "invari": [32, 44, 45, 65], "harold": 32, "discov": [32, 51, 58, 60, 72], "coordin": [32, 49, 50, 51, 59, 60, 64, 70], "mathcal": [32, 79, 86, 88], "_": [32, 35, 39, 55, 61, 64, 73, 74, 75, 76, 78, 88, 92], "succinctli": 32, "sharp": [32, 56, 65, 92], "peak": [32, 34, 35, 38, 39, 56, 61, 65, 92], "propto": [32, 34, 35, 39, 88, 92], "reparametr": [32, 60, 70, 88], "phi_1": 32, "phi_2": 32, "matric": [32, 73, 75, 78], "recogn": [32, 88, 89], "difficult": [32, 34, 39, 56, 59, 60, 79], "intract": [32, 40, 79], "against": [32, 40, 56, 57, 61, 62, 64, 71, 74, 75], "tediou": 32, "bernoulli": [32, 36, 69, 86], "success": [32, 34, 36, 69, 79, 86, 92], "trial": [32, 36, 67, 69, 71, 72, 86], "proper": [32, 34], "highli": [32, 45, 52, 56, 69, 75], "suggest": [32, 46, 51, 61], "priori": [32, 36, 56, 58], "regardless": [32, 59, 88], "littl": [32, 34, 38, 47, 55, 58, 59, 61, 76, 86], "influenc": [32, 73], "lack": [32, 44, 61], "imposs": [32, 45, 47, 51, 56, 58, 92], "nefari": 32, "care": [32, 34, 35, 49, 56, 61, 73, 79, 81], "anywai": [32, 34, 75], "travel": 32, "suppos": [32, 92], "somewhat": [32, 92], "breadth": [32, 34, 88], "broader": [32, 39], "opt": [32, 86], "wiki": [32, 59], "loss": [32, 61], "precis": [32, 58, 59, 75, 88], "compar": [32, 34, 39, 40, 53, 57, 60, 61, 62, 64, 70, 71, 75, 76, 78, 79, 90, 92], "popul": [32, 49, 51, 92], "expert": 32, "seriou": [32, 51, 79, 81], "gain": [32, 61], "robust": [32, 55, 64, 88], "separ": [32, 49, 50, 56, 58, 67, 69, 78, 81, 92], "sublim": 32, "ridicul": 32, "consider": [32, 34, 51, 56, 73], "difficulti": [32, 55, 66, 72, 81], "rare": [32, 39, 45, 56, 61], "complex": [32, 36, 50, 51, 56, 58, 73, 79, 86, 88, 89, 90, 92], "certainli": [32, 35, 39, 51, 56, 59, 90], "hierarchi": [32, 66, 70, 79], "parametriz": 32, "greatest": 32, "unbound": 32, "idiomat": 32, "giant": [32, 58], "wager": 32, "salari": 32, "pig": [32, 61], "fly": [32, 61], "comfort": 32, "wage": 32, "don": [32, 38, 59, 70, 73, 86, 88, 90, 92], "hope": [32, 51, 71, 90], "lo": 32, "angel": 32, "footbal": 32, "club": 32, "win": 32, "ml": 32, "cup": 32, "someon": [32, 36, 86], "tell": [32, 35, 36, 38, 39, 46, 49, 50, 56, 61, 70, 71, 72, 78, 86, 88], "bacterium": 32, "absurdli": 32, "bigger": [32, 38, 56, 64, 65, 76, 92], "nanomet": [32, 58], "diamet": [32, 34, 35, 38, 40, 52, 53, 56, 57, 62, 79], "strand": 32, "nm": [32, 38, 70, 79], "flinch": 32, "bacteria": [32, 75], "smaller": [32, 38, 56, 60, 61, 64, 70, 86, 92], "uneasi": 32, "won": [32, 60, 70, 71, 86], "meter": [32, 58], "cm": 32, "gigant": 32, "mm": [32, 38], "huge": [32, 86, 92], "tremend": 32, "divers": 32, "eukaryot": [32, 56], "xenopu": [32, 38, 52, 56], "strongli": [32, 50, 56, 86, 92], "wouldn": [32, 92], "magnitud": [32, 34, 53, 56, 58, 71, 72, 73, 86, 88], "geometr": 32, "boundari": 32, "surprisingli": [32, 70], "bacteri": [32, 49, 75], "logarithm": [32, 34, 38, 39, 49, 51, 58, 60, 61, 64, 70, 73, 76, 79, 88], "ignor": [32, 39, 40, 47, 49, 52, 53, 56, 57, 61, 65, 88], "95": [32, 38, 39, 53, 55, 56, 58, 59, 73, 76, 81], "li": [32, 60], "width": [32, 56, 60, 70, 71, 86], "rang": [32, 34, 35, 38, 40, 44, 49, 51, 56, 57, 61, 67, 71, 72, 73, 74, 76, 79, 86, 90, 92], "log_": [32, 38, 49, 51, 52, 53, 58, 59, 72, 73, 79], "approx": [32, 39, 46, 47, 56, 61, 64, 75, 86], "lognorm": [32, 38, 40, 56, 57, 59, 62, 64, 79, 81], "hesit": [32, 59], "theta_": [32, 44, 45, 79], "max": [32, 34, 35, 38, 40, 41, 51, 73, 74, 75, 76, 78, 86, 90, 92], "divid": [32, 35, 44, 72, 75], "conceiv": [32, 71, 76], "came": [32, 61, 81, 88], "firm": 32, "countless": 32, "pl": [34, 35, 38, 40, 49, 51, 52, 53, 55, 56, 57, 59, 62, 64, 70, 72, 73, 74, 75, 76, 78, 79], "scipi": [34, 35, 36, 38, 39, 40, 41, 49, 50, 51, 56, 72, 75, 76, 78, 86, 90, 92], "stat": [34, 35, 36, 38, 39, 40, 41, 49, 50, 51, 55, 56, 72, 74, 75, 78, 86, 90], "st": [34, 35, 36, 38, 39, 40, 41, 49, 50, 51, 56, 72, 74, 75, 78, 86, 90], "ve": [34, 90, 92], "whole": [34, 38, 60, 70, 92], "bread": 34, "butter": 34, "inaccess": 34, "viabl": 34, "mitot": [34, 56, 62], "encapsul": [34, 52], "matt": [34, 79], "refamiliar": [34, 38], "remind": [34, 35, 53, 59, 61, 67, 76, 78, 79], "good_invitro_droplet_data": [34, 35, 38, 40, 52, 53, 56, 57, 62, 79], "frame": [34, 35, 38, 40, 50, 51, 52, 53, 55, 56, 59, 62, 70, 72, 74, 79], "df": [34, 35, 38, 40, 49, 51, 52, 53, 56, 57, 59, 62, 64, 70, 72, 73, 74, 75, 76, 78, 79, 90], "read_csv": [34, 35, 38, 40, 49, 51, 52, 53, 56, 57, 59, 62, 64, 70, 72, 73, 74, 75, 76, 78, 79, 90], "join": [34, 35, 38, 40, 49, 51, 52, 53, 56, 57, 59, 62, 64, 70, 72, 73, 74, 75, 76, 78, 79, 81, 89, 90, 92], "comment_prefix": [34, 35, 38, 40, 49, 51, 52, 53, 56, 57, 59, 62, 64, 72, 75, 79], "um": [34, 35, 38, 40, 52, 53, 56, 57, 62, 79], "to_numpi": [34, 35, 38, 40, 49, 51, 52, 53, 55, 56, 57, 59, 62, 64, 72, 73, 74, 75, 76, 78, 79], "300": [34, 35, 36, 38, 40, 41, 50, 52, 53, 56, 72, 79, 86, 92], "x_rang": [34, 35, 36, 38, 39, 40, 41, 49, 52, 53, 56, 57, 60, 62, 72, 73, 79], "y_rang": [34, 35, 38, 39, 40, 41, 52, 53, 56, 72, 79, 86], "to_dict": [34, 35, 38, 40, 52, 53, 56, 72, 73, 74, 76, 79], "object": [34, 36, 38, 50, 51, 59, 64, 74, 79, 81, 86, 88, 90], "treat": [34, 56, 73], "jeffrei": [34, 35, 38, 52], "l_i": [34, 35, 38, 40, 52, 53, 56, 57, 62, 79], "implicit": [34, 61], "somedistribut": 34, "vanilla": 34, "tubulin": [34, 38, 52, 53, 62], "conserv": [34, 38, 52, 53, 56, 62, 64, 86, 88], "proport": [34, 44, 47, 49, 61, 92], "evalu": [34, 35, 36, 39, 40, 73, 74, 75, 76, 79, 86, 88, 92], "handi": [34, 53], "progress": [34, 50, 73], "postpon": 34, "secondli": [34, 90], "hit": [34, 59, 70, 74, 86], "underflow": [34, 35, 38, 51, 92], "circumst": 34, "insid": [34, 88, 92], "behav": [34, 39, 51, 65, 73, 86, 92], "risk": 34, "logsumexp": 34, "log_marginalized_posterior": [34, 35], "inf": [34, 38, 40, 49, 64, 74, 75], "len": [34, 35, 38, 49, 51, 52, 53, 56, 57, 59, 62, 64, 67, 72, 73, 74, 75, 76, 78, 79, 86, 90, 92], "grung": [34, 73], "linspac": [34, 35, 36, 38, 39, 40, 41, 56, 57, 60, 62, 72, 73, 74, 75, 76, 78, 79, 86], "log_marg_post": 34, "phi_val": [34, 35], "\u03c6": [34, 35, 38, 40, 53, 79], "l\u1d62": [34, 35], "line_width": [34, 35, 36, 38, 39, 40, 41, 49, 51, 55, 56, 59, 60, 72, 73, 74, 75, 76, 86], "33": [34, 38, 49, 51, 55, 60, 92], "awai": [34, 38, 39, 40, 56, 58, 60, 64, 71, 72, 73, 74, 86, 88], "subtract": [34, 61, 92], "marg": 34, "log_marg_post_max": 34, "marg_post": 34, "visual": [34, 35, 38, 39, 49, 51, 52, 55, 56, 72, 73, 88], "axi": [34, 40, 44, 49, 53, 56, 58, 71, 72, 92], "g_": 34, "proportion": [34, 56], "clever": [34, 44, 79], "momentarili": [34, 59, 70, 73], "quad": [34, 35], "marginalized_posterior": [34, 35], "unnorm": [34, 35, 51, 92], "integrand": [34, 35], "resolv": [34, 56], "domain": [34, 52, 58, 74], "pass": [34, 38, 40, 49, 50, 51, 56, 57, 59, 62, 72, 79, 81, 90], "arg": [34, 35, 38, 40, 56, 74, 75, 90], "kwarg": [34, 38, 49, 50, 51, 53, 56, 57, 64, 76, 78, 79], "err": 34, "46386461926837497": 34, "981239131261995e": 34, "review": [34, 79, 80, 86], "unorm": 34, "found": [34, 38, 39, 40, 47, 69, 73, 78, 79, 90, 92], "straightforwardli": 34, "grungi": 34, "bar": [34, 50, 51, 69, 73], "hat": [34, 46, 60, 61, 88], "nu": [34, 58, 73, 75], "std": [34, 55, 73, 74, 75, 76, 78], "exact_pdf": 34, "color": [34, 36, 39, 40, 41, 49, 51, 53, 55, 60, 67, 70, 72, 73, 74, 75, 76, 78, 86, 92], "line_dash": 34, "dash": 34, "perfect": [34, 86], "efficaci": 34, "tough": 34, "contour": [34, 35, 38, 40, 60, 88], "furthermor": [34, 38, 40, 47, 55, 57, 58, 70, 71, 73, 90], "clean": [34, 88], "log_prior_indep_s": 34, "param": [34, 35, 38, 40, 49, 51, 53, 56, 73, 74, 75, 78], "log_likelihood_indep_s": 34, "logpdf": [34, 38, 40, 74, 75], "loc": [34, 38, 39, 40, 41, 51, 56, 72, 74, 75], "log_posterior_indep_s": 34, "lp": [34, 38, 40, 50, 51, 74, 75, 92], "prevent": [34, 56, 90], "bug": [34, 59, 81, 90], "trade": 34, "overhead": 34, "log_likelihood_indep_size_numpy_onli": 34, "timeit": 34, "ntime": 34, "136": 34, "452": 34, "loop": [34, 51, 56, 90], "000": [34, 40, 59, 72, 79, 90], "nearli": [34, 56, 70, 81, 86, 92], "slow": [34, 38, 73, 75], "increasingli": 34, "nonneglig": 34, "shrink": [34, 67], "rapidli": [34, 36, 73, 88], "dimens": [34, 39, 49, 50, 51, 57, 59, 64, 86, 88], "log_post": [34, 35, 40], "enumer": [34, 35], "overflow": [34, 35, 59], "packag": [34, 50, 53, 61, 64, 74, 75, 78, 81, 90, 95], "viz": [34, 35, 38, 39, 40, 49, 51, 52, 53, 56, 57, 59, 60, 62, 64, 67, 70, 72, 73, 74, 75, 76, 78, 79, 92], "overlaid": [34, 35, 40, 60, 61], "\u03c3": [34, 38, 40, 52, 53, 56, 74, 75, 78, 79], "harder": [34, 40, 50, 59], "zoom": [34, 35, 70, 75, 92], "31": [34, 41, 51, 55, 59, 60, 62, 79, 92, 96], "35": [34, 38, 40, 49, 50, 51, 52, 56, 57, 59, 60, 62, 64, 67, 69, 70, 72, 73, 79, 92], "shape": [34, 36, 40, 49, 51, 53, 55, 56, 57, 59, 60, 70, 72, 76, 79, 92], "spindl": [35, 38, 40, 52, 53, 57, 62], "d_i": [35, 40, 52, 53, 56, 57, 62, 79], "trivari": 35, "tri": [35, 56], "theor_spindle_length": 35, "eyebal": 35, "somewher": [35, 38, 56], "37": [35, 40, 51, 62, 70, 79, 92], "asymptot": [35, 56, 61, 79], "slope": 35, "gamma_v": 35, "adjust": [35, 50, 53, 56, 57, 62, 71, 75, 79], "\u03d5": [35, 38, 40, 52, 53, 56, 67], "\u03b3": [35, 40, 52, 53, 56, 79], "log_post_max": 35, "calc": 35, "varphi": 35, "infin": [35, 73, 86], "unnormalized_marg_post_phi": 35, "empty_lik": [35, 40], "d\u1d62": 35, "trapezoid": 35, "trapz": [35, 40, 92], "normalization_const": 35, "wrinkl": 35, "lambda": [35, 60, 73, 76, 86], "swap": 35, "input": [35, 49, 50, 56, 57, 64, 75, 76, 78, 90, 92], "unnormalized_marg_post_gamma": 35, "norm_const": 35, "valuabl": [35, 58, 95], "rear": 35, "doom": 35, "handl": [35, 45, 51, 71, 74, 88, 90], "spend": [35, 81, 90], "sophist": [35, 64], "seem": [36, 45, 49, 56, 62, 70, 71, 72, 73, 79, 88, 90, 92], "mossman": 36, "2019": 36, "author": [36, 49, 90, 95], "ag": 36, "drosophila": 36, "parent": 36, "viabil": 36, "offspr": 36, "vial": 36, "mate": 36, "young": 36, "dai": [36, 45, 70, 79, 81, 90, 96], "male": 36, "femal": 36, "176": [36, 79], "period": [36, 44, 73], "94": [36, 53, 76], "hatch": 36, "remaind": 36, "fail": [36, 57, 64, 71, 72, 90], "154": 36, "failur": 36, "binom": [36, 64, 65, 67, 86], "seek": [36, 39, 49, 61, 64], "Its": 36, "mother": 36, "n_old": 36, "n_young": 36, "instanti": [36, 55, 56, 90], "\u03b8": [36, 60, 67, 70, 86], "legend_label": [36, 39, 55, 60, 67, 70, 73, 79, 86, 92], "legend": [36, 55, 60, 67, 70, 86, 92], "top_left": [36, 86], "disavantag": 36, "tractabl": [36, 39, 52], "paltri": 36, "hopeless": 36, "coin": 36, "slightli": [36, 74], "bias": [36, 88], "bimod": [36, 49, 51, 55, 64], "sivia": 36, "bear": [36, 44, 55, 59], "conduct": [36, 72, 89, 90], "upon": [36, 56, 61, 70], "statsmodel": [38, 40], "numdiff": [38, 40], "smnd": [38, 40], "tqdm": [38, 40], "342": [38, 40, 52, 53, 56, 62], "856": [38, 40, 52, 53, 56, 59, 62], "860": [38, 40, 52, 53, 56, 62], "2013": [38, 40, 52, 53, 56, 62], "abandon": 38, "bet": [38, 49, 52, 58], "farm": [38, 49, 52, 58], "breviti": 38, "logspac": 38, "1e": [38, 56, 73, 74, 75, 76, 78], "1e5": 38, "x_axis_typ": [38, 72], "half": [38, 52, 56, 58, 65, 70, 74, 89], "halfnorm": [38, 40, 52, 53, 56, 65, 67, 70, 73, 74, 75, 76, 78, 79, 92], "albeit": 38, "themselv": [38, 50, 59], "y_3": 38, "sum_j": [38, 61], "fortun": [38, 40, 46, 51, 61, 64, 78, 92], "log_prior": [38, 40, 74, 75], "log_likelihood": [38, 40, 62, 64, 74, 75, 92], "log_posterior": [38, 40, 74, 75], "indpend": [38, 40], "algorithm": [38, 43, 44, 46, 50, 59, 61, 73], "powel": [38, 40, 74, 75], "reli": [38, 55, 88, 92], "discontinu": 38, "hurt": 38, "particularli": [38, 53, 59, 79, 88, 90], "constrain": [38, 51, 79, 88], "bfg": 38, "cobyla": 38, "neg_log_posterior": [38, 40, 74, 75], "routin": 38, "converg": [38, 59, 79], "params_0": [38, 40, 74, 75], "minimz": 38, "optimzi": 38, "attribut": [38, 49, 50, 51, 59, 64], "extra": [38, 73, 75, 79, 81, 86], "popt": [38, 40], "phi_map": [38, 40], "sigma_map": [38, 40], "2f": [38, 40], "3f": [38, 40, 56, 67], "32": [38, 51, 64, 70, 79, 90, 92], "86": [38, 59, 64], "784": 38, "successfulli": 38, "invert": [38, 40, 73], "element": [38, 39, 51, 52, 70, 88], "approx_hess": [38, 40], "shove": 38, "cov": [38, 40, 73], "linalg": [38, 40], "inv": [38, 40, 58, 78], "41668904e": 38, "02": [38, 50, 51, 72, 96], "09388085e": 38, "06": [38, 51, 70, 79, 96], "70799615e": 38, "multipli": [38, 61, 73, 74, 75, 92], "96": [38, 39, 40, 55, 70, 72, 73, 74, 75, 79], "256": 38, "multivariate_norm": [38, 40, 73, 74, 75], "neighborhood": [38, 88], "post_norm": [38, 40], "empti": [38, 90], "log_post_exact": 38, "00": [38, 40, 49, 50, 51, 64, 72, 90, 96], "lt": [38, 40, 49, 50, 51, 59, 64, 72, 92], "50it": 38, "post_exact": [38, 40], "line_kwarg": [38, 39, 40, 55, 56, 59, 60, 67, 79], "dict": [38, 39, 40, 49, 51, 52, 53, 56, 59, 60, 62, 67, 70, 72, 73, 74, 75, 76, 78, 79, 90, 92], "line_color": [38, 40, 41, 55, 67, 75, 76, 78, 79], "danger": [38, 40], "66": [38, 40, 55], "catch_warn": 39, "simplefilt": 39, "abbrevi": [39, 50], "paramount": 39, "dwell": 39, "seldom": [39, 55, 81], "Near": 39, "taylor": 39, "truncat": [39, 53, 56], "b_": 39, "y_gamma": 39, "y_norm": 39, "tomato": [39, 73, 74], "percent": [39, 44], "confid": [39, 50, 71, 72], "erron": 39, "025": [39, 79], "975": 39, "benefit": [39, 71, 73, 79, 90], "afford": [39, 73], "ii": 39, "pm": [39, 55, 56, 81, 96], "asymmetr": [39, 55], "extrem": [39, 56, 58, 59, 64, 69, 70, 73, 74, 88], "flaw": [39, 46], "median": [39, 47, 55, 56, 57, 67, 79], "34": [39, 49, 51, 59, 67, 70, 79, 92], "ppf": [39, 41, 86], "99": [39, 49, 56, 57, 60, 62, 67, 70, 72, 73, 76, 79], "perc_cred_int": 39, "gamma_low": 39, "gamma_high": 39, "norm_low": 39, "norm_high": 39, "fill_between": [39, 73, 74, 75], "patch_kwarg": [39, 73, 74, 75], "shift": [39, 92], "rightward": 39, "notabl": [39, 59, 67, 92], "miss": [39, 58, 59, 62, 71, 72, 86, 88], "despit": [39, 78, 88], "character": [39, 51, 56, 58, 72, 88], "throughput": [39, 89], "attract": 39, "pathologi": [39, 60, 64, 88], "breakdown": [39, 50, 73, 81], "mechan": [39, 86, 92], "p_data": [40, 53], "relationship": [40, 61, 70], "toward": [40, 58, 67, 70, 71, 73, 79, 88, 92], "embark": 40, "solver": [40, 73, 88], "differenti": [40, 49, 51, 73, 75, 78], "theoretical_spindle_length": 40, "And": [40, 49, 56, 57, 59, 62, 64, 71, 72, 86], "gamma_map": 40, "38": [40, 44, 60, 72, 79, 92], "77": [40, 51, 64], "859": 40, "034": 40, "754": 40, "201": [40, 67], "grid": [40, 51, 55], "sigma_0": [40, 56, 57, 62, 79], "million": [40, 86], "brute": [40, 52, 56, 92], "forc": [40, 52, 56, 86, 92], "style": [40, 50, 67, 86], "tight": [40, 57], "sea": 40, "needl": [40, 60], "haystack": 40, "39": [40, 49, 50, 51, 53, 64, 70, 74, 79, 90, 92], "91": [40, 90], "meshgrid": [40, 60, 86], "51": [40, 50, 70, 79], "52": [40, 59], "post_margin": 40, "narrow": [40, 60, 71], "cut": 40, "instantan": 40, "dstack": 40, "discourag": 40, "d_theor": 40, "ell_theor": [40, 52, 53, 56, 57, 62, 79], "linear": [40, 51, 56, 58, 73, 74, 75, 78], "regim": [40, 56], "caught": [40, 72], "dynam": [40, 49, 88], "blackcellmag": 41, "seed": [41, 51, 55, 59, 60, 64, 70, 79, 92], "12341234": 41, "udraw": 41, "04": [41, 50, 72, 96], "xgrid": 41, "grid_line_color": 41, "ygrid": 41, "x_val": 41, "y_val": [41, 55], "grai": [41, 55, 86], "zeros_lik": [41, 73, 74, 75], "black": [41, 67, 76, 92], "circl": [41, 53, 86, 88, 92], "fill_color": [41, 75, 76, 78], "level": [41, 49, 51, 61, 66, 70, 73, 79, 86, 88], "educ": 42, "vignett": 42, "michael": [42, 51, 57, 59, 71, 86, 95], "hmc": [42, 45, 50, 70, 92], "hamiltonian": [42, 45, 59, 92], "transit": [43, 44, 46, 47, 79], "kernel": [43, 44, 46, 47, 53, 74, 76, 78, 86], "metropoli": [43, 88], "hast": [43, 88], "capabl": [44, 49, 64, 89, 90], "pcg64": 44, "128": [44, 64], "float": [44, 51, 56, 61, 64], "nonuniform": 44, "muller": 44, "quantil": [44, 47, 55, 59], "mark": [44, 92], "vertic": [44, 70, 73], "horizont": [44, 73], "target": [44, 45, 51, 59, 60, 64, 88, 90, 92], "arbitrari": [44, 45, 47, 51, 59, 70, 73, 76, 88], "correct": [44, 61, 81, 86], "simplic": [44, 73, 90], "walk": [44, 46, 58, 88], "walker": [44, 45, 46, 53, 59, 64, 88, 92], "bold": [44, 57], "sentenc": [44, 59], "achiev": [44, 45, 46, 59, 72, 86], "condit": [44, 45, 51, 56, 61, 66, 69, 70, 71, 73, 76, 79, 86, 88, 90], "stationari": [44, 46, 75], "uniqu": [44, 51, 73, 79], "ergod": [44, 45, 88], "aperiod": 44, "2k": 44, "3k": 44, "irreduc": 44, "recurr": [44, 88], "revisit": 44, "checklist": 44, "moment": [44, 46, 49, 56, 61, 70, 73, 86, 88, 92], "preced": [44, 51, 52, 58, 86], "1000": [44, 49, 50, 51, 52, 53, 56, 57, 59, 64, 65, 67, 71, 72, 73, 74, 76, 78, 79, 86, 90, 92], "margossian": 44, "randomli": 45, "ratio": [45, 59, 75, 88, 92], "ge": 45, "accept": [45, 56, 71, 81, 88, 90], "nut": [45, 86], "earth": 45, "sequenti": [45, 58, 90], "bracket": 45, "art": [45, 49, 57, 59], "origin": [45, 50, 60, 65, 70, 71, 72, 73, 86], "1953": 45, "thumb": [45, 46, 59, 71], "wander": [45, 58], "reject": [45, 60, 88], "tune": [45, 46, 70, 73, 88], "gibb": 45, "modern": 45, "popular": [45, 50, 92], "special": [45, 51, 58, 70, 71, 73, 75, 86, 88, 90, 92], "improv": [45, 70, 72, 73], "subclass": 45, "overemphas": 45, "naiv": 45, "anyhow": 45, "devis": [46, 60, 89], "theta_0": 46, "travers": 46, "incredibli": [46, 73, 86, 88], "began": 46, "weight": [46, 49, 62, 75], "burn": 46, "reach": [46, 59, 75], "heurist": 46, "coauthor": 46, "rubin": 46, "metric": [46, 59, 71, 86, 88], "stationar": [46, 59], "famou": 46, "defer": [46, 52], "vehtari": [46, 59, 61, 64], "stringent": 46, "01": [46, 50, 55, 59, 60, 64, 70, 73, 79, 88, 90, 92, 96], "regular": [46, 92], "neglect": [46, 58, 79], "bunch": [46, 92], "strategi": [46, 51, 60, 71, 88, 92], "phase": [46, 49, 75, 86, 88], "h": [47, 61, 86, 88], "histogram": [47, 49, 53, 55], "averag": [47, 61, 64, 71, 86, 88, 89, 92], "th": [47, 56, 61], "abundantli": 47, "abil": [47, 59, 61, 71, 73, 90, 92], "superscript": [47, 70], "parenthet": 47, "hello": 48, "drew": 49, "reconstruct": 49, "miracul": 49, "elowitz": [49, 72, 89, 90], "singer": [49, 59, 64], "heterogen": 49, "methyl": 49, "embryon": 49, "stem": 49, "molec": 49, "331": 49, "2014": 49, "paragraph": [49, 81], "eda": 49, "situ": 49, "hybrid": 49, "focus": [49, 90], "pluripot": 49, "associ": [49, 50, 51, 58, 72, 88, 96], "regul": [49, 69], "hallmark": 49, "tempor": 49, "laps": [49, 89, 92], "movi": 49, "insight": [49, 88], "279": [49, 64, 92], "rex1": [49, 51, 64], "nanog": 49, "prdm14": 49, "singer_transcript_count": [49, 51, 59, 64, 72, 90], "q": [49, 53, 59, 61, 70, 72, 76, 86, 90, 92], "layout": [49, 53, 55, 56, 79, 86, 92], "fewer": [49, 56, 60, 92], "copi": [49, 64, 72, 76, 78, 90], "presenc": 49, "inflect": [49, 58], "edcf": 49, "impli": [49, 56, 70], "n_i": [49, 51, 59, 64, 65, 67, 69, 72, 73, 76, 90], "higher": [49, 51, 61, 86, 88, 89, 90], "frequent": 49, "assembl": 49, "shorter": [49, 90], "environment": [49, 90], "lifetim": [49, 72], "promot": [49, 72, 75], "strength": [49, 72, 86], "thousand": [49, 71, 72, 90], "syntax": [49, 50, 51, 53, 56, 78, 95], "log10_alpha": [49, 51, 59, 64, 72], "log10_b": [49, 51, 59, 64, 72], "beta_": [49, 51, 59, 64, 67, 72, 90, 92], "neg_binomi": [49, 59, 64, 72, 90], "rais": 49, "block": [49, 50, 52, 56, 57, 58, 73, 74, 75, 76, 78, 88, 90, 92], "declar": [49, 50, 51, 52], "dictionari": [49, 51, 62, 64, 70, 73, 74, 75, 78], "iter_sampl": [49, 50, 51, 52, 53, 56, 57, 59, 67, 72, 73, 90, 92], "inferencedata": [49, 50, 51, 56, 59, 64], "info": [49, 50, 90], "fatal": 49, "neg_binomial_lpmf": [49, 64, 90], "show_consol": 49, "unclear": 49, "fed": 49, "aris": [49, 51, 90, 92], "silenc": 49, "throw": [49, 71], "pedagog": [49, 95], "disabl": 49, "xarrai": [49, 50, 51, 57, 59, 64], "dataset": [49, 50, 51, 57, 59, 64, 90, 92], "gt": [49, 50, 51, 59, 64, 90, 92], "168kb": 49, "int64": [49, 50, 51, 59, 64], "32b": [49, 50, 51, 59, 64], "8kb": [49, 50, 51, 59, 64], "993": [49, 50, 51, 59, 64], "994": [49, 50, 51, 59, 64], "995": [49, 50, 51, 59, 64], "996": [49, 50, 51, 59, 64], "997": [49, 50, 51, 59, 64], "998": [49, 50, 51, 59, 64], "999": [49, 50, 51, 56, 59, 64], "float64": [49, 50, 51, 59, 64], "32kb": [49, 50, 51, 59], "722": [49, 59], "814": 49, "808": 49, "155": 49, "271": [49, 59, 64], "48": 49, "64": [49, 51], "07": [49, 50, 51, 64, 70, 79, 96], "05002": 49, "04916": 49, "0567": 49, "05535": 49, "5707": 49, "5814": 49, "6186": 49, "6305": 49, "301": [49, 79], "308": [49, 92], "246": 49, "257": 49, "created_at": [49, 50, 51, 64], "19t23": [49, 50], "29": [49, 51, 59, 72, 79, 92, 96], "089569": 49, "arviz_vers": [49, 50, 51, 64], "inference_librari": [49, 50, 51, 64], "inference_library_vers": [49, 50, 51, 64], "4xarrai": [49, 50, 51, 64], "datasetdimens": [49, 50, 51, 59, 64], "4draw": [49, 50, 51, 59, 64], "1000coordin": [49, 50, 51], "int640": [49, 50, 51, 59, 64], "3arrai": [49, 50, 51, 59, 64], "999arrai": [49, 50, 51, 59, 64], "float643": 49, "271arrai": 49, "72176": 49, "81412": 49, "8077": 49, "02461": 49, "95251": 49, "49689": 49, "82657": 49, "61593": 49, "68701": 49, "36608": 49, "37078": 49, "37826": 49, "87778": 49, "33051": 49, "30581": 49, "38294": 49, "52823": 49, "08891": 49, "80512": 49, "22812": 49, "36809": 49, "38976": 49, "15537": 49, "27078": 49, "float6419": 49, "07arrai": 49, "9922": 49, "3422": 49, "4787": 49, "5616": 49, "3612": 49, "3301": 49, "2128": 49, "9165": 49, "9441": 49, "5362": 49, "5644": 49, "7573": 49, "2453": 49, "2903": 49, "8039": 49, "0338": 49, "6761": 49, "7705": 49, "1302": 49, "1052": 49, "1311": 49, "5695": 49, "6351": 49, "0655": 49, "float640": [49, 50, 51], "05535arrai": 49, "0500194": 49, "049159": 49, "0488312": 49, "0686739": 49, "0650993": 49, "0612367": 49, "0616795": 49, "0591138": 49, "0590177": 49, "0570248": 49, "0569334": 49, "0563149": 49, "065594": 49, "0578358": 49, "05951": 49, "0587069": 49, "059966": 49, "0532751": 49, "0619955": 49, "0584618": 49, "0551539": 49, "0569168": 49, "056705": 49, "0553542": 49, "6305arrai": 49, "570748": 49, "581394": 49, "580663": 49, "701103": 49, "694826": 49, "652913": 49, "683638": 49, "664259": 49, "670896": 49, "640091": 49, "640559": 49, "641301": 49, "688222": 49, "636539": 49, "634055": 49, "641766": 49, "655928": 49, "611608": 49, "681705": 49, "626147": 49, "640292": 49, "642441": 49, "61861": 49, "630507": 49, "float641": [49, 50, 51, 59], "257arrai": 49, "30086": 49, "3084": 49, "3113": 49, "16321": 49, "18642": 49, "21299": 49, "20986": 49, "22831": 49, "22902": 49, "24394": 49, "24463": 49, "24938": 49, "18314": 49, "2378": 49, "22541": 49, "23131": 49, "2221": 49, "27348": 49, "20764": 49, "23313": 49, "25842": 49, "24476": 49, "24638": 49, "25685": 49, "chainpandasindexpandasindex": [49, 50, 51, 59, 64], "dtype": [49, 50, 51, 59, 64], "x27": [49, 50, 51, 59, 64], "drawpandasindexpandasindex": [49, 50, 51, 59, 64], "990": [49, 50, 51, 59, 64], "991": [49, 50, 51, 59, 64], "992": [49, 50, 51, 59, 64], "00arviz_vers": [49, 50, 51, 64], "0inference_librari": [49, 50, 51, 64], "cmdstanpyinference_library_vers": [49, 50, 51, 64], "puls": 49, "plot_scatt": 49, "\u03b1": [49, 56, 67, 72, 73, 74, 75], "bin": [49, 53, 55, 90], "rug": [49, 53, 55], "send": [49, 89], "foolishli": 49, "grab": [49, 75], "arang": [49, 51, 55, 76, 86], "251": [49, 79], "flatten": [49, 50, 51, 55, 60, 67, 70, 73, 74, 79, 92], "zip": [49, 51, 55, 56, 72, 76, 81, 86], "nbinom": [49, 51], "x_plot": [49, 51], "y_plot": [49, 51], "cdf_to_staircas": [49, 51], "underlai": [49, 51], "425": 49, "426": 49, "amazon": [50, 90], "julia": 50, "matlab": [50, 90], "stata": 50, "across": [50, 64, 90, 92], "dive": 50, "disk": 50, "seven": [50, 59], "intend": 50, "ventur": 50, "friend": [50, 92], "guid": [50, 95], "manual": [50, 51, 59, 92], "static": [50, 52], "semicolon": 50, "curli": 50, "prepar": [50, 70, 86, 88, 90, 92, 96], "favorit": [50, 55], "editor": [50, 90], "groundwork": 50, "hello_world": 50, "bebi103_cours": 50, "2025": 50, "08": [50, 70, 72, 79, 96], "ex": 50, "43": [50, 51], "iter": [50, 51, 53, 59, 60, 62, 64, 67, 70, 71, 72, 73, 75, 76, 78, 79, 86, 88, 90, 92], "44": [50, 51, 72, 79], "job": [50, 76, 86, 90], "cmdstanmcmc": 50, "num_sampl": 50, "engag": [50, 79], "csv_file": 50, "var": [50, 72, 79, 86, 88], "j_": [50, 79], "c5r9ch0913v3h1w4bdwzm0lh0000gn": [50, 79], "tmpvzktutt3": 50, "hello_worldg4sdgzab": 50, "20240719161944_1": 50, "20240719161944_2": 50, "20240719161944_3": 50, "20240719161944_4": 50, "output_fil": 50, "20240719161944_0": 50, "pronounc": 50, "rv": 50, "recreat": 50, "vehicl": 50, "40kb": 50, "6374": 50, "5841": 50, "5403": 50, "6269": 50, "542659": 50, "6269arrai": 50, "637411": 50, "58407": 50, "302226": 50, "474132": 50, "962219": 50, "03972": 50, "75933": 50, "254514": 50, "365888": 50, "96866": 50, "20111": 50, "82037": 50, "477287": 50, "556766": 50, "32425": 50, "55547": 50, "494835": 50, "364278": 50, "015963": 50, "141604": 50, "35541": 50, "39819": 50, "540314": 50, "626918": 50, "sample_stat": [50, 51, 59], "204kb": [50, 51], "acceptance_r": [50, 51], "9468": 50, "8258": 50, "9861": 50, "9895": 50, "bool": [50, 51], "4kb": [50, 51, 59], "energi": [50, 51, 59, 73, 79], "5121": 50, "564": [50, 59], "1502": 50, "215": 50, "2031": 50, "1706": 50, "1965": 50, "n_step": [50, 51], "step_siz": [50, 51], "015": 50, "tree_depth": [50, 51, 59], "549548": 50, "9895arrai": 50, "946755": 50, "82582": 50, "998086": 50, "91481": 50, "689701": 50, "794211": 50, "991144": 50, "725178": 50, "979043": 50, "928644": 50, "989108": 50, "945146": 50, "757333": 50, "998694": 50, "864913": 50, "978766": 50, "99792": 50, "791233": 50, "982238": 50, "986148": 50, "989484": 50, "boolfals": [50, 51], "falsearrai": [50, 51, 59], "139": [50, 70], "215arrai": 50, "512115": 50, "56356": 50, "138952": 50, "137244": 50, "462933": 50, "42688": 50, "55296": 50, "33155": 50, "0698188": 50, "39816": 50, "793701": 50, "70602": 50, "858483": 50, "6095": 50, "70213": 50, "43293": 50, "44248": 50, "113932": 50, "07941": 50, "0126613": 50, "4355": 50, "107657": 50, "150176": 50, "214951": 50, "146": 50, "1965arrai": 50, "03146e": 50, "70569e": 50, "56703e": 50, "12401e": 50, "62933e": 50, "40512e": 50, "54763e": 50, "23887e": 50, "69369e": 50, "69151e": 50, "21337e": 50, "65687e": 50, "13902e": 50, "54994e": 50, "70108e": 50, "20974e": 50, "22431e": 50, "63494e": 50, "27409e": 50, "00259e": 50, "18573e": 50, "92776e": 50, "45970e": 50, "96513e": 50, "int643": 50, "1arrai": [50, 51, 59], "0arrai": 50, "01508": 50, "07811": 50, "841159": 50, "00025": 50, "int641": 50, "group": [50, 51, 61, 70, 90], "dataarrai": [50, 51, 57, 59], "panda": [50, 51, 59, 74, 79, 90, 92], "interestingli": [50, 53], "arbitrarili": 50, "multidimension": [50, 53, 64, 73, 75], "999xarrai": [50, 59], "3022": 50, "2444": 50, "01371": 50, "3982": 50, "togeth": [50, 65, 67, 69, 70, 73, 74, 88, 89, 90, 92], "np_sampl": 50, "sp_sampl": 50, "staircas": [50, 67], "palett": [50, 55, 67, 86], "b_glasbey_category10": 50, "normal_rng": [50, 56, 57, 62, 72, 73, 75, 76, 78, 79], "sm_rng": 50, "norm_rng": 50, "mote": 50, "fixed_param": [50, 56, 72, 73, 90, 92], "stan_sampl": 50, "novel": 50, "occasion": [50, 56], "visibl": [50, 55, 67], "netcdf": 50, "to_netcdf": 50, "stan_hello_world": 50, "nc": 50, "from_netcdf": 50, "hpp": 50, "exit": 50, "delet": [50, 76], "outpur_dir": 50, "datafram": [51, 55, 72, 76, 92], "unimod": 51, "alpha_1": 51, "alpha_2": 51, "beta_1": 51, "beta_2": 51, "burst": [51, 58, 59, 72], "concis": 51, "retain": [51, 58, 79], "alpha_i": [51, 92], "b_i": 51, "beta_i": 51, "hood": [51, 88, 90], "summand": [51, 61], "a_1": [51, 76], "a_2": 51, "a_i": 51, "stabl": [51, 61, 73, 74, 78, 88], "log_mix": [51, 64], "keyword": [51, 78], "n_val": [51, 64], "neg_binomial_lupmf": 51, "negative_binomial_lpmf": 51, "_lpmf": [51, 64], "_lpdf": [51, 64], "_lupmf": 51, "_lupdf": 51, "signifi": 51, "wise": [51, 74, 90], "vvector": 51, "log10_beta": 51, "front": [51, 88, 90], "slash": 51, "elementwis": 51, "smart": 51, "enclos": [51, 56], "inclus": [51, 73], "3252": [51, 55, 59, 60, 64, 70, 79], "360kb": 51, "alpha_dim_0": [51, 64], "b_dim_0": [51, 64], "beta__dim_0": 51, "log10_alpha_dim_0": 51, "log10_b_dim_0": 51, "16b": 51, "64kb": 51, "867": 51, "379": 51, "235": 51, "691": 51, "191": [51, 79], "2132": 51, "4575": 51, "7189": 51, "159": 51, "8032": 51, "8652": 51, "20t01": 51, "493203": 51, "1000alpha_dim_0": 51, "2b_dim_0": 51, "2beta__dim_0": 51, "2log10_alpha_dim_0": 51, "2log10_b_dim_0": 51, "2coordin": 51, "float642": 51, "773": 51, "745": 51, "842": 51, "379arrai": 51, "86735": 51, "77317": 51, "74531": 51, "08933": 51, "06105": 51, "65147": 51, "56703": 51, "75107": 51, "16542": 51, "79654": 51, "77347": 51, "10867": 51, "63497": 51, "5682": 51, "16957": 51, "98005": 51, "53614": 51, "5058": 51, "88295": 51, "46085": 51, "9517": 51, "19794": 51, "67976": 51, "08075": 51, "55802": 51, "94599": 51, "01463": 51, "48093": 51, "25886": 51, "19726": 51, "78945": 51, "78982": 51, "45851": 51, "7594": 51, "09546": 51, "03334": 51, "60415": 51, "37894": 51, "04128": 51, "18814": 51, "3936": 51, "73299": 51, "86744": 51, "82427": 51, "84191": 51, "37865": 51, "float645": 51, "406": 51, "691arrai": 51, "2351": 51, "3362": 51, "40603": 51, "9016": 51, "64434": 51, "5218": 51, "6283": 51, "2829": 51, "59981": 51, "1368": 51, "85139": 51, "3799": 51, "4836": 51, "88547": 51, "2705": 51, "66373": 51, "2696": 51, "29264": 51, "7265": 51, "78734": 51, "3232": 51, "54503": 51, "02042": 51, "726": 51, "6697": 51, "1807": 51, "61744": 51, "0982": 51, "98924": 51, "8056": 51, "25143": 51, "1896": 51, "27248": 51, "2288": 51, "2259": 51, "96834": 51, "481": 51, "33478": 51, "0416": 51, "76565": 51, "2165": 51, "88078": 51, "172": [51, 79], "65381": 51, "3025": 51, "69076": 51, "02912": 51, "02915": 51, "2132arrai": 51, "191018": 51, "0291238": 51, "184979": 51, "0303937": 51, "274398": 51, "0289672": 51, "150868": 51, "0341496": 51, "277793": 51, "0292939": 51, "350706": 51, "0308834": 51, "028182": 51, "101159": 51, "0366697": 51, "176562": 51, "0341652": 51, "188942": 51, "0296503": 51, "208884": 51, "0309375": 51, "132538": 51, "24873": 51, "0315199": 51, "0731546": 51, "0354853": 51, "276439": 51, "0355895": 51, "334533": 51, "0271698": 51, "444163": 51, "0292486": 51, "440048": 51, "0276023": 51, "030097": 51, "201274": 51, "0339201": 51, "157859": 51, "0302649": 51, "173441": 51, "0342272": 51, "25768": 51, "0301459": 51, "176872": 51, "0291524": 51, "213185": 51, "6788": 51, "685": 51, "5287arrai": 51, "457481": 51, "678807": 51, "438592": 51, "706661": 51, "608639": 51, "66759": 51, "409431": 51, "759749": 51, "619659": 51, "680928": 51, "761437": 51, "708308": 51, "666047": 51, "1954": 51, "790255": 51, "474224": 51, "743207": 51, "398946": 51, "688683": 51, "539182": 51, "694754": 51, "342016": 51, "565819": 51, "705928": 51, "192574": 51, "774224": 51, "603645": 51, "738854": 51, "629294": 51, "622966": 51, "762637": 51, "680319": 51, "737074": 51, "677552": 51, "707183": 51, "481921": 51, "74851": 51, "376383": 51, "70254": 51, "503538": 51, "731878": 51, "572057": 51, "687301": 51, "450906": 51, "685017": 51, "528744": 51, "536": 51, "535": 51, "6712arrai": 51, "718925": 51, "53575": 51, "732878": 51, "51722": 51, "561619": 51, "53809": 51, "821402": 51, "46661": 51, "556279": 51, "53322": 51, "455057": 51, "51028": 51, "55003": 51, "994998": 51, "43569": 51, "753102": 51, "46642": 51, "723672": 51, "52797": 51, "680094": 51, "50951": 51, "877661": 51, "604271": 51, "50141": 51, "13576": 51, "44995": 51, "558401": 51, "44868": 51, "475561": 51, "56591": 51, "352458": 51, "53389": 51, "3565": 51, "55905": 51, "52148": 51, "696211": 51, "46954": 51, "801731": 51, "51906": 51, "760848": 51, "46563": 51, "58892": 51, "52077": 51, "752341": 51, "53533": 51, "671243": 51, "8652arrai": 51, "179038": 51, "159009": 51, "133145": 51, "194928": 51, "146822": 51, "152438": 51, "806095": 51, "846002": 51, "835965": 51, "872181": 51, "858328": 51, "136364": 51, "213688": 51, "164984": 51, "133647": 51, "125085": 51, "12076": 51, "793301": 51, "801544": 51, "807659": 51, "822806": 51, "803243": 51, "865222": 51, "alpha_dim_0pandasindexpandasindex": 51, "b_dim_0pandasindexpandasindex": 51, "beta__dim_0pandasindexpandasindex": 51, "log10_alpha_dim_0pandasindexpandasindex": 51, "log10_b_dim_0pandasindexpandasindex": 51, "9871": 51, "9415": 51, "9976": 51, "9587": 51, "597e": 51, "03": [51, 59, 64, 79, 96], "598e": 51, "595e": 51, "1227": 51, "1186": 51, "501268": 51, "9587arrai": 51, "987143": 51, "941549": 51, "977411": 51, "99892": 51, "976145": 51, "732715": 51, "910988": 51, "992787": 51, "951251": 51, "9523": 51, "919331": 51, "63308": 51, "997946": 51, "999491": 51, "932981": 51, "886662": 51, "992565": 51, "839946": 51, "972186": 51, "989851": 51, "943136": 51, "999211": 51, "997595": 51, "958723": 51, "03arrai": [51, 59], "1596": 51, "84": [51, 76], "75": [51, 52, 53, 56, 57, 59, 62, 70, 79, 81, 86], "1597": 51, "82": 51, "1599": 51, "1600": [51, 79], "58": [51, 59, 70, 79, 92], "1598": 51, "47": [51, 70, 72], "1601": 51, "73": [51, 70, 79], "87": [51, 59], "53": [51, 59, 70, 76, 79], "69": [51, 59, 70, 79], "1602": 51, "68": [51, 56, 59, 70, 79], "1595": 51, "59": 51, "78": [51, 59, 64], "65": [51, 70, 79], "int6423": 51, "31arrai": 51, "63": [51, 70, 79], "1186arrai": 51, "122749": 51, "119707": 51, "102969": 51, "11862": 51, "int644": 51, "5arrai": 51, "futur": [51, 53, 59, 60], "doc": 51, "478": 51, "184b": 51, "8b": [51, 59], "642": 51, "802": [51, 79], "2082": 51, "02532": 51, "422": 51, "6277": 51, "6815": 51, "597": 51, "1674": 51, "int642arrai": 51, "int64478arrai": 51, "243arrai": 51, "64227": 51, "24292": 51, "float644": 51, "80233": 51, "4987": 51, "02532arrai": 51, "208232": 51, "0253173": 51, "6277arrai": 51, "421977": 51, "627665": 51, "597arrai": 51, "681452": 51, "59658": 51, "1674arrai": 51, "167433": 51, "1xarrai": 51, "int641arrai": 51, "scalar": [51, 74, 75], "to_datafram": 51, "from_panda": [51, 79], "include_index": 51, "chaindrawalpha_dim_0b_dim_0beta__dim_0log10_alpha_dim_0log10_b_dim_0alphabbeta_log10_alphalog10_bwi64i64i64i64i64i64i64f64f64f64f64f64f6400000002": 51, "867355": 51, "23510": 51, "1910180": 51, "4574810": 51, "7189250": 51, "17903800000012": 51, "4574811": 51, "535750": 51, "17903800000102": 51, "6788070": 51, "17903800000112": 51, "6788071": 51, "17903800001002": 51, "02912380": 51, "cumbersom": [51, 61, 75], "arviz_to_datafram": [51, 53], "df_mcmc": [51, 53], "wchain__draw__diverging__f64f64f64f64f64f64f64f64f64f64f64i64i64bool2": 51, "867354": 51, "773175": 51, "235134": 51, "33620": 51, "7189251": 51, "17903800false2": 51, "745315": 51, "089335": 51, "4060332": 51, "90160": 51, "1849790": 51, "03039370": 51, "4385920": 51, "7066610": 51, "7328781": 51, "517220": 51, "15900901false4": 51, "061054": 51, "651473": 51, "6443434": 51, "52180": 51, "2743980": 51, "02896720": 51, "6086390": 51, "667590": 51, "5616191": 51, "538090": 51, "13314502false5": 51, "017854": 51, "427832": 51, "7704935": 51, "84410": 51, "3609480": 51, "02789860": 51, "7005180": 51, "6461910": 51, "4425561": 51, "554420": 51, "14577403false2": 51, "309674": 51, "870747": 51, "4160534": 51, "1050": 51, "1348430": 51, "02932120": 51, "3635510": 51, "6875950": 51, "8701731": 51, "532820": 51, "19200404fals": 51, "chain__": 51, "draw__": 51, "diverging__": 51, "par": 51, "\u03b1\u2081": 51, "\u03b1\u2082": 51, "b\u2081": 51, "b\u2082": 51, "peculiar": 51, "reveal": 51, "glyph": [51, 53], "id": [51, 79, 90], "color_by_chain": [51, 92], "blue": [51, 56, 69], "red": [51, 92], "green": 51, "uncov": [51, 71, 72], "observation": 51, "emphas": [51, 59, 73], "devilish": 51, "vigil": 51, "b_1": 51, "b_2": 51, "overlap": [51, 61, 74, 92], "filter": [51, 55, 75], "col": [51, 55, 72, 73, 74, 75, 76, 78], "renam": 51, "with_column": [51, 55, 72, 73, 74, 76, 78], "alia": [51, 55, 72, 73, 74, 76, 78], "df_switch": 51, "concat": [51, 92], "alon": [51, 56], "param_mean": 51, "wf64f64f64f64f645": 51, "2096973": 51, "16429831": 51, "9572976": 51, "2381460": 51, "831563": 51, "init": [51, 64, 79], "unconstrain": 51, "warmup": 51, "advis": 51, "hoc": [51, 58], "05": [51, 70, 73, 74, 76, 78, 86, 96], "alpha0": 51, "alpha1": 51, "beta0": 51, "beta1": 51, "fragil": 51, "closer": [51, 56, 61, 62, 64, 79], "microtubul": [52, 56, 79, 92], "departur": [52, 79], "sacrific": 52, "largest": 52, "smallest": 52, "uncomfort": 52, "millimet": 52, "gamma_": [52, 53, 56, 57, 62, 79], "denom_ratio": [52, 53, 56, 57, 62, 79], "log10_phi": [52, 53], "syntact": 52, "parenthes": 52, "plane": 52, "plot_ecdf": [52, 53], "depict": [52, 70], "eschew": 52, "promis": 53, "quickli": [53, 55, 81, 86, 90], "aesthet": 53, "trajectori": [53, 59, 86, 88], "trace_plot": 53, "plot_": 53, "backend": 53, "plot_trac": 53, "kde": 53, "bandwidth": 53, "dan": 53, "minimum": [53, 58], "plot_parallel": 53, "var_nam": [53, 72, 90], "norm_method": 53, "minmax": [53, 70], "parcoord": [53, 60, 70], "neck": 53, "vice": [53, 86], "versa": [53, 86], "plot_dens": 53, "highest": [53, 55], "hpd": [53, 55], "shortest": [53, 55], "backend_kwarg": 53, "bokehdeprecationwarn": 53, "deprec": 53, "remov": [53, 60, 61, 70, 76, 90], "gamma_log10_phiphisigmachain__draw__diverging__f64f64f64f64i64i64bool0": 53, "8760751": 53, "5813638": 53, "13823": 53, "7229800false0": 53, "8695911": 53, "5794137": 53, "96693": 53, "7328201false0": 53, "8521091": 53, "5858338": 53, "53243": 53, "803702false0": 53, "8800941": 53, "5797237": 53, "99453": 53, "7278603false0": 53, "8934751": 53, "5709837": 53, "23743": 53, "7522504fals": 53, "hist": 53, "transpar": 53, "plot_pair": 53, "scatter_kwarg": 53, "fill_alpha": [53, 72], "radius_unit": 53, "represent": [53, 88, 90], "uni": 53, "hex": 53, "hexbin": 53, "xtick_label_orient": [53, 57, 62, 64, 67, 70, 92], "beauti": [55, 61, 65, 86], "lie": [55, 56, 57, 62], "plu": [55, 73, 78, 86], "5th": [55, 59], "percentil": [55, 56, 57, 59, 62, 67], "97": [55, 70, 79], "hdi": 55, "scheme": 55, "tail": [55, 56, 58, 59, 60, 64, 70, 74, 88, 92], "sigma_2": [55, 58], "x_expon": 55, "15000": 55, "x_norm": 55, "which_norm": 55, "x_2norm": 55, "pareto": [55, 61, 64], "x_heavytail": 55, "readili": [55, 74], "trace": [55, 59, 60, 92], "df_summari": 55, "hpd_low": 55, "hpd_high": 55, "schema": 55, "dist": 55, "concaten": [55, 76], "hdi_prob": 55, "statisticexponentialnormaltwo": 55, "normalsheavi": 55, "tailstrf64f64f64f64": 55, "quot": [55, 70, 72], "0078431": 55, "0014472": 55, "0040054": 55, "134071": 55, "0053510": 55, "249141": 55, "0738544": 55, "580247": 55, "0248750": 55, "5115520": 55, "5904380": 55, "02307": 55, "7010921": 55, "0006981": 55, "7679750": 55, "79814": 55, "6495411": 55, "492053": 55, "80497720": 55, "613608": 55, "0000880": 55, "5318630": 55, "5613620": 55, "000057": 55, "9965491": 55, "5073143": 55, "75565311": 55, "296449": 55, "y_valu": 55, "category10": [55, 67], "plot_interv": 55, "barx": 55, "is_in": 55, "asymmetri": 55, "finder": 55, "uniniti": 55, "suffer": [55, 88], "interquantil": 55, "modal": [55, 92], "mislead": 55, "futil": 55, "deceiv": 55, "chanc": [55, 59, 86, 92], "reeeealli": 55, "71": 55, "struggl": [56, 88], "symptom": [56, 70], "produc": [56, 57, 61, 71, 74, 89, 90, 92], "obei": 56, "cytoplasm": 56, "embryogenesi": 56, "colleagu": 56, "regress": [56, 57, 63, 73], "hone": 56, "670": [56, 57, 62], "uniformli": [56, 71, 72], "inher": [56, 59, 73], "resid": 56, "depolymer": 56, "e_i": 56, "compon": [56, 86, 89, 92], "datum": [56, 61], "establish": 56, "sound": 56, "varieti": [56, 64, 90], "uncertain": [56, 61], "irrelev": [56, 74], "ey": [56, 57, 64, 74, 75, 90], "nonposit": 56, "vanish": 56, "unrealist": 56, "ultim": [56, 58, 70, 72], "jettison": 56, "halfnorm_pdf": 56, "350": [56, 73, 74, 75, 76], "lognorm_pdf": 56, "n_ppc_sampl": 56, "ab": [56, 60, 72, 80], "ph": [56, 73], "sig": 56, "thin": [56, 67, 92], "20th": 56, "ell_val": 56, "line_alpha": [56, 60, 72], "predictive_ecdf": [56, 57, 62, 64, 72, 92], "n_": [56, 59, 76], "middl": [56, 57, 62, 79], "darker": 56, "fill": [56, 90], "extent": 56, "willing": 56, "toler": [56, 74], "tug": 56, "substanti": [56, 60, 71, 79], "059903": 56, "linearli": [56, 86, 89], "gamma_pdf": 56, "\u03c3\u2080": 56, "settl": 56, "clearer": [56, 72, 79], "_rng": 56, "lognormal_rng": 56, "gamma_rng": [56, 72, 90, 92], "tweak": 56, "recompil": 56, "phi_mu": 56, "phi_sigma": 56, "sigma_0_alpha": 56, "sigma_0_beta": 56, "sm_prior_pr": [56, 72], "indep_size_model_prior_predict": 56, "alert": [56, 81], "parallel": [56, 59, 60, 70, 88, 90], "prior_predict": [56, 72, 73, 90], "reshap": [56, 57], "2d": [56, 88], "verbos": 56, "hing": 56, "polymer": 56, "assembli": 56, "balanc": [56, 88], "catastroph": [56, 86, 92], "t_0": [56, 86], "t_1": 56, "t_": [56, 74, 88], "gg": [56, 62], "l_": 56, "mt": 56, "unimport": 56, "geometri": [56, 88], "nmol": 56, "threshold": 56, "ccl": 56, "assur": 56, "prolat": 56, "spheroid": 56, "spheric": 56, "microscop": [56, 58, 70, 92], "growth": [56, 75], "spectroscop": 56, "vitro": 56, "assai": 56, "2t_": 56, "distinguish": [56, 65, 86], "ones": [56, 59, 72, 74, 75, 79, 86, 92], "lest": [56, 59], "unidentifi": 56, "dire": 56, "commensur": [56, 57, 58, 61], "enhanc": [56, 90], "strive": [56, 81], "didn": [56, 72, 73], "slight": [56, 69], "baselin": 56, "continuum": 56, "basi": [56, 73, 88], "gamma_alpha": 56, "gamma_beta": 56, "beta_rng": 56, "cons_tubulin_model_prior_predict": 56, "span": [56, 64], "predictive_regress": [56, 57, 62, 73, 74, 75, 76, 78, 79], "30th": 56, "60th": 56, "90th": 56, "99th": [56, 57, 62], "samples_x": [56, 57, 62, 73], "60": [56, 72, 75, 79], "javascript": 56, "slider": [56, 70], "draw_slid": 56, "data_dict": 56, "str": 56, "sel": [56, 64, 67], "cd": 56, "columndatasourc": 56, "params_dict": 56, "squeez": [56, 72], "cds_param": 56, "div": 56, "js_code": 56, "cb_obj": 56, "tostr": 56, "toprecis": 56, "emit": 56, "customj": 56, "js_on_chang": 56, "spacer": 56, "encompass": [56, 71, 72, 73, 74], "replot": 56, "heavili": [56, 71, 79, 86, 88, 92], "coupl": [56, 57, 73, 92], "examin": 56, "mayb": [56, 58, 73], "relax": 56, "spindle_volum": 56, "vol_ratio": 56, "ul": 56, "v0": 56, "nonconst": 56, "highlight": [56, 57, 79], "ell_ppc": [57, 62, 79], "indep_size_model": 57, "posterior_predict": [57, 62, 64, 72, 73, 75, 76, 78, 92], "n_sampl": 57, "stack": [57, 59, 62, 64, 72, 73, 74, 75, 76, 78, 92], "collaps": 57, "transpos": [57, 62, 64, 72, 73, 74, 75, 76, 78, 92], "ell_ppc_dim_0": [57, 62], "diff": [57, 62, 72, 92], "vstack": [57, 73], "trend": 57, "envelop": [57, 71, 72, 73, 74], "n_ppc": [57, 62, 64, 72, 73, 79, 90, 92], "d_ppc": [57, 62, 79], "mu_ppc": [57, 62, 79], "cons_tubulin_model": 57, "lost": 57, "former": [57, 88], "shelf": 58, "oftentim": 58, "pare": 58, "pixel": 58, "interpixel": 58, "optic": [58, 75], "digit": 58, "camera": 58, "simplifi": 58, "bivari": 58, "fourth": 58, "symmetri": 58, "s_": [58, 73], "sigma_1": 58, "c_": 58, "lkj": 58, "rethink": [58, 95], "underpin": [58, 88], "inappropri": 58, "underli": [58, 61, 71, 73, 76, 92], "inclin": 58, "depart": 58, "inadequ": 58, "adequ": [58, 72], "lightest": 58, "heaviest": 58, "cauchi": 58, "distirbut": 58, "heavier": [58, 88], "opposit": [58, 70], "slower": [58, 92], "log10_v": 58, "reproduc": [59, 81], "rhat": [59, 60, 62, 64, 67, 70, 72, 73, 75, 76, 78, 92], "40b": 59, "007": 59, "007xarrai": 59, "007arrai": 59, "00714323": 59, "00676445": 59, "00684101": 59, "00707471": 59, "00687351": 59, "sd": 59, "hdi_3": 59, "hdi_97": 59, "mcse_mean": 59, "mcse_sd": 59, "ess_bulk": 59, "ess_tail": 59, "r_hat": 59, "521": 59, "398": [59, 79], "769": 59, "266": 59, "014": [59, 79], "010": 59, "797": 59, "679": 59, "706": 59, "056": 59, "040": [59, 79], "763": 59, "709": 59, "060": 59, "006": [59, 64, 79], "049": 59, "070": 59, "654": 59, "038": [59, 79], "576": 59, "221": 59, "142": 59, "295": 59, "samples_limited_warmup": 59, "iter_warmup": [59, 72, 73], "018": [59, 79], "876": 59, "119": [59, 70], "151": 59, "729": 59, "798": 59, "644": 59, "31633592": 59, "252": 59, "091": 59, "299": 59, "683": 59, "486": 59, "734": 59, "293": 59, "149": 59, "241": 59, "114": 59, "714": 59, "841": 59, "059": 59, "419": 59, "321": 59, "868": 59, "327": 59, "925": 59, "181": [59, 79], "661": 59, "506": [59, 76], "272": [59, 64], "395": 59, "314": 59, "866": [59, 79], "695": 59, "532": 59, "poor": [59, 60, 72, 92], "rejec": 59, "caveat": [59, 92], "ideal": [59, 72, 92], "ess": [59, 60, 64, 70, 72, 88, 92], "eff": 59, "prescript": [59, 73], "4000": [59, 60, 62, 64, 67, 70, 72, 73, 75, 76, 78, 79, 92], "500": [59, 79, 86, 92], "ess_mean": 59, "ess_sd": 59, "land": [59, 90], "mcse": 59, "msce_mean": 59, "accur": [59, 86], "wonder": 59, "curvatur": [59, 60, 86, 88], "veer": 59, "sharpli": [59, 61, 65], "regist": 59, "1000fals": 59, "improperli": 59, "3002": 59, "yike": 59, "endem": 59, "sciencei": 59, "unfamiliar": 59, "recurs": 59, "en": 59, "org": [59, 90], "recursion_": 59, "computer_sci": 59, "deep": [59, 60, 90], "cap": 59, "wrong": 59, "10003": 59, "decreas": [59, 60, 73, 86, 88, 90], "ineffici": [59, 88], "1379": 59, "1378": 59, "09": [59, 96], "1377": 59, "98": 59, "1381": 59, "76": [59, 70, 79], "62": 59, "1380": 59, "1383": 59, "1382": 59, "72": [59, 64, 70, 79], "10001": 59, "379e": 59, "38e": 59, "nope": 59, "wrote": [59, 61, 81, 92], "submodul": 59, "check_all_diagnost": [59, 60, 62, 64, 67, 70, 72, 73, 75, 76, 78, 92], "satur": [59, 60, 62, 64, 67, 70, 72, 73, 75, 76, 78, 92], "forthcom": 60, "hack": 60, "probabilti": 60, "thoma": 60, "wiecki": 60, "microinject": 60, "tip": [60, 81], "radford": 60, "neal": 60, "girolami": 60, "450": [60, 70, 73, 86], "66c2a5": 60, "indep": 60, "bottom_left": 60, "2509935801914": 60, "17582178946987": 60, "061082354895177": 60, "103015323352217": 60, "483": 60, "075": 60, "tree": [60, 62, 64, 67, 70, 72, 73, 75, 76, 78, 92], "bfmi": [60, 62, 64, 67, 70, 72, 73, 75, 76, 78, 88, 92], "trust": 60, "hide": [60, 70], "fc8d62": 60, "click_polici": [60, 70], "penetr": 60, "correctli": 60, "awar": [60, 72], "clue": 60, "stuck": [60, 92], "log10": 60, "divergence_kwarg": 60, "advic": [60, 79], "messag": [60, 79, 81], "crank": 60, "8da0cb": 60, "335": 60, "8697624482687": 60, "188": [60, 79], "9130440674577": 60, "123": 60, "79148039281294": 60, "109": 60, "7300569471941": 60, "0225440084677622": 60, "028248959476883": 60, "825": 60, "5103845064002706": 60, "3791047493010087": 60, "6261488838631215": 60, "28202314605045126": 60, "shy": [60, 64], "tild": [60, 61, 64, 70, 71, 74, 76], "uncent": [60, 70, 71, 73, 74, 75, 76, 78, 96], "henc": [60, 70, 86, 88, 92], "theta_tild": 60, "bother": [60, 61, 72], "funnel_noncent": 60, "excel": [60, 71, 72, 74], "No": [60, 81, 86, 88, 90, 96], "e78ac3": 60, "spent": [61, 81], "biolog": [61, 69], "theta_m": [61, 73], "g_m": 61, "f_m": 61, "eq": 61, "model_bay": 61, "f_t": [61, 64], "digest": 61, "overli": 61, "reduct": 61, "p_i": [61, 88], "haven": 61, "pope": 61, "cathol": 61, "improb": 61, "garner": 61, "p_ip_j": 61, "p_j": 61, "addabl": 61, "tradit": 61, "ensembl": 61, "surpris": [61, 76, 92], "shannon": [61, 79], "thermodynam": 61, "delv": 61, "rich": [61, 90], "knew": 61, "unbias": 61, "shortcut": 61, "1948": 61, "claud": [61, 81], "desiderata": 61, "composit": 61, "law": [61, 73], "extend": [61, 81, 88], "cross": [61, 64, 92], "q_i": [61, 79, 86, 88], "govern": [61, 69, 70, 92], "induc": [61, 88], "kl": [61, 79], "d_": [61, 79], "sum_ip_i": 61, "f_": 61, "m_a": 61, "m_b": 61, "awkward": 61, "_i": [61, 64, 71, 73, 75, 76], "nf_m": 61, "elppd": 61, "lpd": 61, "lppd": 61, "_j": [61, 64, 73], "_t": 61, "overestim": [61, 71, 79], "discrep": [61, 71], "p_": [61, 64], "gabri": [61, 64], "arxiv": [61, 64, 86], "therein": 61, "incred": 61, "histor": [61, 64], "held": 61, "remain": [61, 74, 79, 81], "pleasant": 61, "expens": [61, 71, 79], "pacakg": 61, "criteria": [61, 62, 64, 88], "m_i": 61, "m_j": 61, "w_i": [61, 64], "plai": 61, "immens": [61, 90], "invis": 61, "log_lik": [62, 64, 92], "normal_lpdf": [62, 92], "sm_indep": 62, "indep_s": 62, "sm_con": 62, "cons_tubulin": 62, "samples_indep": 62, "samples_con": 62, "ic": [62, 64], "devianc": [62, 64, 73], "elpd_loo": [62, 64], "p_loo": [62, 64], "elpd_diff": [62, 64], "se": [62, 64, 73, 74, 75, 76, 78, 88], "dse": [62, 64], "3662": 62, "643494": 62, "260725": 62, "000000": [62, 64], "354190": 62, "00000": 62, "4003": 62, "001053": 62, "950445": 62, "340": 62, "357559": 62, "379594": 62, "52863": 62, "elpd": 64, "kullback": [64, 79], "leibler": [64, 79], "watanab": 64, "akaik": 64, "criterion": 64, "terribli": 64, "prospect": 64, "straightforward": [64, 65, 70], "easiest": [64, 70, 74], "scientist": [64, 81], "aim": [64, 73, 88], "yao": 64, "pure": [64, 73, 75], "academ": 64, "spectacularli": 64, "neg_binomial_rng": [64, 72, 90], "neg_binom": 64, "doesn": [64, 88, 92], "n_ppc_dim_0": [64, 72], "9mb": 64, "log_lik_dim_0": 64, "2kb": 64, "274": 64, "275": 64, "276": 64, "277": 64, "278": 64, "24t05": 64, "208975": 64, "1000log_lik_dim_0": 64, "279coordin": 64, "278arrai": 64, "871": 64, "571": 64, "006arrai": 64, "9195": 64, "87102": 64, "68695": 64, "26063": 64, "48547": 64, "87587": 64, "86585": 64, "88487": 64, "24419": 64, "48612": 64, "91271": 64, "66727": 64, "93771": 64, "63568": 64, "34274": 64, "58902": 64, "79424": 64, "68369": 64, "92896": 64, "68832": 64, "29315": 64, "55258": 64, "86131": 64, "83427": 64, "8913": 64, "70419": 64, "25863": 64, "50083": 64, "89138": 64, "72091": 64, "92151": 64, "6401": 64, "32705": 64, "56721": 64, "8041": 64, "69304": 64, "9281": 64, "75358": 64, "24444": 64, "5209": 64, "94195": 64, "63444": 64, "94668": 64, "80166": 64, "22269": 64, "52082": 64, "99609": 64, "90389": 64, "8773": 64, "59252": 64, "33818": 64, "53827": 64, "75795": 64, "83866": 64, "892": 64, "73364": 64, "23837": 64, "48808": 64, "92752": 64, "44289": 64, "99838": 64, "74154": 64, "30305": 64, "61111": 64, "90777": 64, "69926": 64, "9251": 64, "67632": 64, "29999": 64, "55376": 64, "84761": 64, "72413": 64, "91933": 64, "65612": 64, "3123": 64, "5567": 64, "82437": 64, "47554": 64, "99033": 64, "81682": 64, "24099": 64, "56584": 64, "0027": 64, "65642": 64, "93676": 64, "68018": 64, "30494": 64, "56586": 64, "84914": 64, "7639": 64, "90806": 64, "69262": 64, "2766": 64, "52578": 64, "87242": 64, "91387": 64, "87357": 64, "60488": 64, "32544": 64, "52772": 64, "77417": 64, "45548": 64, "99638": 64, "82115": 64, "2423": 64, "57115": 64, "00638": 64, "log_lik_dim_0pandasindexpandasindex": 64, "269": 64, "270": 64, "273": 64, "tradition": 64, "deviance_wa": 64, "3281": 64, "p_waic": 64, "single_loo": 64, "deviance_loo": 64, "pct": 64, "wider": 64, "_logpmf": 64, "uniform_rng": 64, "sm_mix": 64, "neg_binom_mix": 64, "samples_mix": 64, "004040383981042": 64, "318": 64, "7069921736581": 64, "836302265033044": 64, "2393686900295": 64, "432640073574931": 64, "126": 64, "12692598049735": 64, "210628341260978": 64, "183": [64, 79], "7239430399982": 64, "432641423716465": 64, "12692598048358": 64, "210629331032064": 64, "72394304000517": 64, "1460975400222795": 64, "170": [64, 79], "8943375375399": 64, "3240338139575638": 64, "3286803456589167": 64, "6654700530731357": 64, "72055885067414": 64, "665470122994841": 64, "7205589366050218": 64, "7356984105623074": 64, "oof": [64, 72, 76, 79], "2774578420000005": 64, "23979613": 64, "64700481": 64, "16986432480000002": 64, "nicer": 64, "3191": 64, "mix_loo": 64, "88": 64, "89": 64, "33459299576725": 64, "d_loo": 64, "w_singl": 64, "w_mix": 64, "99245113565338e": 64, "agreement": 64, "884444": 64, "778852": 64, "983497": 64, "718306": 64, "219037": 64, "927518": 64, "334593": 64, "016503": 64, "315398": 64, "565504": 64, "hyperprior": [65, 67, 69, 70, 73, 78], "theta_k": [65, 69, 73, 74, 75, 78], "permut": 65, "worm": [65, 66, 67, 69], "revers": [65, 66, 67, 90], "permuat": 65, "nuanc": 65, "advanc": 65, "recov": [65, 71, 88], "nonhierarch": 65, "kappa": [65, 67], "hyperparamet": [66, 67, 69, 70, 73, 75, 76, 77, 79], "portion": [66, 76, 81, 86, 88], "d3": 67, "2016": [67, 69], "synthet": [67, 76], "110": 67, "660": 67, "pool": [67, 70, 79], "worm_hier": 67, "adapt_delta": [67, 70, 73, 76, 79, 86, 88], "2000": [67, 72, 79], "global": [67, 69, 79, 90], "diamond": [67, 92], "650": 67, "theta_dim_0": 67, "\u03b2": [67, 92], "theta_map": 67, "bottom_right": [67, 70, 92], "significantli": [67, 79, 90], "240": 67, "292": 67, "exposur": 69, "channelrhodopsin": 69, "neuron": 69, "ash": 69, "sensori": 69, "1x": 69, "disfavor": 69, "n_1": 69, "n_2": 69, "indirectli": 69, "compris": 69, "dig": 70, "mondai": [70, 79, 81, 96], "batch": [70, 79, 90], "plate": 70, "coloni": [70, 79, 92], "mount": 70, "slide": [70, 80], "microscopi": [70, 89, 92], "wednesdai": [70, 79, 81, 96], "thursdai": [70, 79, 81, 96], "diagram": 70, "phantom": 70, "theta_3": [70, 79], "condition": 70, "j_1": [70, 79], "j_2": [70, 79], "j_k": 70, "j_3": [70, 79], "straight": 70, "clariti": 70, "index_1": [70, 79], "index_2": [70, 79], "index_3": [70, 79], "fabric": [70, 81], "weird": [70, 90], "compact": 70, "data_str": [70, 79], "41": [70, 79], "74": [70, 79], "nw": [70, 79], "42": [70, 79], "nr": [70, 79], "stringio": [70, 79], "daybatchcolonyystri64i64f64": 70, "1111": 70, "1110": 70, "1112": 70, "metadata": 70, "cat": [70, 72, 76, 79, 92], "color_column": [70, 72, 79], "marker_kwarg": [70, 72, 76, 79], "adher": 70, "categor": [70, 72, 92], "df_to_datadict_hi": [70, 79], "convei": 70, "level_col": [70, 79], "data_col": [70, 79], "hellip": [70, 79], "129": [70, 79], "1210": 70, "1310": 70, "1412": 70, "sm_center": 70, "samples_cent": 70, "hopefulli": [70, 72, 79, 88], "dianost": 70, "120": 70, "6206946627826": 70, "193": [70, 79], "46855809117585": 70, "0181667967555237": 70, "0104461055496787": 70, "17398128059170156": 70, "09851564271989993": 70, "12373822952024313": 70, "07573497349280298": 70, "whew": 70, "strikingli": [70, 72], "theta_1_dim_0": 70, "theta_2_dim_0": 70, "theta_3_dim_0": 70, "allevi": 70, "_1": [70, 73, 74, 75], "_2": [70, 74, 75], "_3": 70, "theta_1_tild": 70, "theta_2_tild": 70, "theta_3_tild": 70, "sm_noncent": 70, "samples_noncent": 70, "gone": 70, "y_axis_typ": [70, 72, 75], "articl": 71, "unsatisfi": [71, 92], "flow": [71, 89], "reliabl": [71, 72], "ground": [71, 72], "truth": [71, 72], "talt": 71, "umbrella": 71, "sensit": [71, 72], "abus": [71, 73, 86], "forgiv": 71, "ant": [71, 92], "experimentum": 71, "hundr": 71, "uncertainti": [71, 73], "z_i": 71, "rangle_": 71, "sign": [71, 86], "overfit": [71, 72], "s_i": 71, "drift": [71, 88], "permit": 71, "coverag": [71, 72], "surround": 71, "diagnosi": 71, "empir": [72, 88], "justif": 72, "prior_pr": [72, 90], "choke": 72, "samples_prior_pr": [72, 90], "range1d": 72, "3e5": 72, "nanmax": 72, "poissonian": 72, "dispers": 72, "upward": 72, "mammalian": 72, "ingredi": 72, "requisit": [72, 81], "df_sbc": [72, 90], "prior_predictive_model": [72, 90], "posterior_model": [72, 90], "prior_predictive_model_data": [72, 90], "posterior_model_data": [72, 90], "measured_data": [72, 90], "measured_data_dtyp": [72, 90], "progress_bar": [72, 90], "07it": 72, "ground_truthrank_statisticmeansdshrinkagez_scorerhatessess_per_itertail_esstail_ess_per_itern_divergencesn_bad_ebfmin_max_treedepthwarning_codeltrialerrorparameterf64i64f64f64f64f64f64f64f64f64f64i64i64i64i64i64i64strstr0": 72, "002862101": 72, "0053340": 72, "0052541": 72, "0190": 72, "8112971": 72, "0023851662": 72, "3330420": 72, "4155831245": 72, "9198970": 72, "31148000040000": 72, "592778483": 72, "8443910": 72, "3097990": 72, "9999590": 72, "8122061": 72, "004025732": 72, "4173080": 72, "183104694": 72, "8219580": 72, "173705000040001": 72, "2772539031": 72, "1166130": 72, "0717330": 72, "999998": 72, "2393821": 72, "004734780": 72, "7275920": 72, "1951821050": 72, "450650": 72, "262613200440002": 72, "62861396101": 72, "20665711": 72, "1994990": 72, "9459420": 72, "4087731": 72, "005957512": 72, "1181450": 72, "12803548": 72, "8116860": 72, "137203000040003": 72, "91851601": 72, "0684490": 72, "0510140": 72, "9999992": 72, "9390361": 72, "001264807": 72, "4313030": 72, "201858936": 72, "5215790": 72, "23413100440004": 72, "warning_cod": 72, "succinct": 72, "parse_warning_cod": 72, "treedepth": 72, "tooltip": 72, "sub_df": 72, "1f77b4": 72, "group_bi": 72, "z_score": 72, "evidenc": 72, "good_z": 72, "ground_truth": 72, "jitter": [72, 76], "creat": [72, 75, 90], "expos": 72, "abort": 72, "signal": [72, 89, 92], "002": [72, 90], "5000": 72, "problemat": [72, 88], "sm_prior_pred_2": [72, 90], "prior_pred_2": 72, "1e6": 72, "sm_2": [72, 90], "model_2": 72, "posterior_predictive_var_nam": [72, 90], "48it": 72, "warning_codeleni64u32087721073818": 72, "sampling_kwarg": [72, 90], "93it": 72, "warning_codeleni64u32210999": 72, "decent": 72, "sbc_rank_ecdf": 72, "hadn": 73, "untest": 73, "amplitud": [73, 74, 76], "methylglucopyranosid": 73, "hydrolysi": 73, "cellulos": 73, "wolfenden": [73, 74, 76, 78], "snider": [73, 74, 78], "enzym": 73, "catalyst": 73, "glucosid": 73, "temperatur": [73, 74, 76, 78], "wolfenden_arrheniu": [73, 74, 76, 78], "chemic": [73, 76, 78], "arrheniu": 73, "e_a": 73, "k_bt": 73, "k_b": 73, "t_i": [73, 75, 76, 92], "k_i": 73, "fun": 73, "t_ppc": [73, 92], "log10_ea": 73, "log10_a": 73, "ea": 73, "k_ppc": [73, 74, 78], "uncatalyz": 73, "reaction": 73, "530": 73, "sm_parametr": 73, "max_treedepth": [73, 76], "16000": 73, "k_ppc_dim_0": 73, "sec": 73, "meaning": 73, "kinet": [73, 76], "capit": 73, "epsilon_i": 73, "primarili": 73, "_n": 73, "latent": [73, 78, 79, 92], "semi": 73, "hugo": 73, "bown": 73, "anderson": 73, "arithmet": 73, "certain": [73, 86, 90], "k_": [73, 75, 76], "gram": 73, "sigma_b": 73, "polynomi": 73, "sigma_p": 73, "vert": 73, "vert_2": 73, "mat\u00e9rn": 73, "sin": [73, 76], "modifi": [73, 75, 79, 86, 88, 90], "bessel": [73, 75], "quadrat": 73, "radial": 73, "spirit": 73, "realiz": 73, "rough": [73, 75], "farther": [73, 86], "apart": 73, "unrel": 73, "tunabl": 73, "multinorm": [73, 74, 75, 76, 78, 79], "nstar": [73, 74, 75, 76, 78], "xstar": [73, 74, 75, 76, 78], "gp_exp_quad_cov": [73, 74, 75, 76, 78], "diag_matrix": [73, 74, 75, 76, 78], "rep_vector": [73, 74, 75, 76, 78], "choleski": [73, 74, 76, 78], "decomposit": [73, 74, 76, 78], "cholesky_decompos": [73, 74, 75, 76, 78], "multi_normal_cholesky_rng": [73, 75, 78], "gp_cov_exp_quad": 73, "stabil": [73, 92], "sm_prior": 73, "gp_prior_fixed_rho_alpha": 73, "\u03c1": [73, 74, 75], "rougher": [73, 75], "cov_matern": [73, 75], "rg": 73, "spaghetti": 73, "cov_exp_quad": [73, 74, 75, 78], "multi_lin": 73, "mult_kern": 73, "x1": 73, "x2": 73, "rho_s": 73, "rho_per": 73, "periodic_kernel": 73, "se_kernel": 73, "cov_from_kernel": 73, "add_kern": 73, "linear_kernel": 73, "c_1": 73, "c_2": 73, "iptg": 73, "poi": 73, "c_i": 73, "heteroscedast": 73, "lll": 73, "diag": [73, 74, 75], "unmeasur": 73, "5em": [73, 88], "triangular": 73, "stabli": 73, "shade": 73, "k_scale": [73, 74, 76, 78], "t_scale": [73, 74, 75, 76, 78], "t_rang": [73, 74, 76, 78], "manipul": [73, 78, 79, 90], "posterior_mean_cov": [73, 74, 75], "mstar": [73, 74, 75, 78], "sigmastar": [73, 74, 75, 78], "unscal": [73, 74, 75, 76, 78], "tstar": [73, 74, 75, 76, 78], "kstar": [73, 74, 75, 78], "show_lin": [73, 74, 75], "exent": 73, "muster": 73, "dampen": 73, "favor": [73, 75, 92], "flatter": 73, "simplif": 73, "gp": [74, 77], "stipul": 74, "wiggli": 74, "outlier": 74, "contort": 74, "invgamma": [74, 75, 76, 78], "singular": [74, 75, 88, 90], "diag_to_add": [74, 75], "ky": [74, 75, 78], "4f": [74, 75], "5887": 74, "5791": 74, "0886": 74, "miniconda3": [74, 75, 90], "env": [74, 75], "bebi103_build": [74, 75], "lib": [74, 75, 90], "python3": [74, 75, 90], "_optim": [74, 75], "py": [74, 75, 86, 90], "2472": [74, 75], "runtimewarn": [74, 75, 86], "tmp2": [74, 75], "fx": [74, 75], "fw": [74, 75], "nonparametr": [74, 75, 76, 78], "draw_gp_ppc": 74, "y_mean": 74, "y_std": 74, "nonparameter": 74, "inv_gamma": [74, 75, 76, 78], "multi_normal_choleski": [74, 75, 78], "gp_kinetics_no_ppc": [74, 78], "optimized_params_dict": 74, "ordereddict": 74, "lp__": [74, 79], "79106": 74, "40338": 74, "25657": 74, "0893158": 74, "optimized_params_pd": 74, "od": [75, 88], "remark": 75, "peter": 75, "swain": 75, "tom": [75, 86, 88], "r\u00f6schinger": [75, 86], "wild": 75, "roeschinger_growth_rate_data": 75, "tetracycline_conc_\u00b5g_per_ml": 75, "mg1655": 75, "a01": 75, "time_min": 75, "od600": 75, "hr": 75, "extrapol": 75, "od600_scal": 75, "solak": 75, "ourselv": 75, "2_x": 75, "z_j": 75, "partial_1": 75, "partial_2": 75, "pertin": 75, "matern": 75, "1420": 75, "5917": 75, "0118": 75, "augment": 75, "posterior_mean_cov_deriv": 75, "exp_quad_kernel": 75, "gstar": 75, "sigma_g_star": 75, "od600star": 75, "deriv_high": 75, "deriv_low": 75, "deriv_star": 75, "dt": [75, 86], "2_z": 75, "mu_z": 75, "mu_x": 75, "2_y": 75, "shortli": 75, "growth_rat": 75, "sigma_growth_r": 75, "gr_high": 75, "gr_low": 75, "redefin": 75, "matern_kernel": 75, "wiggl": 75, "gp_one_dimension": [75, 78], "stanfunct": 75, "fstar": [75, 76, 78], "dfstar": 75, "y_ppc": [75, 76, 78], "kstarstar": [75, 78], "d1_kstar": 75, "d1_cov_exp_quad": 75, "d1_d2_kstarstar": 75, "d1_d2_cov_exp_quad": 75, "gp_posterior_mstar": [75, 78], "lstar": [75, 78], "gp_posterior_sigmastar_choleski": [75, 78], "sigmag": 75, "l_g_star": 75, "gp_growth_curv": 75, "stanc_opt": [75, 78], "include_path": [75, 78], "y_ppc_dim_0": [75, 78], "od600_ppc": 75, "dfstar_scal": 75, "dfstar_dim_0": 75, "fstar_scal": [75, 76, 78], "fstar_dim_0": [75, 78], "experienc": 75, "unmargin": 76, "f_i": 76, "layer": 76, "hyperparamat": 76, "preprocess": 76, "xstar_ind": 76, "f_tild": 76, "append_sort_index": 76, "index_origin": 76, "duplic": 76, "indici": 76, "73988004": 76, "67222743": 76, "60457482": 76, "58919923": 76, "53692222": 76, "46926961": 76, "401617": 76, "3339644": 76, "26631179": 76, "22693001": 76, "19865918": 76, "13100658": 76, "06335397": 76, "99570136": 76, "96124699": 76, "92804876": 76, "86039615": 76, "79274354": 76, "72509093": 76, "65743833": 76, "58978572": 76, "52324311": 76, "52213311": 76, "45448051": 76, "3868279": 76, "31917529": 76, "25152269": 76, "18459205": 76, "18387008": 76, "11621747": 76, "04856487": 76, "01908774": 76, "08674035": 76, "15439295": 76, "22204556": 76, "28969817": 76, "35735077": 76, "42500338": 76, "49265599": 76, "50367757": 76, "56030859": 76, "6279612": 76, "69561381": 76, "76326641": 76, "81156517": 76, "83091902": 76, "89857163": 76, "96622423": 76, "03387684": 76, "10152945": 76, "16918205": 76, "23683466": 76, "2418742": 76, "30448727": 76, "37213987": 76, "42441689": 76, "43979248": 76, "50744509": 76, "57509769": 76, "56": [76, 90], "526": 76, "97268063": 76, "522": 76, "8398459": 76, "513": 76, "09748852": 76, "12679808": 76, "490": 76, "5441167": 76, "482": 76, "87692992": 76, "472": [76, 79], "96035845": 76, "466": 76, "94519538": 76, "458": 76, "74328484": 76, "leapfrog": [76, 79, 88], "gp_kinetics_no_marg": 76, "dial": 76, "475": 76, "f_dim_0": 76, "data_kwarg": [76, 78], "1f78b4": [76, 78], "contriv": [76, 79], "scenario": [76, 90, 92], "a_0": 76, "varying_funct": 76, "a0": 76, "a1": 76, "\u03bb": 76, "time_point": 76, "n_cell": 76, "astyp": 76, "plop": 76, "fram": 76, "q_axi": 76, "600": [76, 79], "t_ind": 76, "log_f_tild": 76, "log_f": 76, "poisson_log": 76, "poisson_log_rng": 76, "gp_transcript_count": 76, "184": [76, 79], "3782": 76, "log_fstar": 76, "log_f_dim_0": 76, "mdivide_left_tri_low": 78, "mdivide_right_tri_low": 78, "sigma_star": 78, "po": 78, "emploi": [78, 79, 89, 92], "wherev": 78, "suffix": 78, "stan_includ": 78, "comma": 78, "gp_kinet": 78, "pathto": 78, "force_compil": 78, "k_ppc_scale": 78, "heidi": [79, 89], "klump": [79, 89], "selector": 79, "adopt": 79, "interchang": 79, "blei": 79, "dissimilar": 79, "leiber": 79, "resembl": [79, 86, 88], "poorli": 79, "prod_i": 79, "phi_i": 79, "partit": [79, 88], "neq": 79, "q_j": 79, "hurdl": 79, "q_": 79, "randon": 79, "advi": 79, "alp": 79, "kucukelbir": 79, "zeta": 79, "zeta_i": 79, "meanfield": 79, "optimum": 79, "samples_vi": 79, "pertain": 79, "stdout_fil": 79, "runset": 79, "_stdout_fil": 79, "10000": 79, "grad_sampl": 79, "elbo_sampl": 79, "tol_rel_obj": 79, "eval_elbo": 79, "output_sampl": 79, "tmpcshdblkp": 79, "01ufoem2": 79, "json": 79, "spindlezaxcnbxg": 79, "20240727161414": 79, "diagnostic_fil": 79, "sig_fig": 79, "profile_fil": 79, "save_cmdstan_config": 79, "num_thread": 79, "unstabl": 79, "buggi": 79, "gradient": [79, 86, 88], "000392": 79, "ascent": 79, "delta_elbo_mean": 79, "delta_elbo_m": 79, "6093": 79, "3580": 79, "851": 79, "3473": 79, "163": 79, "578": 79, "702": 79, "3406": 79, "187": 79, "438": 79, "3310": 79, "589": 79, "356": 79, "031": 79, "3197": 79, "393": 79, "303": 79, "035": 79, "700": 79, "3119": 79, "716": 79, "263": 79, "800": 79, "3118": 79, "230": 79, "900": 79, "3055": 79, "396": 79, "207": 79, "029": 79, "3007": 79, "033": 79, "1100": 79, "2958": 79, "594": 79, "090": 79, "1200": 79, "2882": 79, "045": 79, "022": 79, "1300": 79, "2825": 79, "021": 79, "1400": 79, "2755": 79, "1500": 79, "2656": 79, "2549": 79, "177": 79, "023": 79, "1700": 79, "2429": 79, "026": 79, "1800": 79, "2310": 79, "505": 79, "027": 79, "1900": 79, "2205": 79, "968": 79, "037": 79, "2103": 79, "036": 79, "042": 79, "2100": 79, "2027": 79, "055": 79, "039": 79, "2200": 79, "1952": 79, "219": 79, "2300": 79, "1908": 79, "2400": 79, "1881": 79, "840": [79, 90], "2500": 79, "1870": 79, "947": 79, "2600": 79, "1869": 79, "602": 79, "032": 79, "2700": 79, "1859": 79, "828": 79, "2800": 79, "1852": 79, "081": 79, "2900": 79, "1855": 79, "085": 79, "3000": [79, 92], "1848": 79, "013": 79, "variational_sample_pd": 79, "df_vi": 79, "1_546": 79, "lp__log_p__log_g__phigamma_sigma_0mu": 79, "164": 79, "165": 79, "166": 79, "167": 79, "168": 79, "169": 79, "171": 79, "173": 79, "174": 79, "175": 79, "178": 79, "180": 79, "182": 79, "185": 79, "186": [79, 92], "189": 79, "192": 79, "194": 79, "195": 79, "197": 79, "198": 79, "199": 79, "f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64": 79, "f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f640": 79, "1835": 79, "33121238": 79, "2270": 79, "8426290": 79, "11378121": 79, "410822": 79, "116822": 79, "863123": 79, "818223": 79, "818224": 79, "107224": 79, "221524": 79, "391524": 79, "5625": 79, "109525": 79, "217225": 79, "377425": 79, "483325": 79, "640725": 79, "796425": 79, "899425": 79, "899426": 79, "052426": 79, "153526": 79, "303726": 79, "40326": 79, "403": 79, "248343": 79, "154236": 79, "822544": 79, "668738": 79, "665544": 79, "02741": 79, "527232": 79, "699924": 79, "670637": 79, "833836": 79, "934941": 79, "205144": 79, "229931": 79, "700542": 79, "786742": 79, "284843": 79, "183633": 79, "922841": 79, "924440": 79, "99631": 79, "870935": 79, "84937": 79, "39738": 79, "296335": 79, "662538": 79, "725243": 79, "700342": 79, "188434": 79, "516936": 79, "389942": 79, "901239": 79, "483443": 79, "509634": 79, "06443": 79, "242134": 79, "12140": 79, "64320": 79, "1840": 79, "78530839": 79, "15010": 79, "8652280": 79, "11209321": 79, "974922": 79, "698523": 79, "463224": 79, "441524": 79, "737524": 79, "854625": 79, "028725": 79, "201225": 79, "763925": 79, "874125": 79, "874126": 79, "038126": 79, "146526": 79, "307626": 79, "46726": 79, "572426": 79, "72926": 79, "832426": 79, "986227": 79, "087827": 79, "0878": 79, "852838": 79, "859240": 79, "255547": 79, "723140": 79, "816530": 79, "954534": 79, "280637": 79, "754237": 79, "441734": 79, "807737": 79, "139236": 79, "539429": 79, "180541": 79, "470439": 79, "744540": 79, "545239": 79, "189340": 79, "0141": 79, "243634": 79, "44339": 79, "726140": 79, "452141": 79, "051329": 79, "214242": 79, "083739": 79, "000348": 79, "029239": 79, "175628": 79, "694240": 79, "588942": 79, "45241": 79, "212443": 79, "891929": 79, "079348": 79, "109934": 79, "261135": 79, "85890": 79, "1858": 79, "3135140": 79, "27760": 79, "8440270": 79, "12307621": 79, "626222": 79, "358723": 79, "135824": 79, "134924": 79, "438324": 79, "558524": 79, "914925": 79, "49525": 79, "608925": 79, "778525": 79, "890726": 79, "057726": 79, "223126": 79, "332526": 79, "495326": 79, "60326": 79, "763126": 79, "86926": 79, "869": 79, "305746": 79, "086545": 79, "675337": 79, "458641": 79, "120538": 79, "046242": 79, "214834": 79, "958247": 79, "576935": 79, "842340": 79, "759945": 79, "705848": 79, "77944": 79, "312848": 79, "809835": 79, "705734": 79, "544637": 79, "255641": 79, "519542": 79, "743345": 79, "759829": 79, "798840": 79, "612251": 79, "127443": 79, "244447": 79, "42946": 79, "350742": 79, "102934": 79, "758235": 79, "285637": 79, "087235": 79, "45129": 79, "324637": 79, "891744": 79, "517646": 79, "607338": 79, "60070": 79, "57": 79, "2506237": 79, "61070": 79, "8235380": 79, "12039920": 79, "9521": 79, "643522": 79, "376723": 79, "315823": 79, "600123": 79, "712623": 79, "879923": 79, "879924": 79, "045724": 79, "586724": 79, "692824": 79, "850524": 79, "954825": 79, "109825": 79, "263325": 79, "364725": 79, "515525": 79, "615225": 79, "763325": 79, "861125": 79, "8611": 79, "700133": 79, "765741": 79, "01630": 79, "692931": 79, "122833": 79, "522642": 79, "145236": 79, "1543": 79, "160140": 79, "126942": 79, "508540": 79, "00243": 79, "993937": 79, "575338": 79, "000436": 79, "304840": 79, "071936": 79, "101739": 79, "003932": 79, "224645": 79, "635435": 79, "53938": 79, "868137": 79, "839935": 79, "145742": 79, "555744": 79, "950539": 79, "690740": 79, "796237": 79, "734439": 79, "588133": 79, "151932": 79, "761429": 79, "640840": 79, "012242": 79, "179343": 79, "35860": 79, "1837": 79, "70917538": 79, "33510": 79, "8371120": 79, "11236821": 79, "305322": 79, "011622": 79, "758623": 79, "715523": 79, "715524": 79, "005224": 79, "119824": 79, "290424": 79, "459425": 79, "01125": 79, "119125": 79, "279925": 79, "386325": 79, "544425": 79, "700925": 79, "804325": 79, "958125": 79, "958126": 79, "059826": 79, "210826": 79, "310726": 79, "3107": 79, "389538": 79, "487935": 79, "552138": 79, "478339": 79, "257242": 79, "376948": 79, "535439": 79, "861436": 79, "31238": 79, "527838": 79, "715338": 79, "726839": 79, "719838": 79, "526837": 79, "728746": 79, "05735": 79, "144146": 79, "713130": 79, "492937": 79, "246445": 79, "322936": 79, "658942": 79, "086337": 79, "391944": 79, "149438": 79, "827439": 79, "504842": 79, "60740": 79, "123337": 79, "005437": 79, "151228": 79, "840532": 79, "462543": 79, "715541": 79, "509742": 79, "00435": 79, "4243": 79, "legaci": 79, "log_p__": 79, "log_g__": 79, "variational_params_pd": 79, "4521": 79, "853254": 79, "116228": 79, "6552": 79, "3666": 79, "1182": 79, "0794": 79, "4477": 79, "673": 79, "7122": 79, "1776": 79, "381": 79, "9442": 79, "6642": 79, "46": 79, "0142": 79, "2081": 79, "4419": 79, "1546": 79, "plot_marginal_ecdf": 79, "p_phi": 79, "p_gamma": 79, "fullrank": 79, "3251": 79, "88812": 79, "noncent": [79, 88], "hier_lognorm": 79, "32520": 79, "require_converg": 79, "tendenc": 79, "underestim": 79, "p_theta": 79, "p_sigma": 79, "p_tau": 79, "gridplot": [79, 92], "ncol": [79, 92], "custom": 79, "ranganath": 79, "morn": 81, "noon": [81, 96], "kerckhoff": [81, 96], "b123": [81, 96], "attend": 81, "recit": [81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 93, 94, 96], "offic": [81, 96], "tuesdai": [81, 96], "dilig": 81, "golden": 81, "opportun": 81, "submit": [81, 90, 96], "schedul": [81, 90], "skill": 81, "_lastname_firstnam": 81, "pacif": 81, "sundai": 81, "perfectli": 81, "aspect": 81, "fridai": 81, "hw": 81, "restart": 81, "runnabl": 81, "submitt": 81, "credit": [81, 86], "name_of_datafil": 81, "embed": 81, "mathjax": 81, "latex": 81, "inversegamma": 81, "justifi": 81, "guidelin": 81, "adjac": [81, 88], "explanatori": 81, "markdown": 81, "header": 81, "delin": 81, "late": 81, "six": 81, "grace": 81, "penalti": 81, "saturdai": 81, "ill": 81, "health": 81, "cass": 81, "accommod": 81, "coursework": 81, "exam": 81, "announc": 81, "offici": 81, "passag": 81, "receiv": [81, 86, 90], "nullifi": 81, "violat": 81, "publicli": 81, "unpublish": 81, "institut": 81, "faith": 81, "imper": 81, "dissemin": 81, "classmat": 81, "whom": 81, "consult": 81, "websit": 81, "materi": [81, 82, 91, 92, 93], "cite": 81, "llm": 81, "chatgpt": 81, "gpt": 81, "llama": 81, "gemini": 81, "cursor": 81, "copilot": 81, "ai": 81, "engin": [81, 95], "deni": 81, "contrari": 81, "basal": 81, "compet": 81, "reiter": 81, "chatbot": 81, "privat": 81, "email": [81, 90], "shot": 81, "anonym": 81, "spur": 81, "dialog": [82, 93], "factori": 86, "curdoc": 86, "ticker": 86, "fixedtick": 86, "holoview": 86, "hv": 86, "pallete1": 86, "9faeb2": 86, "ab6e7d": 86, "1c2630": 86, "autohid": 86, "text_font": 86, "helvetica": 86, "text_font_s": 86, "16px": 86, "xaxi": 86, "axis_label_text_font": 86, "yaxi": 86, "axis_label_text_font_s": 86, "13px": 86, "axis_label_text_font_styl": 86, "background_fill_alpha": 86, "toolbar": 86, "anyon": 86, "background": [86, 89, 90], "break": [86, 90], "subset": 86, "bob": 86, "carpent": 86, "weigh": 86, "coeffici": 86, "375": 86, "326": 86, "420": 86, "binomial_coeff": 86, "prob": 86, "patch": 86, "eaeaea": 86, "degeneraci": 86, "999999": 86, "1000000": 86, "imbal": 86, "classic": [86, 88, 92], "quantum": 86, "harmon": 86, "oscil": [86, 88], "attach": [86, 89], "spring": 86, "act": 86, "kx": 86, "movement": 86, "mv": 86, "2m": 86, "momentum": [86, 88], "fiat": 86, "brick": 86, "wall": 86, "wreck": 86, "train": 86, "consum": [86, 90], "ellipsoid": 86, "simple_oscil": 86, "bupu": 86, "x_arr": 86, "p_plu": 86, "p_minu": 86, "add_layout": 86, "major_label_text_font_s": 86, "0pt": 86, "evolut": 86, "hamilton": [86, 88], "motion": [86, 88], "qquad": 86, "angl": 86, "mag": 86, "arctan2": 86, "vectorfield": 86, "cmap": 86, "viridi": 86, "xlabel": 86, "ylabel": 86, "interrupt": 86, "therm": 86, "preprint": 86, "1701": 86, "02434": 86, "momenta": 86, "scatter1": 86, "scatter2": 86, "arrow1": 86, "arrow1_1": 86, "arrow1_2": 86, "arrow2": 86, "arrow2_1": 86, "arrow2_2": 86, "partial_h": 86, "xlim": 86, "ylim": 86, "show_grid": 86, "distinct": 86, "h1": 86, "h2": 86, "h3": 86, "x_arr1": 86, "x_arr2": 86, "x_arr3": 86, "p_plus1": 86, "p_minus1": 86, "p_plus2": 86, "p_minus2": 86, "p_plus3": 86, "p_minus3": 86, "scatter12": 86, "79": 86, "scatter22": 86, "arrow12": 86, "arrow1_12": 86, "arrow1_22": 86, "arrow22": 86, "arrow2_12": 86, "arrow2_22": 86, "partial_h2": 86, "l3": 86, "n6j3jk1n1p94lc552kcbzq280000gn": 86, "ipykernel_5666": 86, "985606356": 86, "prime": 86, "prime_i": 86, "rotat": 86, "parameter": 86, "disrupt": 86, "regard": 86, "const": [86, 88], "lap": 86, "unexplor": 86, "backward": [86, 88], "met": 86, "euler": 86, "inaccuraci": [86, 88], "drastic": 86, "stackoverflow": 86, "33601089": 86, "n0": 86, "dn": 86, "dx_dt": 86, "liouvil": 86, "symplect": [86, 88], "detriment": 86, "shoot": 86, "bridg": 86, "rail": 86, "fought": 86, "rosita": 88, "fu": 88, "linger": 88, "r\u00f6esching": 88, "alongsid": 88, "math": [88, 90], "int_q": 88, "hspace": 88, "mathbb": 88, "entireti": 88, "ordinari": 88, "dq": 88, "1d": 88, "3d": 88, "cube": [88, 90], "denisti": 88, "predomin": 88, "sit": 88, "x_": 88, "sole": 88, "creativ": 88, "allud": 88, "determinist": [88, 92], "dictat": 88, "f_n": 88, "btw": 88, "habit": 88, "hover": 88, "overcompens": 88, "usag": 88, "diffus": 88, "irredeem": 88, "incapacit": 88, "jump": [88, 92], "sluggish": 88, "increment": 88, "overal": [88, 92], "q_1": 88, "q_2": 88, "q_3": 88, "cast": 88, "hearken": 88, "metaphor": 88, "planet": 88, "gravit": 88, "orbit": 88, "satellit": 88, "crash": [88, 90], "eject": 88, "auxiliari": 88, "2xd": 88, "q_n": 88, "rightarrow": 88, "p_n": 88, "canon": 88, "nbsphinx": 88, "8em": 88, "9em": 88, "interepret": 88, "lift": [88, 92], "omega": 88, "omega_": 88, "microcanon": 88, "ring": 88, "jointli": 88, "cfrac": 88, "2em": 88, "3em": 88, "phi_t": 88, "altogeth": 88, "somehow": 88, "unlock": 88, "expon": 88, "decoupl": 88, "retriev": [88, 90], "repeatedli": 88, "project": [88, 89, 90], "swiftli": 88, "euclidean": 88, "riemannian": 88, "pi_": 88, "pi_e": 88, "e_bfmi": 88, "proven": 88, "ke": 88, "pick": 88, "convolut": 88, "distribtuion": 88, "de": 88, "distribuion": 88, "Their": 88, "smoothen": 88, "persist": [88, 92], "stronger": 88, "suspicion": 88, "distribt": 88, "termin": [88, 90], "mysteri": 88, "impress": 88, "takeawai": 88, "life": 88, "exploit": 88, "glean": 88, "face": [88, 92], "cellular": 89, "pathwai": [89, 92], "architectur": 89, "extracellular": 89, "surfac": 89, "confoc": 89, "membran": [89, 92], "autom": 89, "cytometri": 89, "fluorophor": 89, "cytomet": 89, "bead": 89, "subunit": 89, "spontan": 89, "weren": 89, "multimer": [89, 92], "intracellular": [89, 92], "fusion": [89, 92], "zachari": 90, "martinez": 90, "tailor": 90, "cluster": 90, "terabyt": 90, "petabyt": 90, "facillit": 90, "acceler": 90, "node": 90, "cento": 90, "admin": 90, "grant": 90, "authent": 90, "duo": 90, "wifi": 90, "vpn": 90, "zmartin": 90, "host": 90, "refus": 90, "ondemand": 90, "studio": 90, "desktop": 90, "compos": 90, "script": 90, "alloc": 90, "queue": 90, "princeton": 90, "my_slurm_script": 90, "sbatch": 90, "walltim": 90, "ntask": 90, "processor": 90, "mem": 90, "16g": 90, "my_first_job": 90, "mail": 90, "purg": 90, "export": 90, "ld_library_path": 90, "mthomson": 90, "zam": 90, "miniconda": 90, "librari": 90, "example_env": 90, "highly_parallelized_script": 90, "my_first_job_xxxxxx": 90, "cheatsheet": 90, "flag": 90, "gre": 90, "qo": 90, "debug": 90, "prioriti": 90, "forev": 90, "cascadelak": 90, "squeue": 90, "pend": 90, "scancel": 90, "12345678": 90, "kill": [90, 92], "jobid": 90, "srun": 90, "pty": 90, "xx": 90, "lastli": 90, "programat": 90, "slurm_ntask": 90, "n_task": 90, "gui": 90, "winscp": 90, "filezilla": 90, "cyberduck": 90, "awscli": 90, "forth": 90, "remote_script": 90, "local_script": 90, "local_filenam": 90, "currect": 90, "remote_filenam": 90, "3ish": 90, "50gb": 90, "10tb": 90, "thomson": 90, "80tb": 90, "scratch": 90, "20tb": 90, "scratchio": 90, "2tb": 90, "quota": 90, "mmlsquota": 90, "auto": 90, "ticket": 90, "vscode": 90, "plugin": 90, "vim": 90, "friendli": 90, "isn": [90, 92], "geeksforgeek": 90, "realpython": 90, "superfastpython": 90, "prematur": 90, "evil": 90, "donald": 90, "knuth": 90, "multiprocess": 90, "exhaust": 90, "unexpect": 90, "silent": 90, "multithread": 90, "lock": 90, "gil": 90, "thread": 90, "cpu_count": 90, "mp": 90, "laptop": 90, "squareroot": 90, "benchmark": 90, "square_list": 90, "input_list": 90, "num": [90, 92], "squareroot_list": 90, "mylist": 90, "100_000_001": 90, "100_000_000": 90, "ran": 90, "elaps": 90, "94840407371521": 90, "ascend": 90, "overcom": 90, "__name__": 90, "__main__": 90, "p1": [90, 92], "p2": [90, 92], "p3": 90, "30126214027405": 90, "demo": 90, "10_000_001": 90, "10_000_000": 90, "8647820949554443": 90, "teardown": 90, "3583669662475586": 90, "precari": 90, "race": 90, "cube_and_revers": 90, "val": 90, "arr": 90, "125": 90, "random_word": 90, "randomword": 90, "flush": 90, "get_random_word": 90, "consumer_process": 90, "producer_process": 90, "modulenotfounderror": 90, "traceback": 90, "firstli": 90, "dramat": 90, "bebi103b": 90, "thirdli": 90, "capac": 90, "infeas": 90, "simultan": 90, "benefici": 90, "timefram": 90, "paralleliz": 90, "pd": [90, 92], "prep": [90, 92], "prior_predictive_check": 90, "stan_model_cod": 90, "example_model": 90, "_perform_sbc": 90, "_get_output_dir": 90, "samples_dir": 90, "prior_sample_cmdstanpi": 90, "posterior_samples_cmdstanpi": 90, "parallel_chain": 90, "arg_input_gener": 90, "stan_sbc": 90, "my_job": 90, "thefilenam": 90, "6g": 90, "stan_sbc_test": 90, "touch": 90, "chunk": 90, "cpp_option": 90, "stan_thread": 90, "rewritten": 90, "reduce_sum": 90, "piecewis": 90, "partial_sum_neg_binom": 90, "slice_n": 90, "mere": 90, "iceberg": 90, "taught": 90, "foot": 90, "door": 90, "luck": 90, "zach": 91, "julian": 92, "wagner": 92, "bespok": 92, "ecolog": 92, "recaptur": 92, "afterward": 92, "worst": 92, "dread": 92, "nan": 92, "datatyp": 92, "explod": 92, "ecologi": 92, "leg": 92, "band": 92, "bird": 92, "fin": 92, "shark": 92, "stradl": 92, "radioact": 92, "phosphor": 92, "32p": 92, "tissu": 92, "worker": 92, "myrmica": 92, "rubra": 92, "gari": 92, "alpert": 92, "hypergeometr": 92, "white": 92, "ball": 92, "unlabel": 92, "stickler": 92, "todai": 92, "insist": 92, "stick": 92, "negative_binomi": 92, "log_sum_exp": 92, "game": 92, "mark_recapture_hypergeometr": 92, "max_pop": 92, "min_pop": 92, "neg_binomial_2_lpmf": 92, "hypergeometric_lpmf": 92, "simplex": 92, "pstate": 92, "funni": 92, "346": 92, "sample_it": 92, "aren": 92, "distibut": 92, "0000000284678414": 92, "yai": 92, "gotten": 92, "sake": 92, "ra": 92, "a_min": 92, "a_max": 92, "mt_gamma": 92, "20000": 92, "ndiagnost": 92, "t_ppc_dim_0": 92, "alpha_": 92, "t_j": 92, "a_": 92, "hei": 92, "sm2": 92, "mt_gamma_integer_alpha": 92, "beta2": 92, "binomial_lpmf": 92, "gamma_lpdf": 92, "log_p_norm": 92, "categorical_logit_rng": 92, "round": 92, "logit": 92, "samples_discret": 92, "odd": 92, "funki": 92, "intermediari": 92, "df_sample_compar": 92, "peaki": 92, "confirm": 92, "87136123": 92, "170593759154506": 92, "76135737638342": 92, "5281784828052738": 92, "mt_gamma_integer_alpha_jb": 92, "log_alpha_prior": 92, "un": 92, "log_q": 92, "samp": 92, "log_norm_const": 92, "log_g": 92, "net": 92, "monstrou": 92, "numba": 92, "3rd": 95, "freeli": 95, "channel": 95, "video": 95, "2nd": 95, "richard": 95, "mcelreath": 95, "ben": 95, "lambert": 95, "beginn": 95, "press\u00e9": 95, "sgourali": 95, "exposit": 95, "phil": 95, "supplement": 95, "kerkchoff": 96, "februari": 96, "march": 96, "martin": 96, "luther": 96, "king": 96, "presid": 96}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"homework": [1, 3, 4, 6, 7, 9, 81, 85, 94, 96], "1": [1, 2, 3, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 26, 56, 79], "first": 1, "attempt": 1, "bayesian": [1, 23, 29, 30, 33, 39, 73, 79, 89], "gener": [1, 2, 28, 44, 45, 49, 52, 56, 66, 70, 72, 76], "model": [1, 2, 24, 29, 30, 33, 34, 35, 38, 40, 49, 51, 52, 53, 56, 57, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 76, 79, 89], "70": 1, "pt": [1, 3, 4, 6, 7], "intuit": 2, "2": [3, 4, 5, 7, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 33, 56, 79], "overwhelm": 3, "prior": [3, 4, 23, 29, 30, 32, 49, 56, 58, 65, 72, 73, 74, 83, 84], "45": 3, "exponenti": [4, 75], "conjug": [4, 32, 36], "55": 4, "analyt": [5, 34, 35, 73], "graphic": 5, "method": [5, 32, 55, 88], "analysi": [5, 38, 49, 71], "posterior": [5, 23, 30, 34, 36, 38, 39, 49, 53, 55, 57, 61, 73, 74, 78], "3": [6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 34, 56], "least": 6, "squar": [6, 75], "20": [6, 16, 70], "map": [7, 38, 39, 74], "estim": [7, 8, 29, 37, 38, 39, 40, 49, 61, 73, 78], "zero": 7, "inflat": 7, "drop": 7, "seq": 7, "control": 7, "80": 7, "maximum": [8, 39], "posteriori": 8, "paramet": [8, 29, 34, 37, 38, 39, 40, 49, 53, 56, 69, 73, 92], "BE": 9, "bi": 9, "103": 9, "b": [9, 88], "statist": [9, 23, 57, 59, 71], "infer": [9, 23, 73, 79], "biolog": 9, "scienc": [9, 23], "us": [9, 19, 20, 32, 39, 50, 52, 73, 75, 76, 78, 86, 90, 91], "link": 9, "peopl": 9, "lesson": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 81, 96], "schedul": [9, 96], "polici": [9, 81], "resourc": [9, 21], "previou": 9, "edit": 9, "cours": [9, 81], "e1": 10, "To": [10, 11, 12, 13, 14, 15, 16, 17, 18], "complet": [10, 11, 12, 13, 14, 15, 16, 17, 18], "after": [10, 11, 12, 13, 14, 15, 16, 17, 18, 19], "5": [10, 11, 14, 16, 19, 36], "exercis": [10, 11, 12, 13, 14, 15, 16, 17, 18, 81, 96], "4": [10, 11, 12, 13, 14, 15, 16, 18, 19, 35], "e2": 11, "6": [11, 15, 19, 37], "e3": 12, "10": [12, 52, 93], "e4": 13, "13": [13, 57], "e5": 14, "16": [14, 60], "e6": 15, "18": [15, 63], "e7": 16, "7": [16, 19, 43], "e8": 17, "22": [17, 72], "8": [17, 19, 48], "e9": 18, "25": [18, 79], "9": [18, 19, 51], "aw": 19, "setup": 19, "usag": 19, "creat": 19, "an": [19, 28, 34, 64, 72, 73, 88], "amazon": 19, "web": 19, "servic": 19, "account": 19, "launch": 19, "your": [19, 22, 50], "instanc": 19, "connect": 19, "jupyterlab": 19, "copi": 19, "result": [19, 54, 55], "from": [19, 29, 75], "local": 19, "machin": [19, 22], "exit": 19, "serious": 19, "stop": 19, "you": 19, "ar": [19, 50], "them": 19, "again": 19, "termin": 19, "class": 19, "i": [19, 23, 38, 56, 90], "over": 19, "googl": 20, "colab": 20, "watchout": 20, "when": 20, "softwar": [20, 90, 95], "A": [20, 34, 40, 60, 69, 70, 71, 76, 79, 86, 88], "sampl": [20, 49, 50, 51, 52, 53, 55, 59, 60, 70, 72, 73, 74, 75, 76, 88, 92], "calcul": [20, 34, 64, 75], "comput": [20, 21, 22, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 72, 73, 74, 75, 76, 78, 79, 86, 92], "environ": [20, 22, 34, 35, 36, 38, 39, 40, 49, 50, 51, 52, 53, 55, 56, 57, 59, 60, 62, 64, 67, 72, 73, 74, 75, 76, 78, 79, 86, 92], "0": 21, "set": [21, 34, 49, 56, 58, 59, 70, 73, 86, 88], "up": [21, 46, 50, 51, 70, 80], "configur": 22, "instal": 22, "python": [22, 90], "packag": 22, "stan": [22, 48, 49, 50, 52, 56, 70, 73, 74, 75, 76, 78, 79, 90, 92], "c": [22, 88], "toolchain": 22, "maco": 22, "window": 22, "linux": 22, "cmdstanpi": 22, "check": [22, 40, 56, 57, 58, 59, 61, 70, 72, 78], "probabl": [23, 26, 28, 82, 92], "logic": [23, 26], "what": [23, 86, 90], "The": [23, 29, 30, 32, 34, 35, 36, 40, 44, 45, 49, 53, 56, 57, 59, 61, 69, 72, 73, 79, 86, 88], "problem": 23, "frequentist": 23, "desiderata": 23, "sum": 23, "rule": 23, "product": 23, "condit": [23, 28, 65], "applic": 23, "scientif": [23, 26], "measur": [23, 29], "bay": [23, 24, 25, 28], "": [23, 24, 25, 28, 56, 58, 90, 91], "theorem": [23, 24, 25, 28], "likelihood": [23, 29, 31, 34, 38, 56, 64, 73, 76, 78], "evid": 23, "learn": 24, "notat": [25, 88], "part": 25, "reason": 26, "margin": [27, 34, 35, 49, 53, 92], "distribut": [28, 29, 53, 55, 58, 65, 73, 92], "joint": 28, "pdf": 28, "chang": 28, "variabl": [28, 58, 76], "formula": 28, "continu": 28, "multipl": 28, "dimens": 28, "exampl": [28, 29, 32, 62, 64, 73, 79], "anoth": [28, 29], "log": [28, 34, 61, 64, 90, 92], "normal": [28, 29, 34, 38, 39, 40, 73, 76, 78], "repeat": [29, 69], "revisit": 29, "choic": [29, 65, 88], "succinctli": 29, "state": [29, 90], "task": 30, "build": [30, 49, 56, 71, 89], "role": 30, "make": 30, "sens": 30, "choos": [31, 32, 45, 58, 65, 79, 83, 84, 86], "uniform": 32, "jeffrei": 32, "why": [32, 39, 47, 50], "weakli": 32, "inform": [32, 61], "bet": 32, "farm": 32, "specifi": 32, "introduct": [33, 43, 48, 73, 87], "plot": [34, 36, 49, 51, 53, 71, 73], "data": [34, 38, 49, 56, 59, 69, 70, 73, 75], "spindl": [34, 56, 79], "size": [34, 38, 49, 56, 57, 59, 79], "singl": 34, "numer": [34, 35, 86], "quadratur": [34, 35], "prescript": 34, "1d": 34, "express": [34, 75], "2d": 34, "asid": [34, 70, 78], "speed": 34, "tubulin": [35, 40, 56, 57], "conserv": [35, 40, 57], "curs": 35, "dimension": [35, 88], "overcom": 35, "conjugaci": 36, "beta": 36, "binomi": 36, "pair": [36, 53], "find": 36, "comment": 36, "optim": [37, 38, 39, 40, 74, 75, 83, 84, 88], "case": [38, 60], "studi": [38, 60], "exploratori": 38, "independ": [38, 56, 57, 69, 90], "approxim": [38, 39, 40], "credibl": [38, 39], "interv": [38, 39], "how": [38, 55, 88, 90], "good": 38, "approach": 39, "summar": [39, 55], "its": 39, "demonstr": 39, "mai": 39, "skew": 39, "variat": [40, 52, 79], "covari": [40, 52, 73, 75], "displai": [40, 49, 50, 53, 54, 55], "best": [40, 49, 69], "fit": [40, 49], "line": 40, "further": 42, "read": [42, 95], "mcmc": [42, 44, 47, 48, 49, 51, 52, 53, 54, 55, 59, 76, 78, 90, 91], "markov": [43, 49, 88], "chain": [43, 49], "mont": [43, 49, 59, 86, 87, 88], "carlo": [43, 49, 59, 86, 87, 88], "random": 44, "number": [44, 58, 73], "basic": [44, 50], "idea": [44, 79], "behind": 44, "transit": [45, 86, 88], "kernel": [45, 73, 75], "metropoli": 45, "hast": 45, "algorithm": [45, 79, 88], "detail": [45, 86], "balanc": 45, "warm": 46, "our": [49, 72], "engin": 49, "ecdf": [49, 71, 72], "mrna": [49, 72], "count": [49, 72], "burst": 49, "inter": 49, "time": [49, 86, 88], "all": [49, 56, 88], "gene": 49, "hello": 50, "world": [50, 69], "program": 50, "sai": 50, "hi": 50, "pars": [50, 51], "output": [50, 51], "arviz": [50, 53], "direct": 50, "we": [50, 88], "code": [50, 51, 70, 81, 90], "save": 50, "clean": 50, "shrapnel": 50, "mixtur": [51, 64], "label": 51, "switch": 51, "initi": 51, "walker": 51, "conclus": [51, 70, 72, 73], "updat": 52, "visual": 53, "examin": 53, "trace": 53, "bebi103": 53, "interpet": 53, "parallel": 53, "coordin": 53, "intepret": 53, "one": [53, 61], "iqplot": 53, "two": [53, 92], "corner": 53, "11": 54, "report": 55, "summari": [55, 57, 79], "some": 55, "error": [55, 59], "bar": 55, "rel": 55, "merit": 55, "each": 55, "text": 55, "12": 56, "predict": [56, 57, 61, 73, 74, 78], "droplet": 56, "take": [56, 92], "depend": 56, "total": 56, "concentr": 56, "indentifi": 56, "limit": 56, "behavior": 56, "assumpt": 56, "v_": 56, "mathrm": 56, "v_0": 56, "ll": 56, "do": [56, 88], "have": 56, "same": 56, "aspect": 56, "ratio": 56, "k": [56, 88], "bewar": 57, "14": 58, "collector": 58, "box": 58, "out": [58, 60, 61, 73], "explor": 58, "start": 58, "simpl": 58, "ad": 58, "flexibl": 58, "support": [58, 90], "posit": 58, "real": 58, "15": 59, "diagnost": [59, 60, 70, 71], "ani": 59, "sampler": 59, "gelman": 59, "rubin": 59, "r": 59, "hat": 59, "effect": 59, "standard": 59, "hmc": [59, 86], "diverg": [59, 61, 86], "tree": 59, "depth": 59, "e": 59, "bfmi": 59, "quickli": 59, "artifici": 60, "funnel": 60, "hell": 60, "conquer": 60, "adjust": [60, 72], "adapt_delta": 60, "noncent": [60, 70, 76], "hierarch": [60, 65, 66, 67, 68, 69, 70, 79], "featur": [60, 88], "17": 61, "comparison": [61, 63, 64], "metric": 61, "assess": 61, "close": 61, "entropi": 61, "kullback": 61, "leibler": 61, "expect": 61, "pointwis": [61, 64], "densiti": 61, "watanab": 61, "akaik": 61, "criterion": 61, "leav": 61, "elpd": 61, "weight": [61, 64], "select": 62, "regress": 62, "practic": [63, 64, 72, 75], "waic": 64, "loo": 64, "exchang": 65, "implement": [67, 70, 77, 88], "19": 68, "experi": 69, "revers": 69, "pool": [69, 90], "ident": 69, "both": 69, "structur": 70, "quick": 70, "input": 70, "draw": 70, "parametr": 70, "21": 71, "principl": 71, "pipelin": 71, "workflow": 71, "refer": 71, "terminologi": 71, "simul": [71, 72], "base": [71, 72], "calibr": [71, 72], "z": 71, "score": 71, "shrinkag": 71, "v": 71, "rank": 71, "histogram": 71, "full": 71, "relat": 72, "perform": 72, "sbc": 72, "new": 72, "23": 73, "gaussian": [73, 74, 76, 77, 86], "process": [73, 74, 76, 77, 90], "nonparametr": 73, "finit": 73, "point": 73, "mean": 73, "function": [73, 79], "center": 73, "scale": 73, "matrix": 73, "gp": [73, 75, 76, 78], "numpi": 73, "compos": 73, "valu": [73, 92], "hyperparamet": [74, 78], "scipi": 74, "obtain": [74, 90], "hyperprior": 74, "deriv": 75, "mat\u00e9rn": 75, "gradient": 75, "non": 76, "latent": 76, "poisson": 76, "24": 77, "includ": 78, "file": [78, 90], "main": 79, "q": [79, 88], "\u03b8": 79, "vi": 79, "automat": 79, "differenti": 79, "volum": 79, "multilevel": 79, "26": 80, "wrap": 80, "meet": 81, "lab": 81, "session": 81, "submiss": 81, "assign": 81, "grade": 81, "collabor": 81, "honor": 81, "commun": [81, 90], "ediquett": 81, "r1": 82, "review": [82, 83, 84, 92], "r2": [83, 84], "r3": 85, "just": [85, 94], "help": [85, 94], "more": 86, "hamiltonian": [86, 87, 88], "typic": [86, 88], "kinet": [86, 88], "energi": [86, 88], "euclidean": 86, "short": 86, "note": 86, "integr": [86, 88], "happen": 86, "r4": 87, "overview": [88, 96], "motiv": 88, "interest": 88, "high": 88, "space": 88, "But": 88, "question": 88, "remain": 88, "design": 88, "so": 88, "thi": 88, "lead": 88, "u": 88, "ideal": 88, "actual": 88, "consider": 88, "p": 88, "conclud": 88, "thought": 88, "r5": 89, "r6": [90, 91], "caltech": [90, 91], "hpc": [90, 91], "even": 90, "supercomput": 90, "hpcc": 90, "access": 90, "slurm": 90, "transfer": 90, "storag": 90, "pro": 90, "tip": 90, "write": 90, "concurr": 90, "between": 90, "share": 90, "run": 90, "foreword": 90, "r7": 92, "discret": 92, "logsumexp": 92, "cornerston": 92, "stabl": 92, "handl": 92, "vector": 92, "paremet": 92, "integ": 92, "\u03b1": 92, "gamma": 92, "via": 92, "r8": 93, "discuss": 93, "hw": 93, "project": 93, "propos": 93, "r9": 94, "tutori": 95, "due": 96, "date": 96, "weekli": 96}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"Homework 1.1: First attempts at Bayesian generative modeling (70 pts)": [[1, "Homework-1.1:-First-attempts-at-Bayesian-generative-modeling-(70-pts)"]], "1. Intuitive generative modeling": [[2, "intuitive-generative-modeling"]], "Homework 2.1: Overwhelming a prior (45 pts)": [[3, "Homework-2.1:-Overwhelming-a-prior-(45-pts)"]], "Homework 2.2: Exponential conjugate prior (55 pts)": [[4, "Homework-2.2:-Exponential-conjugate-prior-(55-pts)"]], "2. Analytical and graphical methods for analysis of the posterior": [[5, "analytical-and-graphical-methods-for-analysis-of-the-posterior"]], "Homework 3.1: Least squares (20 pts)": [[6, "Homework-3.1:-Least-squares-(20-pts)"]], "Homework 3.2: MAP estimates and zero-inflation for Drop-Seq controls (80 pts)": [[7, "Homework-3.2:-MAP-estimates-and-zero-inflation-for-Drop-Seq-controls-(80-pts)"]], "3. Maximum a posteriori parameter estimation": [[8, "maximum-a-posteriori-parameter-estimation"]], "BE/Bi 103 b: Statistical Inference in the Biological Sciences": [[9, "be-bi-103-b-statistical-inference-in-the-biological-sciences"]], "Useful links": [[9, "useful-links"]], "People": [[9, "people"]], "Lessons": [[9, null]], "Homework": [[9, null], [81, "homework"]], "Schedule": [[9, null]], "Policies": [[9, null]], "Resources": [[9, null]], "Previous editions of the course": [[9, "previous-editions-of-the-course"]], "E1. To be completed after lesson 5": [[10, "E1.-To-be-completed-after-lesson-5"]], "Exercise 1.1": [[10, "Exercise-1.1"]], "Exercise 1.2": [[10, "Exercise-1.2"]], "Exercise 1.3": [[10, "Exercise-1.3"]], "Exercise 1.4": [[10, "Exercise-1.4"]], "E2. To be completed after lesson 6": [[11, "E2.-To-be-completed-after-lesson-6"]], "Exercise 2.1": [[11, "Exercise-2.1"]], "Exercise 2.2": [[11, "Exercise-2.2"]], "Exercise 2.3": [[11, "Exercise-2.3"]], "Exercise 2.4": [[11, "Exercise-2.4"]], "Exercise 2.5": [[11, "Exercise-2.5"]], "E3. To be completed after lesson 10": [[12, "E3.-To-be-completed-after-lesson-10"]], "Exercise 3.1": [[12, "Exercise-3.1"]], "Exercise 3.2": [[12, "Exercise-3.2"]], "Exercise 3.3": [[12, "Exercise-3.3"]], "Exercise 3.4": [[12, "Exercise-3.4"]], "E4. To be completed after lesson 13": [[13, "E4.-To-be-completed-after-lesson-13"]], "Exercise 4.1": [[13, "Exercise-4.1"]], "Exercise 4.2": [[13, "Exercise-4.2"]], "Exercise 4.3": [[13, "Exercise-4.3"]], "Exercise 4.4": [[13, "Exercise-4.4"]], "E5. To be completed after lesson 16": [[14, "E5.-To-be-completed-after-lesson-16"]], "Exercise 5.1": [[14, "Exercise-5.1"]], "Exercise 5.2": [[14, "Exercise-5.2"]], "Exercise 5.3": [[14, "Exercise-5.3"]], "Exercise 5.4": [[14, "Exercise-5.4"]], "E6. To be completed after lesson 18": [[15, "E6.-To-be-completed-after-lesson-18"]], "Exercise 6.1": [[15, "Exercise-6.1"]], "Exercise 6.2": [[15, "Exercise-6.2"]], "Exercise 6.3": [[15, "Exercise-6.3"]], "Exercise 6.4": [[15, "Exercise-6.4"]], "E7. To be completed after lesson 20": [[16, "E7.-To-be-completed-after-lesson-20"]], "Exercise 7.1": [[16, "Exercise-7.1"]], "Exercise 7.2": [[16, "Exercise-7.2"]], "Exercise 7.3": [[16, "Exercise-7.3"]], "Exercise 7.4": [[16, "Exercise-7.4"]], "Exercise 7.5": [[16, "Exercise-7.5"]], "E8. To be completed after lesson 22": [[17, "E8.-To-be-completed-after-lesson-22"]], "Exercise 8.1": [[17, "Exercise-8.1"]], "Exercise 8.2": [[17, "Exercise-8.2"]], "Exercise 8.3": [[17, "Exercise-8.3"]], "E9. To be completed after lesson 25": [[18, "E9.-To-be-completed-after-lesson-25"]], "Exercise 9.1": [[18, "Exercise-9.1"]], "Exercise 9.2": [[18, "Exercise-9.2"]], "Exercise 9.3": [[18, "Exercise-9.3"]], "Exercise 9.4": [[18, "Exercise-9.4"]], "AWS setup and usage": [[19, "AWS-setup-and-usage"]], "1. Create an Amazon Web Services account": [[19, "1.-Create-an-Amazon-Web-Services-account"]], "2. Launch your instance": [[19, "2.-Launch-your-instance"]], "3. Connect to your instance": [[19, "3.-Connect-to-your-instance"]], "4. Launch JupyterLab": [[19, "4.-Launch-JupyterLab"]], "5. Copying results to and from AWS to your local machine": [[19, "5.-Copying-results-to-and-from-AWS-to-your-local-machine"]], "6. Exiting": [[19, "6.-Exiting"]], "7. Seriously. Stop your instances if you are not using them.": [[19, "7.-Seriously.-Stop-your-instances-if-you-are-not-using-them."]], "8. Using your instance again": [[19, "8.-Using-your-instance-again"]], "9. Terminate your instances after the class is over": [[19, "9.-Terminate-your-instances-after-the-class-is-over"]], "Using Google Colab": [[20, "Using-Google-Colab"]], "Watchouts when using Colab": [[20, "Watchouts-when-using-Colab"]], "Software in Colab": [[20, "Software-in-Colab"]], "A sample calculation": [[20, "A-sample-calculation"]], "Computing environment": [[20, "Computing-environment"], [22, "Computing-environment"], [34, "Computing-environment"], [35, "Computing-environment"], [36, "Computing-environment"], [38, "Computing-environment"], [39, "Computing-environment"], [40, "Computing-environment"], [49, "Computing-environment"], [50, "Computing-environment"], [51, "Computing-environment"], [52, "Computing-environment"], [53, "Computing-environment"], [55, "Computing-environment"], [56, "Computing-environment"], [57, "Computing-environment"], [59, "Computing-environment"], [60, "Computing-environment"], [62, "Computing-environment"], [64, "Computing-environment"], [67, "Computing-environment"], [72, "Computing-environment"], [73, "Computing-environment"], [74, "Computing-environment"], [75, "Computing-environment"], [76, "Computing-environment"], [78, "Computing-environment"], [79, "Computing-environment"], [92, "Computing-environment"]], "0. Setting up computing resources": [[21, "setting-up-computing-resources"]], "Configuring your machine": [[22, "Configuring-your-machine"]], "Installing Python packages": [[22, "Installing-Python-packages"]], "Stan installation": [[22, "Stan-installation"]], "Configuring a C++ toolchain for MacOS": [[22, "Configuring-a-C++-toolchain-for-MacOS"]], "Configuring a C++ toolchain for Windows": [[22, "Configuring-a-C++-toolchain-for-Windows"]], "Configuring a C++ toolchain for Linux": [[22, "Configuring-a-C++-toolchain-for-Linux"]], "Installing Stan with CmdStanPy": [[22, "Installing-Stan-with-CmdStanPy"]], "Checking your Stan installation": [[22, "Checking-your-Stan-installation"]], "Probability as the logic of science": [[23, "probability-as-the-logic-of-science"]], "What is statistical inference?": [[23, "what-is-statistical-inference"]], "The problem of probability": [[23, "the-problem-of-probability"]], "Frequentist probability.": [[23, "frequentist-probability"]], "Bayesian probability.": [[23, "bayesian-probability"]], "Desiderata for Bayesian probability": [[23, "desiderata-for-bayesian-probability"]], "The sum rule, the product rule, and conditional probability": [[23, "the-sum-rule-the-product-rule-and-conditional-probability"]], "Application to scientific measurement": [[23, "application-to-scientific-measurement"]], "Bayes\u2019s Theorem": [[23, "bayess-theorem"]], "The prior probability.": [[23, "the-prior-probability"]], "The likelihood.": [[23, "the-likelihood"]], "The evidence.": [[23, "the-evidence"]], "The posterior probability.": [[23, "the-posterior-probability"]], "Bayes\u2019s theorem as a model for learning": [[24, "bayes-s-theorem-as-a-model-for-learning"]], "Notation of parts of Bayes\u2019s Theorem": [[25, "notation-of-parts-of-bayess-theorem"]], "1. Probability and the logic of scientific reasoning": [[26, "probability-and-the-logic-of-scientific-reasoning"]], "Marginalization": [[27, "marginalization"]], "Probability distributions": [[28, "probability-distributions"]], "Joint and conditional distributions and Bayes\u2019s theorem for PDFs": [[28, "joint-and-conditional-distributions-and-bayess-theorem-for-pdfs"]], "Change of variables formula for continuous distributions": [[28, "change-of-variables-formula-for-continuous-distributions"]], "Generalization to multiple dimensions": [[28, "generalization-to-multiple-dimensions"]], "An example of change of variables": [[28, "an-example-of-change-of-variables"]], "Another example of change of variables: the Log-Normal distribution": [[28, "another-example-of-change-of-variables-the-log-normal-distribution"]], "Bayesian modeling example: parameter estimation from repeated measurements": [[29, "bayesian-modeling-example-parameter-estimation-from-repeated-measurements"]], "The likelihood": [[29, "the-likelihood"], [56, "The-likelihood"]], "The Normal distribution": [[29, "the-normal-distribution"]], "The likelihood revisited: and another parameter": [[29, "the-likelihood-revisited-and-another-parameter"]], "Choice of prior": [[29, "choice-of-prior"]], "Succinctly stating the model": [[29, "succinctly-stating-the-model"]], "Tasks of Bayesian modeling": [[30, "tasks-of-bayesian-modeling"]], "Model building": [[30, "model-building"]], "The role of the prior": [[30, "the-role-of-the-prior"]], "Making sense of the posterior": [[30, "making-sense-of-the-posterior"]], "Choosing likelihoods": [[31, "choosing-likelihoods"]], "Choosing priors": [[32, "choosing-priors"]], "Uniform priors": [[32, "uniform-priors"]], "Jeffreys priors": [[32, "jeffreys-priors"]], "Example Jeffreys priors": [[32, "example-jeffreys-priors"]], "Why not use Jeffreys priors?": [[32, "why-not-use-jeffreys-priors"]], "Weakly informative priors": [[32, "weakly-informative-priors"]], "Conjugate priors": [[32, "conjugate-priors"]], "The bet-the-farm method of specifying weakly informative priors": [[32, "the-bet-the-farm-method-of-specifying-weakly-informative-priors"]], "2. Introduction to Bayesian modeling": [[33, "introduction-to-bayesian-modeling"]], "3. Plotting posteriors": [[34, "3.-Plotting-posteriors"]], "The data set": [[34, "The-data-set"], [49, "The-data-set"], [56, "The-data-set"], [59, "The-data-set"]], "Models for spindle size": [[34, "Models-for-spindle-size"]], "Plotting the posterior for a single parameter": [[34, "Plotting-the-posterior-for-a-single-parameter"]], "Analytically marginalizing": [[34, "Analytically-marginalizing"]], "Computing and plotting the marginalized posterior": [[34, "Computing-and-plotting-the-marginalized-posterior"]], "Normalizing by numerical quadrature": [[34, "Normalizing-by-numerical-quadrature"]], "A prescription for plotting 1D posteriors": [[34, "A-prescription-for-plotting-1D-posteriors"]], "An analytical expression for the marginal posterior": [[34, "An-analytical-expression-for-the-marginal-posterior"]], "Plotting a 2D posterior": [[34, "Plotting-a-2D-posterior"]], "Aside: Speed of likelihood calculation": [[34, "Aside:-Speed-of-likelihood-calculation"]], "Computing the log of a 2D posterior": [[34, "Computing-the-log-of-a-2D-posterior"]], "4. Marginalization by numerical quadrature": [[35, "4.-Marginalization-by-numerical-quadrature"]], "The tubulin conservation model": [[35, "The-tubulin-conservation-model"], [40, "The-tubulin-conservation-model"], [57, "The-tubulin-conservation-model"]], "Analytical marginalization": [[35, "Analytical-marginalization"]], "Numerical marginalization": [[35, "Numerical-marginalization"]], "The curse of dimensionality and overcoming it": [[35, "The-curse-of-dimensionality-and-overcoming-it"]], "5. Conjugacy": [[36, "5.-Conjugacy"]], "The Beta-Binomial conjugate pair": [[36, "The-Beta-Binomial-conjugate-pair"]], "Finding the conjugate": [[36, "Finding-the-conjugate"]], "Plots of the posteriors": [[36, "Plots-of-the-posteriors"]], "Comments on conjugates": [[36, "Comments-on-conjugates"]], "6. Parameter estimation by optimization": [[37, "parameter-estimation-by-optimization"]], "Parameter estimation by optimization case study: Normal likelihood": [[38, "Parameter-estimation-by-optimization-case-study:-Normal-likelihood"]], "Exploratory data analysis": [[38, "Exploratory-data-analysis"]], "Independent size model": [[38, "Independent-size-model"]], "Estimation of the MAP parameters": [[38, "Estimation-of-the-MAP-parameters"]], "Normal approximation of the posterior": [[38, "Normal-approximation-of-the-posterior"]], "Credible intervals": [[38, "Credible-intervals"], [39, "Credible-intervals"]], "How good is the approximation?": [[38, "How-good-is-the-approximation?"]], "Bayesian approach to parameter estimation by optimization": [[39, "Bayesian-approach-to-parameter-estimation-by-optimization"]], "Summarizing the posterior near its maximum": [[39, "Summarizing-the-posterior-near-its-maximum"]], "Demonstration of the Normal approximation": [[39, "Demonstration-of-the-Normal-approximation"]], "Credible intervals may be skewed": [[39, "Credible-intervals-may-be-skewed"]], "Why use the MAP for parameter estimation?": [[39, "Why-use-the-MAP-for-parameter-estimation?"]], "Parameter estimation by optimization: A variate-covariate model": [[40, "Parameter-estimation-by-optimization:-A-variate-covariate-model"]], "Parameter estimation": [[40, "Parameter-estimation"]], "Checking the Normal approximation": [[40, "Checking-the-Normal-approximation"]], "Displaying the best fit line": [[40, "Displaying-the-best-fit-line"]], "Further reading on MCMC": [[42, "further-reading-on-mcmc"]], "7. Introduction to Markov chain Monte Carlo": [[43, "introduction-to-markov-chain-monte-carlo"]], "Random number generation": [[44, "random-number-generation"]], "The basic idea behind MCMC": [[44, "the-basic-idea-behind-mcmc"]], "Generating a transition kernel: The Metropolis-Hastings algorithm": [[45, "generating-a-transition-kernel-the-metropolis-hastings-algorithm"]], "The algorithm/kernel": [[45, "the-algorithm-kernel"]], "Detailed balance": [[45, "detailed-balance"]], "Choosing the transition kernel": [[45, "choosing-the-transition-kernel"]], "Warm-up": [[46, "warm-up"]], "Why MCMC?": [[47, "why-mcmc"]], "8. Introduction to MCMC with Stan": [[48, "introduction-to-mcmc-with-stan"]], "Parameter estimation with Markov chain Monte Carlo": [[49, "Parameter-estimation-with-Markov-chain-Monte-Carlo"]], "Stan: Our MCMC engine": [[49, "Stan:-Our-MCMC-engine"]], "ECDFs of mRNA counts": [[49, "ECDFs-of-mRNA-counts"], [72, "ECDFs-of-mRNA-counts"]], "Building a generative model": [[49, "Building-a-generative-model"], [56, "Building-a-generative-model"]], "Priors for burst size and inter-burst time": [[49, "Priors-for-burst-size-and-inter-burst-time"]], "Sampling the posterior": [[49, "Sampling-the-posterior"]], "Plots of the samples": [[49, "Plots-of-the-samples"]], "Marginalizing the posterior": [[49, "Marginalizing-the-posterior"]], "Analysis for all genes": [[49, "Analysis-for-all-genes"]], "Display of \u201cbest fit\u201d": [[49, "Display-of-%22best-fit%22"]], "\u201cHello, world\u201d \u2014Stan": [[50, "%22Hello,-world%22-\u2014Stan"]], "Basics of Stan programs": [[50, "Basics-of-Stan-programs"]], "Say hi, Stan": [[50, "Say-hi,-Stan"]], "Parsing output with ArviZ": [[50, "Parsing-output-with-ArviZ"]], "Direct sampling": [[50, "Direct-sampling"]], "Why are we using that?": [[50, "Why-are-we-using-that?"]], "Displaying your Stan code": [[50, "Displaying-your-Stan-code"]], "Saving samples": [[50, "Saving-samples"]], "Cleaning up the shrapnel": [[50, "Cleaning-up-the-shrapnel"]], "9. Mixture models and label switching with MCMC": [[51, "9.-Mixture-models-and-label-switching-with-MCMC"]], "Mixture models": [[51, "Mixture-models"]], "Coding up a mixture model": [[51, "Coding-up-a-mixture-model"]], "Parsing the output": [[51, "Parsing-the-output"]], "Plotting the samples": [[51, "Plotting-the-samples"]], "Label switching": [[51, "Label-switching"]], "Initializing walkers": [[51, "Initializing-walkers"]], "Conclusions": [[51, "Conclusions"], [70, "Conclusions"], [72, "Conclusions"], [73, "Conclusions"]], "10. Variate-covariate models with MCMC": [[52, "10.-Variate-covariate-models-with-MCMC"]], "Updated generative model": [[52, "Updated-generative-model"]], "Using Stan to sample": [[52, "Using-Stan-to-sample"]], "Display of MCMC samples": [[53, "Display-of-MCMC-samples"]], "Visualization with ArviZ": [[53, "Visualization-with-ArviZ"]], "The model and samples": [[53, "The-model-and-samples"]], "Examining traces": [[53, "Examining-traces"]], "Trace plots": [[53, "Trace-plots"]], "Trace plots with ArviZ": [[53, "Trace-plots-with-ArviZ"]], "Trace plots with bebi103": [[53, "Trace-plots-with-bebi103"]], "Interpetation of trace plots": [[53, "Interpetation-of-trace-plots"]], "Parallel coordinate plots": [[53, "Parallel-coordinate-plots"]], "Parallel coordinate plots with ArviZ": [[53, "Parallel-coordinate-plots-with-ArviZ"]], "Parallel coordinate plots with bebi103": [[53, "Parallel-coordinate-plots-with-bebi103"]], "Intepretation of parallel coordinate plots": [[53, "Intepretation-of-parallel-coordinate-plots"]], "Plots of marginalized distributions": [[53, "Plots-of-marginalized-distributions"]], "Plotting marginalized distributions of one parameter": [[53, "Plotting-marginalized-distributions-of-one-parameter"]], "Plotting marginalized distributions with ArviZ": [[53, "Plotting-marginalized-distributions-with-ArviZ"]], "Plotting marginalized distributions with iqplot": [[53, "Plotting-marginalized-distributions-with-iqplot"]], "Marginal posteriors of two parameters and corner plots": [[53, "Marginal-posteriors-of-two-parameters-and-corner-plots"]], "Pair plots with ArviZ": [[53, "Pair-plots-with-ArviZ"]], "Corner plots with bebi103": [[53, "Corner-plots-with-bebi103"]], "11. Display of MCMC results": [[54, "display-of-mcmc-results"]], "Reporting summaries of the posterior": [[55, "Reporting-summaries-of-the-posterior"]], "Reporting summaries of MCMC samples": [[55, "Reporting-summaries-of-MCMC-samples"]], "Some distributions to sample": [[55, "Some-distributions-to-sample"]], "Summarizing the \u201cMCMC\u201d results with error bars": [[55, "Summarizing-the-%22MCMC%22-results-with-error-bars"]], "Relative merits of each method": [[55, "Relative-merits-of-each-method"]], "How to display the summary in text.": [[55, "How-to-display-the-summary-in-text."]], "12. Model building with prior predictive checks": [[56, "12.-Model-building-with-prior-predictive-checks"]], "Model 1: Spindle size is independent of droplet size": [[56, "Model-1:-Spindle-size-is-independent-of-droplet-size"]], "The prior": [[56, "The-prior"]], "The prior, take 2": [[56, "The-prior,-take-2"]], "Prior predictive checks": [[56, "Prior-predictive-checks"], [56, "id1"]], "The prior, take 3": [[56, "The-prior,-take-3"]], "Prior predictive checks, take 2": [[56, "Prior-predictive-checks,-take-2"]], "Prior predictive checks with Stan": [[56, "Prior-predictive-checks-with-Stan"]], "Model 2: Spindle size dependent on total tubulin concentration": [[56, "Model-2:-Spindle-size-dependent-on-total-tubulin-concentration"]], "Indentifiability of parameters": [[56, "Indentifiability-of-parameters"]], "Limiting behavior": [[56, "Limiting-behavior"]], "Generative model": [[56, "Generative-model"]], "Checking model assumptions": [[56, "Checking-model-assumptions"]], "Is V_\\mathrm{s} / V_0 \\ll 1?": [[56, "Is-V_\\mathrm{s}-/-V_0-\\ll-1?"]], "Do all spindles have the same aspect ratio k?": [[56, "Do-all-spindles-have-the-same-aspect-ratio-k?"]], "13. Posterior predictive checks": [[57, "13.-Posterior-predictive-checks"]], "The independent size model": [[57, "The-independent-size-model"]], "Beware the summary statistic": [[57, "Beware-the-summary-statistic"]], "14. Collector\u2019s box of distributions": [[58, "collector-s-box-of-distributions"]], "Check out the Distribution Explorer": [[58, "check-out-the-distribution-explorer"]], "Choosing distributions": [[58, "choosing-distributions"]], "Starting simple and adding flexibility": [[58, "starting-simple-and-adding-flexibility"]], "Priors for variables with support on the set of positive real numbers": [[58, "priors-for-variables-with-support-on-the-set-of-positive-real-numbers"]], "15. MCMC diagnostics": [[59, "15.-MCMC-diagnostics"]], "The model": [[59, "The-model"]], "Diagnostics for any MCMC sampler": [[59, "Diagnostics-for-any-MCMC-sampler"]], "The Gelman-Rubin R-hat statistic": [[59, "The-Gelman-Rubin-R-hat-statistic"]], "Effective samples size": [[59, "Effective-samples-size"]], "Monte Carlo standard error": [[59, "Monte-Carlo-standard-error"]], "Diagnostics for HMC": [[59, "Diagnostics-for-HMC"]], "Divergences": [[59, "Divergences"]], "Tree depth": [[59, "Tree-depth"]], "E-BFMI": [[59, "E-BFMI"]], "Quickly checking the diagnostics": [[59, "Quickly-checking-the-diagnostics"]], "16. A diagnostics case study: Artificial funnel of hell": [[60, "16.-A-diagnostics-case-study:-Artificial-funnel-of-hell"]], "Sampling out of the funnel": [[60, "Sampling-out-of-the-funnel"]], "Conquering the Funnel of Hell": [[60, "Conquering-the-Funnel-of-Hell"]], "Adjusting adapt_delta": [[60, "Adjusting-adapt_delta"]], "Noncentering": [[60, "Noncentering"], [76, "Noncentering"]], "Hierarchical models feature a Funnel of Hell": [[60, "Hierarchical-models-feature-a-Funnel-of-Hell"]], "17. Model comparison": [[61, "model-comparison"]], "Metrics for model assessment": [[61, "metrics-for-model-assessment"]], "Posterior predictive checks": [[61, "posterior-predictive-checks"]], "Closeness metrics": [[61, "closeness-metrics"]], "Entropy and the Kullback-Leibler divergence": [[61, "entropy-and-the-kullback-leibler-divergence"]], "The expected log pointwise predictive density": [[61, "the-expected-log-pointwise-predictive-density"]], "The Watanabe-Akaike information criterion": [[61, "the-watanabe-akaike-information-criterion"]], "Leave-one-out estimates of elpd": [[61, "leave-one-out-estimates-of-elpd"]], "The Akaike weights": [[61, "the-akaike-weights"]], "Example model selection: regression": [[62, "Example-model-selection:-regression"]], "18. Model comparison in practice": [[63, "model-comparison-in-practice"]], "Model comparison in practice": [[64, "Model-comparison-in-practice"]], "An example model comparison": [[64, "An-example-model-comparison"]], "Computing the pointwise log likelihood": [[64, "Computing-the-pointwise-log-likelihood"]], "Computing the WAIC and LOO": [[64, "Computing-the-WAIC-and-LOO"]], "Calculations with the mixture model": [[64, "Calculations-with-the-mixture-model"]], "Computing the weights": [[64, "Computing-the-weights"]], "Choosing a hierarchical prior": [[65, "Choosing-a-hierarchical-prior"]], "Exchangeability": [[65, "Exchangeability"]], "Choice of the conditional distribution": [[65, "Choice-of-the-conditional-distribution"]], "Generalization of hierarchical models": [[66, "Generalization-of-hierarchical-models"]], "Implementation of a hierarchical model": [[67, "Implementation-of-a-hierarchical-model"]], "19. Hierarchical models": [[68, "hierarchical-models"]], "Modeling repeated experiments": [[69, "Modeling-repeated-experiments"]], "A model for reversals": [[69, "A-model-for-reversals"]], "Pooled data: identical parameters": [[69, "Pooled-data:-identical-parameters"]], "Independent parameters": [[69, "Independent-parameters"]], "The best of both worlds: A hierarchical model": [[69, "The-best-of-both-worlds:-A-hierarchical-model"]], "20. Implementation of hierarchical models": [[70, "20.-Implementation-of-hierarchical-models"]], "Hierarchical model structure": [[70, "Hierarchical-model-structure"]], "Coding up the hierarchical model in Stan": [[70, "Coding-up-the-hierarchical-model-in-Stan"]], "A quick aside: generating a data set": [[70, "A-quick-aside:-generating-a-data-set"]], "Generating input data for Stan": [[70, "Generating-input-data-for-Stan"]], "Drawing samples and checking diagnostics": [[70, "Drawing-samples-and-checking-diagnostics"]], "A noncentered parametrization": [[70, "A-noncentered-parametrization"]], "21. Principled analysis pipelines": [[71, "21.-Principled-analysis-pipelines"]], "Building a workflow": [[71, "Building-a-workflow"]], "References and terminology": [[71, "References-and-terminology"]], "Simulation-based calibration": [[71, "Simulation-based-calibration"]], "Diagnostics": [[71, "Diagnostics"]], "z-score": [[71, "z-score"]], "Shrinkage": [[71, "Shrinkage"]], "Shrinkage vs. z-score plot": [[71, "Shrinkage-vs.-z-score-plot"]], "Rank statistics": [[71, "Rank-statistics"]], "A rank statistic ECDF plot": [[71, "A-rank-statistic-ECDF-plot"]], "Rank statistic histograms": [[71, "Rank-statistic-histograms"]], "A full principled pipeline": [[71, "A-full-principled-pipeline"]], "22: Simulation based calibration and related checks in practice": [[72, "22:-Simulation-based-calibration-and-related-checks-in-practice"]], "The generative model": [[72, "The-generative-model"]], "Performing SBC": [[72, "Performing-SBC"]], "An adjusted prior": [[72, "An-adjusted-prior"]], "Sampling with our new model": [[72, "Sampling-with-our-new-model"]], "23. Introduction to Gaussian processes": [[73, "23.-Introduction-to-Gaussian-processes"]], "Predicting using posterior estimates": [[73, "Predicting-using-posterior-estimates"]], "An example data set": [[73, "An-example-data-set"]], "Processes and nonparametric Bayesian inference": [[73, "Processes-and-nonparametric-Bayesian-inference"]], "Gaussian processes with a finite number of points": [[73, "Gaussian-processes-with-a-finite-number-of-points"]], "The mean function and centering and scaling": [[73, "The-mean-function-and-centering-and-scaling"]], "The kernel and covariance matrix": [[73, "The-kernel-and-covariance-matrix"]], "Sampling out of a Gaussian process prior": [[73, "Sampling-out-of-a-Gaussian-process-prior"]], "Sampling out of a GP prior using Stan": [[73, "Sampling-out-of-a-GP-prior-using-Stan"]], "Sampling out of a GP prior using Numpy": [[73, "Sampling-out-of-a-GP-prior-using-Numpy"]], "Composing kernels": [[73, "Composing-kernels"]], "Inference with GPs": [[73, "Inference-with-GPs"]], "Normal likelihoods with Gaussian process priors": [[73, "Normal-likelihoods-with-Gaussian-process-priors"]], "The posterior predictive distribution of function values": [[73, "The-posterior-predictive-distribution-of-function-values"]], "Computing the parameters of the posterior predictive distribution": [[73, "Computing-the-parameters-of-the-posterior-predictive-distribution"]], "Plotting an analytical posterior": [[73, "Plotting-an-analytical-posterior"]], "Gaussian process hyperparameters by optimization": [[74, "Gaussian-process-hyperparameters-by-optimization"]], "Priors for hyperparameters": [[74, "Priors-for-hyperparameters"]], "Computing the MAP with SciPy": [[74, "Computing-the-MAP-with-SciPy"]], "Posterior predictive samples": [[74, "Posterior-predictive-samples"]], "Obtaining hyperpriors by optimizing with Stan": [[74, "Obtaining-hyperpriors-by-optimizing-with-Stan"]], "Calculating derivatives from data with GPs": [[75, "Calculating-derivatives-from-data-with-GPs"]], "Derivatives of GPs": [[75, "Derivatives-of-GPs"]], "Derivative of the squared exponential kernel": [[75, "Derivative-of-the-squared-exponential-kernel"]], "Derivatives of the Mat\u00e9rn kernel": [[75, "Derivatives-of-the-Mat\u00e9rn-kernel"]], "Expressions for the gradient and covariance of the gradient": [[75, "Expressions-for-the-gradient-and-covariance-of-the-gradient"]], "Derivatives of GPs in practice using optimization": [[75, "Derivatives-of-GPs-in-practice-using-optimization"]], "Derivatives with a Mat\u00e9rn kernel": [[75, "Derivatives-with-a-Mat\u00e9rn-kernel"]], "Sampling derivatives with Stan": [[75, "Sampling-derivatives-with-Stan"]], "Gaussian processes with non-Normal likelihoods": [[76, "Gaussian-processes-with-non-Normal-likelihoods"]], "Generating samples of latent variables using MCMC": [[76, "Generating-samples-of-latent-variables-using-MCMC"]], "A GP generative model": [[76, "A-GP-generative-model"]], "Sampling latent variables with Stan": [[76, "Sampling-latent-variables-with-Stan"]], "Sampling with a Poisson likelihood": [[76, "Sampling-with-a-Poisson-likelihood"]], "24. Implementation of Gaussian processes": [[77, "implementation-of-gaussian-processes"]], "MCMC with GPs with Normal likelihoods": [[78, "MCMC-with-GPs-with-Normal-likelihoods"]], "Hyperparameter estimation using MCMC": [[78, "Hyperparameter-estimation-using-MCMC"]], "Posterior predictive checks with GPs": [[78, "Posterior-predictive-checks-with-GPs"]], "Aside: Stan include files": [[78, "Aside:-Stan-include-files"]], "25. Variational Bayesian inference": [[79, "25.-Variational-Bayesian-inference"]], "The main ideas of variational inference": [[79, "The-main-ideas-of-variational-inference"]], "Choosing Q(\u03b8)": [[79, "Choosing-Q(\u03b8)"]], "Summary of VI algorithm": [[79, "Summary-of-VI-algorithm"]], "Automatic Differentiation Variational Inference and Stan": [[79, "Automatic-Differentiation-Variational-Inference-and-Stan"]], "Examples": [[79, "Examples"]], "Example 1: Spindle size as a function of volume": [[79, "Example-1:-Spindle-size-as-a-function-of-volume"]], "Example 2: A multilevel hierarchical model": [[79, "Example-2:-A-multilevel-hierarchical-model"]], "26: Wrap-up": [[80, "wrap-up"]], "Meetings": [[81, "meetings"]], "Lab sessions": [[81, "lab-sessions"]], "Submission of assignments": [[81, "submission-of-assignments"]], "Lessons and lesson exercises": [[81, "lessons-and-lesson-exercises"]], "Grading": [[81, "grading"]], "Collaboration policy and Honor Code": [[81, "collaboration-policy-and-honor-code"]], "Course communications": [[81, "course-communications"]], "\u201cEdiquette\u201d": [[81, "ediquette"]], "R1: Review of probability": [[82, "r1-review-of-probability"]], "R2: Choosing priors and review of optimization": [[83, "r2-choosing-priors-and-review-of-optimization"], [84, "r2-choosing-priors-and-review-of-optimization"]], "R3: Just homework help": [[85, "r3-just-homework-help"]], "More details on Hamiltonian Monte Carlo": [[86, "More-details-on-Hamiltonian-Monte-Carlo"]], "The typical set": [[86, "The-typical-set"]], "Hamiltonians": [[86, "Hamiltonians"]], "Hamiltonian Monte Carlo": [[86, "Hamiltonian-Monte-Carlo"]], "Transition using HMC": [[86, "Transition-using-HMC"]], "Choosing Kinetic Energy (Euclidean-Gaussian)": [[86, "Choosing-Kinetic-Energy-(Euclidean-Gaussian)"]], "A short note on integration times": [[86, "A-short-note-on-integration-times"]], "Numerical integration and what happens in divergences": [[86, "Numerical-integration-and-what-happens-in-divergences"]], "Computing Environment": [[86, "Computing-Environment"]], "R4. Introduction to Hamiltonian Monte Carlo": [[87, "r4-introduction-to-hamiltonian-monte-carlo"]], "Overview of Hamiltonian Monte Carlo": [[88, "Overview-of-Hamiltonian-Monte-Carlo"]], "Notation": [[88, "Notation"]], "Motivating interest:": [[88, "Motivating-interest:"]], "Features of a high-dimensional space Q:": [[88, "Features-of-a-high-dimensional-space-Q:"]], "But the question then remains: how do we design an algorithm to sample the typical set?": [[88, "But-the-question-then-remains:-how-do-we-design-an-algorithm-to-sample-the-typical-set?"]], "So this all leads us to \u2026 \ud83c\udf89 Hamiltonian Monte Carlo! \ud83c\udf89": [[88, "So-this-all-leads-us-to-...-\ud83c\udf89-Hamiltonian-Monte-Carlo!-\ud83c\udf89"]], "The Ideal Hamiltonian Markov Transition": [[88, "The-Ideal-Hamiltonian-Markov-Transition"]], "Actual Implementation of Hamiltonian Markov Transition Considerations": [[88, "Actual-Implementation-of-Hamiltonian-Markov-Transition-Considerations"]], "(A) Optimizing Choice of Kinetic Energy K(q, p)": [[88, "(A)-Optimizing-Choice-of-Kinetic-Energy-K(q,-p)"]], "(B) Integration method": [[88, "(B)-Integration-method"]], "(C) Integration time": [[88, "(C)-Integration-time"]], "Concluding thoughts": [[88, "Concluding-thoughts"]], "R5: Bayesian model building": [[89, "R5:-Bayesian-model-building"]], "R6: MCMC using Caltech\u2019s HPC": [[90, "R6:-MCMC-using-Caltech's-HPC"], [91, "r6-mcmc-using-caltech-s-hpc"]], "What even is a supercomputer?": [[90, "What-even-is-a-supercomputer?"]], "How to use the Caltech HPCC?": [[90, "How-to-use-the-Caltech-HPCC?"]], "Obtaining access": [[90, "Obtaining-access"]], "Logging on": [[90, "Logging-on"]], "SLURM": [[90, "SLURM"]], "Transferring files": [[90, "Transferring-files"]], "Storage": [[90, "Storage"]], "Software": [[90, "Software"], [95, "software"]], "Support": [[90, "Support"]], "Pro-Tip for writing code on the HPCC": [[90, "Pro-Tip-for-writing-code-on-the-HPCC"]], "Concurrency with Python": [[90, "Concurrency-with-Python"]], "Independent processes": [[90, "Independent-processes"]], "Pooling between processes": [[90, "Pooling-between-processes"]], "Sharing state between processes": [[90, "Sharing-state-between-processes"]], "Communicating between processes": [[90, "Communicating-between-processes"]], "Running Stan on the HPCC": [[90, "Running-Stan-on-the-HPCC"]], "Foreword": [[90, "Foreword"]], "R7: Sampling discrete parameters with Stan": [[92, "R7:-Sampling-discrete-parameters-with-Stan"]], "Review of LogSumExp, the cornerstone of stable marginalization with discrete parameters": [[92, "Review-of-LogSumExp,-the-cornerstone-of-stable-marginalization-with-discrete-parameters"]], "Handling log probabilities of discrete valued vectors in Stan": [[92, "Handling-log-probabilities-of-discrete-valued-vectors-in-Stan"]], "Discrete paremeters in Stan: integer \u03b1 for gamma distribution": [[92, "Discrete-paremeters-in-Stan:-integer-\u03b1-for-gamma-distribution"]], "Take two: handling discrete parameters via marginalization": [[92, "Take-two:-handling-discrete-parameters-via-marginalization"]], "R8: Discussion of HW 10 project proposals": [[93, "r8-discussion-of-hw-10-project-proposals"]], "R9: Just homework help": [[94, "r9-just-homework-help"]], "Reading/tutorials": [[95, "reading-tutorials"]], "Schedule overview": [[96, "schedule-overview"]], "Homework due dates": [[96, "homework-due-dates"]], "Lesson exercise due dates": [[96, "lesson-exercise-due-dates"]], "Weekly schedule": [[96, "weekly-schedule"]]}, "indexentries": {}})