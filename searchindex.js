Search.setIndex({"docnames": ["homework/01/hw1.1", "homework/01/index", "homework/02/hw2.1", "homework/02/hw2.2", "homework/02/index", "homework/03/hw3.1", "homework/03/hw3.2", "homework/03/index", "homework/04/hw4.1", "homework/04/hw4.2", "homework/04/index", "homework/05/hw5.1", "homework/05/hw5.2", "homework/05/index", "homework/06/hw6.1", "homework/06/hw6.2", "homework/06/index", "index", "lesson_exercises/exercise_01", "lesson_exercises/exercise_02", "lesson_exercises/exercise_03", "lesson_exercises/exercise_04", "lesson_exercises/exercise_05", "lesson_exercises/exercise_06", "lesson_exercises/exercise_07", "lesson_exercises/exercise_08", "lesson_exercises/exercise_09", "lessons/00/aws_setup", "lessons/00/colab", "lessons/00/index", "lessons/00/setup", "lessons/01/bayes_logic", "lessons/01/bayes_model_for_learning", "lessons/01/bayes_notation", "lessons/01/index", "lessons/01/marginalization", "lessons/01/probability_distributions", "lessons/02/bayesian_modeling_example", "lessons/02/bayesian_modeling_tasks", "lessons/02/choice_of_likelihood", "lessons/02/choice_of_prior", "lessons/02/index", "lessons/03/plotting_posteriors", "lessons/04/marginalization_by_numerical_quadrature", "lessons/05/conjugacy", "lessons/06/index", "lessons/06/normal_optimization", "lessons/06/optimization_basics", "lessons/06/variate_covariate_optimization", "lessons/07/Untitled", "lessons/07/further_reading", "lessons/07/index", "lessons/07/mcmc_idea", "lessons/07/metropolis_hastings", "lessons/07/warm_up", "lessons/07/why_mcmc", "lessons/08/index", "lessons/08/parameter_estimation_with_mcmc", "lessons/08/stan_hello_world", "lessons/09/mixture_model_stan", "lessons/10/variate_covariate_with_stan", "lessons/11/display_of_mcmc_samples", "lessons/11/index", "lessons/11/posterior_summaries", "lessons/12/prior_predictive_checks", "lessons/13/posterior_predictive_checks", "lessons/14/box_of_distributions", "lessons/15/mcmc_diagnostics", "lessons/16/funnel_of_hell", "lessons/17/model_comparison", "lessons/18/comparing_regressions", "lessons/18/index", "lessons/18/model_comparison", "lessons/19/choosing_a_hierarchical_prior", "lessons/19/generalization", "lessons/19/implementation", "lessons/19/index", "lessons/19/modeling_repeated_experiments", "lessons/20/hierarchical_implementation", "lessons/21/sbc", "lessons/22/sbc_in_practice", "lessons/23/intro_to_gps", "lessons/24/gp_hyperparams_by_optimization", "lessons/24/gps_and_derivatives", "lessons/24/gps_without_marginalization", "lessons/24/index", "lessons/24/mcmc_with_gps", "lessons/25/variational_inference", "lessons/26/wrapup", "policies", "recitations/EM/R01_expectation_maximization", "resources", "schedule"], "filenames": ["homework/01/hw1.1.ipynb", "homework/01/index.rst", "homework/02/hw2.1.ipynb", "homework/02/hw2.2.ipynb", "homework/02/index.rst", "homework/03/hw3.1.ipynb", "homework/03/hw3.2.ipynb", "homework/03/index.rst", "homework/04/hw4.1.ipynb", "homework/04/hw4.2.ipynb", "homework/04/index.rst", "homework/05/hw5.1.ipynb", "homework/05/hw5.2.ipynb", "homework/05/index.rst", "homework/06/hw6.1.ipynb", "homework/06/hw6.2.ipynb", "homework/06/index.rst", "index.rst", "lesson_exercises/exercise_01.ipynb", "lesson_exercises/exercise_02.ipynb", "lesson_exercises/exercise_03.ipynb", "lesson_exercises/exercise_04.ipynb", "lesson_exercises/exercise_05.ipynb", "lesson_exercises/exercise_06.ipynb", "lesson_exercises/exercise_07.ipynb", "lesson_exercises/exercise_08.ipynb", "lesson_exercises/exercise_09.ipynb", "lessons/00/aws_setup.ipynb", "lessons/00/colab.ipynb", "lessons/00/index.rst", "lessons/00/setup.ipynb", "lessons/01/bayes_logic.rst", "lessons/01/bayes_model_for_learning.rst", "lessons/01/bayes_notation.rst", "lessons/01/index.rst", "lessons/01/marginalization.rst", "lessons/01/probability_distributions.rst", "lessons/02/bayesian_modeling_example.rst", "lessons/02/bayesian_modeling_tasks.rst", "lessons/02/choice_of_likelihood.rst", "lessons/02/choice_of_prior.rst", "lessons/02/index.rst", "lessons/03/plotting_posteriors.ipynb", "lessons/04/marginalization_by_numerical_quadrature.ipynb", "lessons/05/conjugacy.ipynb", "lessons/06/index.rst", "lessons/06/normal_optimization.ipynb", "lessons/06/optimization_basics.ipynb", "lessons/06/variate_covariate_optimization.ipynb", "lessons/07/Untitled.ipynb", "lessons/07/further_reading.rst", "lessons/07/index.rst", "lessons/07/mcmc_idea.rst", "lessons/07/metropolis_hastings.rst", "lessons/07/warm_up.rst", "lessons/07/why_mcmc.rst", "lessons/08/index.rst", "lessons/08/parameter_estimation_with_mcmc.ipynb", "lessons/08/stan_hello_world.ipynb", "lessons/09/mixture_model_stan.ipynb", "lessons/10/variate_covariate_with_stan.ipynb", "lessons/11/display_of_mcmc_samples.ipynb", "lessons/11/index.rst", "lessons/11/posterior_summaries.ipynb", "lessons/12/prior_predictive_checks.ipynb", "lessons/13/posterior_predictive_checks.ipynb", "lessons/14/box_of_distributions.rst", "lessons/15/mcmc_diagnostics.ipynb", "lessons/16/funnel_of_hell.ipynb", "lessons/17/model_comparison.rst", "lessons/18/comparing_regressions.ipynb", "lessons/18/index.rst", "lessons/18/model_comparison.ipynb", "lessons/19/choosing_a_hierarchical_prior.ipynb", "lessons/19/generalization.ipynb", "lessons/19/implementation.ipynb", "lessons/19/index.rst", "lessons/19/modeling_repeated_experiments.ipynb", "lessons/20/hierarchical_implementation.ipynb", "lessons/21/sbc.ipynb", "lessons/22/sbc_in_practice.ipynb", "lessons/23/intro_to_gps.ipynb", "lessons/24/gp_hyperparams_by_optimization.ipynb", "lessons/24/gps_and_derivatives.ipynb", "lessons/24/gps_without_marginalization.ipynb", "lessons/24/index.rst", "lessons/24/mcmc_with_gps.ipynb", "lessons/25/variational_inference.ipynb", "lessons/26/wrapup.rst", "policies.rst", "recitations/EM/R01_expectation_maximization.ipynb", "resources.rst", "schedule.rst"], "titles": ["Homework 1.1: First attempts at Bayesian generative modeling (70 pts)", "1. Intuitive generative modeling", "Homework 2.1: Overwhelming a prior (45 pts)", "Homework 2.2: Exponential conjugate prior (55 pts)", "2. Analytical and graphical methods for analysis of the posterior", "Homework 3.1: Least squares (20 pts)", "Homework 3.2: MAP estimates and zero-inflation for Drop-Seq controls (80 pts)", "3. Maximum a posteriori parameter estimation", "Homework 4.1: Writing your own MCMC sampler (70 pts)", "Homework 4.2: MCMC with Boolean data (30 pts)", "4. Sampling with MCMC", "Homework 5.1: MCMC with Boolean data with Stan (25 pts)", "Homework 5.2: Microtubule catastrophe (75 pts)", "5. Inference with Stan", "Homework 6.1: Surviving osmotic shock (40 pts)", "Homework 6.2: Diagnosing nonidentifiability with MCMC (60 pts)", "6. MCMC with ion channels", "BE/Bi 103 b: Statistical Inference in the Biological Sciences", "E1. To be completed after lesson 5", "E2. To be completed after lesson 6", "E3. To be completed after lesson 10", "E4. To be completed after lesson 13", "E5. To be completed after lesson 16", "E6. To be completed after lesson 18", "E7. To be completed after lesson 20", "E8. To be completed after lesson 22", "E9. To be completed after lesson 25", "AWS setup and usage", "Using Google Colab", "0. Setting up computing resources", "Configuring your machine", "Probability as the logic of science", "Bayes\u2019s theorem as a model for learning", "Notation of parts of Bayes\u2019s Theorem", "1. Probability and the logic of scientific reasoning", "Marginalization", "Probability distributions", "Bayesian modeling example: parameter estimation from repeated measurements", "Tasks of Bayesian modeling", "Choosing likelihoods", "Choosing priors", "2. Introduction to Bayesian modeling", "3. Plotting posteriors", "4. Marginalization by numerical quadrature", "5. Conjugacy", "6. Parameter estimation by optimization", "Parameter estimation by optimization case study: Normal likelihood", "Bayesian approach to parameter estimation by optimization", "Parameter estimation by optimization: A variate-covariate model", "&lt;no title&gt;", "Further reading on MCMC", "7. Introduction to Markov chain Monte Carlo", "Random number generation", "Generating a transition kernel: The Metropolis-Hastings algorithm", "Warm-up", "Why MCMC?", "8. Introduction to MCMC with Stan", "Parameter estimation with Markov chain Monte Carlo", "\u201cHello, world\u201d \u2014Stan", "9. Mixture models and label switching with MCMC", "10. Variate-covariate models with MCMC", "Display of MCMC samples", "11. Display of MCMC results", "Reporting summaries of the posterior", "12. Model building with prior predictive checks", "13. Posterior predictive checks", "14. Collector\u2019s box of distributions", "15. MCMC diagnostics", "16. A diagnostics case study: Artificial funnel of hell", "17. Model comparison", "Example model selection: regression", "18. Model comparison in practice", "Model comparison in practice", "Choosing a hierarchical prior", "Generalization of hierarchical models", "Implementation of a hierarchical model", "19. Hierarchical models", "Modeling repeated experiments", "20. Implementation of hierarchical models", "21. Principled analysis pipelines", "22: Simulation based calibration and related checks in practice", "23. Introduction to Gaussian processes", "Gaussian process hyperparameters by optimization", "Calculating derivatives from data with GPs", "Gaussian processes with non-Normal likelihoods", "24. Implementation of Gaussian processes", "MCMC with GPs with Normal likelihoods", "25. Variational Bayesian inference", "26: Wrap-up", "Meetings", "Introduction to the EM Algorithm", "Software", "Schedule overview"], "terms": {"collard": 0, "cowork": [0, 6, 15, 54, 64, 72, 79, 83, 87], "did": [0, 12, 14, 15, 18, 30, 31, 32, 39, 40, 42, 43, 46, 48, 57, 58, 60, 61, 64, 65, 68, 69, 70, 72, 73, 75, 77, 79, 80, 81, 82, 89, 90], "simpl": [0, 31, 37, 38, 42, 44, 47, 54, 58, 59, 63, 68, 69, 73, 79, 80, 81, 82, 84, 86, 87, 89], "experi": [0, 2, 6, 9, 12, 14, 24, 31, 32, 36, 38, 39, 40, 42, 44, 57, 64, 66, 67, 69, 73, 74, 75, 76, 78, 79, 80, 81, 83, 87], "thei": [0, 2, 5, 12, 14, 15, 31, 37, 40, 42, 44, 46, 47, 48, 57, 58, 59, 60, 61, 64, 67, 68, 69, 72, 78, 79, 81, 83, 84, 87, 89], "collect": [0, 14, 55, 57, 58, 65], "sampl": [0, 8, 9, 11, 17, 20, 22, 23, 27, 30, 36, 38, 43, 48, 52, 53, 54, 55, 62, 64, 65, 69, 70, 72, 73, 74, 75, 79, 86, 87, 90, 92], "carrion": 0, "beetl": 0, "feed": 0, "decai": [0, 42, 64, 80], "anim": [0, 9], "matter": [0, 40, 55, 74, 89], "measur": [0, 2, 5, 6, 12, 14, 15, 33, 36, 38, 39, 40, 41, 42, 43, 46, 57, 58, 64, 65, 66, 67, 69, 70, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 87, 90], "morpholog": 0, "featur": [0, 42, 46, 58, 66, 67, 69, 73, 74, 80, 81, 87], "variou": [0, 6, 38, 52, 58, 61, 63, 81, 83, 91], "speci": [0, 40], "from": [0, 2, 3, 5, 6, 9, 12, 14, 15, 28, 30, 31, 32, 35, 36, 38, 40, 41, 42, 44, 46, 47, 48, 50, 52, 53, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90], "differ": [0, 2, 9, 12, 15, 27, 28, 31, 40, 42, 46, 47, 57, 59, 63, 64, 65, 68, 69, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 87, 89, 90], "site": [0, 3, 14, 15, 82, 83, 90], "time": [0, 5, 8, 9, 12, 15, 27, 28, 29, 31, 37, 39, 42, 43, 47, 53, 54, 58, 59, 60, 63, 64, 66, 69, 73, 77, 79, 80, 81, 82, 83, 84, 87, 89, 91, 92], "year": [0, 9, 27, 40, 53, 77], "imagin": [0, 5, 36, 54, 57, 66, 68, 69, 74, 77, 80, 81, 83], "you": [0, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 31, 37, 38, 39, 40, 42, 44, 46, 47, 48, 50, 52, 53, 54, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 74, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91], "ar": [0, 2, 3, 5, 6, 8, 9, 12, 14, 15, 17, 19, 21, 22, 23, 26, 28, 29, 30, 31, 33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "cabin": 0, "main": [0, 40, 46, 47, 52, 57, 58, 61, 66, 79, 84, 91], "There": [0, 6, 9, 27, 28, 29, 30, 31, 37, 40, 44, 53, 54, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 72, 78, 79, 81, 83, 84, 87, 89, 90, 91], "also": [0, 6, 8, 9, 17, 27, 28, 29, 31, 32, 33, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 52, 53, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91], "plenti": [0, 27, 67, 72], "area": [0, 43, 67, 80], "which": [0, 3, 5, 6, 8, 9, 12, 15, 27, 28, 29, 30, 31, 32, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "stai": [0, 59], "so": [0, 2, 9, 12, 14, 24, 27, 28, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "curiou": 0, "look": [0, 3, 6, 8, 9, 27, 40, 42, 44, 46, 47, 48, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "your": [0, 2, 3, 9, 10, 11, 14, 17, 24, 25, 28, 29, 31, 39, 40, 42, 46, 47, 48, 53, 59, 64, 65, 66, 67, 68, 69, 78, 79, 80, 81, 82, 86, 87, 89], "plan": 0, "set": [0, 2, 3, 5, 6, 9, 12, 14, 15, 17, 19, 24, 27, 28, 30, 31, 32, 33, 36, 38, 40, 43, 46, 47, 48, 53, 55, 58, 59, 60, 61, 65, 69, 70, 72, 73, 74, 75, 77, 79, 80, 82, 83, 84, 86, 87, 89, 90], "up": [0, 3, 6, 8, 14, 17, 20, 27, 28, 30, 37, 38, 40, 42, 43, 46, 48, 51, 52, 57, 64, 65, 66, 67, 68, 70, 74, 77, 80, 81, 82, 83, 84, 86, 87, 89, 90, 92], "trap": 0, "specimen": 0, "given": [0, 6, 15, 27, 31, 33, 36, 37, 38, 40, 42, 44, 47, 52, 55, 57, 59, 64, 67, 69, 72, 75, 77, 78, 81, 82, 83, 84, 86, 87, 88, 89, 90], "For": [0, 2, 6, 9, 27, 28, 31, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 52, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 77, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "each": [0, 2, 3, 6, 8, 9, 12, 14, 18, 23, 27, 28, 31, 37, 42, 43, 44, 46, 47, 52, 55, 57, 58, 59, 60, 61, 64, 65, 66, 67, 69, 72, 73, 75, 77, 78, 79, 80, 81, 84, 86, 87, 89, 90, 92], "its": [0, 5, 6, 15, 31, 37, 40, 42, 43, 44, 46, 57, 58, 59, 60, 63, 64, 66, 68, 69, 73, 75, 80, 81, 82, 83, 87, 89, 91], "mass": [0, 6, 36, 40, 46, 59, 63, 66, 68, 72, 79, 80, 81, 89], "length": [0, 8, 37, 39, 40, 42, 43, 46, 48, 57, 58, 59, 60, 61, 64, 65, 66, 67, 70, 72, 79, 81, 82, 84, 87], "elytra": 0, "As": [0, 2, 6, 12, 27, 28, 30, 31, 36, 37, 38, 40, 42, 43, 44, 47, 52, 53, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 89, 90], "we": [0, 2, 3, 5, 6, 8, 9, 11, 12, 15, 17, 18, 19, 23, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90], "learn": [0, 17, 29, 31, 34, 38, 44, 46, 47, 57, 58, 59, 61, 64, 65, 67, 69, 77, 78, 79, 81, 82, 83, 90], "class": [0, 2, 17, 28, 30, 33, 43, 53, 66, 81, 87, 89, 91, 92], "prior": [0, 4, 5, 6, 11, 12, 14, 17, 18, 19, 21, 25, 32, 33, 35, 39, 41, 42, 43, 44, 46, 47, 48, 58, 59, 60, 65, 67, 69, 72, 74, 75, 76, 77, 78, 79, 83, 84, 86, 87, 89, 90, 92], "perform": [0, 6, 12, 19, 25, 27, 29, 38, 39, 40, 42, 43, 46, 53, 55, 57, 58, 59, 60, 63, 64, 65, 67, 69, 72, 75, 78, 79, 81, 82, 83, 84, 86, 87, 89], "an": [0, 3, 6, 9, 14, 15, 28, 29, 30, 31, 32, 33, 35, 37, 38, 39, 40, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 73, 75, 77, 78, 79, 82, 83, 84, 87, 89, 90], "i": [0, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 47, 48, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92], "us": [0, 2, 3, 6, 8, 9, 11, 12, 14, 15, 19, 20, 21, 22, 23, 24, 26, 29, 30, 31, 33, 35, 36, 37, 38, 39, 42, 43, 44, 46, 48, 52, 53, 54, 55, 57, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 82, 87, 89, 90, 91], "think": [0, 5, 6, 14, 31, 37, 38, 40, 46, 48, 52, 58, 59, 63, 64, 67, 69, 72, 78, 81, 82, 84, 90], "about": [0, 6, 8, 12, 14, 27, 28, 31, 32, 33, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 66, 67, 69, 72, 78, 79, 80, 81, 82, 83, 84, 87, 89, 91], "what": [0, 2, 5, 6, 9, 18, 19, 20, 23, 24, 25, 26, 27, 28, 33, 37, 38, 40, 42, 43, 48, 52, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 78, 79, 80, 81, 82, 83, 87, 89], "kind": [0, 31, 53, 59, 61, 64, 67, 69, 80, 81, 82, 83], "data": [0, 2, 3, 5, 6, 10, 12, 13, 14, 15, 17, 24, 27, 28, 30, 31, 32, 33, 36, 37, 38, 39, 40, 43, 44, 47, 48, 54, 55, 58, 59, 60, 61, 63, 65, 66, 69, 70, 72, 73, 74, 75, 79, 80, 82, 84, 85, 86, 87, 89, 90, 91], "might": [0, 6, 8, 9, 14, 27, 28, 30, 37, 38, 39, 40, 42, 44, 52, 55, 58, 59, 61, 63, 64, 66, 68, 69, 73, 79, 80, 81, 82, 86, 87], "expect": [0, 5, 6, 30, 31, 37, 38, 40, 42, 44, 46, 48, 55, 57, 58, 59, 60, 63, 64, 65, 66, 67, 68, 72, 78, 79, 80, 81, 84, 87, 89, 90], "observ": [0, 6, 9, 12, 14, 31, 38, 44, 65, 66, 69, 72, 77, 81, 83, 84, 87, 90], "thi": [0, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 17, 22, 27, 28, 29, 30, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92], "involv": [0, 6, 9, 27, 31, 37, 38, 40, 43, 47, 57, 61, 64, 67, 69, 74, 81, 86, 90], "propos": [0, 6, 8, 15, 53, 54, 64, 67, 68, 69, 79], "draw": [0, 11, 40, 52, 57, 58, 59, 63, 64, 65, 67, 68, 69, 70, 72, 75, 79, 80, 81, 82, 83, 84, 86, 87], "befor": [0, 28, 31, 37, 38, 40, 42, 43, 44, 48, 57, 58, 59, 64, 65, 68, 69, 79, 80, 81, 82, 83, 84, 86, 87, 89, 92], "proceed": [0, 65, 68, 83, 87], "do": [0, 2, 5, 6, 8, 9, 11, 12, 14, 15, 18, 19, 21, 25, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "want": [0, 8, 9, 18, 27, 28, 31, 36, 42, 43, 44, 46, 52, 53, 55, 57, 58, 59, 61, 64, 65, 66, 67, 69, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89], "clarifi": 0, "purpos": [0, 9, 27, 37, 57, 58, 59, 64, 66, 67, 72, 82], "problem": [0, 2, 3, 5, 6, 9, 11, 12, 14, 22, 28, 29, 33, 36, 38, 40, 42, 43, 46, 47, 48, 52, 53, 59, 61, 63, 64, 67, 68, 69, 74, 77, 78, 79, 80, 82, 83, 84, 87, 89], "address": [0, 27, 67, 78, 79, 81], "question": [0, 18, 19, 20, 21, 22, 23, 24, 25, 26, 65, 66, 67, 69, 79, 89], "mai": [0, 3, 5, 6, 8, 11, 19, 20, 21, 22, 23, 27, 28, 29, 30, 31, 33, 36, 37, 38, 40, 46, 52, 55, 57, 58, 59, 63, 64, 65, 66, 67, 68, 69, 72, 73, 77, 78, 79, 81, 82, 84, 86, 87, 89, 90], "my": [0, 18, 30, 31, 36, 37, 40, 46, 53, 61, 63, 80, 87], "formal": [0, 31, 38, 64, 69, 78], "procedur": [0, 5, 8, 39, 40, 43, 48, 64, 65, 69, 79, 80, 83, 87, 90], "build": [0, 2, 12, 14, 17, 39, 40, 58, 60, 66, 80, 81, 83, 86, 89, 92], "The": [0, 2, 3, 5, 6, 8, 9, 12, 14, 27, 28, 29, 30, 33, 36, 39, 46, 47, 51, 58, 59, 60, 63, 66, 68, 70, 72, 73, 74, 75, 78, 79, 82, 83, 84, 86, 88, 89, 90, 91, 92], "concept": [0, 36, 52, 87, 89], "though": [0, 8, 27, 28, 30, 36, 37, 38, 40, 42, 43, 46, 47, 48, 53, 54, 58, 61, 63, 64, 65, 66, 67, 69, 70, 72, 77, 78, 79, 80, 81, 82, 86, 87, 89], "fairli": [0, 48, 59], "intuit": [0, 17, 31, 40, 44, 64, 69, 80, 92], "At": [0, 27, 38, 40, 58, 81], "point": [0, 5, 6, 9, 18, 19, 31, 40, 43, 46, 48, 52, 57, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 72, 78, 79, 82, 83, 84, 86, 87, 89, 90], "re": [0, 3, 37, 44, 46, 48, 52, 57, 61, 63, 67, 68, 77, 81, 82, 83, 84, 90], "ask": [0, 11, 37, 64, 69, 89], "how": [0, 2, 3, 6, 8, 9, 12, 14, 18, 19, 22, 27, 29, 30, 31, 32, 36, 37, 38, 40, 42, 44, 47, 48, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91], "right": [0, 15, 27, 28, 31, 36, 37, 40, 42, 43, 47, 48, 52, 53, 55, 59, 60, 61, 64, 65, 68, 69, 70, 72, 73, 79, 81, 82, 83, 87, 89, 90], "now": [0, 2, 5, 6, 9, 11, 27, 31, 32, 35, 36, 37, 40, 42, 43, 44, 46, 47, 48, 52, 55, 57, 58, 59, 60, 61, 64, 65, 67, 68, 69, 70, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 90], "concern": [0, 27, 38, 57], "some": [0, 2, 5, 6, 8, 12, 25, 27, 28, 29, 30, 31, 36, 37, 38, 40, 47, 55, 57, 58, 59, 60, 61, 64, 66, 67, 68, 69, 70, 72, 75, 77, 78, 79, 80, 81, 82, 84, 86, 87, 89, 91], "definit": [0, 31, 36, 37, 40, 42, 46, 47, 60, 66, 69, 73, 77, 79, 81, 83, 84, 86, 87], "soon": [0, 40, 61], "like": [0, 3, 5, 8, 9, 27, 28, 31, 36, 37, 40, 42, 44, 47, 48, 54, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 73, 77, 78, 79, 80, 81, 83, 84, 87, 89, 90], "likelihood": [0, 2, 3, 5, 6, 12, 18, 19, 23, 33, 35, 38, 40, 41, 43, 44, 45, 47, 48, 57, 59, 60, 65, 66, 67, 69, 70, 74, 75, 77, 79, 80, 82, 83, 85, 87, 90], "function": [0, 3, 8, 9, 28, 30, 31, 33, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 52, 55, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 78, 80, 82, 83, 84, 86, 89, 90, 91], "last": [0, 6, 12, 18, 30, 31, 36, 53, 57, 58, 65, 67, 75, 82, 83, 88, 90], "term": [0, 6, 9, 12, 19, 28, 29, 30, 31, 36, 37, 38, 40, 42, 46, 47, 53, 57, 58, 59, 64, 67, 69, 79, 81, 87, 88, 89, 90, 91], "rather": [0, 36, 38, 42, 47, 57, 58, 64, 67, 70, 72, 81, 82, 83, 87], "just": [0, 6, 8, 28, 32, 36, 37, 38, 40, 42, 43, 44, 46, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 74, 80, 81, 82, 83, 84, 86, 87, 89], "yourself": [0, 39, 42, 44, 46, 50, 78, 80], "when": [0, 2, 5, 9, 15, 19, 23, 24, 25, 27, 30, 31, 37, 38, 39, 40, 42, 43, 44, 48, 52, 54, 55, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 77, 79, 80, 81, 83, 84, 86, 87, 89, 90], "thing": [0, 28, 31, 37, 38, 42, 55, 57, 58, 61, 63, 81, 84], "later": [0, 29, 40, 42, 43, 54, 55, 61, 64, 67], "suspect": [0, 40, 73, 82, 84], "see": [0, 2, 5, 6, 27, 30, 35, 38, 40, 42, 44, 46, 47, 48, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 70, 72, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "close": [0, 8, 15, 38, 40, 42, 46, 47, 48, 60, 65, 66, 68, 78, 79, 80, 81, 82, 84, 87, 90], "match": [0, 37, 39, 40, 42, 44, 64, 66, 70, 78, 80, 90], "That": [0, 2, 6, 9, 27, 28, 31, 32, 36, 37, 38, 40, 42, 44, 46, 57, 59, 64, 66, 67, 68, 69, 72, 77, 78, 79, 80, 81, 82, 87, 89, 90], "said": [0, 31, 40, 44, 52, 53, 57, 58, 64, 73], "most": [0, 2, 6, 27, 28, 30, 38, 40, 42, 43, 46, 47, 48, 53, 54, 55, 57, 58, 61, 63, 64, 66, 67, 69, 72, 73, 75, 78, 80, 81, 82, 87, 89, 90], "take": [0, 2, 5, 6, 8, 17, 25, 27, 28, 29, 30, 31, 37, 38, 40, 42, 46, 48, 52, 53, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 72, 73, 78, 80, 81, 84, 87, 90], "approach": [0, 5, 6, 17, 25, 29, 30, 31, 37, 38, 40, 42, 44, 45, 46, 52, 53, 59, 60, 63, 65, 66, 67, 68, 72, 77, 79, 80, 81, 82, 87, 89, 91], "develop": [0, 8, 9, 14, 17, 40, 64, 87], "cours": [0, 2, 6, 27, 28, 29, 31, 36, 37, 38, 40, 42, 47, 58, 59, 64, 67, 69, 73, 74, 80, 81, 84, 87, 92], "make": [0, 3, 6, 8, 12, 18, 27, 28, 30, 31, 36, 37, 40, 42, 43, 44, 46, 47, 48, 55, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89], "mistak": 0, "ok": [0, 60, 65, 72, 78, 79, 81, 87], "go": [0, 8, 17, 27, 29, 31, 33, 38, 40, 42, 43, 47, 53, 54, 58, 59, 61, 63, 64, 65, 66, 67, 69, 72, 73, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89], "grade": [0, 9, 17], "detail": [0, 2, 6, 12, 17, 44, 46, 50, 54, 59, 61, 67, 69, 72, 81, 83, 87, 89], "implement": [0, 17, 28, 30, 42, 43, 44, 46, 47, 48, 52, 53, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 76, 80, 81, 82, 83, 84, 86, 87, 90, 92], "our": [0, 2, 5, 9, 12, 27, 28, 30, 31, 32, 36, 37, 38, 39, 40, 42, 44, 46, 48, 52, 53, 55, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 77, 78, 79, 81, 82, 83, 84, 86, 87, 89, 90, 91], "get": [0, 6, 8, 9, 14, 27, 28, 29, 31, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 61, 64, 65, 66, 67, 68, 69, 72, 77, 78, 79, 80, 81, 83, 84, 86, 87, 89], "defin": [0, 5, 6, 31, 33, 36, 37, 38, 40, 42, 46, 47, 48, 52, 53, 57, 58, 60, 63, 64, 66, 69, 74, 75, 77, 78, 79, 81, 82, 83, 84, 87, 89, 90], "probabl": [0, 2, 6, 8, 9, 17, 20, 27, 28, 33, 35, 37, 38, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 72, 73, 75, 77, 79, 80, 81, 82, 83, 87, 90, 92], "distribut": [0, 2, 3, 5, 6, 8, 9, 11, 12, 17, 18, 19, 20, 22, 23, 31, 32, 34, 35, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 64, 67, 68, 69, 70, 72, 74, 75, 77, 78, 79, 80, 82, 83, 84, 86, 87, 89, 90, 91, 92], "describ": [0, 6, 12, 23, 24, 25, 26, 31, 32, 33, 36, 37, 38, 39, 40, 44, 46, 47, 55, 57, 58, 63, 65, 66, 69, 72, 74, 77, 79, 81, 82, 83, 87, 89, 90], "b": [0, 2, 3, 5, 6, 8, 9, 11, 12, 20, 31, 36, 40, 44, 46, 47, 57, 58, 59, 64, 67, 69, 72, 79, 80], "sai": [0, 2, 5, 6, 9, 18, 19, 27, 31, 32, 36, 37, 38, 40, 42, 43, 53, 54, 55, 61, 64, 65, 67, 69, 77, 79, 81, 84, 86, 89], "40": [0, 16, 42, 43, 48, 57, 59, 64, 75, 78, 84, 87, 90], "would": [0, 6, 8, 27, 33, 37, 39, 40, 42, 43, 46, 47, 48, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 72, 73, 75, 79, 80, 81, 82, 84, 86, 87, 90], "out": [0, 6, 8, 11, 12, 15, 20, 21, 27, 28, 31, 37, 38, 40, 42, 43, 44, 46, 48, 50, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 67, 70, 72, 73, 74, 77, 78, 79, 80, 82, 83, 84, 86, 87, 89], "respons": [0, 9, 17, 80, 90], "part": [0, 6, 9, 11, 27, 34, 36, 39, 40, 42, 47, 48, 54, 58, 59, 65, 81, 83, 89, 90], "unfortun": [0, 43, 52, 87], "know": [0, 14, 31, 32, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 54, 55, 59, 60, 63, 64, 66, 68, 69, 72, 79, 81, 83, 89, 90], "paramet": [0, 2, 3, 5, 6, 8, 12, 14, 15, 17, 19, 28, 30, 31, 32, 33, 35, 36, 38, 40, 41, 43, 44, 52, 53, 54, 55, 56, 58, 59, 60, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 78, 79, 80, 82, 83, 84, 86, 87, 90, 92], "valu": [0, 5, 6, 8, 31, 32, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 75, 77, 78, 79, 80, 82, 83, 84, 86, 87, 90], "chose": [0, 39, 40, 43, 48, 65, 73, 82, 84], "In": [0, 2, 5, 6, 8, 9, 11, 12, 14, 15, 17, 27, 28, 29, 30, 31, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 53, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "fact": [0, 28, 31, 38, 40, 42, 43, 44, 46, 47, 57, 64, 67, 68, 69, 80, 84, 87], "ahead": [0, 32, 58, 66, 67, 69, 80, 86, 89, 92], "write": [0, 6, 10, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 30, 31, 33, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 53, 55, 58, 59, 64, 66, 69, 77, 78, 81, 83, 84, 87, 89, 91], "down": [0, 6, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 33, 37, 38, 40, 42, 43, 44, 47, 48, 55, 64, 66, 68, 69, 78, 81], "context": [0, 5, 24, 33, 37, 38, 40, 42, 48, 57, 64, 67, 81], "full": [0, 12, 26, 27, 28, 38, 46, 47, 48, 63, 66, 82, 87, 89, 90], "specif": [0, 6, 28, 31, 37, 42, 47, 52, 58, 61, 64, 67, 69, 72, 73, 77, 78, 79, 81, 82, 83, 84, 86, 87, 89, 90], "c": [0, 2, 3, 5, 6, 9, 11, 12, 15, 27, 31, 37, 39, 40, 58, 59, 66, 67, 77, 81, 87], "To": [0, 2, 6, 8, 17, 27, 28, 30, 31, 33, 35, 37, 40, 42, 43, 46, 47, 48, 50, 52, 53, 55, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 72, 75, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "one": [0, 2, 6, 9, 12, 14, 27, 28, 30, 31, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 57, 58, 59, 60, 63, 64, 65, 66, 67, 72, 73, 77, 79, 80, 81, 84, 86, 87, 89, 90], "follow": [0, 2, 6, 15, 18, 27, 28, 29, 30, 31, 33, 40, 42, 43, 48, 52, 55, 57, 58, 59, 60, 61, 64, 65, 66, 67, 70, 78, 79, 80, 81, 82, 83, 84, 86, 89, 90], "construct": [0, 18, 31, 38, 42, 43, 46, 57, 59, 61, 64, 65, 78, 79, 80, 81, 82, 83, 84, 89, 90], "those": [0, 27, 28, 33, 37, 40, 42, 43, 54, 55, 58, 59, 64, 65, 68, 69, 78, 79, 80, 81, 82, 86, 87, 90], "parametr": [0, 37, 40, 44, 57, 63, 64, 67, 68, 69, 73, 80, 81, 82, 84, 87], "can": [0, 3, 6, 8, 9, 12, 14, 15, 22, 23, 24, 27, 28, 29, 30, 31, 33, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91], "mani": [0, 2, 9, 27, 28, 30, 35, 37, 39, 40, 44, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 63, 64, 66, 67, 68, 75, 78, 81, 82, 84, 87, 89, 91], "plot": [0, 2, 3, 6, 8, 9, 11, 17, 21, 28, 30, 38, 40, 43, 46, 47, 48, 49, 52, 55, 58, 60, 63, 64, 65, 67, 68, 69, 70, 72, 75, 78, 80, 82, 83, 84, 86, 87, 90, 92], "them": [0, 6, 17, 31, 40, 42, 44, 52, 53, 54, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 69, 70, 75, 78, 79, 81, 82, 83, 89, 91], "should": [0, 3, 5, 6, 8, 9, 27, 28, 30, 31, 36, 37, 39, 40, 42, 43, 44, 46, 48, 50, 52, 57, 58, 59, 64, 65, 66, 67, 68, 69, 70, 72, 78, 79, 80, 81, 82, 84, 87, 89], "carefulli": [0, 2, 12, 31, 36, 60, 64, 72, 78, 82, 89], "best": [0, 5, 6, 21, 27, 28, 40, 44, 60, 63, 65, 69, 70, 72, 81, 87, 89, 91], "clear": [0, 31, 43, 44, 47, 55, 59, 66, 70, 81, 83, 89, 90, 91], "come": [0, 2, 6, 8, 9, 12, 14, 27, 37, 38, 40, 42, 44, 48, 52, 55, 57, 58, 59, 60, 64, 66, 68, 72, 73, 74, 78, 79, 80, 81, 82], "doe": [0, 2, 3, 8, 20, 21, 25, 27, 28, 31, 36, 37, 39, 40, 42, 46, 48, 53, 57, 58, 59, 63, 64, 67, 68, 69, 72, 78, 80, 81, 82, 84, 86, 87, 89], "jibe": 0, "If": [0, 6, 8, 15, 17, 21, 22, 24, 27, 28, 30, 31, 36, 37, 38, 40, 42, 43, 44, 47, 48, 52, 53, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 73, 78, 79, 80, 81, 83, 84, 87, 89, 90], "have": [0, 2, 5, 6, 8, 9, 12, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91], "ani": [0, 5, 6, 9, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 31, 37, 38, 40, 42, 44, 46, 47, 48, 52, 53, 55, 57, 58, 59, 63, 64, 66, 68, 69, 73, 77, 78, 79, 80, 81, 86, 87, 89, 90], "idea": [0, 6, 20, 26, 31, 39, 40, 44, 51, 57, 59, 63, 64, 67, 69, 70, 72, 79, 81, 90], "why": [0, 2, 3, 6, 18, 19, 20, 21, 22, 23, 24, 36, 42, 51, 59, 61, 72, 78, 80, 87, 89], "d": [0, 3, 5, 6, 27, 30, 36, 37, 38, 40, 42, 43, 46, 47, 48, 52, 53, 55, 60, 61, 64, 65, 68, 69, 70, 72, 79, 81, 83, 87], "until": [0, 12, 79, 90], "through": [0, 15, 17, 27, 28, 29, 37, 40, 44, 47, 48, 55, 59, 61, 69, 78, 80, 81, 82, 83, 89], "complet": [0, 15, 17, 27, 30, 37, 42, 43, 44, 46, 48, 55, 58, 60, 64, 67, 73, 78, 79, 80, 81, 82, 86, 87, 89, 90], "access": [0, 6, 27, 38, 52, 57, 58, 59, 63, 67, 89], "here": [0, 3, 6, 8, 9, 12, 14, 15, 27, 31, 36, 37, 38, 40, 42, 46, 48, 52, 53, 54, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 72, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87], "extract": [0, 46, 48, 58, 64, 82, 83, 87], "made": [0, 5, 22, 27, 42, 57, 64, 66, 89, 91], "nicrophoru": 0, "orbicolli": 0, "locat": [0, 2, 8, 22, 27, 37, 40, 44, 46, 58, 60, 66, 68, 75, 78, 82, 89, 90], "10": [0, 3, 8, 11, 17, 28, 30, 37, 40, 42, 43, 44, 46, 47, 48, 52, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90, 92], "0": [0, 6, 8, 9, 17, 27, 28, 30, 40, 42, 43, 44, 46, 47, 48, 49, 52, 53, 54, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 86, 87, 90, 92], "fall": [0, 63, 80, 81], "within": [0, 2, 27, 40, 54, 57, 59, 60, 64, 65, 67, 69, 80, 89], "homework": [1, 4, 7, 10, 13, 16, 27, 28, 38, 40, 66, 77], "first": [1, 2, 3, 6, 8, 11, 12, 27, 28, 31, 32, 36, 37, 38, 40, 42, 43, 44, 46, 48, 52, 53, 54, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89], "attempt": [1, 6, 18, 40, 63, 68, 69, 87, 89], "bayesian": [1, 5, 12, 17, 33, 39, 40, 42, 43, 45, 46, 52, 54, 55, 57, 58, 63, 64, 67, 69, 79, 80, 91, 92], "70": [1, 10, 63, 65, 67, 70, 78, 87], "pt": [1, 4, 7, 10, 13, 16], "import": [2, 3, 6, 8, 20, 21, 24, 28, 30, 31, 36, 37, 39, 42, 43, 44, 46, 47, 48, 49, 52, 53, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 89, 90], "numpi": [2, 8, 28, 30, 42, 43, 44, 46, 47, 48, 49, 52, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 82, 83, 84, 86, 87, 90], "np": [2, 8, 28, 30, 42, 43, 44, 46, 47, 48, 49, 52, 57, 58, 59, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "continu": [2, 8, 31, 38, 40, 43, 47, 48, 52, 53, 55, 59, 61, 66, 69, 72, 79, 80, 81, 87], "choos": [2, 27, 37, 38, 41, 42, 43, 44, 46, 48, 52, 54, 55, 57, 59, 60, 63, 64, 65, 68, 69, 76, 77, 81, 82, 83, 84, 89], "gener": [2, 5, 6, 8, 11, 12, 14, 15, 17, 18, 21, 28, 31, 33, 37, 38, 39, 40, 42, 43, 46, 47, 48, 51, 54, 55, 58, 59, 61, 63, 65, 66, 67, 68, 69, 70, 72, 76, 77, 79, 81, 82, 83, 86, 87, 89, 90], "model": [2, 3, 5, 6, 12, 14, 15, 17, 18, 20, 21, 24, 25, 28, 30, 31, 33, 34, 36, 39, 40, 44, 45, 47, 52, 55, 58, 63, 66, 73, 79, 81, 82, 83, 86, 89, 91, 92], "nonetheless": [2, 28, 31, 40, 46, 57, 64, 66, 67, 80, 81, 86, 87], "estim": [2, 5, 9, 12, 14, 17, 19, 28, 30, 31, 33, 38, 40, 41, 42, 44, 52, 53, 56, 60, 61, 64, 66, 67, 72, 75, 77, 78, 79, 80, 82, 83, 87, 90, 92], "where": [2, 5, 6, 8, 9, 14, 15, 27, 28, 31, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 52, 54, 55, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 78, 79, 81, 82, 83, 84, 86, 87, 89, 90], "contribut": [2, 37, 59, 72, 87], "exact": [2, 42, 46, 87], "constraint": [2, 64, 82, 90], "less": [2, 22, 36, 40, 42, 52, 57, 64, 67, 72, 79, 80, 90], "explor": [2, 6, 17, 31, 38, 39, 40, 42, 44, 46, 58, 61, 64, 65, 68, 78, 81, 90, 91], "computation": [2, 27, 47, 69, 87], "work": [2, 8, 9, 12, 15, 24, 27, 28, 29, 30, 31, 37, 40, 42, 43, 46, 47, 50, 53, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 86, 89, 92], "david": [2, 87], "prober": 2, "": [2, 3, 9, 11, 14, 15, 17, 21, 27, 28, 29, 30, 34, 35, 37, 38, 40, 42, 43, 46, 47, 50, 52, 53, 54, 57, 58, 59, 60, 61, 63, 65, 67, 68, 69, 70, 72, 74, 75, 77, 78, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91, 92], "lab": [2, 15, 17, 27, 57, 80, 92], "monitor": [2, 12], "activ": [2, 9, 27, 54, 57, 80, 81, 89], "zebrafish": 2, "larva": 2, "genotyp": [2, 15], "effort": [2, 79], "understand": [2, 5, 17, 31, 37, 44, 46, 52, 55, 59, 64, 72, 78, 81, 87, 89], "sleep": 2, "control": [2, 7, 9, 12, 27, 58, 60, 64], "publish": [2, 3, 57, 67, 87], "gandhi": 2, "et": [2, 6, 9, 12, 14, 15, 44, 46, 48, 57, 60, 61, 64, 65, 67, 70, 79, 83, 84, 87, 91], "al": [2, 6, 9, 12, 14, 15, 44, 46, 48, 57, 60, 61, 64, 65, 67, 70, 79, 83, 84, 87, 91], "2015": [2, 9, 59, 75, 77], "minut": [2, 6, 28, 30, 31, 37, 48, 57, 80], "17": [2, 17, 27, 42, 48, 57, 58, 59, 64, 65, 67, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90, 92], "fish": [2, 67, 72, 80, 81, 84], "had": [2, 14, 37, 40, 48, 60, 64, 67, 68, 70, 73, 80, 86, 89], "over": [2, 8, 17, 31, 35, 40, 42, 43, 44, 48, 53, 54, 55, 59, 64, 69, 72, 77, 79, 80, 81, 83, 84, 87, 89, 90], "nine": 2, "hour": [2, 27, 28, 29, 30, 57, 89, 92], "third": [2, 42, 59, 65, 89], "night": 2, "result": [2, 6, 9, 17, 31, 38, 39, 40, 42, 43, 46, 47, 48, 53, 57, 58, 59, 61, 64, 65, 67, 72, 75, 77, 78, 79, 80, 81, 82, 83, 84, 87, 89, 90, 91], "easili": [2, 27, 42, 53, 57, 58, 64, 74, 81, 87], "load": [2, 14, 27, 28, 30, 42, 43, 44, 46, 47, 48, 49, 52, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "directli": [2, 14, 27, 31, 37, 40, 42, 46, 47, 55, 57, 58, 59, 60, 61, 64, 69, 70, 72, 77, 79, 81, 83, 87, 90], "arrai": [2, 3, 8, 37, 42, 43, 46, 48, 57, 58, 59, 60, 61, 63, 64, 65, 67, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "variabl": [2, 5, 8, 31, 35, 37, 40, 42, 43, 46, 53, 57, 58, 59, 60, 61, 64, 65, 67, 68, 72, 74, 77, 78, 79, 80, 81, 82, 83, 86, 87, 90], "call": [2, 8, 27, 30, 31, 35, 36, 37, 38, 40, 42, 52, 54, 57, 58, 59, 61, 64, 68, 69, 70, 77, 78, 81, 84, 86, 87, 90], "y": [2, 5, 6, 28, 30, 31, 33, 35, 36, 37, 38, 40, 42, 43, 46, 47, 48, 49, 52, 55, 57, 58, 59, 60, 61, 63, 64, 66, 69, 72, 74, 78, 79, 80, 81, 82, 83, 84, 86, 87, 90], "200": [2, 42, 43, 44, 46, 47, 48, 49, 57, 59, 60, 61, 63, 64, 65, 70, 80, 81, 87], "190": [2, 44, 87], "249": 2, "232": 2, "319": [2, 57], "104": 2, "93": [2, 72], "233": 2, "287": 2, "49": [2, 42, 59], "311": [2, 57], "225": 2, "243": 2, "113": [2, 27, 87], "133": 2, "179": [2, 87], "normal": [2, 5, 6, 8, 11, 15, 19, 28, 30, 38, 39, 40, 43, 44, 45, 52, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 72, 73, 75, 78, 80, 82, 83, 85, 87], "drawn": [2, 57, 59, 64, 69, 79, 81, 87], "mu": [2, 6, 8, 11, 28, 30, 36, 37, 40, 42, 47, 48, 63, 64, 65, 66, 68, 70, 81, 87, 90], "scale": [2, 37, 40, 42, 46, 47, 48, 49, 57, 58, 60, 61, 64, 66, 69, 70, 72, 78, 80, 82, 83, 84, 86, 90], "sigma": [2, 5, 8, 11, 28, 30, 31, 36, 37, 40, 42, 43, 46, 47, 48, 60, 61, 63, 64, 65, 66, 68, 70, 78, 81, 82, 83, 84, 86, 87, 90], "begin": [2, 5, 6, 8, 11, 15, 27, 31, 32, 33, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 90], "align": [2, 5, 6, 8, 11, 15, 31, 32, 33, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 90], "y_i": [2, 5, 36, 37, 46, 69, 72, 81, 84, 90], "mid": [2, 8, 9, 31, 32, 33, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 52, 53, 55, 57, 58, 59, 60, 61, 64, 66, 68, 69, 72, 73, 74, 77, 79, 81, 82, 83, 84, 86, 87, 90], "sim": [2, 5, 6, 37, 40, 42, 43, 44, 46, 48, 57, 59, 60, 61, 64, 65, 66, 67, 68, 70, 73, 75, 77, 78, 80, 81, 82, 83, 84, 86, 87, 90], "text": [2, 6, 30, 31, 36, 37, 40, 42, 43, 44, 46, 48, 54, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 77, 78, 80, 81, 82, 83, 84, 86, 87, 89, 90], "norm": [2, 5, 37, 40, 42, 46, 47, 48, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 70, 78, 80, 81, 83, 84, 87, 90], "foral": [2, 5, 6, 37, 42, 43, 46, 48, 57, 59, 60, 61, 64, 65, 67, 70, 73, 75, 80, 81, 83, 84, 87], "end": [2, 5, 6, 8, 11, 14, 15, 30, 31, 32, 33, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "task": [2, 14, 31, 40, 41, 46, 65, 70, 89], "posterior": [2, 3, 8, 9, 11, 12, 14, 17, 18, 19, 21, 23, 25, 28, 30, 32, 33, 35, 37, 40, 43, 48, 52, 53, 55, 58, 59, 60, 62, 64, 66, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 83, 84, 87, 90, 92], "g": [2, 9, 14, 27, 28, 31, 32, 33, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 52, 55, 57, 58, 59, 64, 66, 69, 73, 74, 75, 77, 79, 80, 81, 83, 87, 89, 90], "improp": [2, 40, 42, 43], "uninform": 2, "becaus": [2, 6, 8, 27, 28, 29, 31, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 48, 53, 57, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "veri": [2, 6, 31, 36, 37, 38, 40, 42, 44, 46, 47, 48, 53, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 78, 80, 81, 82, 83, 84, 86, 87], "broad": [2, 37, 38, 40, 42, 46, 64, 69, 80, 81, 89, 90, 92], "infinit": [2, 40, 57, 81], "even": [2, 6, 31, 37, 38, 40, 42, 58, 59, 63, 64, 67, 69, 78, 80, 81, 86, 89], "normaliz": [2, 40], "constant": [2, 5, 15, 37, 40, 42, 43, 46, 64, 73, 81, 82, 84, 86, 87], "1em": [2, 37, 40, 42, 43, 44, 46, 48, 53, 57, 59, 60, 61, 64, 65, 67, 68, 70, 72, 73, 75, 77, 78, 80, 81, 82, 83, 84, 86, 87], "Of": [2, 6, 37, 44, 73, 81], "both": [2, 8, 31, 36, 42, 48, 57, 58, 64, 65, 67, 69, 70, 72, 80, 81, 83, 89], "assum": [2, 3, 5, 6, 9, 15, 27, 30, 37, 40, 42, 43, 44, 46, 47, 48, 57, 58, 59, 60, 64, 66, 69, 72, 73, 74, 77, 78, 81, 83, 87, 90], "nonneg": [2, 40], "again": [2, 8, 28, 30, 31, 36, 37, 38, 42, 43, 46, 47, 48, 53, 55, 57, 59, 61, 64, 65, 67, 69, 72, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 90], "150": [2, 57, 59, 61, 87], "min": [2, 40, 49, 53, 64, 81, 82, 83, 84, 86], "effect": [2, 9, 14, 22, 28, 30, 31, 38, 40, 46, 52, 57, 61, 66, 68, 70, 72, 73, 75, 77, 78, 80, 81, 83, 84, 86, 87, 89], "oppos": [2, 8, 43, 64, 89], "uniform": [2, 5, 42, 43, 44, 49, 52, 59, 60, 75, 79, 90], "20": [2, 7, 8, 11, 17, 27, 28, 30, 37, 42, 46, 47, 48, 57, 58, 59, 64, 65, 67, 70, 72, 75, 80, 81, 82, 84, 86, 87, 89, 90, 92], "comment": [2, 6, 26, 58, 81, 89], "download": [3, 6, 12, 14, 15, 27, 28, 42, 43, 46, 48, 57, 59, 60, 61, 64, 65, 67, 70, 72, 80, 81, 82, 83, 84, 86], "wa": [3, 6, 8, 9, 12, 14, 31, 40, 42, 44, 46, 48, 52, 53, 57, 58, 61, 64, 66, 67, 69, 78, 80, 81, 84, 86, 87], "motiv": [3, 36, 44], "discuss": [3, 5, 6, 12, 17, 28, 30, 31, 36, 38, 40, 42, 47, 48, 52, 54, 55, 57, 59, 61, 64, 65, 67, 72, 74, 79, 81, 82, 89, 90, 91], "section": [3, 28, 29, 30, 31, 36, 47, 58, 67, 68, 81, 89, 90], "holm": 3, "huber": 3, "book": [3, 15, 31, 36, 44, 54, 90, 91], "show": [3, 5, 27, 28, 30, 40, 42, 43, 44, 46, 47, 48, 49, 53, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 89, 90], "gamma": [3, 12, 15, 43, 44, 47, 48, 49, 52, 59, 60, 61, 64, 65, 66, 70, 73, 80, 81, 82, 83, 84, 87, 90], "updat": [3, 8, 27, 32, 38, 40, 44, 46, 59, 64, 66, 78, 79, 80, 83, 87, 90], "welcom": 3, "wikipedia": [3, 44, 67, 90], "tabl": [3, 44, 58, 64], "check": [3, 6, 9, 11, 12, 14, 17, 21, 23, 24, 25, 27, 28, 44, 50, 57, 58, 59, 60, 68, 70, 72, 75, 79, 81, 83, 84, 87, 89, 92], "answer": [3, 22, 58, 65, 66, 67, 69, 89], "actual": [3, 38, 40, 42, 44, 47, 55, 57, 64, 65, 69, 72, 75, 77, 79, 80, 81, 83, 84, 86], "proof": [3, 36, 83], "sequenc": [3, 6, 14], "chromosom": 3, "dna": [3, 40, 57], "e": [3, 6, 14, 15, 27, 28, 30, 31, 36, 38, 40, 42, 43, 47, 52, 57, 59, 64, 66, 68, 69, 70, 72, 73, 75, 77, 78, 80, 81, 83, 84, 86, 87, 89, 90], "coli": [3, 40, 78, 83], "strain": [3, 9, 77], "atcc": 3, "baa": 3, "196": [3, 87], "fasta": 3, "format": [3, 24, 30, 46, 48, 58, 64, 75, 82, 83, 90], "resist": 3, "multipl": [3, 8, 29, 47, 58, 67, 69, 86, 87, 90], "drug": 3, "studi": [3, 9, 15, 17, 31, 38, 45, 57, 59, 60, 64, 77, 78, 81, 84, 87, 91], "antibiot": 3, "paper": [3, 6, 15, 37, 38, 44, 54, 57, 58, 59, 67, 68, 69, 72, 79, 80, 81, 83, 87], "read": [3, 6, 17, 28, 37, 39, 46, 51, 52, 54, 58, 59, 66, 67, 69, 72, 77, 78, 79, 80, 87, 92], "singl": [3, 6, 12, 32, 35, 36, 37, 39, 40, 44, 47, 57, 59, 61, 63, 65, 66, 67, 69, 72, 77, 78, 83, 84, 89, 90], "string": [3, 58, 78], "below": [3, 8, 9, 15, 17, 28, 30, 31, 36, 44, 48, 52, 58, 59, 60, 61, 63, 64, 65, 67, 68, 72, 78, 79, 81, 83, 86, 89, 90], "1": [3, 4, 6, 7, 9, 10, 12, 13, 15, 16, 17, 28, 30, 31, 35, 36, 37, 38, 40, 42, 43, 44, 46, 47, 48, 49, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 90, 92], "def": [3, 8, 42, 43, 46, 48, 57, 63, 81, 82, 83, 84, 86, 87, 90], "read_fasta_single_record": 3, "filenam": [3, 58, 89], "file": [3, 6, 12, 27, 58, 64, 83, 87, 89], "contain": [3, 8, 31, 36, 40, 43, 44, 47, 55, 57, 58, 59, 61, 63, 64, 66, 72, 73, 77, 78, 81, 84, 86, 87, 89, 91], "line": [3, 21, 27, 30, 37, 40, 42, 43, 44, 46, 47, 49, 57, 58, 59, 60, 61, 63, 64, 80, 81, 82, 83, 84, 86, 90], "descriptor": 3, "all": [3, 5, 6, 17, 27, 28, 31, 35, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 53, 55, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89], "subsequ": [3, 38, 66, 81, 86], "open": [3, 14, 15, 27, 28, 30, 87], "r": [3, 30, 31, 53, 54, 58, 68, 78, 87, 90], "f": [3, 6, 15, 28, 30, 32, 33, 35, 36, 37, 38, 40, 42, 44, 46, 47, 49, 52, 57, 59, 64, 66, 69, 72, 73, 74, 75, 77, 78, 79, 81, 82, 83, 84, 86, 87, 90], "readlin": 3, "rstrip": 3, "strip": [3, 78, 80, 84, 87, 89], "whitespac": 3, "seq": [3, 7], "while": [3, 9, 27, 40, 42, 43, 44, 46, 53, 54, 57, 58, 59, 61, 64, 67, 69, 79, 81, 82, 84, 87, 89], "return": [3, 8, 17, 36, 42, 43, 46, 47, 48, 52, 54, 57, 58, 60, 61, 64, 65, 70, 72, 81, 82, 83, 84, 86, 87, 90], "find": [3, 5, 6, 18, 19, 27, 28, 35, 37, 38, 39, 40, 42, 43, 46, 47, 48, 59, 63, 64, 66, 69, 72, 79, 81, 82, 83, 86, 87, 89, 90, 91], "index": [3, 6, 55, 57, 58, 59, 64, 65, 67, 72, 78, 84, 87, 90], "shine": [3, 9], "delgarno": 3, "motif": 3, "initi": [3, 27, 43, 44, 46, 48, 64, 66, 72, 82, 83, 90], "protein": [3, 64], "synthesi": 3, "aggaggt": 3, "recognit": 3, "recognition_sites_with_r": 3, "recog_seq": 3, "indic": [3, 18, 46, 59, 61, 64, 66, 67, 68, 70, 72, 73, 75, 78, 79, 80, 81, 83, 84, 86, 89, 90], "findit": 3, "append": [3, 57, 63, 64, 84], "start": [3, 8, 9, 12, 27, 30, 31, 38, 40, 42, 43, 46, 48, 54, 57, 58, 59, 60, 61, 63, 64, 67, 68, 72, 78, 79, 81, 82, 83, 84, 90], "store": [3, 27, 42, 43, 58, 63, 64, 65, 67, 72, 82], "number": [3, 6, 8, 9, 11, 14, 22, 27, 28, 30, 31, 36, 37, 38, 40, 42, 44, 51, 55, 57, 58, 59, 61, 63, 64, 65, 67, 69, 72, 75, 77, 78, 79, 80, 84, 86, 87, 89, 90], "base": [3, 9, 12, 17, 25, 27, 28, 31, 37, 38, 40, 57, 58, 59, 63, 64, 66, 67, 69, 70, 81, 82, 87, 90, 91, 92], "between": [3, 5, 9, 12, 15, 31, 36, 38, 39, 40, 43, 48, 54, 57, 59, 60, 61, 64, 66, 67, 69, 70, 72, 73, 78, 79, 80, 81, 84, 87, 90], "occurr": [3, 31], "distanc": [3, 40, 66, 87], "explain": [3, 20, 22, 24, 83, 89], "reason": [3, 6, 8, 17, 31, 37, 40, 42, 46, 47, 57, 59, 64, 65, 66, 67, 68, 69, 70, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 91], "exploratori": [3, 6], "ecdf": [3, 9, 55, 58, 59, 60, 61, 64, 65, 67, 70, 75, 87, 90], "inter": 3, "comput": [3, 6, 8, 9, 14, 17, 18, 19, 23, 27, 31, 35, 36, 37, 38, 40, 52, 53, 54, 55, 69, 74, 77, 78, 79, 90], "rate": [3, 8, 12, 36, 53, 64, 81, 82, 83, 86], "invers": [3, 15, 40, 46, 47, 52, 57, 59, 66, 81, 82, 84], "characterist": [3, 46, 64, 83], "overwhelm": [4, 75], "45": [4, 43, 44, 59, 63, 84], "exponenti": [4, 12, 36, 39, 42, 43, 47, 48, 52, 63, 66, 69, 81, 82, 84, 86], "conjug": [4, 18, 81], "55": [4, 9, 57, 78, 84], "heard": [5, 31], "fit": [5, 21, 27, 31, 60, 64, 77, 81, 84, 90, 91], "variat": [5, 17, 26, 37, 38, 42, 43, 45, 58, 61, 64, 77, 81, 84, 90, 92], "covari": [5, 8, 11, 17, 37, 45, 46, 47, 61, 66, 82, 84, 86, 87, 92], "minim": [5, 42, 46, 47, 48, 58, 64, 82, 83, 87, 89, 90], "sum": [5, 9, 35, 36, 38, 42, 43, 46, 48, 52, 53, 59, 63, 64, 66, 67, 69, 75, 87, 90], "residu": 5, "pars": [5, 80, 81, 91], "mean": [5, 8, 11, 12, 19, 20, 21, 25, 26, 27, 28, 30, 31, 37, 39, 40, 42, 46, 48, 52, 54, 55, 57, 58, 59, 63, 64, 66, 67, 68, 69, 72, 73, 77, 78, 79, 80, 82, 83, 84, 86, 87, 89, 90], "x": [5, 8, 31, 33, 36, 42, 43, 46, 47, 48, 49, 57, 58, 59, 60, 61, 63, 64, 68, 80, 81, 82, 83, 84, 86, 87, 90], "independ": [5, 8, 22, 26, 37, 39, 40, 42, 43, 48, 52, 59, 60, 66, 67, 68, 69, 70, 72, 73, 75, 78, 81, 87], "known": [5, 8, 31, 37, 38, 39, 40, 43, 44, 47, 52, 54, 63, 64, 66, 69, 72, 79, 81, 90], "essenti": [5, 23, 37, 58, 67, 78, 89], "exactli": [5, 31, 37, 44, 59, 64, 66, 72, 81, 82, 83, 87, 90], "could": [5, 14, 29, 36, 37, 40, 42, 43, 46, 48, 53, 55, 57, 59, 60, 63, 64, 65, 66, 68, 69, 73, 77, 78, 80, 81, 84, 86, 87, 90], "someth": [5, 8, 27, 31, 42, 44, 64, 69, 77, 79, 81, 89, 90], "depend": [5, 28, 37, 39, 42, 43, 44, 47, 52, 53, 57, 59, 65, 70, 74, 77, 80, 81, 87, 90], "ha": [5, 6, 8, 9, 15, 19, 27, 30, 31, 36, 37, 38, 39, 40, 42, 43, 44, 46, 47, 52, 53, 54, 57, 58, 59, 61, 64, 66, 67, 68, 69, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 86, 87, 89, 90, 91], "stochast": [5, 64, 81, 87], "nois": [5, 31, 37, 83], "deriv": [5, 31, 36, 39, 40, 42, 46, 47, 52, 64, 66, 69, 79, 81, 85, 87, 90], "theoret": [5, 6, 15, 37, 38, 43, 44, 48, 57, 59, 64, 66, 80, 81, 82, 89], "relat": [5, 6, 12, 17, 25, 36, 37, 40, 46, 47, 52, 64, 68, 69, 79, 81, 89], "written": [5, 8, 30, 31, 33, 38, 40, 42, 43, 57, 58, 59, 64, 69, 73, 77, 84, 89, 90], "f_y": [5, 36], "phi": [5, 6, 40, 42, 43, 46, 48, 60, 61, 64, 65, 70, 73, 74, 75, 77, 84, 87], "wish": [5, 36, 37, 38, 42, 43, 52, 57, 58, 59, 60, 63, 64, 66, 68, 69, 78, 79, 81, 87, 89, 90], "determin": [5, 6, 36, 40, 44, 59, 64, 66, 67, 69, 72, 75, 78, 81, 82, 90], "infer": [5, 26, 27, 29, 33, 38, 40, 42, 43, 46, 47, 58, 59, 64, 67, 69, 75, 79, 80, 82, 83, 84, 91, 92], "x_1": [5, 36, 66, 83], "y_1": [5, 32, 36, 37, 46, 69, 72, 90], "x_2": [5, 36, 66, 83], "y_2": [5, 32, 36, 37, 46, 69, 72], "ldot": [5, 36, 37, 52, 55, 66, 69, 72, 73, 77, 78, 81, 82], "x_n": 5, "y_n": [5, 37, 69, 72, 90], "mathrm": [5, 15, 36, 37, 38, 40, 42, 43, 47, 52, 53, 55, 67, 68, 69, 72, 79, 81, 82, 83, 84, 86, 90], "x_i": [5, 42, 66, 81, 83, 90], "sigma_i": [5, 37, 64, 65, 70, 81, 87], "A": [5, 6, 8, 9, 15, 17, 31, 33, 36, 37, 39, 40, 45, 47, 52, 58, 59, 61, 63, 65, 67, 69, 73, 80, 81, 83, 89, 91], "r_i": 5, "frac": [5, 15, 31, 32, 33, 35, 36, 37, 38, 40, 42, 43, 44, 47, 48, 53, 54, 55, 59, 60, 61, 64, 65, 67, 68, 69, 70, 72, 73, 74, 77, 79, 81, 83, 87, 90], "sum_": [5, 35, 37, 42, 43, 55, 69, 72, 77, 87, 90], "n": [5, 9, 14, 36, 37, 42, 43, 44, 52, 55, 57, 59, 60, 61, 64, 65, 67, 69, 70, 72, 73, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 90], "2": [5, 7, 8, 10, 11, 13, 16, 17, 28, 30, 31, 36, 37, 40, 42, 43, 44, 46, 47, 48, 49, 52, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 89, 90, 92], "equival": [5, 31, 36, 40, 42, 59, 64, 66, 68, 84, 87, 90], "map": [5, 7, 19, 48, 59, 63, 75, 81, 83, 86, 90], "abov": [5, 6, 8, 9, 27, 28, 32, 37, 40, 42, 43, 52, 57, 59, 61, 64, 65, 68, 72, 77, 78, 79, 81, 83, 86, 87, 90], "note": [5, 6, 8, 9, 12, 14, 27, 30, 31, 33, 36, 38, 40, 42, 43, 44, 46, 47, 48, 53, 55, 57, 58, 59, 60, 64, 65, 66, 67, 68, 69, 70, 72, 73, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89], "taken": [5, 8, 27, 38, 52, 55, 58, 67, 68], "homoscedast": [5, 48, 60, 81, 82, 83], "error": [5, 37, 42, 57, 59, 64, 66, 72, 77, 80, 81, 82, 83, 89], "further": [5, 21, 31, 42, 51, 64, 69, 78, 80, 81, 87], "whose": [5, 31, 52], "still": [5, 23, 37, 40, 47, 53, 57, 61, 63, 64, 65, 66, 68, 69, 72, 78, 80, 81, 87], "need": [5, 6, 8, 11, 14, 22, 27, 28, 29, 30, 31, 36, 37, 38, 39, 42, 43, 46, 48, 52, 53, 54, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 77, 78, 80, 81, 82, 83, 84, 86, 87, 89, 90], "consid": [5, 6, 12, 31, 37, 38, 40, 42, 43, 46, 47, 48, 53, 57, 59, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "assumpt": [5, 69, 72, 77], "often": [5, 6, 28, 31, 36, 37, 38, 40, 42, 47, 52, 55, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 77, 80, 81, 83, 89], "done": [5, 9, 27, 31, 37, 38, 46, 57, 58, 59, 61, 64, 69, 72, 77, 78, 81, 84, 86], "issu": [5, 6, 36, 37, 38, 40, 42, 61, 63, 64, 68, 78, 80, 81], "inspir": 6, "valentin": 6, "svensson": 6, "blog": [6, 59, 81, 89], "post": [6, 42, 43, 59, 79, 81, 83, 86, 89], "viewabl": 6, "cell": [6, 12, 14, 15, 28, 37, 40, 48, 57, 59, 60, 64, 67, 72, 78, 80, 81, 83, 84, 89], "rna": [6, 57, 72, 80, 81], "scrna": 6, "technologi": 6, "more": [6, 9, 12, 27, 28, 31, 32, 36, 37, 38, 40, 42, 43, 44, 46, 48, 50, 53, 54, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "common": [6, 31, 40, 61, 69, 73, 81], "It": [6, 8, 27, 28, 30, 31, 36, 37, 39, 40, 42, 43, 44, 46, 47, 48, 52, 53, 55, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 72, 78, 79, 80, 81, 82, 83, 84, 86, 89, 90], "enabl": [6, 8, 12, 28, 44, 47, 57, 58, 60, 61, 64, 65, 67, 82, 84], "research": [6, 28, 31, 37, 38, 40, 48, 63, 89, 91], "count": [6, 59, 66, 67, 72, 81, 84, 90], "mrna": [6, 59, 67, 72, 84], "transcript": [6, 57, 59, 67, 72, 80, 81, 84], "gene": [6, 14, 59, 66, 67, 72, 78, 80, 81, 84], "techniqu": [6, 17, 40, 52, 57, 58, 61, 67, 69, 72, 79, 83, 87], "usual": [6, 22, 28, 31, 42, 48, 58, 60, 64, 66, 67, 69, 72, 75, 79, 81, 82, 83, 84], "individu": [6, 9, 39, 43, 64, 72, 75, 78], "encas": [6, 86], "droplet": [6, 42, 43, 46, 48, 60, 61, 65, 70, 87], "microfluid": [6, 14], "devic": 6, "importantli": [6, 28, 36, 37, 38, 44, 48, 52, 53, 55, 57, 59, 64, 67, 69, 72, 78, 79, 80, 81, 84, 87], "cdna": 6, "barcod": 6, "molecul": [6, 12, 39, 57, 64, 66, 67, 84], "identif": 6, "output": [6, 8, 27, 48, 57, 64, 69, 72, 78, 82, 87], "matrix": [6, 8, 11, 36, 37, 40, 46, 47, 48, 59, 66, 72, 82, 83, 84, 86], "row": [6, 57, 58, 63, 64, 65, 78, 81, 87], "correspond": [6, 27, 31, 36, 57, 59, 78, 81, 83, 84, 87, 90], "column": [6, 8, 57, 58, 59, 61, 63, 64, 65, 67, 78, 80, 87, 90], "entri": [6, 37, 40, 47, 59, 66, 78, 81, 82, 84, 87, 89], "integ": [6, 8, 36, 52, 57, 59, 66], "process": [6, 8, 12, 17, 27, 28, 31, 35, 37, 38, 39, 52, 57, 58, 64, 65, 66, 68, 69, 79, 83, 86, 90], "worth": [6, 39, 81, 83], "analysi": [6, 12, 17, 25, 31, 38, 40, 42, 48, 54, 55, 58, 59, 60, 64, 80, 81, 83, 84, 87, 89, 91], "tool": [6, 17, 30, 31, 46, 48, 69, 89, 90, 91], "kalisto": 6, "fulli": [6, 31, 37, 38, 65, 81, 87], "saw": [6, 36, 38, 59, 61, 80, 83, 87], "smfish": [6, 57, 59, 67], "abund": 6, "neg": [6, 37, 40, 42, 46, 47, 48, 57, 59, 64, 66, 67, 72, 80, 82, 87], "binomi": [6, 40, 57, 59, 67, 72, 75, 77, 80], "under": [6, 27, 31, 40, 42, 43, 47, 59, 64, 65, 67, 75, 77, 79, 89], "bursti": [6, 57, 59, 67, 81, 84], "express": [6, 9, 31, 32, 35, 37, 43, 44, 46, 47, 55, 57, 59, 60, 64, 66, 67, 68, 69, 73, 77, 78, 79, 81, 84, 87, 90], "absenc": [6, 52, 67, 81], "zheng": 6, "inject": [6, 31, 68], "ercc": 6, "extern": [6, 38], "consortium": 6, "spike": 6, "solut": [6, 17, 81, 86, 87, 89, 90], "thu": [6, 31, 32, 36, 40, 44, 46, 53, 60, 64, 66, 68, 69, 72, 77, 78, 80, 81, 82, 84, 87, 89], "confound": [6, 37], "absent": 6, "poisson": [6, 12, 39, 66, 81], "turn": [6, 31, 37, 42, 57, 58, 59, 68, 69, 70, 74, 75, 80, 89], "hi": [6, 40, 44, 50, 54, 61], "link": [6, 36, 61, 84, 91], "caus": [6, 9, 27, 59, 68, 78], "constern": 6, "among": [6, 27, 35, 40, 64, 87, 89], "commun": [6, 17, 28, 57], "explan": [6, 67, 91], "unknown": [6, 38, 64, 69, 81], "captur": [6, 37, 40, 42, 65, 66, 70, 77, 78, 79, 80, 81, 82, 84, 87], "flexibl": [6, 69, 70, 72, 79, 87], "than": [6, 22, 27, 31, 36, 37, 38, 40, 42, 44, 46, 47, 48, 52, 54, 57, 58, 59, 63, 64, 66, 67, 69, 72, 73, 75, 77, 79, 80, 81, 83, 87, 89], "limit": [6, 15, 28, 31, 37, 39, 40, 52, 53, 54, 58, 66, 67, 70, 79, 81, 83], "understood": [6, 38, 64, 69], "formul": [6, 31], "http": [6, 14, 15, 27, 28, 42, 46, 57, 67, 89], "s3": [6, 14, 15, 28, 42, 46, 57, 89], "amazonaw": [6, 14, 15, 28, 42, 46, 57, 89], "com": [6, 14, 15, 27, 28, 42, 46, 57, 89], "bebi103": [6, 8, 14, 15, 27, 28, 30, 42, 43, 46, 47, 48, 57, 58, 59, 60, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 89, 91], "caltech": [6, 9, 14, 15, 17, 27, 28, 29, 42, 46, 57, 89], "edu": [6, 14, 15, 17, 28, 42, 46, 57, 89], "zheng_gemcode_control": 6, "csv": [6, 12, 14, 15, 27, 42, 43, 46, 48, 57, 58, 59, 60, 61, 64, 65, 67, 70, 72, 80, 81, 82, 83, 84, 86, 87, 89], "presum": 6, "raw": 6, "deposit": [6, 58], "short": [6, 68, 83], "archiv": 6, "srp073767": 6, "avail": [6, 27, 28, 40, 42, 57, 58, 63, 64, 65, 67, 70, 80, 86, 89, 91], "figshar": 6, "licens": 6, "cc": 6, "BY": 6, "4": [6, 11, 12, 17, 28, 30, 36, 40, 42, 44, 46, 47, 48, 53, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 92], "addition": [6, 8, 79, 89], "inform": [6, 9, 19, 27, 28, 31, 32, 36, 42, 43, 44, 46, 48, 58, 60, 63, 64, 65, 67, 70, 72, 73, 78, 79, 80, 87, 92], "concentr": [6, 12, 15, 73, 79, 81, 90], "mix": [6, 67, 68, 72, 78, 83, 90], "obtain": [6, 31, 38, 42, 43, 57, 58, 61, 63, 67, 69, 79, 83, 86, 87], "thermo": 6, "fisher": [6, 40], "were": [6, 12, 31, 33, 40, 43, 47, 52, 57, 58, 61, 64, 65, 66, 67, 69, 72, 75, 78, 79, 80, 81, 84, 87], "dilut": 6, "50": [6, 37, 40, 42, 43, 46, 47, 48, 49, 52, 60, 61, 63, 64, 65, 70, 75, 78, 80, 84, 87, 89], "fold": [6, 31, 46], "eas": [6, 38, 40, 81, 87], "although": [6, 69], "strictli": [6, 40, 64, 66, 86], "refer": [6, 27, 31, 37, 40, 47, 58, 59, 60, 63, 67, 69, 81, 83, 87, 89, 90, 91], "obviou": [6, 36, 37, 38, 64, 70, 72, 78, 79], "deviat": [6, 8, 37, 63, 64, 66, 67, 78, 79, 80, 81, 82, 83], "being": [6, 20, 25, 28, 40, 42, 44, 57, 58, 60, 64, 66, 67, 69, 78, 81, 84, 86, 87, 89], "sure": [6, 8, 12, 27, 30, 37, 40, 42, 46, 52, 57, 61, 64, 65, 66, 67, 69, 72, 78, 79, 80, 82, 86, 87, 89], "strang": [6, 44, 55, 64, 81], "specul": 6, "hint": 6, "obvious": [6, 8, 64], "inconsist": [6, 40], "onli": [6, 9, 27, 28, 31, 37, 38, 40, 42, 44, 46, 48, 52, 53, 55, 59, 61, 64, 66, 67, 69, 77, 78, 80, 81, 83, 86, 87, 89, 90], "behavior": [6, 9, 67, 68, 70, 72, 75, 78, 80, 81, 83, 84, 86], "calcul": [6, 27, 29, 31, 37, 38, 40, 43, 44, 46, 48, 57, 58, 63, 64, 66, 67, 69, 70, 79, 80, 81, 85, 86, 87, 89], "quick": [6, 27, 28, 42, 46, 48, 57, 60, 61, 64, 65, 67, 68, 69, 72, 80, 81, 84, 87, 90, 91], "graphic": [6, 12, 17, 21, 23, 47, 52, 64, 68, 78, 79, 89], "verif": [6, 64], "inde": [6, 23, 36, 37, 38, 57, 58, 59, 64, 81, 86], "principl": [6, 17, 25, 40, 64, 66, 69, 80, 81, 92], "wai": [6, 14, 30, 31, 32, 38, 40, 42, 43, 53, 54, 57, 59, 61, 63, 64, 66, 67, 68, 69, 70, 72, 73, 77, 78, 81, 83, 84, 87, 89], "week": [6, 9, 12, 48, 65, 89, 92], "dirti": 6, "credibl": [6, 19, 48, 60, 61, 63, 75, 81, 82, 83, 86], "interv": [6, 19, 40, 44, 48, 52, 58, 59, 60, 61, 63, 66, 74, 75, 79, 80, 81, 82, 83, 86], "local": [6, 19, 28, 30, 38, 43, 46, 47, 81], "notic": [6, 27, 40, 48, 57, 58, 59, 87, 90], "sourc": [6, 27, 42, 43, 46, 48, 60, 61, 64, 80, 81, 82, 84, 87, 89, 90], "commonli": [6, 38, 40, 54, 58, 61, 63, 67, 83, 86], "occur": 6, "typic": [6, 28, 37, 38, 40, 44, 48, 57, 59, 60, 64, 66, 67, 73, 78, 79, 80, 81], "nonzero": [6, 36, 37, 46], "let": [6, 27, 31, 32, 35, 37, 40, 42, 43, 46, 47, 54, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 75, 77, 78, 80, 81, 83, 84, 86, 87, 89, 90], "p": [6, 8, 28, 30, 31, 33, 36, 42, 43, 44, 46, 47, 48, 49, 52, 53, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "case": [6, 17, 27, 35, 36, 37, 38, 39, 40, 42, 43, 45, 47, 48, 52, 53, 55, 57, 58, 59, 60, 63, 64, 65, 66, 67, 69, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 87, 89, 90, 91], "detect": [6, 67], "due": [6, 17, 28, 31, 40, 64, 69, 83, 89], "unspecifi": 6, "includ": [6, 9, 17, 27, 28, 29, 30, 31, 36, 38, 40, 46, 47, 52, 55, 57, 58, 59, 61, 63, 64, 65, 67, 69, 70, 72, 78, 79, 80, 81, 83, 87, 89, 90], "Then": [6, 11, 15, 31, 32, 35, 37, 40, 42, 53, 55, 58, 60, 68, 69, 79, 81], "accord": [6, 30, 43, 47, 54, 59, 60, 61, 67, 77, 83, 84, 90], "version": [6, 27, 28, 30, 42, 43, 44, 46, 47, 48, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "mixtur": [6, 17, 63, 92], "delta_": [6, 9, 81, 83], "0y": 6, "otherwis": [6, 8, 53, 54, 58, 79, 87, 90], "investig": [6, 12, 14, 32, 43, 44, 53, 57, 64, 67, 68, 69, 75, 77], "whether": [6, 9, 14, 67, 80, 82, 84, 89], "rel": [6, 27, 28, 31, 37, 69, 72, 79], "similar": [6, 12, 36, 42, 44, 58, 59, 60, 64, 65, 69, 70, 78, 89], "versu": [6, 12, 42, 46, 61, 64, 65, 70, 78, 80, 81], "fraction": [6, 15, 42, 64, 67], "stand": 6, "technic": [6, 38], "quantifi": [6, 9, 31, 69, 82, 87], "well": [6, 27, 28, 30, 37, 38, 39, 40, 42, 46, 47, 48, 55, 58, 61, 65, 69, 72, 73, 77, 80, 81, 82, 83, 90], "other": [6, 8, 12, 29, 30, 31, 33, 36, 37, 38, 40, 42, 43, 46, 47, 52, 55, 57, 58, 59, 60, 61, 64, 67, 69, 73, 75, 77, 78, 79, 81, 86, 87, 89, 90, 91], "With": [6, 37, 40, 57, 58, 60, 64, 65, 72, 73, 80, 83, 90], "mind": [6, 31, 36, 37, 58, 67, 78, 81, 82], "new": [6, 27, 31, 36, 38, 40, 42, 57, 58, 59, 64, 65, 66, 69, 81, 82, 91], "wherein": 6, "mu_i": [6, 37, 48, 60, 61, 64, 65, 66, 70, 81, 83, 87], "share": [6, 17, 27, 40], "j": [6, 28, 30, 35, 40, 42, 43, 46, 48, 69, 87, 90], "y_": [6, 69, 90], "ij": [6, 37, 40, 47, 81, 83, 90], "negbinom": [6, 57, 59, 67, 80], "trickier": [6, 63, 82], "optim": [6, 8, 17, 19, 38, 42, 43, 53, 57, 58, 72, 84, 85, 86, 87, 90, 92], "solv": [6, 47, 59, 64, 81], "big": [6, 40, 48, 57, 63, 64, 78, 87], "report": [6, 46, 47, 48, 57, 59, 62, 67, 69, 77, 78, 79], "hessian": [6, 40, 46, 47, 48], "sever": [6, 28, 29, 30, 40, 42, 43, 46, 48, 54, 63, 68, 80, 90], "smooth": [6, 42, 65, 69, 72, 81, 83], "curv": [6, 42, 43, 48, 60, 64, 65, 81, 83], "overlai": [6, 46, 49, 65, 68, 82, 84], "light": [6, 9, 12, 37, 38, 40, 64, 66, 77], "least": [7, 31, 43, 46, 47, 67, 80, 81, 87, 89], "squar": [7, 37, 40, 81, 82, 84, 86], "zero": [7, 14, 36, 37, 40, 42, 43, 46, 47, 48, 52, 57, 58, 59, 60, 64, 66, 68, 77, 78, 79, 80, 81, 82, 84, 87, 90], "inflat": 7, "drop": [7, 60, 64, 81], "80": [7, 64, 75, 87], "numba": 8, "emploi": [8, 86, 87], "metropoli": [8, 9, 51], "hast": [8, 9, 51], "algorithm": [8, 46, 51, 52, 54, 58, 67, 69, 81], "handl": [8, 43, 53, 59, 79, 82], "discret": [8, 36, 38, 40, 52, 53, 59, 66, 72, 81], "sinc": [8, 27, 31, 37, 40, 42, 43, 46, 47, 48, 52, 53, 57, 58, 59, 60, 63, 64, 65, 67, 68, 69, 70, 72, 73, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90], "multi": [8, 37, 63, 86, 90], "dimension": [8, 18, 37, 38, 40, 42, 58, 59, 61, 65, 72, 81, 86], "diagon": [8, 37, 46, 47, 59, 80, 81, 82, 84, 86, 87], "word": [8, 20, 23, 26, 31, 38, 52, 57, 60, 64, 69, 77, 79, 81, 90], "target": [8, 52, 53, 59, 67, 68, 72], "organ": [8, 17, 57, 72, 78], "code": [8, 17, 27, 28, 30, 37, 42, 43, 46, 48, 57, 60, 61, 63, 64, 65, 67, 68, 70, 72, 80, 81, 82, 83, 84, 86, 87, 90], "suggest": [8, 40, 54, 59, 69], "step": [8, 22, 27, 30, 31, 38, 42, 46, 48, 52, 53, 54, 58, 61, 64, 65, 67, 68, 69, 74, 78, 79, 81, 84, 87, 90], "instead": [8, 27, 30, 36, 40, 42, 43, 46, 47, 48, 52, 59, 61, 63, 64, 65, 66, 68, 69, 72, 77, 80, 81, 82, 83, 84, 87, 89, 90], "pass": [8, 9, 42, 46, 48, 57, 58, 59, 64, 65, 67, 70, 80, 87, 89], "ing": [8, 27], "mh_step": 8, "logtarget": 8, "logtarget_curr": 8, "arg": [8, 42, 43, 46, 48, 64, 82, 83, 90], "ndarrai": 8, "shape": [8, 12, 42, 44, 48, 57, 59, 61, 63, 64, 65, 67, 68, 78, 80, 84, 87, 90], "n_variabl": 8, "present": [8, 12, 28, 31, 42, 46, 58, 59, 61, 64, 68, 70, 78, 79, 82, 83, 86, 89], "walker": [8, 52, 53, 54, 61, 67, 72], "space": [8, 36, 40, 42, 52, 53, 54, 60, 61, 63, 65, 67, 78, 79], "log": [8, 23, 27, 28, 40, 43, 46, 47, 48, 57, 59, 63, 64, 65, 66, 68, 70, 78, 80, 82, 83, 87, 90], "signatur": 8, "float": [8, 52, 59, 64, 69, 72], "current": [8, 37, 40, 42, 53, 61, 69], "standard": [8, 37, 38, 58, 63, 64, 72, 78, 79, 80, 81, 82, 83, 89], "tupl": 8, "addit": [8, 24, 25, 26, 28, 38, 42, 59, 69, 75, 87], "argument": [8, 27, 40, 42, 46, 48, 59, 60, 82, 86], "new_x": 8, "posit": [8, 37, 40, 42, 43, 46, 47, 52, 53, 54, 57, 64, 72, 73, 78, 81, 82, 83, 84, 86, 87], "after": [8, 12, 15, 17, 30, 31, 37, 38, 43, 44, 48, 52, 57, 58, 64, 65, 67, 69, 79, 80, 84, 86, 87, 89, 90], "input": [8, 43, 57, 58, 64, 65, 72, 83, 84, 86], "new_logtarget": 8, "densiti": [8, 33, 36, 37, 40, 42, 43, 46, 47, 53, 55, 57, 60, 61, 63, 64, 68, 72, 81, 83, 87, 90], "accept": [8, 53, 64, 79, 89], "bool": [8, 58, 59], "true": [8, 9, 19, 30, 31, 40, 42, 57, 58, 59, 60, 61, 63, 64, 68, 69, 70, 72, 75, 78, 79, 80, 81, 86, 87, 90], "fals": [8, 9, 28, 30, 48, 57, 58, 59, 61, 63, 64, 67, 70, 72, 78, 80, 81, 82, 83, 87, 90], "anoth": [8, 9, 12, 27, 32, 43, 44, 52, 58, 59, 61, 64, 66, 67, 68, 69, 72, 73, 78, 81, 91], "am": [8, 37, 46, 55, 59, 66, 69, 72, 75, 89, 92], "n_burn": 8, "n_warmup": 8, "burn": [8, 54], "contrast": [8, 12], "stan": [8, 9, 17, 27, 28, 40, 50, 53, 54, 59, 61, 65, 66, 67, 68, 70, 72, 74, 75, 79, 80, 89, 91, 92], "tune": [8, 53, 54, 78, 81], "dure": [8, 29, 54, 57, 64, 89], "warm": [8, 20, 51, 57, 67], "phase": [8, 54, 57, 83], "3": [8, 12, 17, 28, 30, 31, 36, 40, 43, 44, 46, 47, 48, 55, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 69, 70, 72, 75, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 92], "mh_sampl": 8, "x0": 8, "1000": [8, 11, 52, 57, 58, 59, 60, 61, 64, 65, 67, 72, 73, 75, 79, 80, 81, 82, 84, 86, 87], "n_step": [8, 58, 59], "variable_nam": 8, "none": [8, 37, 39, 49, 57, 64, 66, 70, 80, 90], "int": [8, 28, 30, 36, 37, 38, 40, 42, 52, 53, 55, 57, 59, 60, 61, 64, 65, 67, 68, 69, 70, 72, 75, 78, 79, 80, 81, 82, 83, 84, 86, 87], "default": [8, 27, 28, 38, 58, 59, 61, 67, 68, 72, 81, 87], "list": [8, 27, 59, 63, 66, 73, 80, 81, 89], "name": [8, 15, 27, 31, 37, 39, 40, 52, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 72, 89, 90], "sequenti": [8, 53, 66], "datafram": [8, 59, 63, 80, 84, 90], "lnprob": 8, "test": [8, 28, 31, 65, 69, 79, 80, 87], "bivari": [8, 11, 66], "boldsymbol": [8, 11, 37, 81, 82, 83, 84, 86, 87], "mathsf": [8, 11, 37, 40, 46, 47, 66, 81, 82, 83, 84, 86, 87], "pmatrix": [8, 11, 36, 40, 44, 81], "6": [8, 9, 11, 17, 36, 42, 43, 46, 47, 48, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90, 92], "pdf": [8, 37, 39, 40, 42, 43, 44, 46, 47, 48, 55, 57, 61, 63, 64, 80, 82, 89, 90], "unnorm": [8, 42, 43, 59], "jit": 8, "speed": [8, 40, 47, 63, 66, 84, 87], "confus": [8, 18, 19, 80, 81, 89], "mathbf": [8, 36, 57, 81, 82, 83, 84, 86, 90], "rememb": [8, 27, 37, 38, 40, 42, 57, 58, 60, 64, 69, 72, 81, 82, 87, 90], "arbitrari": [8, 52, 53, 55, 59, 67, 78, 81, 84, 90], "furthermor": [8, 42, 46, 48, 55, 63, 65, 66, 78, 79, 81], "log_test_distribut": 8, "cov": [8, 46, 48, 81], "inv_cov": 8, "linalg": [8, 46, 48], "inv": [8, 46, 48, 66, 86], "njit": 8, "multivari": [8, 19, 37, 38, 40, 47, 48, 66, 81, 84], "gaussian": [8, 17, 26, 37, 43, 74, 83, 86, 87, 90], "dot": [8, 17, 59], "viz": [8, 42, 43, 46, 47, 48, 57, 59, 60, 61, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87], "corner": [8, 27, 59, 60, 63, 65, 68, 70, 72, 75, 78, 80, 81, 83, 84, 86, 87], "everyth": [8, 27, 31, 58, 61, 64, 67, 70, 72, 78, 80, 81, 84, 86], "sens": [8, 18, 31, 36, 37, 40, 42, 43, 44, 47, 48, 64, 69, 77, 79, 80, 81], "add": [8, 27, 31, 48, 58, 59, 63, 65, 68, 69, 70, 73, 81, 82, 83, 84, 86, 89], "logic": [8, 17, 36, 61, 69, 81, 91, 92], "automat": [8, 38, 42, 59, 64, 67, 68], "adjust": [8, 43, 58, 61, 64, 65, 70, 79, 83, 87], "desir": [8, 31, 54, 69, 81], "good": [8, 9, 14, 21, 37, 42, 43, 47, 48, 54, 57, 58, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 72, 73, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91], "pymc": 8, "scheme": [8, 63], "adapt": [8, 15, 31, 57, 58, 80, 87], "001": [8, 67], "05": [8, 59, 78, 81, 82, 84, 86, 92], "5": [8, 17, 28, 30, 36, 37, 40, 42, 43, 46, 47, 48, 49, 52, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 72, 75, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 92], "9": [8, 9, 17, 28, 30, 42, 43, 46, 48, 57, 58, 64, 65, 67, 68, 70, 72, 75, 77, 78, 80, 81, 82, 83, 84, 86, 87, 89, 90, 92], "75": [8, 13, 59, 60, 61, 64, 65, 67, 70, 78, 87, 89, 90], "95": [8, 40, 46, 47, 61, 63, 64, 66, 67, 81, 84, 89], "Be": [8, 12, 27, 38, 78], "demonstr": [8, 30, 37, 40, 44, 58, 59, 63, 64, 72, 75, 81, 84, 86, 89], "type": [9, 15, 27, 40, 57, 58, 59, 60, 61, 80, 83], "lot": [9, 27, 31, 42, 57, 58, 61, 65, 66, 69, 70, 78, 81, 84], "biolog": [9, 69, 77], "scienc": [9, 34, 36, 46, 48, 60, 61, 64, 70, 81, 91], "exampl": [9, 27, 31, 33, 38, 39, 41, 42, 43, 44, 46, 47, 52, 54, 55, 57, 59, 61, 63, 64, 66, 67, 69, 71, 73, 74, 77, 78, 80, 83, 84, 86, 89], "certain": [9, 81], "mutat": [9, 15], "drosophila": [9, 44], "affect": [9, 12, 28, 40, 44, 47, 80, 81], "egg": [9, 37, 39, 40, 44, 46, 60, 66], "hatch": [9, 44], "past": [9, 27, 67, 86], "bi": [9, 30, 61, 77, 88], "1x": [9, 77], "meaghan": 9, "sullivan": 9, "help": [9, 25, 27, 32, 33, 42, 61, 64, 65, 66, 67, 68, 70, 79, 81, 89, 92], "ravi": 9, "nath": 9, "jimmi": 9, "hamilton": 9, "sophi": 9, "walton": 9, "improv": [9, 53, 78, 80, 81, 90], "neural": 9, "circuit": 9, "elegan": [9, 37, 39, 40, 66, 77], "optogenet": 9, "seri": [9, 31, 43, 44, 63, 79, 81, 91], "interconnect": 9, "neuron": [9, 77], "creat": [9, 80, 83], "pathwai": 9, "transmit": 9, "signal": [9, 80, 90], "receiv": [9, 89], "revers": [9, 73, 74, 75], "consist": [9, 12, 31, 36, 40, 44, 55, 58, 67, 79, 80, 82, 89], "three": [9, 12, 28, 37, 42, 48, 59, 60, 61, 63, 65, 66, 67, 69, 72, 74, 75, 77, 79, 89, 90], "sensori": [9, 77], "stimuli": 9, "environ": [9, 27], "command": [9, 27, 30, 58], "interneuron": 9, "integr": [9, 37, 38, 40, 42, 43, 44, 48, 52, 53, 55, 68, 69, 79, 87, 92], "motor": [9, 40, 64, 66], "worm": [9, 73, 74, 75, 77], "six": [9, 89], "non": [9, 33, 57, 59, 66, 68, 81, 85], "act": 9, "respond": 9, "environment": [9, 57], "cue": 9, "trigger": 9, "shown": [9, 15, 36, 40, 43, 46, 52, 53, 64, 69, 79, 81, 90], "figur": [9, 28, 30, 31, 36, 42, 43, 44, 46, 47, 48, 49, 57, 60, 61, 64, 68, 78, 80, 81, 82, 83, 84, 87, 90], "schulthei": 9, "2011": [9, 12], "These": [9, 27, 28, 31, 42, 53, 57, 58, 59, 61, 64, 67, 75, 78, 80, 81, 86, 89], "four": [9, 12, 15, 27, 40, 57, 58, 61, 64, 65, 67, 74, 78, 79], "alm": 9, "avm": 9, "ash": [9, 77], "plm": 9, "two": [9, 12, 28, 29, 30, 31, 37, 38, 40, 42, 43, 44, 46, 48, 53, 57, 58, 59, 63, 64, 65, 66, 67, 69, 70, 72, 73, 74, 77, 78, 79, 80, 81, 86, 87, 88, 90], "avd": 9, "ava": 9, "sensit": [9, 79, 80], "stimulu": 9, "chemosensori": 9, "toxin": 9, "mechan": [9, 47], "touch": 9, "bodi": 9, "send": [9, 57], "provid": [9, 28, 36, 37, 42, 46, 47, 48, 52, 57, 58, 59, 67, 69, 72, 78, 79, 81, 82, 83, 89, 91], "impuls": 9, "order": [9, 27, 28, 31, 38, 40, 42, 43, 47, 52, 57, 58, 63, 64, 65, 66, 67, 69, 72, 78, 79, 80, 81, 83, 89, 90], "fire": [9, 27, 28], "must": [9, 28, 31, 36, 37, 42, 44, 46, 47, 57, 58, 60, 72, 79, 81, 84, 87, 89, 90, 92], "exce": [9, 28], "threshold": [9, 64], "onc": [9, 27, 28, 54, 58, 65, 81, 90], "induc": [9, 69], "action": 9, "potenti": [9, 15, 22, 61], "modul": [9, 28, 46, 52, 57, 61, 64, 81, 89], "dissect": 9, "channelrhodopsin": [9, 77], "chr2": 9, "repres": [9, 31, 57, 61, 75, 79, 81, 90], "red": [9, 59], "barrel": 9, "blue": [9, 59, 64, 77], "allow": [9, 27, 28, 47, 52, 53, 55, 57, 59, 60, 64, 65, 67, 68, 70, 72, 75, 81, 83, 84, 86, 87, 89], "sodium": 9, "calcium": 9, "cation": 9, "flow": [9, 15, 79], "simul": [9, 17, 25, 27, 64, 90, 92], "robustli": 9, "stimul": 9, "exhibit": 9, "avers": 9, "goal": [9, 31, 38, 42, 44, 46, 47, 52, 55, 69, 84, 87, 90], "compar": [9, 40, 42, 47, 48, 61, 65, 68, 69, 70, 72, 78, 79, 83, 84, 86, 87, 90], "wild": [9, 15, 83], "undergo": 9, "student": [9, 28, 42, 66, 77, 89, 91], "trial": [9, 40, 44, 75, 77, 79, 80], "wt": 9, "2017": [9, 38, 75, 77, 87], "7": [9, 17, 28, 30, 40, 42, 43, 46, 48, 49, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 92], "54": [9, 27, 67, 75, 77, 78, 87], "18": [9, 17, 28, 30, 42, 57, 58, 59, 60, 63, 64, 65, 67, 70, 72, 75, 77, 78, 80, 81, 83, 84, 87, 90, 92], "52": [9, 48, 67], "28": [9, 28, 30, 59, 64, 80, 84, 87, 90, 92], "2016": [9, 75, 77], "36": [9, 30, 42, 43, 46, 59, 70, 82, 84, 86, 87], "35": [9, 42, 46, 48, 57, 58, 59, 60, 64, 65, 67, 68, 70, 72, 75, 77, 78, 80, 81, 83, 87], "12": [9, 12, 17, 28, 30, 42, 43, 46, 48, 57, 58, 59, 60, 61, 63, 65, 66, 67, 68, 70, 72, 75, 77, 78, 80, 81, 82, 83, 84, 86, 87, 90, 92], "33": [9, 42, 46, 57, 59, 63, 68, 90], "pool": [9, 75, 78, 87], "13": [9, 17, 42, 43, 46, 48, 57, 58, 59, 60, 61, 63, 64, 67, 68, 70, 72, 78, 80, 81, 82, 83, 84, 87, 90, 92], "126": [9, 72], "39": [9, 48, 57, 58, 59, 61, 72, 78, 82, 87, 90], "124": 9, "91": [9, 48, 59, 90], "theta": [9, 28, 30, 31, 32, 33, 35, 36, 38, 40, 42, 44, 46, 47, 52, 53, 55, 58, 59, 64, 66, 68, 69, 72, 73, 74, 75, 77, 78, 79, 84, 87, 90], "upon": [9, 12, 44, 64, 69, 78], "exposur": [9, 12, 77], "sampler": [9, 10, 11, 20, 22, 50, 53, 54, 57, 58, 59, 61, 65, 68, 70, 78, 79], "previou": [9, 38, 39, 46, 47, 48, 59, 60, 61, 65, 67, 70, 72, 78, 79, 80, 82, 84, 86, 89], "same": [9, 27, 28, 31, 32, 36, 37, 40, 43, 44, 46, 48, 53, 57, 58, 59, 61, 65, 67, 68, 69, 72, 73, 78, 79, 80, 81, 82, 83, 84, 87, 90], "either": [9, 27, 28, 30, 42, 43, 57, 61, 64, 66, 67], "histogram": [9, 55, 57, 61, 63], "illumin": 9, "suppos": [9, 40], "n_1": [9, 77], "n_2": [9, 77], "equiv": [9, 37, 40, 64, 69, 78, 81], "theta_2": [9, 38, 40, 46, 73, 77, 78, 87], "theta_1": [9, 38, 40, 46, 73, 77, 78, 87], "hand": [9, 31, 36, 42, 46, 57, 60, 63, 65, 77, 79, 83, 89, 90], "possibl": [9, 25, 30, 31, 35, 37, 39, 40, 52, 58, 59, 60, 61, 63, 64, 69, 78, 79, 80, 81, 87, 90], "quit": [9, 14, 40, 59, 64, 66, 69, 72, 79, 81, 86, 89], "difficult": [9, 14, 40, 42, 47, 64, 67, 68, 87, 90], "Not": [9, 31, 58, 64, 78, 80], "practic": [9, 11, 17, 31, 37, 40, 52, 59, 66, 67, 69, 81, 89, 92], "repeat": [9, 11, 27, 31, 36, 39, 41, 57, 61, 64, 65, 66, 76, 81, 84], "own": [10, 11, 14, 24, 27, 28, 29, 30, 31, 58, 81, 83, 87, 89], "boolean": [10, 13], "30": [10, 27, 42, 43, 49, 59, 64, 65, 70, 87, 89, 90, 92], "got": [11, 27, 32, 42, 57, 63, 67, 68, 69, 81, 82, 87], "built": [11, 28, 42, 46, 52, 58, 59, 64, 67, 72, 75, 78, 81, 86], "random": [11, 31, 36, 49, 51, 58, 59, 63, 64, 66, 67, 68, 80, 81, 82, 83, 84, 87, 90], "real": [11, 17, 28, 30, 31, 36, 40, 47, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89], "predict": [11, 12, 14, 17, 21, 23, 25, 31, 48, 57, 58, 60, 66, 70, 72, 75, 79, 80, 83, 87, 90, 92], "nor": [11, 37, 40, 46, 63, 72, 81, 82], "simpli": [11, 27, 28, 38, 40, 44, 48, 54, 55, 57, 59, 61, 65, 66, 69, 75], "acquir": [11, 31, 32, 44, 57, 58, 82, 84], "necessari": [11, 23, 27, 28, 42, 53, 54, 55, 59, 63, 66, 67, 78, 84, 89], "gardner": 12, "zanic": 12, "depolymer": [12, 64], "kinesin": [12, 40, 66], "kip3": 12, "mcak": 12, "cellular": 12, "architectur": 12, "differenti": [12, 48, 57, 59, 81, 83, 86], "147": 12, "1092": 12, "1103": 12, "author": [12, 44, 57, 91], "dynam": [12, 48, 57], "switch": [12, 17, 72, 73, 92], "grow": [12, 38, 40, 42, 64, 78, 81], "shrink": [12, 42, 75], "state": [12, 15, 27, 31, 36, 38, 40, 52, 53, 57, 59, 63, 67, 70, 81, 83, 87], "particular": [12, 14, 35, 40, 43, 55, 57, 58, 59, 61, 63, 65, 67, 68, 75, 81, 82, 90], "interest": [12, 31, 37, 39, 42, 44, 48, 53, 55, 57, 58, 59, 61, 66, 67, 69, 75, 78, 81], "growth": [12, 64, 83], "event": [12, 31, 36, 39, 40, 53, 66, 67, 69], "tirf": 12, "assai": [12, 64], "tubulin": [12, 42, 46, 60, 61, 70], "monom": 12, "compris": [12, 77], "label": [12, 14, 17, 69, 72, 73, 78, 92], "fluoresc": [12, 14, 37, 57, 78], "marker": 12, "laser": 12, "interfer": 12, "dic": 12, "microscopi": [12, 78], "unlabel": 12, "analyz": [12, 31, 38, 57, 70, 78, 79, 89], "conclus": 12, "underli": [12, 66, 69, 79, 81, 84], "gardner_mt_catastrophe_only_tubulin": 12, "alreadi": [12, 27, 28, 30, 32, 36, 38, 46, 47, 48, 52, 57, 59, 61, 64, 69, 81, 83, 84, 87], "folder": [12, 27, 58, 87], "aw": [12, 14, 28, 29, 58], "run": [12, 27, 28, 29, 30, 31, 42, 48, 57, 58, 59, 64, 67, 68, 78, 79, 80, 84, 87, 89, 90], "\u00b5m": [12, 37, 40, 42, 43, 46, 48, 60, 61, 64, 65, 66, 70, 87], "amount": [12, 39, 40, 46, 64, 66, 69, 70], "weibul": 12, "happen": [12, 31, 37, 47, 64, 65, 67, 68, 69, 81, 89], "arriv": [12, 39, 52, 54, 87], "second": [12, 27, 30, 38, 40, 42, 43, 46, 47, 48, 57, 58, 61, 64, 65, 66, 72, 77, 79, 80, 81, 83, 87, 89], "descript": [12, 38, 57, 67, 79, 80], "specifi": [12, 27, 37, 38, 42, 43, 46, 57, 58, 59, 60, 61, 64, 65, 66, 72, 73, 78, 81, 82, 87], "stori": [12, 19, 37, 39, 40, 44, 59, 66], "give": [12, 27, 32, 35, 38, 40, 42, 43, 46, 48, 53, 57, 58, 59, 61, 63, 64, 67, 69, 72, 74, 78, 79, 80, 81, 82, 83, 87, 89, 91], "physic": [12, 15, 27, 31, 38, 42, 43, 48, 60, 64, 81, 91], "recal": [12, 40, 42, 47, 48, 58, 67, 69, 72, 80, 83, 90], "prefer": [12, 29, 31, 40, 60, 61, 64, 69, 72, 90], "quantit": [12, 17, 31, 64, 65], "comparison": [12, 17, 64, 65, 68, 70, 84, 87, 92], "mcmc": [13, 17, 22, 24, 27, 38, 40, 51, 53, 54, 58, 64, 65, 68, 69, 72, 75, 79, 80, 81, 85, 87, 91, 92], "25": [13, 17, 28, 30, 42, 43, 46, 48, 57, 58, 60, 61, 63, 64, 65, 67, 68, 70, 72, 78, 80, 81, 82, 84, 86, 90, 92], "microtubul": [13, 60, 64, 87], "catastroph": [13, 64], "mechosensit": 14, "ion": [14, 15, 17], "channel": [14, 15, 17, 91], "imbu": 14, "bacteri": [14, 40, 57, 83], "abil": [14, 55, 67, 69, 79, 81], "withstand": 14, "chure": 14, "place": [14, 28, 46, 63, 64, 83, 84, 89], "chamber": 14, "expos": [14, 80], "explod": 14, "mechanosensit": 14, "mscl": 14, "mcsl": 14, "copi": [14, 57, 72, 80, 84, 86], "vari": [14, 15, 28, 30, 31, 37, 46, 61, 64, 77, 78, 81, 82, 84, 87], "ribosom": 14, "bind": [14, 15, 39], "rb": 14, "therebi": [14, 38, 40, 44], "inhibit": 14, "translat": [14, 30, 58], "intens": [14, 27, 37, 47, 78], "simultan": 14, "pair": [14, 27, 31, 38, 42, 43, 59, 64, 81, 87], "machin": [14, 28, 29, 58, 69, 80, 81, 90], "imag": [14, 27, 42, 43, 58, 64, 66, 68, 84], "df": [14, 42, 43, 46, 48, 57, 59, 60, 61, 64, 65, 67, 70, 72, 78, 80, 81, 82, 83, 84, 86, 87, 90], "pd": [14, 90], "read_csv": [14, 42, 43, 46, 48, 57, 59, 60, 61, 64, 65, 67, 70, 72, 78, 80, 81, 82, 83, 84, 86, 87], "chure_mscl_surviv": 14, "necessarili": [14, 31, 40, 46, 57, 63, 64, 67, 69], "phenomenolog": 14, "impart": 14, "almost": [14, 28, 36, 37, 38, 40, 42, 46, 48, 52, 54, 55, 57, 59, 66, 72, 80, 81, 82, 89], "certinali": 14, "exercis": [14, 17, 27, 42, 63, 64, 72, 90], "therewith": 14, "henri": 15, "lester": 15, "been": [15, 31, 36, 38, 48, 64, 69, 82, 84, 87, 90], "nicotin": 15, "acetylcholin": 15, "receptor": [15, 39], "decad": 15, "schemat": 15, "five": [15, 37, 74, 79, 80], "uniqu": [15, 52, 59, 81, 87], "subunit": 15, "biologi": 15, "ligand": [15, 39], "\u03b1": [15, 57, 64, 75, 80, 81, 82, 83], "unit": [15, 28, 37, 40, 46, 57, 58, 60, 64, 69, 78, 81, 84], "divot": 15, "1995": 15, "labarca": 15, "voltag": 15, "across": [15, 58, 72], "asterisk": 15, "denot": [15, 31, 33, 36, 38, 40, 47, 67, 69, 81, 90], "alpha_2": [15, 59], "beta": [15, 36, 47, 48, 49, 52, 57, 59, 60, 61, 64, 65, 66, 67, 70, 72, 73, 74, 75, 77, 80, 81, 83, 87], "delta": [15, 37, 38, 69, 83, 84, 86], "lester_acetylcholin": 15, "logist": 15, "equat": [15, 32, 37, 52, 69, 77, 79, 89], "f_": [15, 69], "k_b": [15, 81], "t": [15, 31, 36, 37, 40, 42, 46, 47, 52, 53, 58, 63, 64, 66, 67, 68, 69, 72, 78, 79, 80, 81, 82, 83, 84, 86, 87, 90], "thermal": 15, "energi": [15, 58, 59, 67, 81, 87], "bohr": 15, "christian": 15, "father": 15, "nobel": 15, "laureat": 15, "niel": 15, "danish": 15, "nation": 15, "team": 15, "footbal": [15, 40], "mathematician": 15, "harald": 15, "grandfath": 15, "aag": 15, "e_": 15, "u": [15, 27, 31, 32, 33, 35, 38, 42, 43, 46, 47, 48, 49, 55, 57, 58, 64, 65, 68, 69, 70, 72, 75, 78, 80, 81, 83, 89], "ln": [15, 36, 40, 42, 46, 47, 52, 59, 64, 65, 69, 70, 72, 81, 82, 84, 86, 87, 90], "left": [15, 27, 31, 36, 37, 40, 42, 43, 47, 48, 53, 55, 57, 59, 60, 61, 64, 65, 68, 69, 70, 72, 73, 77, 79, 81, 83, 87, 89, 90], "k_": [15, 81, 83, 84], "dc": 15, "unbound": [15, 40], "without": [15, 31, 36, 38, 39, 40, 44, 48, 54, 58, 68, 69, 81, 83, 89], "bound": [15, 40, 42, 43, 46, 47, 57, 59, 60, 61, 63, 64, 67, 81, 82, 83, 87, 90], "dissoci": 15, "larg": [15, 29, 31, 37, 40, 42, 43, 55, 57, 60, 64, 67, 68, 69, 78, 80, 81, 82, 84, 87, 89], "v": [15, 28, 30, 42, 43, 44, 46, 47, 48, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "system": [15, 30, 37, 58, 69, 77, 81], "surviv": 16, "osmot": 16, "shock": 16, "diagnos": [16, 22, 61, 68, 78, 79, 80], "nonidentifi": [16, 20, 59], "60": [16, 64, 80, 83, 87], "prequel": [17, 42], "pipelin": [17, 64, 80], "preserv": [17, 66], "displai": [17, 59, 64, 67, 68, 81, 83, 87, 89, 92], "basic": [17, 20, 26, 51, 57, 61, 87, 90], "resampl": [17, 58], "method": [17, 28, 31, 38, 39, 42, 43, 46, 47, 48, 54, 57, 58, 59, 60, 61, 64, 65, 67, 69, 72, 78, 79, 82, 83, 87, 90], "frequentist": [17, 40, 47, 58], "deeper": [17, 78], "mostli": [17, 40, 48, 79, 80], "hierarch": [17, 24, 30, 38, 40, 64, 66, 81, 84, 92], "markov": [17, 20, 38, 40, 43, 47, 50, 52, 55, 56, 58, 64, 65, 67, 79, 86, 92], "chain": [17, 20, 22, 38, 40, 43, 47, 50, 52, 53, 54, 55, 56, 58, 59, 60, 61, 64, 65, 67, 68, 70, 72, 74, 77, 78, 79, 80, 81, 83, 84, 86, 92], "mont": [17, 20, 38, 40, 43, 47, 50, 53, 55, 56, 58, 64, 65, 79, 86, 92], "carlo": [17, 20, 38, 40, 43, 47, 50, 53, 55, 56, 58, 64, 65, 79, 86, 92], "workflow": [17, 38, 64, 89, 92], "topic": [17, 40, 50, 67, 73, 81], "enrol": 17, "pleas": [17, 24, 40, 44, 79, 81, 89], "ed": [17, 89, 91], "canva": [17, 89], "assign": [17, 31, 36, 40, 58, 59, 64, 90], "submiss": 17, "password": 17, "protect": [17, 72, 82, 83], "instructor": [17, 89, 92], "justin": 17, "boi": [17, 58, 82, 83, 90], "ta": [17, 89, 92], "kayla": 17, "jackson": 17, "scientif": [17, 28, 91, 92], "introduct": [17, 50, 58, 67, 92], "margin": [17, 18, 31, 34, 36, 37, 38, 46, 47, 48, 53, 55, 59, 60, 63, 66, 75, 79, 81, 82, 84, 86, 87, 92], "numer": [17, 38, 46, 47, 48, 59, 69, 77, 81, 82, 86], "quadratur": [17, 48], "conjugaci": [17, 43, 81, 92], "e1": 17, "e2": 17, "8": [17, 28, 30, 42, 43, 44, 46, 47, 48, 49, 57, 58, 59, 60, 63, 64, 65, 67, 68, 70, 72, 75, 78, 79, 80, 81, 82, 83, 84, 86, 87, 89, 90, 92], "e3": 17, "11": [17, 28, 30, 42, 43, 44, 46, 47, 48, 57, 58, 59, 61, 64, 65, 66, 67, 68, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90, 92], "e4": 17, "14": [17, 42, 43, 46, 48, 57, 58, 59, 61, 64, 65, 67, 68, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90, 92], "collector": [17, 92], "box": [17, 31, 52, 92], "15": [17, 28, 30, 42, 43, 44, 46, 47, 48, 57, 58, 59, 63, 64, 65, 68, 72, 75, 78, 80, 81, 82, 83, 84, 87, 90, 92], "diagnost": [17, 22, 24, 54, 59, 61, 70, 72, 75, 80, 81, 83, 84, 86, 92], "16": [17, 28, 30, 42, 48, 57, 58, 59, 61, 64, 65, 67, 72, 78, 80, 81, 82, 83, 84, 87, 90, 92], "artifici": [17, 63], "funnel": [17, 78, 84, 87, 92], "hell": [17, 92], "e5": 17, "e6": 17, "19": [17, 42, 47, 57, 58, 59, 64, 67, 72, 80, 81, 83, 84, 87, 92], "e7": 17, "21": [17, 42, 43, 46, 48, 57, 58, 60, 63, 64, 65, 66, 67, 68, 70, 72, 78, 80, 81, 87, 92], "22": [17, 59, 64, 66, 72, 78, 81, 84, 87, 92], "calibr": [17, 25, 27, 64, 92], "e8": 17, "23": [17, 59, 61, 64, 78, 80, 87], "24": [17, 61, 64, 80, 86, 87, 89, 90, 92], "e9": 17, "26": [17, 28, 30, 42, 43, 44, 46, 47, 48, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90, 92], "wrap": [17, 92], "analyt": [17, 38, 40, 44, 47, 48, 55, 60, 68, 84, 87, 90], "maximum": [17, 40, 42, 46, 61, 66, 67, 68, 70, 72, 75, 78, 80, 81, 83, 84, 86], "posteriori": [17, 44, 47, 82], "overview": 17, "date": [17, 89], "weekli": [17, 89], "meet": 17, "session": [17, 27, 28, 58], "collabor": [17, 28], "honor": 17, "ediquett": 17, "softwar": [17, 27, 53], "tutori": [17, 68, 72], "winter": 17, "2024": [17, 28, 57, 58, 72], "2022": 17, "2021": [17, 67], "2020": [17, 54], "statement": [18, 59, 60, 64, 81, 86], "curs": [18, 38, 42], "appear": [18, 27, 28, 42, 64, 87], "few": [18, 29, 38, 40, 42, 44, 48, 54, 57, 58, 59, 60, 63, 64, 67, 69, 70, 72, 78, 79, 80, 81, 84, 87, 90], "approxim": [19, 37, 38, 43, 52, 55, 57, 61, 63, 64, 66, 67, 68, 69, 72, 74, 78, 81, 83, 87], "possibli": [19, 55, 61, 78, 79, 81], "meant": [19, 27, 59, 79], "weakli": [19, 46, 60, 64, 73, 77, 78], "off": [19, 37, 42, 46, 58, 60, 66, 68, 77, 80, 81, 83], "abl": [20, 43, 48, 52, 55, 57, 61, 64, 67, 69, 78, 80, 81, 89], "behind": [20, 26, 37, 44, 51, 57, 69, 72, 87, 89], "contend": 21, "suffici": [21, 37, 42, 52, 53, 82], "assess": [21, 40, 46, 57, 59, 64, 66, 72, 79], "better": [21, 40, 52, 59, 61, 65, 69, 70, 72, 78, 80, 81, 84, 87, 89], "agre": [21, 31, 40, 67, 69], "total": [22, 27, 46, 48, 63, 65, 67, 69, 70, 77, 78, 80, 81, 87, 89], "diverg": [22, 40, 58, 59, 68, 70, 72, 75, 78, 80, 81, 83, 84, 86, 87, 90], "ever": [22, 27, 68, 87], "guarante": [22, 30, 40, 46, 47, 59, 67, 87, 90], "properli": [22, 42, 57, 58, 60, 61, 67, 68, 78, 79, 80, 83, 89], "finit": [22, 52, 57, 83], "ye": [22, 58, 65], "stop": [22, 64, 72, 79, 87], "underscor": [22, 59, 69], "extens": [22, 59], "pointwis": [23, 70], "waic": [23, 69], "loo": [23, 69, 70], "tidi": [24, 61, 78], "encount": [24, 36, 40, 42, 47, 58, 67, 80, 81, 82, 83, 84, 90], "structur": [24, 31, 43, 58, 59, 66, 84, 87, 89], "briefli": [24, 58, 61], "situat": [24, 40, 72, 73], "exchang": 24, "thoroughli": [24, 87], "especi": [24, 44, 46, 59, 63, 72, 89, 90, 91], "z": [25, 31, 80, 81, 83, 86], "score": [25, 80], "verifi": [25, 28, 30, 58, 65, 79, 82, 89], "shrinkag": [25, 80], "rank": [25, 26, 63, 67, 68, 70, 72, 78, 80, 87], "statist": [25, 27, 29, 30, 37, 54, 55, 58, 59, 63, 64, 66, 69, 78, 80, 81, 87, 90, 91], "pitfal": 25, "By": [25, 32, 37, 40, 55, 61, 67, 72, 79, 81], "cautiou": 25, "sbc": [25, 27, 64, 79], "analys": [25, 28, 38, 79], "elbo": [26, 87], "advantag": [26, 29, 30, 40, 44, 63, 64, 69, 77, 81], "disadvantag": [26, 29, 44], "field": [26, 87], "famili": [26, 38, 81, 87], "power": [27, 30, 55, 57, 58, 59, 67, 69, 79, 81, 90], "instal": [27, 28, 57, 58], "suffic": [27, 46, 64], "serv": [27, 31, 32, 44, 57, 64, 75, 81, 82], "expans": [27, 47], "resourc": [27, 28, 30, 47, 89], "option": [27, 42, 46, 61, 64, 89], "googl": [27, 29, 30, 57, 58, 89], "cloud": [27, 28, 29, 30], "platform": [27, 28], "microsoft": [27, 28, 29], "azur": [27, 29], "high": [27, 29, 37, 40, 47, 54, 61, 67, 68, 81, 82, 83], "center": [27, 40, 47, 59, 63, 64, 68, 78, 82, 83, 84, 86], "lesson": [27, 29, 30, 38, 40, 42, 43, 46, 47, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 72, 74, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87], "much": [27, 28, 30, 31, 36, 37, 38, 42, 43, 46, 47, 48, 53, 55, 58, 59, 63, 64, 65, 66, 67, 68, 69, 70, 72, 78, 79, 80, 81, 82, 83, 84, 87, 89], "next": [27, 28, 31, 32, 40, 42, 43, 46, 47, 48, 52, 53, 58, 64, 65, 66, 75, 77, 81, 82, 87], "spin": 27, "outlin": [27, 54, 72, 83, 89], "cost": [27, 79], "100": [27, 31, 40, 42, 46, 47, 48, 57, 64, 68, 72, 78, 80, 81, 87, 89, 90, 92], "core": [27, 28, 29, 58, 80, 90], "entir": [27, 40, 46, 64, 66, 78, 83, 89], "consol": 27, "click": [27, 28, 68], "button": 27, "upper": [27, 40, 47, 59, 60, 63, 64, 65, 67, 70, 72, 75, 81, 82, 83, 87], "page": [27, 28, 44, 55, 89, 92], "ami": 27, "pre": [27, 28, 81, 89], "oregon": [27, 58], "west": 27, "select": [27, 30, 43, 59, 61, 66, 71, 78, 87, 89], "region": [27, 42, 47, 48, 54, 58, 61, 63, 64, 67, 68, 81], "top": [27, 28, 64, 75, 89, 90], "throughout": [27, 30, 37, 47, 64, 89, 91], "live": [27, 80], "ec2": 27, "pulldown": [27, 89], "menu": [27, 89], "screen": [27, 57, 61, 89], "pane": 27, "me": [27, 31, 38, 40, 63, 64, 69], "public": 27, "search": [27, 86, 89], "doubl": [27, 52, 59, 84, 90], "request": [27, 28, 57], "spot": 27, "save": [27, 64], "monei": [27, 31], "lose": [27, 73, 87], "whatev": [27, 81], "tag": 27, "recommend": [27, 28, 50, 67, 87], "back": [27, 77, 79, 80, 81, 87, 89], "mine": 27, "skip": [27, 30, 67, 81], "applic": [27, 37, 40, 53, 69, 81, 82], "o": [27, 28, 42, 43, 46, 48, 57, 58, 59, 60, 61, 64, 65, 67, 70, 72, 80, 81, 82, 83, 84, 86, 87, 89, 90], "choic": [27, 40, 44, 48, 61, 63, 65, 66, 77, 81, 82, 87, 89, 90], "c5": 27, "xlarg": 27, "2xlarg": 27, "larger": [27, 64, 66, 68, 78, 81, 84], "kei": [27, 57, 64, 72, 81], "login": 27, "pop": 27, "window": [27, 89], "enter": 27, "bebi103_aws_keypair": 27, "fine": [27, 28, 61, 65, 70, 86, 89], "leav": [27, 29, 40, 58, 61, 72, 81, 82], "radio": 27, "NOT": 27, "git": [27, 58], "repositori": 27, "anyth": [27, 28, 31, 40, 69, 78, 79], "dropbox": [27, 58], "never": [27, 37, 42, 52, 53, 54, 58, 67, 72, 81, 87], "internet": [27, 29], "reus": 27, "forward": [27, 31, 33, 43, 64, 69, 81, 86], "network": 27, "ssh": 27, "traffic": 27, "anywher": [27, 57, 80, 89, 91], "els": [27, 28, 57, 58, 72, 89], "secur": 27, "ip": 27, "prove": [27, 35, 37, 42, 81], "inconveni": 27, "home": [27, 86], "campu": 27, "configur": [27, 29], "storag": [27, 28], "gib": 27, "gp2": 27, "root": [27, 40, 78], "volum": [27, 42, 64], "enough": [27, 28, 40, 42, 48, 52, 59, 64, 67, 81], "rest": [27, 28, 37, 38, 57, 67, 80], "bottom": [27, 68, 78], "summari": [27, 40, 42, 62, 67, 80, 81], "view": [27, 38, 59, 80], "dashboard": [27, 64], "statu": 27, "readi": [27, 46, 67, 82, 83, 84, 90], "protocol": 27, "instruct": [27, 29, 30, 31, 43, 58, 64, 78, 89], "maco": 27, "linux": 27, "bash": 27, "zsh": 27, "accomplish": [27, 48, 55, 58, 59, 63, 67, 72, 81, 82, 84], "gitbash": 27, "identifi": [27, 38, 42, 43, 44, 47, 57, 59, 64, 67, 69, 79, 80, 81, 89, 90], "put": [27, 40, 58, 60, 61, 64, 66, 67, 73, 79, 80, 81, 83], "keypair": 27, "directori": [27, 28, 58, 86, 89], "key_pair": 27, "pem": 27, "chang": [27, 28, 40, 57, 59, 64, 67, 68, 69, 77, 79, 83, 84, 87, 89, 92], "permiss": 27, "chmod": 27, "400": [27, 44, 47, 49, 67, 68, 78, 87], "clink": 27, "webpag": 27, "ipv4": 27, "92": [27, 72, 87], "67": 27, "user": [27, 58, 82, 83, 90], "avoid": [27, 28, 37, 42, 43, 46, 57, 78, 80, 81, 84, 89], "profil": [27, 87], "echo": 27, "k": [27, 48, 52, 53, 63, 72, 73, 75, 77, 78, 81, 82, 83, 84, 86, 87, 90], "zshrc": 27, "world": [27, 56], "oyster": 27, "clone": 27, "keep": [27, 31, 33, 42, 54, 58, 64, 66, 67, 68, 72, 78, 82, 84, 87], "github": [27, 28, 57], "my_user_nam": 27, "my_favorite_repositori": 27, "appropri": [27, 31, 57, 59, 63, 64, 67, 78, 81, 89], "path": [27, 28, 42, 43, 46, 48, 57, 59, 60, 61, 64, 65, 67, 70, 72, 80, 81, 82, 83, 84, 86, 87, 89], "ipynb": [27, 89], "whenev": [27, 90], "ad": [27, 38, 59, 61, 72, 81, 82, 86], "bebi103_upd": 27, "document": [27, 30, 46, 57, 58, 79, 86, 87, 89, 91], "edit": [27, 28, 89], "manag": [27, 57, 58, 68], "push": [27, 80, 82, 84], "pull": [27, 42, 43, 46, 48, 60, 61, 64, 67, 80, 87], "execut": [27, 28, 58, 60], "jupyt": [27, 28, 30, 58, 64, 89], "browser": [27, 28, 80], "server": 27, "runtim": 27, "jpserver": 27, "30060": 27, "html": [27, 28, 64, 89], "Or": [27, 66, 81], "url": 27, "localhost": 27, "8888": 27, "token": 27, "e52184f06c9fb0f9ceea176b1d51d9cb36c72a019e688f": 27, "127": 27, "socket": 27, "l": [27, 42, 43, 46, 48, 60, 64, 79, 81, 84, 87, 89], "8000": 27, "port": 27, "8889": 27, "substitut": [27, 38, 42, 69, 77, 81, 87], "8001": 27, "90": [27, 37, 64, 75, 78, 87], "direct": [27, 44, 81, 90], "8890": 27, "notebook": [27, 28, 30, 57, 58, 64, 80, 89], "move": [27, 40, 53, 64, 67, 68, 80], "commit": 27, "intermedi": [27, 48, 64], "scp": 27, "yet": [27, 30, 40, 65, 81, 84, 89], "my_fil": 27, "transfer": 27, "colon": [27, 90], "similarli": [27, 31, 36, 48, 69, 81], "upload": 27, "txt": [27, 58], "finish": [27, 58], "shut": 27, "shutdown": 27, "prompt": [27, 30], "hard": [27, 37, 46, 64, 78, 83, 84], "press": [27, 36, 48], "ctrl": 27, "unless": [27, 54, 58, 63, 87], "realli": [27, 31, 37, 38, 40, 42, 43, 46, 64, 66, 68, 69, 72, 79, 80, 81, 83, 84, 87, 89], "rid": 27, "charg": 27, "rack": 27, "massiv": 27, "bill": 27, "idl": [27, 28], "minor": [27, 64], "pain": 27, "wait": [27, 31, 37, 44, 81], "forget": 27, "pocketbook": 27, "easier": [27, 31, 37, 38, 42, 46, 59, 63, 69, 81, 82], "navig": [27, 28], "via": [27, 28, 39, 44, 57, 58, 78, 81, 89], "spun": 27, "per": [27, 40, 42, 57, 64, 66, 68, 72, 78, 80, 81, 87], "eb": 27, "etc": [27, 28, 31, 37, 38, 58, 74, 77, 81, 86, 87, 89], "intact": 27, "free": [27, 28, 29, 65, 69, 78, 82, 87, 89], "tier": [27, 28], "expir": 27, "promo": 27, "wipe": 27, "conveni": [28, 37, 40, 42, 46, 47, 48, 52, 55, 57, 58, 59, 61, 63, 64, 65, 67, 69, 72, 74, 78, 81, 83, 84, 86], "account": [28, 57, 67, 89], "employe": 28, "suit": 28, "person": [28, 63], "gmail": 28, "youtub": [28, 91], "facilit": [28, 39, 86], "teammat": [28, 89], "staff": [28, 89], "annoi": [28, 29, 58], "trick": [28, 38, 42, 53, 59, 78], "safari": 28, "edg": 28, "web": 28, "brows": 28, "chrome": 28, "firefox": 28, "jupyterlab": [28, 30, 42, 43, 44, 46, 47, 48, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "support": [28, 87], "launch": [28, 59], "altern": [28, 46, 57, 66, 68, 69, 77, 90], "badg": 28, "content": [28, 39, 58, 59, 64, 66, 81, 83, 86, 87], "virtual": 28, "cpu": 28, "gb": 28, "ram": [28, 58], "gpu": 28, "tpu": 28, "tensor": 28, "too": [28, 31, 37, 40, 42, 43, 53, 63, 66, 67, 68, 79, 80, 81, 82, 84, 87, 89], "long": [28, 31, 40, 53, 54, 58, 63, 66, 67, 73, 83, 84], "disconnect": [28, 29], "timeout": 28, "alwai": [28, 30, 31, 37, 40, 42, 46, 48, 52, 55, 57, 59, 63, 64, 66, 72, 73, 81, 87, 89], "effici": [28, 64, 67, 86], "offer": [28, 42, 46, 53, 61, 67, 69, 72, 90], "longer": [28, 40, 43, 57, 59, 64, 73, 82, 86, 90], "pro": [28, 29], "howev": [28, 40, 42, 44, 47, 48, 55, 57, 59, 64, 65, 66, 67, 68, 69, 72, 79, 81, 82, 83, 89, 90], "encourag": [28, 78, 79, 81, 89], "bokeh": [28, 30, 42, 43, 44, 46, 47, 48, 49, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "app": 28, "python": [28, 42, 43, 44, 46, 47, 48, 57, 58, 59, 60, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 89, 90, 91], "callback": [28, 64], "instanc": [28, 29, 42, 57, 58, 64], "major": [28, 40, 42, 46, 48, 64, 79], "burden": 28, "circumv": 28, "upgrad": [28, 29, 57], "faq": 28, "latest": 28, "januari": [28, 92], "wherea": [28, 47], "anaconda": 28, "preinstal": 28, "variant": [28, 72], "thereof": [28, 69, 72, 89], "cmdstanpi": [28, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 91], "install_cmdstan": [28, 30, 57], "setup": [28, 29, 57, 66, 83], "sy": [28, 57, 89], "subprocess": [28, 37, 57], "cmd": [28, 57], "pip": [28, 57], "polar": [28, 42, 43, 46, 48, 57, 59, 60, 61, 63, 64, 65, 67, 70, 72, 78, 80, 81, 82, 83, 84, 86, 87], "iqplot": [28, 57, 58, 59, 60, 63, 64, 67, 75, 78, 80, 84, 87, 90], "colorcet": [28, 57, 58], "datashad": [28, 57], "arviz": [28, 30, 57, 59, 60, 63, 64, 65, 67, 68, 69, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 91], "watermark": [28, 30, 42, 43, 44, 46, 47, 48, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "popen": [28, 57], "split": [28, 31, 38, 57, 59, 64, 69], "stdout": [28, 57, 58], "pipe": [28, 57], "stderr": [28, 57], "data_path": [28, 42, 43, 46, 48, 57, 59, 60, 61, 64, 65, 67, 70, 72, 80, 81, 82, 83, 84, 86, 87, 89], "ensur": [28, 37, 54, 59, 67, 68, 79, 84, 86, 89], "recent": [28, 78, 89], "cmdstan": [28, 30, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 72, 78, 80, 81, 82, 83, 84, 86, 87], "drawback": [28, 47, 61, 63], "binari": 28, "shutil": [28, 57], "urllib": [28, 57], "latest_vers": [28, 57], "cmdstan_vers": [28, 30, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 72, 78, 80, 81, 82, 83, 84, 86, 87], "cmdstan_url": [28, 57], "dev": [28, 42, 57], "releas": [28, 57, 61], "fname": [28, 57, 87], "tgz": [28, 57], "urlretriev": [28, 57], "unpack_arch": [28, 57], "faster": [28, 40, 42, 47, 57, 64, 66, 80, 89], "mode": [28, 47, 58, 59, 63, 90], "fetch": [28, 86], "hidden": 28, "render": [28, 49, 61, 64, 89], "clutter": [28, 37, 57, 58], "collab": 28, "az": [28, 30, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87], "io": [28, 30, 42, 43, 44, 46, 47, 48, 49, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "output_notebook": [28, 30, 42, 43, 44, 46, 47, 48, 49, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "schools_data": [28, 30], "schools_cod": [28, 30], "lower": [28, 30, 31, 40, 47, 57, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "school": [28, 30], "vector": [28, 30, 59, 64, 72, 78, 81, 82, 83, 84, 86, 87, 90], "treatment": [28, 30, 47, 48, 60, 79, 90], "tau": [28, 30, 40, 78, 87], "eta": [28, 30, 87], "transform": [28, 30, 31, 36, 40, 52, 57, 58, 59, 60, 61, 65, 66, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87], "w": [28, 30, 38, 59, 64, 72, 78, 87, 90, 92], "disable_log": [28, 30, 57, 59, 60, 61, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87], "sm": [28, 30, 57, 58, 59, 60, 61, 65, 67, 68, 72, 75, 80, 82, 83, 84, 86, 87, 89], "cmdstanmodel": [28, 30, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 89], "stan_fil": [28, 30, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87], "output_dir": [28, 30], "show_progress": [28, 30, 57, 58, 64, 87], "from_cmdstanpi": [28, 30, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 83, 84, 86, 87], "clean_cmdstan": [28, 30, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87], "frame_height": [28, 30, 42, 43, 44, 46, 47, 48, 49, 57, 59, 60, 61, 63, 64, 80, 81, 82, 83, 84, 87], "250": [28, 30, 42, 43, 46, 48, 57, 60, 61, 63, 64, 65, 70, 80, 81, 82, 83, 84, 86, 87, 90], "frame_width": [28, 30, 42, 43, 44, 46, 47, 48, 49, 57, 59, 60, 61, 63, 64, 75, 80, 81, 82, 83, 84, 87], "x_axis_label": [28, 30, 42, 43, 44, 46, 47, 48, 49, 57, 59, 60, 61, 63, 64, 65, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 87, 90], "\u03bc": [28, 30, 42, 90], "y_axis_label": [28, 30, 42, 43, 44, 46, 47, 48, 49, 57, 60, 61, 63, 64, 65, 68, 70, 75, 78, 80, 81, 82, 83, 84, 87], "\u03c4": [28, 30, 78, 87], "scatter": [28, 30, 42, 43, 46, 48, 57, 59, 60, 61, 63, 64, 68, 78, 80, 81, 82, 83, 84, 87], "ravel": [28, 30, 57, 58], "alpha": [28, 30, 42, 43, 44, 46, 47, 48, 49, 52, 53, 57, 59, 60, 61, 64, 66, 67, 68, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 86, 87, 90], "bokehj": [28, 30, 42, 43, 44, 46, 47, 48, 49, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "load_ext": [28, 30, 42, 43, 44, 46, 47, 48, 49, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "cpython": [28, 30, 42, 43, 44, 46, 47, 48, 57, 58, 59, 60, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "ipython": [28, 30, 42, 43, 44, 46, 47, 48, 57, 58, 59, 60, 63, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 90], "27": [28, 30, 57, 59, 61, 64, 78, 80, 82, 83, 84, 86, 87, 92], "requir": [29, 31, 38, 52, 55, 57, 64, 67, 69, 80, 87, 89, 90], "signific": [29, 53, 64, 81], "connect": [29, 31, 69, 70], "loud": 29, "hot": 29, "unavail": [29, 42], "colab": [29, 30, 57, 58, 89], "pretti": [29, 40, 44, 52, 55, 59, 61, 64, 69, 80, 81, 90], "fast": [29, 46, 64, 69, 78], "biggest": 29, "interact": [29, 58, 64, 66], "babysit": 29, "commerci": 29, "servic": [29, 38], "hpc": 29, "oper": [30, 40, 57, 59, 81, 83], "BE": [30, 88], "103": [30, 88], "probabilist": [30, 31, 36, 37, 40, 57, 58], "program": [30, 37, 57, 60, 86], "languag": [30, 37, 57, 58, 89], "parser": 30, "compil": [30, 57, 58, 59, 64, 65, 67, 68, 70, 72, 75, 80, 81, 82, 83, 84, 86, 87, 89], "interfac": [30, 57, 58, 87, 91], "wide": [30, 37, 40, 42, 53, 54, 69, 80, 81, 83, 90], "rstan": 30, "pystan": [30, 58], "respect": [30, 37, 40, 42, 48, 58, 59, 61, 63, 68, 69, 72, 73, 75, 78, 81, 83, 86, 87, 89, 90], "simpler": [30, 64, 66, 82], "becom": [30, 31, 32, 38, 40, 42, 43, 48, 55, 59, 64, 66, 69], "appar": [30, 78, 83], "whichev": 30, "tricki": [30, 42, 72, 81], "troubleshoot": 30, "worri": [30, 52, 63], "troubl": [30, 64, 67, 68, 89], "On": [30, 66, 77], "xcode": 30, "previous": [30, 61, 67, 87], "One": [30, 36, 37, 38, 42, 52, 63, 64, 78, 87], "mingw": 30, "conda": 30, "libpython": 30, "m2w64": 30, "msys2": 30, "util": [30, 36, 40, 44, 91], "raspberri": 30, "pi": [30, 33, 35, 36, 37, 38, 40, 42, 47, 61, 64, 65, 68, 70, 72, 75, 79, 81, 84, 87, 90], "took": [30, 42, 44, 48, 53, 67, 69, 77, 87], "appreci": 30, "nifti": 30, "trivial": [30, 31, 55, 58, 65], "feat": 30, "warn": [30, 47, 57, 68, 70, 72, 80, 90], "print": [30, 42, 46, 48, 57, 58, 59, 60, 61, 64, 65, 67, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 87, 89, 90], "thought": [31, 44, 46, 89], "inquiri": 31, "visit": [31, 42, 54], "refresh": [31, 69, 80, 87], "sketch": [31, 37, 40], "cycl": 31, "itself": [31, 64, 69, 72, 78, 82], "natur": [31, 37, 57, 64, 66, 69, 72], "mileston": 31, "along": [31, 40, 54, 57, 58, 61, 66, 67, 70], "arrow": 31, "orang": [31, 42, 44, 46, 48, 57, 59, 68, 78, 80, 81, 82, 83, 84, 86, 87], "fig": [31, 79], "gregori": [31, 91], "cambridg": [31, 36], "2005": 31, "hypothesi": [31, 32, 35, 38], "invent": 31, "refin": [31, 37], "stage": [31, 37, 64], "hypothes": [31, 33, 35, 36], "theori": [31, 47, 57, 72], "pursu": 31, "innov": 31, "sometim": [31, 46, 59, 64, 66, 69, 87], "geniu": 31, "deduct": [31, 89], "deduc": 31, "experiment": [31, 64, 77, 78, 87], "strong": [31, 57, 59, 67, 81, 84, 87], "syllog": 31, "therefor": [31, 35, 37, 39, 40, 42, 43, 44, 46, 47, 48, 57, 58, 60, 64, 66, 67, 69, 72, 80, 81, 83, 84, 87, 89, 90], "plausibl": [31, 37, 38], "perhap": [31, 38, 40, 44, 64, 66, 67, 72, 77, 81], "familiar": [31, 39, 58, 59, 64, 66, 80, 81, 90], "talk": [31, 36, 37, 40, 44, 52, 61, 67, 79], "bullet": 31, "But": [31, 37, 40, 43, 46, 47, 52, 53, 55, 57, 58, 60, 63, 66, 67, 69, 80, 81, 82, 87], "knowledg": [31, 32, 37, 38, 40, 44, 53, 60, 64, 66, 69, 79, 82], "design": [31, 64, 78], "weak": [31, 40], "wastewat": 31, "hydraul": 31, "fractur": 31, "frack": 31, "lead": [31, 38, 40, 47, 57, 59, 64, 68, 72, 84], "greater": [31, 64, 66, 67], "earthquak": 31, "frequenc": [31, 57, 59, 64, 67, 80], "oklahoma": 31, "increas": [31, 42, 64, 78, 80, 81, 90], "2010": 31, "becam": 31, "busi": 31, "obeserv": 31, "role": 31, "crucial": [31, 59, 67, 68, 69], "jayn": [31, 36], "domin": [31, 42, 72, 75, 80], "interpret": [31, 32, 36, 38, 47, 63, 65, 69, 81, 90], "ident": [31, 36, 37, 46, 57, 67, 72], "repetit": 31, "hypothet": 31, "restrict": [31, 44, 81, 87], "proposit": [31, 38], "quantiti": [31, 33, 36, 37, 38, 40, 42, 58, 64, 65, 66, 69, 70, 72, 80, 81, 83, 84, 86, 87], "meaningfulli": 31, "degre": [31, 57], "belief": [31, 57], "fight": 31, "peopl": 31, "who": [31, 89], "appli": [31, 32, 35, 36, 38, 57, 67, 68, 69, 73, 78, 81, 83, 87, 89, 90], "valid": [31, 69, 72, 86], "exclus": 31, "great": [31, 39, 40, 54, 83, 91], "opinion": [31, 53, 61], "proce": [31, 42, 43, 47, 48, 72, 79, 82, 84, 86, 87], "conceptu": [31, 33, 40, 44, 50], "cleaner": 31, "certainti": 31, "convers": [31, 36, 64, 69, 89], "fix": [31, 42, 57, 58, 59, 61, 67, 81, 82], "convert": [31, 40, 52, 57, 58, 59, 61, 64, 65, 66, 67, 69, 72, 78, 81, 83, 86, 87], "1946": 31, "cox": 31, "laid": [31, 38, 44, 54, 58, 61, 67, 80, 86], "properti": [31, 38, 52, 54, 55, 81, 84, 87], "expand": [31, 59], "1970": 31, "ration": 31, "suppli": 31, "rise": 31, "monoton": [31, 46, 69, 90], "manner": 31, "proprieti": 31, "relev": [31, 40, 42, 46, 47, 48, 63], "satisfi": [31, 52, 53, 54, 55, 67, 68, 69, 79, 90], "paus": [31, 37, 38, 42, 59, 60, 69], "chapter": 31, "uniti": [31, 53, 67, 79, 80, 81], "except": [31, 57, 58, 64, 84, 89], "complement": 31, "notion": [31, 40, 69], "bit": [31, 33, 36, 37, 40, 42, 44, 46, 52, 54, 59, 63, 64, 68, 69, 78, 79, 82, 83, 90], "abstract": 31, "bring": [31, 40, 66, 69, 81], "realm": [31, 69], "ll": [31, 43, 48, 57, 58, 63, 65, 66, 67, 68, 70, 72, 79, 80, 83, 84, 87, 90], "rewrit": [31, 64, 77], "explicitli": [31, 37, 42, 53, 58, 59, 69, 73, 81, 84, 89], "henceforth": [31, 81], "vacuum": 31, "ahoi": 31, "pictur": [31, 42, 43, 60, 61, 67, 81], "cannot": [31, 36, 40, 42, 43, 44, 48, 53, 55, 57, 59, 61, 64, 65, 66, 68, 69, 70, 78, 81, 83, 84, 87], "perspect": 31, "commut": 31, "side": [31, 36, 42, 48, 79, 81, 90], "seemingli": [31, 57], "equal": [31, 40, 47, 53, 69, 79, 87, 90], "rearrang": [31, 87], "far": [31, 36, 38, 46, 47, 52, 57, 64, 68, 72, 79, 82, 84, 89], "item": [31, 59, 63], "believ": [31, 40, 46, 73], "instrument": [31, 73], "constitut": [31, 69], "bulk": [31, 43, 64], "algebra": [31, 42, 81, 86, 90], "outcom": [31, 36, 39, 40, 69, 77, 78], "cute": 31, "acronym": 31, "feel": [31, 40, 44, 57, 60, 89], "try": [31, 37, 38, 40, 44, 59, 64, 66, 67, 68, 72, 77, 78, 84, 87, 89], "head": [31, 43, 59, 61, 78, 80, 87, 90], "around": [31, 42, 43, 46, 53, 59, 61, 64, 66, 69, 78, 79, 84], "plug": [32, 37, 69, 90], "product": [32, 37, 38, 40, 42, 59, 64, 77, 81, 87, 89], "rule": [32, 35, 40, 43, 53, 54, 65, 67, 70, 79, 89, 90], "denomin": 32, "insert": [32, 44, 64, 79], "yield": [32, 59, 79, 81], "gave": [32, 58, 80], "combin": [32, 59, 64, 72], "acquisit": [32, 66], "constantli": 32, "symbol": [33, 37, 81], "overload": 33, "aid": 33, "convent": [33, 86, 90], "evid": [33, 35, 37, 38, 59, 66, 87], "joint": [33, 35, 38, 42, 53, 64, 68, 79, 81, 87], "speak": [33, 38, 66, 67, 81], "track": [33, 54, 67, 78, 87], "notat": [34, 36, 37, 42, 52, 69, 81, 83], "bay": [34, 35, 37, 38, 44, 67, 69, 74, 77, 81, 87], "theorem": [34, 35, 37, 38, 39, 44, 69, 74, 77, 79, 81], "mention": [35, 40, 57, 68, 72, 77, 90], "theta_i": [35, 40, 47, 52, 53, 55, 73, 75, 77, 79, 87], "theta_j": [35, 40, 46, 47, 87], "c_j": [35, 81], "nonumb": [35, 37, 53, 69], "ne": [35, 69, 81, 84], "sum_i": [35, 36, 46, 69, 81], "elimin": 35, "lectur": [36, 38, 40, 50, 54, 57, 61, 69, 72, 79, 88, 89, 92], "verbatim": 36, "introduc": [36, 40, 58, 59, 64, 81, 82, 87, 90], "deal": [36, 40, 53, 59, 67, 78, 80], "notation": 36, "le": [36, 42, 43, 48, 64, 81], "cumul": [36, 47], "cdf": [36, 46, 47, 49, 52, 55, 57, 59, 61, 66, 75], "panel": 36, "height": [36, 42, 68, 78, 90], "men": 36, "centimet": 36, "countri": 36, "ly": [36, 82, 83, 86], "y_0": 36, "int_": [36, 90], "satisfact": 36, "axiom": 36, "infti": [36, 37, 40, 42, 43, 46, 66, 81], "necessit": [36, 73], "pmf": [36, 39, 44, 59], "unlik": [36, 37, 48, 59, 64, 66, 68, 72, 78], "roll": 36, "fair": 36, "die": [36, 83], "seen": [36, 38, 42, 44, 52, 57, 59, 63, 65, 67, 70, 74, 81, 83, 86], "hold": [36, 52, 53, 59, 64, 79, 81, 90], "immedi": [36, 44, 55, 58, 64, 68, 78, 80], "consequ": 36, "conjectur": [36, 81], "final": [36, 43, 48, 55, 57, 69, 72, 78, 79, 80, 81, 82, 84, 87, 89, 92], "f_x": 36, "subscript": [36, 55, 69, 78], "enforc": [36, 59, 90], "partial": [36, 40, 47, 83, 90], "factor": [36, 37, 42, 73, 74, 81, 87, 90], "jacobian": 36, "absolut": [36, 68], "jacobi": [36, 40], "cdot": [36, 37, 40, 46, 47, 55, 66, 77, 81, 83, 84, 90], "vdot": [36, 40], "ddot": [36, 40], "rescal": 36, "accordingli": [36, 87], "sqrt": [36, 37, 40, 42, 46, 47, 48, 68, 81, 82, 83, 90], "subtl": [36, 40], "univers": [36, 77], "2003": 36, "subtleti": [36, 69], "simplest": [37, 43, 55, 61], "beak": [37, 72], "depth": [37, 42, 68, 70, 72, 75, 78, 80, 81, 83, 84, 86], "finch": [37, 72], "abound": 37, "concret": [37, 38, 40, 69, 78, 81], "ambigu": [37, 69], "sharpen": 37, "low": [37, 40, 48, 54, 59, 61, 78, 81, 82, 83], "codifi": [37, 38, 40, 60, 69], "everi": [37, 40, 43, 46, 47, 53, 59, 60, 64, 65, 82, 84, 89], "prod_": [37, 42, 69, 73, 90], "dirac": [37, 38, 69], "shall": [37, 42, 81], "heavi": [37, 63, 66, 82], "univari": [37, 61, 65, 66, 84, 86], "exp": [37, 42, 43, 46, 47, 48, 59, 68, 69, 72, 81, 82, 83, 84, 86], "varianc": [37, 39, 46, 54, 58, 64, 66, 67, 68, 69, 78, 79, 80, 81, 83, 90], "confusingli": 37, "literatur": [37, 89, 90], "central": [37, 39, 47, 61, 63], "emerg": 37, "tend": [37, 40, 46, 59, 67, 68, 69, 72, 75, 79, 81, 83], "broadli": 37, "det": [37, 40], "mu_1": [37, 90], "mu_2": [37, 63], "mu_n": 37, "symmetr": [37, 47, 79, 81, 87], "sigma_": [37, 40, 47, 79, 81, 90], "y_j": 37, "correl": [37, 57, 59, 67, 81], "anticorrel": [37, 61], "reduc": [37, 70], "2_i": 37, "decid": [37, 40, 64, 84, 89], "spread": [37, 80, 84], "sought": 37, "beyond": [37, 40, 42, 69, 80, 83, 89], "int_0": [37, 40, 42, 43], "guess": [37, 40, 43, 46, 48, 82, 83], "mu_": [37, 40, 90], "tini": [37, 47, 68], "ten": [37, 40, 66], "micron": [37, 40, 46, 60], "size": [37, 40, 43, 48, 49, 58, 59, 60, 61, 63, 68, 70, 72, 75, 78, 80, 81, 82, 83, 84, 86, 90], "unphys": [37, 64, 80], "mathemat": [37, 40, 42, 43, 44, 46, 64, 66, 69, 81, 87, 89], "disallow": 37, "roughli": [37, 38, 79], "piec": [37, 46], "cover": [37, 40, 53, 70], "exclud": [37, 59], "unreason": [37, 81], "brace": [37, 58, 59, 60, 64], "oh": 37, "mess": [37, 69], "challeng": [37, 38, 39, 40, 44, 59, 78, 81, 90], "easi": [37, 38, 44, 47, 59, 63, 64, 68, 87, 90], "shorthand": [37, 52], "omit": [37, 69], "english": [37, 79], "self": [37, 79, 80], "nasti": [37, 44, 55], "maintain": [37, 40], "focu": [37, 38, 42, 52, 57, 59, 64, 81], "loos": [38, 67, 69], "explicit": [38, 64, 81], "unambigu": [38, 59, 64], "prescrib": [38, 64, 66], "asid": [38, 67], "philosoph": 38, "gelman": [38, 52, 54, 69, 72, 91], "simpson": [38, 61], "betancourt": [38, 50, 59, 65, 67, 68, 79, 91], "clearli": [38, 42, 44, 57, 59, 65, 68, 72, 75, 78, 80, 87, 89], "dilemma": 38, "apt": [38, 57], "titl": [38, 57, 63, 64], "emphasi": [38, 63, 82], "sort": [38, 44, 64, 70], "liter": 38, "social": 38, "intervent": 38, "he": [38, 40, 46, 48, 69], "she": 38, "pattern": [38, 78], "gather": 38, "form": [38, 40, 44, 47, 59, 61, 64, 69, 73, 81, 84, 87, 89, 90], "latter": [38, 59, 69, 79], "destin": 38, "complic": [38, 40, 58], "manifest": [38, 59], "heart": [38, 81], "langl": [38, 55, 79], "xi": [38, 66, 74, 81, 86], "rangl": [38, 55], "replac": [38, 52, 53, 78, 81, 83, 86, 87, 90], "conjagaci": 38, "maxim": [38, 40, 42, 46, 47, 63, 82, 87, 90], "earlier": [38, 40, 59], "resort": 38, "candid": [38, 53], "nice": [38, 52, 57, 61, 63, 65, 79, 81, 83, 86, 91], "enorm": 39, "record": 39, "memori": [39, 52], "exist": [39, 47, 52, 64], "invest": 39, "greatli": [39, 81], "felt": 40, "heat": 40, "framework": 40, "invalid": [40, 57, 82, 83, 90], "bia": [40, 57, 79, 81], "entropi": [40, 87], "bernardo": 40, "eventu": [40, 52], "advoc": 40, "insuffici": 40, "old": [40, 44], "flat": [40, 48, 69], "summar": [40, 46, 61, 90], "Such": [40, 59, 79], "encod": [40, 60, 87], "machineri": [40, 57], "remedi": 40, "outsid": [40, 58, 64, 69, 70, 79, 89], "small": [40, 42, 59, 64, 66, 67, 68, 78, 80, 81, 82, 83, 84, 86, 87, 89, 90], "epsilon": 40, "noth": [40, 58, 64, 80], "goe": [40, 48, 52, 64, 83], "absurd": 40, "primari": [40, 42, 63, 90, 91], "critic": [40, 44, 64], "contemporari": 40, "illustr": [40, 52, 59, 63, 72, 81], "resolut": 40, "earli": [40, 82, 83], "patholog": [40, 67, 68, 70, 72, 75, 78, 79, 80, 81, 83, 84, 86], "bad": [40, 57, 64, 65, 70, 72, 84], "subject": [40, 67, 69, 87, 92], "debat": 40, "complain": 40, "chosen": [40, 59, 63, 64, 65, 78, 81], "formula": [40, 68], "invari": [40, 52, 53, 73], "harold": 40, "discov": [40, 59, 66, 68, 80], "coordin": [40, 57, 58, 59, 67, 68, 72, 78], "mathcal": [40, 87, 90], "_": [40, 43, 47, 63, 69, 72, 81, 82, 83, 84, 86], "succinctli": 40, "sharp": [40, 64, 73], "peak": [40, 42, 43, 46, 47, 64, 69, 73], "propto": [40, 42, 43, 47], "reparametr": [40, 68, 78], "phi_1": 40, "phi_2": 40, "matric": [40, 81, 83, 86], "recogn": 40, "intract": [40, 48, 87], "against": [40, 48, 64, 65, 69, 70, 72, 79, 82, 83], "tediou": 40, "bernoulli": [40, 44, 77], "success": [40, 42, 44, 77, 87], "proper": [40, 42], "highli": [40, 53, 60, 64, 77, 83], "priori": [40, 44, 64, 66], "regardless": [40, 67], "littl": [40, 42, 46, 55, 63, 66, 67, 69, 84], "influenc": [40, 81], "lack": [40, 52, 69], "imposs": [40, 53, 55, 59, 64, 66], "nefari": 40, "care": [40, 42, 43, 57, 64, 69, 81, 87, 89], "anywai": [40, 42, 83], "travel": 40, "somewhat": 40, "breadth": [40, 42], "broader": [40, 47], "opt": 40, "wiki": [40, 67], "loss": [40, 69], "precis": [40, 66, 67, 83], "popul": [40, 57, 59], "expert": 40, "seriou": [40, 59, 87, 89], "gain": [40, 69], "robust": [40, 63, 72], "separ": [40, 57, 58, 64, 66, 75, 77, 86, 89, 90], "sublim": 40, "ridicul": 40, "consider": [40, 42, 59, 64, 81], "difficulti": [40, 63, 74, 80, 89], "rare": [40, 47, 53, 64, 69], "complex": [40, 44, 58, 59, 64, 66, 81, 87, 90], "certainli": [40, 43, 47, 59, 64, 67], "hierarchi": [40, 74, 78, 87], "parametriz": 40, "greatest": [40, 90], "idiomat": 40, "giant": [40, 66], "wager": 40, "salari": 40, "pig": [40, 69], "fly": [40, 69], "comfort": 40, "wage": 40, "don": [40, 46, 67, 78, 81, 90], "hope": [40, 59, 79], "lo": 40, "angel": 40, "club": 40, "win": 40, "ml": 40, "cup": 40, "someon": [40, 44], "tell": [40, 43, 44, 46, 47, 54, 57, 58, 64, 69, 78, 79, 80, 86], "bacterium": 40, "absurdli": 40, "bigger": [40, 46, 64, 72, 73, 84], "nanomet": [40, 66], "diamet": [40, 42, 43, 46, 48, 60, 61, 64, 65, 70, 87], "strand": 40, "nm": [40, 46, 78, 87], "flinch": 40, "m": [40, 59, 64, 69, 78, 81, 82, 83, 84, 86, 87, 90, 92], "bacteria": [40, 83], "smaller": [40, 46, 64, 68, 69, 72, 78], "uneasi": 40, "won": [40, 68, 78, 79], "meter": [40, 66], "cm": 40, "gigant": 40, "mm": [40, 46], "huge": 40, "tremend": 40, "divers": 40, "eukaryot": [40, 64], "xenopu": [40, 46, 60, 64], "strongli": [40, 58, 64], "wouldn": 40, "magnitud": [40, 42, 61, 64, 66, 79, 80, 81], "geometr": 40, "boundari": 40, "surprisingli": [40, 78], "logarithm": [40, 42, 46, 47, 57, 59, 66, 68, 69, 72, 78, 81, 84, 87], "ignor": [40, 47, 48, 55, 57, 60, 61, 64, 65, 69, 73, 90], "li": [40, 68], "width": [40, 64, 68, 78, 79, 90], "rang": [40, 42, 43, 46, 48, 52, 57, 59, 64, 65, 69, 75, 79, 80, 81, 82, 84, 87, 90], "ell": [40, 42, 43, 46, 48, 60, 61, 64, 65, 70, 87, 90], "log_": [40, 46, 57, 59, 60, 61, 66, 67, 80, 81, 87], "approx": [40, 47, 54, 55, 64, 69, 72, 83], "lognorm": [40, 46, 48, 64, 65, 67, 70, 72, 87, 89], "hesit": [40, 67], "theta_": [40, 52, 53, 87, 90], "max": [40, 42, 43, 46, 48, 49, 59, 81, 82, 83, 84, 86], "divid": [40, 43, 52, 80, 83], "conceiv": [40, 79, 84], "came": [40, 69, 89], "firm": 40, "countless": 40, "pl": [42, 43, 46, 48, 57, 59, 60, 61, 63, 64, 65, 67, 70, 72, 78, 80, 81, 82, 83, 84, 86, 87], "scipi": [42, 43, 44, 46, 47, 48, 49, 57, 58, 59, 64, 80, 83, 84, 86, 90], "stat": [42, 43, 44, 46, 47, 48, 49, 57, 58, 59, 63, 64, 80, 82, 83, 86, 90], "st": [42, 43, 44, 46, 47, 48, 49, 57, 58, 59, 64, 80, 82, 83, 86, 90], "ve": 42, "whole": [42, 46, 68, 78], "bread": 42, "butter": 42, "inaccess": 42, "viabl": 42, "mitot": [42, 64, 70], "encapsul": [42, 60], "matt": [42, 87], "refamiliar": [42, 46], "remind": [42, 43, 61, 67, 69, 75, 84, 86, 87], "good_invitro_droplet_data": [42, 43, 46, 48, 60, 61, 64, 65, 70, 87], "frame": [42, 43, 46, 48, 58, 59, 60, 61, 63, 64, 67, 70, 78, 80, 82, 87], "join": [42, 43, 46, 48, 57, 59, 60, 61, 64, 65, 67, 70, 72, 78, 80, 81, 82, 83, 84, 86, 87, 89], "comment_prefix": [42, 43, 46, 48, 57, 59, 60, 61, 64, 65, 67, 70, 72, 80, 83, 87], "um": [42, 43, 46, 48, 60, 61, 64, 65, 70, 87], "to_numpi": [42, 43, 46, 48, 57, 59, 60, 61, 63, 64, 65, 67, 70, 72, 80, 81, 82, 83, 84, 86, 87], "300": [42, 43, 44, 46, 48, 49, 58, 60, 61, 64, 80, 87, 90], "x_rang": [42, 43, 44, 46, 47, 48, 49, 57, 60, 61, 64, 65, 68, 70, 80, 81, 87, 90], "y_rang": [42, 43, 46, 47, 48, 49, 60, 61, 64, 80, 87], "to_dict": [42, 43, 46, 48, 60, 61, 64, 80, 81, 82, 84, 87], "object": [42, 44, 46, 58, 59, 67, 72, 82, 87, 89], "treat": [42, 64, 81], "jeffrei": [42, 43, 46, 60], "l_i": [42, 43, 46, 48, 60, 61, 64, 65, 70, 87], "implicit": [42, 69], "somedistribut": 42, "vanilla": 42, "conserv": [42, 46, 60, 61, 64, 70, 72], "proport": [42, 52, 55, 57, 69], "evalu": [42, 43, 44, 47, 48, 81, 82, 83, 84, 87, 90], "handi": [42, 61], "progress": [42, 58, 81], "postpon": 42, "secondli": 42, "hit": [42, 67, 78, 82], "underflow": [42, 43, 46, 59], "circumst": 42, "insid": 42, "behav": [42, 47, 59, 73, 81], "risk": 42, "logsumexp": 42, "log_marginalized_posterior": [42, 43], "inf": [42, 46, 48, 57, 72, 82, 83, 90], "len": [42, 43, 46, 57, 59, 60, 61, 64, 65, 67, 70, 72, 75, 80, 81, 82, 83, 84, 86, 87], "grung": [42, 81], "linspac": [42, 43, 44, 46, 47, 48, 49, 64, 65, 68, 70, 80, 81, 82, 83, 84, 86, 87], "log_marg_post": 42, "phi_val": [42, 43], "\u03c6": [42, 43, 46, 48, 61, 87], "l\u1d62": [42, 43], "line_width": [42, 43, 44, 46, 47, 48, 49, 57, 59, 63, 64, 67, 68, 80, 81, 82, 83, 84], "awai": [42, 46, 47, 48, 64, 66, 68, 72, 79, 80, 81, 82], "subtract": [42, 69, 90], "marg": 42, "log_marg_post_max": 42, "marg_post": 42, "visual": [42, 43, 46, 47, 57, 59, 60, 63, 64, 80, 81, 90], "axi": [42, 48, 52, 57, 61, 64, 66, 79, 80, 90], "g_": 42, "proportion": [42, 64], "clever": [42, 52, 87], "momentarili": [42, 67, 78, 81], "quad": [42, 43], "marginalized_posterior": [42, 43], "integrand": [42, 43], "resolv": [42, 64], "domain": [42, 60, 66, 82], "kwarg": [42, 46, 57, 58, 59, 61, 64, 65, 72, 84, 86, 87], "err": 42, "46386461926837497": 42, "981239131261995e": 42, "review": [42, 87, 88], "unorm": 42, "found": [42, 46, 47, 48, 55, 77, 81, 86, 87], "straightforwardli": 42, "grungi": 42, "bar": [42, 58, 59, 77, 81], "hat": [42, 54, 68, 69], "nu": [42, 66, 81, 83], "std": [42, 63, 81, 82, 83, 84, 86], "exact_pdf": 42, "color": [42, 44, 47, 48, 49, 57, 59, 61, 63, 68, 75, 78, 80, 81, 82, 83, 84, 86], "line_dash": 42, "dash": 42, "perfect": 42, "efficaci": 42, "tough": 42, "contour": [42, 43, 46, 48, 68], "clean": 42, "log_prior_indep_s": 42, "param": [42, 43, 46, 48, 57, 59, 61, 64, 81, 82, 83, 86, 90], "log_likelihood_indep_s": 42, "logpdf": [42, 46, 48, 82, 83, 90], "loc": [42, 46, 47, 48, 49, 59, 64, 80, 82, 83, 90], "log_posterior_indep_s": 42, "lp": [42, 46, 48, 58, 59, 82, 83, 90], "prevent": [42, 64], "bug": [42, 67, 89], "trade": 42, "overhead": 42, "log_likelihood_indep_size_numpy_onli": 42, "timeit": 42, "ntime": 42, "136": 42, "452": 42, "loop": [42, 59, 64], "000": [42, 48, 67, 80, 87], "nearli": [42, 64, 78, 89], "slow": [42, 46, 81, 83], "increasingli": 42, "nonneglig": 42, "rapidli": [42, 44, 81], "dimens": [42, 47, 57, 58, 59, 65, 67, 72], "log_post": [42, 43, 48], "enumer": [42, 43, 90], "sigma_v": 42, "overflow": [42, 43, 67], "packag": [42, 58, 61, 69, 72, 82, 83, 86, 89, 90, 91], "overlaid": [42, 43, 48, 68, 69], "\u03c3": [42, 46, 48, 60, 61, 64, 82, 83, 86, 87], "harder": [42, 48, 58, 67], "zoom": [42, 43, 78, 83], "31": [42, 49, 59, 63, 67, 68, 70, 87, 92], "spindl": [43, 46, 48, 60, 61, 65, 70], "d_i": [43, 48, 60, 61, 64, 65, 70, 87], "trivari": 43, "tri": [43, 64], "theor_spindle_length": 43, "cbrt": [43, 48, 60, 61, 64, 65, 70, 87], "eyebal": 43, "somewher": [43, 46, 64], "37": [43, 48, 59, 70, 78, 87], "asymptot": [43, 64, 69, 87], "slope": 43, "gamma_v": 43, "\u03d5": [43, 46, 48, 60, 61, 64, 75], "\u03b3": [43, 48, 60, 61, 64, 87], "log_post_max": 43, "calc": 43, "varphi": 43, "infin": [43, 81], "unnormalized_marg_post_phi": 43, "empty_lik": [43, 48], "d\u1d62": 43, "trapezoid": 43, "trapz": [43, 48], "normalization_const": 43, "wrinkl": 43, "lambda": [43, 68, 81, 84], "swap": 43, "unnormalized_marg_post_gamma": 43, "norm_const": 43, "valuabl": [43, 66, 91], "rear": 43, "doom": 43, "spend": [43, 89], "sophist": [43, 72], "seem": [44, 53, 57, 64, 70, 78, 79, 80, 81, 87], "mossman": 44, "2019": 44, "ag": 44, "parent": 44, "viabil": 44, "offspr": 44, "vial": 44, "mate": 44, "young": 44, "dai": [44, 53, 78, 87, 89, 92], "male": 44, "femal": 44, "176": [44, 87], "period": [44, 52, 81], "94": [44, 61, 84, 90], "remaind": 44, "fail": [44, 65, 72, 79, 80, 90], "154": 44, "failur": 44, "binom": [44, 72, 73, 75], "seek": [44, 47, 57, 69, 72], "Its": 44, "mother": 44, "n_old": 44, "n_young": 44, "instanti": [44, 63, 64], "\u03b8": [44, 68, 75, 78], "legend_label": [44, 47, 63, 68, 75, 78, 81, 87], "legend": [44, 63, 68, 75, 78], "top_left": 44, "disavantag": 44, "tractabl": [44, 47, 60], "paltri": 44, "hopeless": 44, "coin": 44, "slightli": [44, 82], "bias": 44, "bimod": [44, 57, 59, 63, 72], "sivia": 44, "bear": [44, 52, 63, 67], "conduct": [44, 80], "statsmodel": [46, 48], "numdiff": [46, 48], "smnd": [46, 48], "tqdm": [46, 48], "342": [46, 48, 60, 61, 64, 70], "856": [46, 48, 60, 61, 64, 67, 70], "860": [46, 48, 60, 61, 64, 70], "2013": [46, 48, 60, 61, 64, 70], "abandon": 46, "bet": [46, 57, 60, 66], "farm": [46, 57, 60, 66], "breviti": 46, "logspac": 46, "1e": [46, 64, 81, 82, 83, 84, 86, 90], "1e5": 46, "x_axis_typ": [46, 80], "half": [46, 60, 64, 66, 73, 78, 82], "halfnorm": [46, 48, 60, 61, 64, 73, 75, 78, 81, 82, 83, 84, 86, 87], "albeit": 46, "themselv": [46, 58, 67], "y_3": 46, "sum_j": [46, 69], "fortun": [46, 48, 54, 59, 69, 72, 86], "log_prior": [46, 48, 82, 83, 90], "log_likelihood": [46, 48, 70, 72, 82, 83, 90], "log_posterior": [46, 48, 82, 83, 90], "indpend": [46, 48], "powel": [46, 48, 82, 83, 90], "reli": [46, 63], "discontinu": 46, "hurt": 46, "particularli": [46, 61, 67, 87, 90], "constrain": [46, 59, 87], "bfg": 46, "cobyla": 46, "neg_log_posterior": [46, 48, 82, 83, 90], "routin": 46, "converg": [46, 67, 87, 90], "params_0": [46, 48, 82, 83], "minimz": 46, "optimzi": 46, "attribut": [46, 57, 58, 59, 67, 72], "extra": [46, 81, 83, 87, 89], "popt": [46, 48], "phi_map": [46, 48], "sigma_map": [46, 48], "2f": [46, 48, 90], "3f": [46, 48, 64, 75], "32": [46, 59, 72, 78, 87, 90], "86": [46, 67, 72], "784": 46, "successfulli": 46, "invert": [46, 48, 81], "element": [46, 47, 59, 60, 78], "approx_hess": [46, 48], "shove": 46, "41668904e": 46, "02": [46, 58, 59, 80, 92], "09388085e": 46, "06": [46, 59, 78, 87, 90, 92], "70799615e": 46, "multipli": [46, 69, 81, 82, 83, 90], "96": [46, 47, 48, 59, 63, 78, 80, 81, 82, 83, 87], "256": 46, "multivariate_norm": [46, 48, 81, 82, 83], "neighborhood": 46, "post_norm": [46, 48], "empti": 46, "log_post_exact": 46, "00": [46, 48, 57, 58, 59, 72, 80, 90, 92], "lt": [46, 48, 57, 58, 59, 67, 72, 80], "50it": 46, "post_exact": [46, 48], "line_kwarg": [46, 47, 48, 63, 64, 67, 68, 75, 87], "dict": [46, 47, 48, 57, 59, 60, 61, 64, 67, 68, 70, 75, 78, 80, 81, 82, 83, 84, 86, 87], "line_color": [46, 48, 49, 63, 75, 83, 84, 86, 87], "danger": [46, 48], "66": [46, 48, 59, 63], "catch_warn": [47, 90], "simplefilt": [47, 90], "abbrevi": [47, 58], "paramount": 47, "dwell": 47, "seldom": [47, 63, 89], "Near": 47, "taylor": 47, "truncat": [47, 61, 64], "b_": 47, "y_gamma": 47, "y_norm": 47, "tomato": [47, 81, 82], "percent": [47, 52], "confid": [47, 58, 79, 80], "erron": 47, "025": [47, 87], "975": 47, "benefit": [47, 79, 81, 87], "afford": [47, 81], "ii": 47, "pm": [47, 63, 64, 89, 92], "asymmetr": [47, 63], "extrem": [47, 64, 66, 67, 72, 77, 78, 81, 82], "flaw": [47, 54], "median": [47, 55, 63, 64, 65, 75, 87], "34": [47, 57, 67, 75, 78, 87], "ppf": [47, 49], "99": [47, 57, 59, 64, 65, 68, 70, 75, 78, 80, 81, 84, 87, 90], "perc_cred_int": 47, "gamma_low": 47, "gamma_high": 47, "norm_low": 47, "norm_high": 47, "fill_between": [47, 81, 82, 83], "patch_kwarg": [47, 81, 82, 83], "shift": 47, "rightward": 47, "notabl": [47, 67, 75], "miss": [47, 66, 67, 70, 79, 80], "despit": [47, 86], "character": [47, 59, 64, 66, 80], "throughput": 47, "attract": 47, "pathologi": [47, 68, 72], "breakdown": [47, 58, 81, 89], "p_data": [48, 61], "relationship": [48, 69, 78], "toward": [48, 66, 75, 78, 79, 81, 87], "embark": 48, "solver": [48, 81], "theoretical_spindle_length": 48, "And": [48, 57, 64, 65, 67, 70, 72, 79, 80], "gamma_map": 48, "38": [48, 52, 59, 68, 80, 87], "77": [48, 59, 72], "859": 48, "034": 48, "754": 48, "201": [48, 75], "grid": [48, 59, 63], "sigma_0": [48, 64, 65, 70, 87], "million": 48, "brute": [48, 60, 64], "forc": [48, 60, 64], "style": [48, 58, 75], "tight": [48, 65], "sea": 48, "needl": [48, 68], "haystack": 48, "meshgrid": [48, 68], "51": [48, 58, 59, 78, 87], "post_margin": 48, "narrow": [48, 68, 79], "cut": 48, "instantan": 48, "dstack": 48, "discourag": 48, "d_theor": 48, "ell_theor": [48, 60, 61, 64, 65, 70, 87], "linear": [48, 59, 64, 66, 81, 82, 83, 86], "regim": [48, 64], "caught": [48, 80], "blackcellmag": 49, "rng": [49, 58, 63, 64, 82, 84], "default_rng": [49, 58, 63, 64, 81, 82, 84], "seed": [49, 59, 63, 67, 68, 72, 78, 87], "12341234": 49, "udraw": 49, "04": [49, 58, 80, 90, 92], "xgrid": 49, "grid_line_color": 49, "ygrid": 49, "x_val": 49, "y_val": [49, 63], "grai": [49, 63], "zeros_lik": [49, 81, 82, 83], "black": [49, 75, 84], "circl": [49, 61], "fill_color": [49, 83, 84, 86], "level": [49, 57, 59, 69, 74, 78, 81, 87, 90], "educ": 50, "vignett": 50, "michael": [50, 59, 65, 67, 79, 90, 91], "hmc": [50, 53, 58, 78], "hamiltonian": [50, 53, 67], "transit": [51, 52, 54, 55, 87], "kernel": [51, 52, 54, 55, 61, 82, 84, 86], "capabl": [52, 57, 72], "pcg64": 52, "128": [52, 72], "nonuniform": 52, "muller": 52, "quantil": [52, 55, 63, 67], "mark": 52, "vertic": [52, 78, 81], "horizont": [52, 81], "correct": [52, 69, 89], "simplic": [52, 81], "walk": [52, 54, 66], "bold": [52, 65], "sentenc": [52, 67], "achiev": [52, 53, 54, 67, 80], "condit": [52, 53, 59, 64, 69, 74, 77, 78, 79, 81, 84, 87], "stationari": [52, 54, 83], "ergod": [52, 53], "aperiod": 52, "2k": 52, "3k": 52, "irreduc": 52, "recurr": 52, "revisit": 52, "checklist": 52, "moment": [52, 54, 57, 64, 69, 78, 81], "preced": [52, 59, 60, 66], "margossian": 52, "randomli": 53, "ratio": [53, 67, 83], "ge": 53, "nut": 53, "earth": 53, "bracket": 53, "art": [53, 57, 65, 67], "origin": [53, 58, 68, 73, 78, 79, 80, 81], "1953": 53, "thumb": [53, 54, 67, 79], "wander": [53, 66], "reject": [53, 68], "gibb": 53, "modern": 53, "popular": [53, 58], "special": [53, 59, 66, 78, 79, 81, 83], "subclass": 53, "overemphas": 53, "naiv": 53, "anyhow": 53, "devis": [54, 68], "theta_0": 54, "travers": 54, "incredibli": [54, 81], "began": 54, "weight": [54, 57, 70, 83, 90], "reach": [54, 67, 83], "heurist": 54, "coauthor": 54, "rubin": 54, "metric": [54, 67, 79], "stationar": [54, 67], "famou": 54, "defer": [54, 60], "vehtari": [54, 67, 69, 72], "stringent": 54, "01": [54, 58, 63, 67, 68, 72, 78, 81, 87, 92], "regular": 54, "neglect": [54, 66, 87], "bunch": 54, "strategi": [54, 59, 68, 79], "h": [55, 69], "averag": [55, 69, 72, 79, 90], "th": [55, 64, 69, 90], "abundantli": 55, "superscript": [55, 78], "parenthet": 55, "hello": 56, "drew": 57, "reconstruct": 57, "miracul": 57, "elowitz": [57, 80], "singer": [57, 67, 72], "heterogen": 57, "methyl": 57, "embryon": 57, "stem": 57, "molec": 57, "331": 57, "2014": 57, "paragraph": [57, 89], "eda": 57, "situ": 57, "hybrid": 57, "focus": 57, "pluripot": 57, "associ": [57, 58, 59, 66, 80, 92], "regul": [57, 77], "hallmark": 57, "tempor": 57, "laps": 57, "movi": 57, "insight": 57, "279": [57, 72], "rex1": [57, 59, 72], "nanog": 57, "prdm14": 57, "singer_transcript_count": [57, 59, 67, 72, 80], "q": [57, 61, 67, 69, 78, 80, 84, 90], "layout": [57, 61, 63, 64, 87], "fewer": [57, 64, 68], "presenc": 57, "inflect": [57, 66], "edcf": 57, "impli": [57, 64, 78], "n_i": [57, 59, 67, 72, 73, 75, 77, 80, 81, 84], "higher": [57, 59, 69], "frequent": 57, "assembl": 57, "shorter": 57, "lifetim": [57, 80], "promot": [57, 80, 83], "strength": [57, 80], "thousand": [57, 79, 80], "syntax": [57, 58, 59, 61, 64, 86, 91], "log10_alpha": [57, 59, 67, 72, 80], "log10_b": [57, 59, 67, 72, 80], "beta_": [57, 59, 67, 72, 75, 80], "neg_binomi": [57, 67, 72, 80], "rais": 57, "block": [57, 58, 60, 64, 65, 66, 81, 82, 83, 84, 86], "declar": [57, 58, 59, 60], "dictionari": [57, 59, 70, 72, 78, 81, 82, 83, 86], "iter_sampl": [57, 58, 59, 60, 61, 64, 65, 67, 75, 80, 81], "inferencedata": [57, 58, 59, 64, 67, 72], "info": [57, 58], "fatal": 57, "neg_binomial_lpmf": [57, 72], "show_consol": 57, "unclear": 57, "fed": 57, "aris": [57, 59], "silenc": 57, "throw": [57, 79], "pedagog": [57, 91], "disabl": 57, "xarrai": [57, 58, 59, 65, 67, 72], "dataset": [57, 58, 59, 65, 67, 72], "gt": [57, 58, 59, 67, 72], "168kb": 57, "int64": [57, 58, 59, 67, 72], "32b": [57, 58, 59, 67, 72], "8kb": [57, 58, 59, 67, 72], "993": [57, 58, 59, 67, 72], "994": [57, 58, 59, 67, 72], "995": [57, 58, 59, 67, 72], "996": [57, 58, 59, 67, 72], "997": [57, 58, 59, 67, 72], "998": [57, 58, 59, 67, 72], "999": [57, 58, 59, 64, 67, 72], "float64": [57, 58, 59, 67, 72], "32kb": [57, 58, 59, 67], "722": [57, 67], "814": 57, "808": 57, "155": 57, "271": [57, 67, 72], "48": [57, 59], "64": 57, "07": [57, 58, 72, 78, 87, 92], "05002": 57, "04916": 57, "0567": 57, "05535": 57, "5707": 57, "5814": 57, "6186": 57, "6305": 57, "301": [57, 87], "308": 57, "246": 57, "257": 57, "created_at": [57, 58, 59, 72], "19t23": [57, 58], "29": [57, 59, 67, 80, 87, 90, 92], "089569": 57, "arviz_vers": [57, 58, 59, 72], "inference_librari": [57, 58, 59, 72], "inference_library_vers": [57, 58, 59, 72], "4xarrai": [57, 58, 72], "datasetdimens": [57, 58, 59, 67, 72], "4draw": [57, 58, 59, 67, 72], "1000coordin": [57, 58, 59], "int640": [57, 58, 59, 67, 72], "3arrai": [57, 58, 59, 67, 72], "999arrai": [57, 58, 59, 67, 72], "float643": [57, 59], "271arrai": 57, "72176": 57, "81412": 57, "8077": 57, "02461": 57, "95251": 57, "49689": 57, "82657": 57, "61593": 57, "68701": 57, "36608": 57, "37078": 57, "37826": 57, "87778": 57, "33051": 57, "30581": 57, "38294": 57, "52823": 57, "08891": 57, "80512": 57, "22812": 57, "36809": 57, "38976": 57, "15537": 57, "27078": 57, "float6419": 57, "07arrai": 57, "9922": 57, "3422": 57, "4787": 57, "5616": 57, "3612": 57, "3301": 57, "2128": 57, "9165": 57, "9441": 57, "5362": 57, "5644": 57, "7573": 57, "2453": 57, "2903": 57, "8039": 57, "0338": 57, "6761": 57, "7705": 57, "1302": 57, "1052": 57, "1311": 57, "5695": 57, "6351": 57, "0655": 57, "float640": [57, 58, 59], "05535arrai": 57, "0500194": 57, "049159": 57, "0488312": 57, "0686739": 57, "0650993": 57, "0612367": 57, "0616795": 57, "0591138": 57, "0590177": 57, "0570248": 57, "0569334": 57, "0563149": 57, "065594": 57, "0578358": 57, "05951": 57, "0587069": 57, "059966": 57, "0532751": 57, "0619955": 57, "0584618": 57, "0551539": 57, "0569168": 57, "056705": 57, "0553542": 57, "6305arrai": 57, "570748": 57, "581394": 57, "580663": 57, "701103": 57, "694826": 57, "652913": 57, "683638": 57, "664259": 57, "670896": 57, "640091": 57, "640559": 57, "641301": 57, "688222": 57, "636539": 57, "634055": 57, "641766": 57, "655928": 57, "611608": 57, "681705": 57, "626147": 57, "640292": 57, "642441": 57, "61861": 57, "630507": 57, "float641": [57, 58, 59, 67], "257arrai": 57, "30086": 57, "3084": 57, "3113": 57, "16321": 57, "18642": 57, "21299": 57, "20986": 57, "22831": 57, "22902": 57, "24394": 57, "24463": 57, "24938": 57, "18314": 57, "2378": 57, "22541": 57, "23131": 57, "2221": 57, "27348": 57, "20764": 57, "23313": 57, "25842": 57, "24476": 57, "24638": 57, "25685": 57, "chainpandasindexpandasindex": [57, 58, 59, 67, 72], "dtype": [57, 58, 59, 67, 72], "x27": [57, 58, 59, 67, 72], "drawpandasindexpandasindex": [57, 58, 59, 67, 72], "990": [57, 58, 59, 67, 72], "991": [57, 58, 59, 67, 72], "992": [57, 58, 59, 67, 72], "00arviz_vers": [57, 58, 59, 72], "0inference_librari": [57, 58, 59, 72], "cmdstanpyinference_library_vers": [57, 58, 59, 72], "puls": 57, "plot_scatt": 57, "bin": [57, 61, 63], "rug": [57, 61, 63], "foolishli": 57, "grab": [57, 83], "arang": [57, 59, 63, 84], "251": [57, 87], "flatten": [57, 58, 59, 63, 68, 75, 78, 81, 82, 87, 90], "zip": [57, 59, 63, 64, 80, 84, 89, 90], "nbinom": [57, 59], "x_plot": [57, 59], "y_plot": [57, 59], "cdf_to_staircas": [57, 59], "underlai": [57, 59], "425": 57, "426": 57, "amazon": 58, "julia": 58, "matlab": 58, "stata": 58, "dive": 58, "disk": 58, "seven": [58, 67], "intend": 58, "ventur": 58, "friend": 58, "guid": [58, 91], "manual": [58, 59, 67], "static": [58, 60], "semicolon": 58, "curli": 58, "prepar": [58, 78, 92], "favorit": [58, 63], "editor": 58, "groundwork": 58, "hello_world": 58, "bebi103_cours": 58, "2025": [58, 59], "08": [58, 59, 78, 80, 87, 92], "ex": 58, "43": [58, 59], "iter": [58, 59, 61, 67, 68, 70, 72, 75, 78, 79, 80, 81, 83, 84, 86, 87, 90], "44": [58, 80, 87], "job": [58, 84], "cmdstanmcmc": 58, "num_sampl": 58, "engag": [58, 87], "csv_file": 58, "var": [58, 80, 87, 90], "j_": [58, 87], "c5r9ch0913v3h1w4bdwzm0lh0000gn": [58, 87], "tmpvzktutt3": 58, "hello_worldg4sdgzab": 58, "20240719161944_1": 58, "20240719161944_2": 58, "20240719161944_3": 58, "20240719161944_4": 58, "output_fil": 58, "20240719161944_0": 58, "pronounc": 58, "rv": [58, 90], "recreat": 58, "vehicl": 58, "40kb": 58, "6374": 58, "5841": 58, "5403": 58, "6269": 58, "542659": 58, "6269arrai": 58, "637411": 58, "58407": 58, "302226": 58, "474132": 58, "962219": 58, "03972": 58, "75933": 58, "254514": 58, "365888": 58, "96866": 58, "20111": 58, "82037": 58, "477287": 58, "556766": 58, "32425": 58, "55547": 58, "494835": 58, "364278": 58, "015963": 58, "141604": 58, "35541": 58, "39819": 58, "540314": 58, "626918": 58, "sample_stat": [58, 59, 67], "204kb": [58, 59], "acceptance_r": [58, 59], "9468": 58, "8258": 58, "9861": 58, "9895": 58, "4kb": [58, 59, 67], "5121": 58, "564": [58, 67], "1502": 58, "215": 58, "2031": 58, "1706": 58, "1965": 58, "step_siz": [58, 59], "015": 58, "tree_depth": [58, 59, 67], "549548": 58, "9895arrai": 58, "946755": 58, "82582": 58, "998086": 58, "91481": 58, "689701": 58, "794211": 58, "991144": 58, "725178": 58, "979043": 58, "928644": 58, "989108": 58, "945146": 58, "757333": 58, "998694": 58, "864913": 58, "978766": 58, "99792": 58, "791233": 58, "982238": 58, "986148": 58, "989484": 58, "boolfals": [58, 59], "falsearrai": [58, 59, 67], "139": [58, 78], "215arrai": 58, "512115": 58, "56356": 58, "138952": 58, "137244": 58, "462933": 58, "42688": 58, "55296": 58, "33155": 58, "0698188": 58, "39816": 58, "793701": 58, "70602": 58, "858483": 58, "6095": 58, "70213": 58, "43293": 58, "44248": 58, "113932": 58, "07941": 58, "0126613": 58, "4355": 58, "107657": 58, "150176": 58, "214951": 58, "146": 58, "1965arrai": 58, "03146e": 58, "70569e": 58, "56703e": 58, "12401e": 58, "62933e": 58, "40512e": 58, "54763e": 58, "23887e": 58, "69369e": 58, "69151e": 58, "21337e": 58, "65687e": 58, "13902e": 58, "54994e": 58, "70108e": 58, "20974e": 58, "22431e": 58, "63494e": 58, "27409e": 58, "00259e": 58, "18573e": 58, "92776e": 58, "45970e": 58, "96513e": 58, "int643": [58, 59], "1arrai": [58, 59, 67], "0arrai": [58, 59], "01508": 58, "07811": 58, "841159": 58, "00025": 58, "int641": 58, "group": [58, 59, 69, 78, 90], "dataarrai": [58, 59, 65, 67], "panda": [58, 59, 67, 82, 87, 90], "interestingli": [58, 61], "arbitrarili": 58, "multidimension": [58, 61, 72, 81, 83], "999xarrai": [58, 67], "3022": 58, "2444": 58, "01371": 58, "3982": 58, "togeth": [58, 73, 75, 77, 78, 81, 82], "np_sampl": 58, "sp_sampl": 58, "staircas": [58, 75], "palett": [58, 63, 75], "b_glasbey_category10": 58, "normal_rng": [58, 64, 65, 70, 80, 81, 83, 84, 86, 87], "sm_rng": 58, "norm_rng": 58, "mote": 58, "fixed_param": [58, 64, 80, 81], "stan_sampl": 58, "novel": 58, "occasion": [58, 64], "visibl": [58, 63, 75], "netcdf": 58, "to_netcdf": 58, "stan_hello_world": 58, "nc": 58, "from_netcdf": 58, "hpp": 58, "exit": 58, "delet": [58, 84], "outpur_dir": 58, "selector": [59, 87], "unimod": 59, "alpha_1": 59, "beta_1": 59, "beta_2": 59, "burst": [59, 66, 67, 80], "concis": 59, "retain": [59, 66, 87], "alpha_i": 59, "b_i": 59, "beta_i": 59, "hood": 59, "summand": [59, 69], "a_1": [59, 84], "a_2": 59, "a_i": 59, "stabl": [59, 69, 81, 82, 86], "log_mix": [59, 72], "keyword": [59, 86], "n_val": [59, 72], "neg_binomial_lupmf": 59, "negative_binomial_lpmf": 59, "_lpmf": [59, 72], "_lpdf": [59, 72], "_lupmf": 59, "_lupdf": 59, "signifi": 59, "wise": [59, 82], "vvector": 59, "log10_beta": 59, "front": 59, "slash": 59, "elementwis": 59, "smart": 59, "enclos": [59, 64], "inclus": [59, 81], "3252": [59, 63, 67, 68, 72, 78, 87], "360kb": 59, "log10_alpha_dim_0": 59, "log10_b_dim_0": 59, "alpha_dim_0": [59, 72], "b_dim_0": [59, 72], "beta__dim_0": 59, "16b": 59, "64kb": 59, "3836": 59, "8141": 59, "2084": 59, "1713": 59, "8397": 59, "419": [59, 67], "769": [59, 67], "517": 59, "078": 59, "1534": 59, "1238": 59, "01t23": 59, "481192": 59, "5xarrai": 59, "1000log10_alpha_dim_0": 59, "2log10_b_dim_0": 59, "2alpha_dim_0": 59, "2b_dim_0": 59, "2beta__dim_0": 59, "2coordin": 59, "7601": 59, "7117": 59, "2476arrai": 59, "383558": 59, "76015": 59, "318055": 59, "776362": 59, "632581": 59, "698278": 59, "434909": 59, "624682": 59, "317887": 59, "665548": 59, "474134": 59, "690187": 59, "793154": 59, "172747": 59, "771194": 59, "17953": 59, "723434": 59, "439665": 59, "735731": 59, "43064": 59, "701591": 59, "475074": 59, "718137": 59, "456976": 59, "731085": 59, "592183": 59, "636089": 59, "610418": 59, "514078": 59, "745703": 59, "376068": 59, "706137": 59, "238429": 59, "771948": 59, "465333": 59, "79383": 59, "670008": 59, "783871": 59, "67299": 59, "847895": 59, "69092": 59, "58087": 59, "626073": 59, "519294": 59, "655079": 59, "650985": 59, "711708": 59, "247645": 59, "468": 59, "917": 59, "485": 59, "9073arrai": 59, "814061": 59, "46776": 59, "91696": 59, "45494": 59, "487664": 59, "5125": 59, "69554": 59, "58669": 59, "839242": 59, "55029": 59, "712321": 59, "52555": 59, "44958": 59, "10039": 59, "42929": 59, "1812": 59, "50267": 59, "790429": 59, "48496": 59, "768569": 59, "51188": 59, "683075": 59, "48368": 59, "801915": 59, "319508": 59, "65369": 59, "445748": 59, "57301": 59, "751932": 59, "49101": 59, "839428": 59, "49077": 59, "945245": 59, "44738": 59, "784991": 59, "42668": 59, "51651": 59, "229926": 59, "5146": 59, "264802": 59, "50987": 59, "524788": 59, "59825": 59, "67355": 59, "54787": 59, "510542": 59, "48518": 59, "907301": 59, "8296": 59, "8397arrai": 59, "208442": 59, "17129": 59, "162889": 59, "144711": 59, "163428": 59, "163456": 59, "77109": 59, "764797": 59, "849972": 59, "838438": 59, "818635": 59, "835604": 59, "132839": 59, "122035": 59, "200187": 59, "184432": 59, "1527": 59, "213495": 59, "90327": 59, "86866": 59, "910199": 59, "851003": 59, "829587": 59, "839727": 59, "float642": 59, "756": 59, "149": [59, 67], "769arrai": 59, "41857": 59, "75639": 59, "07996": 59, "97533": 59, "29122": 59, "99203": 59, "72213": 59, "21388": 59, "07916": 59, "62965": 59, "97944": 59, "8999": 59, "21089": 59, "48849": 59, "90465": 59, "51193": 59, "28973": 59, "75211": 59, "44166": 59, "6955": 59, "03027": 59, "98589": 59, "22561": 59, "86402": 59, "38375": 59, "91005": 59, "32602": 59, "07773": 59, "26647": 59, "56805": 59, "37721": 59, "0832": 59, "73152": 59, "91491": 59, "91966": 59, "22057": 59, "67743": 59, "07955": 59, "70966": 59, "04522": 59, "90818": 59, "80952": 59, "22739": 59, "30594": 59, "51939": 59, "47698": 59, "14882": 59, "76866": 59, "float646": 59, "56": [59, 84], "078arrai": 59, "5172": 59, "3605": 59, "25962": 59, "5065": 59, "07372": 59, "5459": 59, "96067": 59, "6088": 59, "90625": 59, "5054": 59, "1561": 59, "5392": 59, "1566": 59, "6005": 59, "8716": 59, "1776": [59, 87], "8178": 59, "17205": 59, "5465": 59, "86907": 59, "5001": 59, "82031": 59, "4565": 59, "33745": 59, "08693": 59, "0493": 59, "79093": 59, "4116": 59, "64849": 59, "9752": 59, "9092": 59, "9577": 59, "81546": 59, "014": [59, 67, 87], "09524": 59, "7102": 59, "8484": 59, "69796": 59, "7042": 59, "83993": 59, "34802": 59, "6507": 59, "71574": 59, "3079": 59, "23998": 59, "5617": 59, "07795": 59, "03406": 59, "03272": 59, "1238arrai": 59, "15344": 59, "0340593": 59, "121071": 59, "0350797": 59, "325339": 59, "0307258": 59, "201586": 59, "0259008": 59, "144796": 59, "0281647": 59, "193945": 59, "0298159": 59, "0355156": 59, "0793619": 59, "0372139": 59, "0658866": 59, "031429": 59, "162021": 59, "032737": 59, "170385": 59, "0307691": 59, "207456": 59, "0328337": 59, "157792": 59, "479173": 59, "0221979": 59, "358304": 59, "0267297": 59, "177038": 59, "0322839": 59, "144735": 59, "0323021": 59, "113437": 59, "0356964": 59, "164062": 59, "0374389": 59, "0304428": 59, "588944": 59, "0305771": 59, "543498": 59, "0309119": 59, "298684": 59, "0252202": 59, "212056": 59, "0283223": 59, "308644": 59, "0327207": 59, "123794": 59, "log10_alpha_dim_0pandasindexpandasindex": 59, "log10_b_dim_0pandasindexpandasindex": 59, "alpha_dim_0pandasindexpandasindex": 59, "b_dim_0pandasindexpandasindex": 59, "beta__dim_0pandasindexpandasindex": 59, "597e": 59, "03": [59, 67, 72, 87, 92], "598e": 59, "9272": 59, "9948": 59, "9495": 59, "9129": 59, "09361": 59, "1234": 59, "63": [59, 78, 87], "601e": 59, "483368": 59, "03arrai": [59, 67], "1596": 59, "65": [59, 78, 87], "1595": 59, "46": [59, 87], "1597": 59, "1599": 59, "81": 59, "1602": 59, "1598": 59, "74": [59, 78, 87], "1601": 59, "9129arrai": 59, "927232": 59, "994825": 59, "903361": 59, "936047": 59, "979267": 59, "989478": 59, "809944": 59, "987703": 59, "915043": 59, "999915": 59, "848044": 59, "706127": 59, "819151": 59, "937766": 59, "969471": 59, "983138": 59, "996052": 59, "981441": 59, "991736": 59, "990876": 59, "94946": 59, "912856": 59, "1234arrai": 59, "0936073": 59, "144739": 59, "118046": 59, "123407": 59, "5arrai": 59, "int6415": 59, "51arrai": 59, "47": [59, 78, 80], "87": [59, 67], "62": [59, 67], "53": [59, 67, 78, 84, 87], "1600": [59, 87], "88": [59, 72, 90], "09": [59, 67, 92], "1606": 59, "1605": 59, "82": 59, "83": 59, "1604": 59, "futur": [59, 61, 67, 68], "doc": 59, "478": 59, "184b": 59, "8b": [59, 67], "4777": 59, "6959": 59, "6956": 59, "518": 59, "1779": 59, "004": 59, "964": 59, "962": 59, "0303": 59, "int642arrai": 59, "int64478arrai": 59, "6959arrai": 59, "477727": 59, "695863": 59, "518arrai": 59, "695619": 59, "5185": 59, "1779arrai": 59, "177928": 59, "964arrai": 59, "00419": 59, "96436": 59, "float644": 59, "96157": 59, "9987": 59, "0303arrai": 59, "201549": 59, "0303042": 59, "1xarrai": 59, "int641arrai": 59, "scalar": [59, 82, 83, 90], "to_datafram": 59, "from_panda": [59, 87], "include_index": 59, "chaindrawlog10_alpha_dim_0log10_b_dim_0alpha_dim_0b_dim_0beta__dim_0log10_alphalog10_bwalphabbeta_i64i64i64i64i64i64i64f64f64f64f64f64f6400000000": 59, "3835580": 59, "8140610": 59, "2084422": 59, "418576": 59, "51720": 59, "1534400000010": 59, "034059300000100": 59, "4185729": 59, "36050": 59, "1534400000110": 59, "034059300001000": 59, "2084425": 59, "756396": 59, "cumbersom": [59, 69, 83], "arviz_to_datafram": [59, 61], "df_mcmc": [59, 61], "walpha": 59, "chain__draw__diverging__f64f64f64f64f64f64f64f64f64f64f64i64i64bool0": 59, "760150": 59, "8140611": 59, "467760": 59, "418575": 59, "517229": 59, "153440": 59, "034059300false0": 59, "3180550": 59, "7763620": 59, "916961": 59, "454940": 59, "171292": 59, "079965": 59, "975338": 59, "2596228": 59, "50650": 59, "1210710": 59, "035079701false0": 59, "6325810": 59, "6982780": 59, "4876641": 59, "51250": 59, "1628894": 59, "291224": 59, "992033": 59, "0737232": 59, "54590": 59, "3253390": 59, "030725802false0": 59, "4557490": 59, "7081540": 59, "6870931": 59, "499740": 59, "1324032": 59, "855945": 59, "106864": 59, "8651131": 59, "60350": 59, "2055450": 59, "031642103false0": 59, "3010130": 59, "7127020": 59, "8691321": 59, "497520": 59, "137341": 59, "999925": 59, "160627": 59, "398331": 59, "44250": 59, "1351660": 59, "031804104fals": 59, "chain__": 59, "draw__": 59, "diverging__": 59, "par": 59, "\u03b1\u2081": 59, "\u03b1\u2082": 59, "b\u2081": 59, "b\u2082": 59, "peculiar": 59, "reveal": 59, "glyph": [59, 61], "id": [59, 87], "color_by_chain": 59, "green": 59, "uncov": [59, 79, 80], "observation": 59, "emphas": [59, 67, 81], "devilish": 59, "vigil": 59, "b_1": 59, "b_2": 59, "overlap": [59, 69, 82], "filter": [59, 63, 83], "col": [59, 63, 80, 81, 82, 83, 84, 86], "renam": [59, 90], "with_column": [59, 63, 80, 81, 82, 84, 86], "alia": [59, 63, 80, 81, 82, 84, 86], "df_switch": 59, "concat": 59, "alon": [59, 64], "param_mean": 59, "f64f64f64f64f64f64f64f64f64f64f640": 59, "72730": 59, "4500451": 59, "4858760": 59, "7563780": 59, "8270435": 59, "3899333": 59, "04777830": 59, "8696536": 59, "6347030": 59, "0329470": 59, "204229": 59, "init": [59, 72, 87], "unconstrain": 59, "warmup": 59, "advis": 59, "hoc": [59, 66], "alpha0": 59, "alpha1": 59, "beta0": 59, "beta1": 59, "fragil": 59, "closer": [59, 64, 69, 70, 72, 87], "departur": [60, 87], "sacrific": 60, "largest": 60, "smallest": 60, "uncomfort": 60, "millimet": 60, "gamma_": [60, 61, 64, 65, 70, 87, 90], "denom_ratio": [60, 61, 64, 65, 70, 87], "log10_phi": [60, 61], "syntact": 60, "parenthes": 60, "plane": 60, "plot_ecdf": [60, 61], "depict": [60, 78], "eschew": 60, "promis": 61, "quickli": [61, 63, 89], "aesthet": 61, "trajectori": [61, 67], "trace_plot": 61, "plot_": 61, "backend": 61, "plot_trac": 61, "kde": 61, "bandwidth": 61, "dan": 61, "minimum": [61, 66], "plot_parallel": 61, "var_nam": [61, 80], "norm_method": 61, "minmax": [61, 78], "parcoord": [61, 68, 78], "neck": 61, "vice": 61, "versa": 61, "plot_dens": 61, "highest": [61, 63], "hpd": [61, 63], "shortest": [61, 63], "backend_kwarg": 61, "bokehdeprecationwarn": 61, "deprec": 61, "remov": [61, 68, 69, 78, 84], "gamma_log10_phiphisigmachain__draw__diverging__f64f64f64f64i64i64bool0": 61, "8760751": 61, "5813638": 61, "13823": 61, "7229800false0": 61, "8695911": 61, "5794137": 61, "96693": 61, "7328201false0": 61, "8521091": 61, "5858338": 61, "53243": 61, "803702false0": 61, "8800941": 61, "5797237": 61, "99453": 61, "7278603false0": 61, "8934751": 61, "5709837": 61, "23743": 61, "7522504fals": 61, "hist": 61, "transpar": 61, "plot_pair": 61, "scatter_kwarg": 61, "fill_alpha": [61, 80], "radius_unit": 61, "represent": 61, "uni": 61, "hex": 61, "hexbin": 61, "xtick_label_orient": [61, 65, 70, 72, 75, 78], "beauti": [63, 69, 73], "lie": [63, 64, 65, 70], "plu": [63, 81, 86], "5th": [63, 67], "percentil": [63, 64, 65, 67, 70, 75], "97": [63, 78, 87, 90], "hdi": 63, "tail": [63, 64, 66, 67, 68, 72, 78, 82], "sigma_2": [63, 66], "x_expon": 63, "15000": 63, "x_norm": 63, "which_norm": 63, "x_2norm": 63, "pareto": [63, 69, 72], "x_heavytail": 63, "readili": [63, 82], "trace": [63, 67, 68], "df_summari": 63, "hpd_low": 63, "hpd_high": 63, "schema": 63, "dist": 63, "concaten": [63, 84], "hdi_prob": 63, "statisticexponentialnormaltwo": 63, "normalsheavi": 63, "tailstrf64f64f64f64": 63, "quot": [63, 78, 80], "0078431": 63, "0014472": 63, "0040054": 63, "134071": 63, "0053510": 63, "249141": 63, "0738544": 63, "580247": 63, "0248750": 63, "5115520": 63, "5904380": 63, "02307": 63, "7010921": 63, "0006981": 63, "7679750": 63, "79814": 63, "6495411": 63, "492053": 63, "80497720": 63, "613608": 63, "0000880": 63, "5318630": 63, "5613620": 63, "000057": 63, "9965491": 63, "5073143": 63, "75565311": 63, "296449": 63, "y_valu": 63, "category10": [63, 75], "plot_interv": 63, "barx": 63, "is_in": 63, "asymmetri": 63, "finder": 63, "uniniti": 63, "suffer": 63, "interquantil": 63, "modal": [63, 90], "mislead": 63, "futil": 63, "deceiv": 63, "chanc": [63, 67], "reeeealli": 63, "71": 63, "struggl": 64, "symptom": [64, 78], "produc": [64, 65, 69, 79, 82], "obei": 64, "cytoplasm": 64, "embryogenesi": 64, "colleagu": 64, "regress": [64, 65, 71, 81], "hone": 64, "670": [64, 65, 70], "uniformli": [64, 79, 80], "inher": [64, 67, 81], "resid": 64, "e_i": 64, "compon": [64, 90], "datum": [64, 69, 90], "establish": 64, "sound": 64, "varieti": [64, 72], "uncertain": [64, 69], "irrelev": [64, 82], "ey": [64, 65, 72, 82, 83], "nonposit": 64, "vanish": 64, "unrealist": 64, "ultim": [64, 66, 78, 80], "jettison": 64, "halfnorm_pdf": 64, "350": [64, 81, 82, 83, 84], "lognorm_pdf": 64, "n_ppc_sampl": 64, "ab": [64, 68, 80, 88, 90], "ph": [64, 81], "sig": 64, "thin": [64, 75], "20th": 64, "ell_val": 64, "line_alpha": [64, 68, 80], "predictive_ecdf": [64, 65, 70, 72, 80], "n_": [64, 67, 84], "middl": [64, 65, 70, 87], "darker": 64, "fill": 64, "68": [64, 67, 78, 87], "extent": 64, "willing": 64, "toler": [64, 82, 90], "tug": 64, "substanti": [64, 68, 79, 87], "059903": 64, "linearli": 64, "gamma_pdf": 64, "\u03c3\u2080": 64, "settl": 64, "clearer": [64, 80, 87], "_rng": 64, "lognormal_rng": 64, "gamma_rng": [64, 80], "tweak": 64, "recompil": 64, "phi_mu": 64, "phi_sigma": 64, "sigma_0_alpha": 64, "sigma_0_beta": 64, "sm_prior_pr": [64, 80], "indep_size_model_prior_predict": 64, "alert": [64, 89], "parallel": [64, 67, 68, 78], "prior_predict": [64, 80, 81], "reshap": [64, 65, 90], "2d": 64, "verbos": 64, "hing": 64, "polymer": 64, "assembli": 64, "balanc": 64, "t_0": 64, "t_1": 64, "t_": [64, 82], "gg": [64, 70], "l_": 64, "mt": 64, "unimport": 64, "geometri": 64, "nmol": 64, "ccl": 64, "assur": 64, "prolat": 64, "spheroid": 64, "spheric": 64, "microscop": [64, 66, 78], "spectroscop": 64, "vitro": 64, "2t_": 64, "distinguish": [64, 73], "ones": [64, 67, 80, 82, 83, 87], "lest": [64, 67], "unidentifi": 64, "dire": 64, "commensur": [64, 65, 66, 69], "enhanc": 64, "strive": [64, 89], "didn": [64, 80, 81], "slight": [64, 77], "baselin": 64, "continuum": 64, "basi": [64, 81], "gamma_alpha": 64, "gamma_beta": 64, "beta_rng": 64, "cons_tubulin_model_prior_predict": 64, "span": [64, 72], "predictive_regress": [64, 65, 70, 81, 82, 83, 84, 86, 87], "30th": 64, "60th": 64, "90th": 64, "99th": [64, 65, 70], "samples_x": [64, 65, 70, 81], "javascript": 64, "slider": [64, 78], "draw_slid": 64, "data_dict": 64, "str": [64, 90], "sel": [64, 72, 75], "cd": 64, "columndatasourc": [64, 90], "params_dict": 64, "squeez": [64, 80], "cds_param": 64, "div": 64, "js_code": 64, "cb_obj": 64, "tostr": 64, "toprecis": 64, "emit": 64, "customj": 64, "js_on_chang": 64, "spacer": 64, "encompass": [64, 79, 80, 81, 82], "replot": 64, "heavili": [64, 79, 87], "coupl": [64, 65, 81], "examin": 64, "mayb": [64, 66, 81], "relax": 64, "spindle_volum": 64, "vol_ratio": 64, "ul": 64, "v0": 64, "nonconst": 64, "highlight": [64, 65, 87], "ell_ppc": [65, 70, 87], "indep_size_model": 65, "posterior_predict": [65, 70, 72, 80, 81, 83, 84, 86], "n_sampl": 65, "stack": [65, 67, 70, 72, 80, 81, 82, 83, 84, 86, 90], "collaps": 65, "transpos": [65, 70, 72, 80, 81, 82, 83, 84, 86], "ell_ppc_dim_0": [65, 70], "diff": [65, 70, 80], "vstack": [65, 81], "trend": 65, "envelop": [65, 79, 80, 81, 82], "n_ppc": [65, 70, 72, 80, 81, 87], "d_ppc": [65, 70, 87], "mu_ppc": [65, 70, 87], "cons_tubulin_model": 65, "lost": 65, "former": 65, "shelf": 66, "oftentim": 66, "pare": 66, "pixel": 66, "interpixel": 66, "optic": [66, 83], "digit": 66, "camera": 66, "simplifi": 66, "fourth": 66, "symmetri": 66, "s_": [66, 81], "sigma_1": [66, 90], "c_": 66, "rho": [66, 81, 82, 83, 84, 86], "lkj": 66, "rethink": [66, 91], "underpin": 66, "inappropri": 66, "inclin": 66, "depart": 66, "inadequ": 66, "adequ": [66, 80], "lightest": 66, "heaviest": 66, "cauchi": 66, "distirbut": 66, "heavier": 66, "opposit": [66, 78], "slower": 66, "log10_v": 66, "reproduc": [67, 89], "rhat": [67, 68, 70, 72, 75, 78, 80, 81, 83, 84, 86], "40b": 67, "007": 67, "007xarrai": 67, "007arrai": 67, "00714323": 67, "00676445": 67, "00684101": 67, "00707471": 67, "00687351": 67, "sd": 67, "hdi_3": 67, "hdi_97": 67, "mcse_mean": 67, "mcse_sd": 67, "ess_bulk": 67, "ess_tail": 67, "r_hat": 67, "521": 67, "398": [67, 87], "266": 67, "010": 67, "797": 67, "679": 67, "706": 67, "056": 67, "040": [67, 87], "763": 67, "709": 67, "060": 67, "006": [67, 72, 87], "049": 67, "070": 67, "654": 67, "038": [67, 87], "576": 67, "221": 67, "142": 67, "295": 67, "samples_limited_warmup": 67, "iter_warmup": [67, 80, 81], "018": [67, 87], "69": [67, 78, 87], "876": 67, "119": [67, 78], "151": 67, "729": 67, "798": 67, "644": 67, "31633592": 67, "252": 67, "091": 67, "299": 67, "683": 67, "486": 67, "734": 67, "293": 67, "241": 67, "114": 67, "714": 67, "841": 67, "059": 67, "321": 67, "868": 67, "327": 67, "925": 67, "181": [67, 87], "661": 67, "506": [67, 84], "272": [67, 72], "395": 67, "314": 67, "866": [67, 87], "695": 67, "532": 67, "poor": [67, 68, 80], "rejec": 67, "caveat": 67, "ideal": [67, 80], "ess": [67, 68, 72, 78, 80], "eff": 67, "prescript": [67, 81], "4000": [67, 68, 70, 72, 75, 78, 80, 81, 83, 84, 86, 87], "500": [67, 87, 90], "ess_mean": 67, "ess_sd": 67, "land": 67, "mcse": 67, "msce_mean": 67, "accur": 67, "wonder": 67, "curvatur": [67, 68], "veer": 67, "sharpli": [67, 69, 73], "regist": 67, "1000fals": 67, "improperli": 67, "3002": 67, "yike": 67, "endem": 67, "sciencei": 67, "unfamiliar": 67, "recurs": 67, "en": 67, "org": 67, "recursion_": 67, "computer_sci": 67, "deep": [67, 68], "cap": 67, "wrong": 67, "10003": 67, "decreas": [67, 68, 81], "ineffici": 67, "1379": 67, "1378": 67, "1377": 67, "98": 67, "1381": 67, "76": [67, 78, 87], "1380": 67, "58": [67, 78, 87], "1383": 67, "1382": 67, "72": [67, 72, 78, 87], "78": [67, 72], "10001": 67, "379e": 67, "38e": 67, "nope": 67, "wrote": [67, 69, 89], "submodul": 67, "check_all_diagnost": [67, 68, 70, 72, 75, 78, 80, 81, 83, 84, 86], "satur": [67, 68, 70, 72, 75, 78, 80, 81, 83, 84, 86], "forthcom": 68, "hack": 68, "probabilti": 68, "thoma": 68, "wiecki": 68, "microinject": 68, "tip": [68, 89], "radford": 68, "neal": 68, "girolami": 68, "450": [68, 78, 81, 90], "66c2a5": 68, "indep": 68, "bottom_left": 68, "2509935801914": 68, "17582178946987": 68, "061082354895177": 68, "103015323352217": 68, "483": 68, "075": 68, "tree": [68, 70, 72, 75, 78, 80, 81, 83, 84, 86], "bfmi": [68, 70, 72, 75, 78, 80, 81, 83, 84, 86], "trust": 68, "hide": [68, 78], "fc8d62": 68, "click_polici": [68, 78], "penetr": 68, "correctli": 68, "awar": [68, 80], "clue": 68, "stuck": 68, "log10": 68, "divergence_kwarg": 68, "advic": [68, 87], "messag": [68, 87, 89], "crank": 68, "8da0cb": 68, "335": 68, "8697624482687": 68, "188": [68, 87], "9130440674577": 68, "123": 68, "79148039281294": 68, "109": 68, "7300569471941": 68, "0225440084677622": 68, "028248959476883": 68, "825": 68, "5103845064002706": 68, "3791047493010087": 68, "6261488838631215": 68, "28202314605045126": 68, "shy": [68, 72], "tild": [68, 69, 72, 78, 79, 82, 84], "uncent": [68, 78, 79, 81, 82, 83, 84, 86, 92], "henc": [68, 78], "theta_tild": 68, "bother": [68, 69, 80], "funnel_noncent": 68, "excel": [68, 79, 80, 82], "No": [68, 89, 92], "e78ac3": 68, "spent": [69, 89], "theta_m": [69, 81], "g_m": 69, "f_m": 69, "eq": 69, "model_bay": 69, "f_t": [69, 72], "digest": 69, "overli": 69, "reduct": 69, "p_i": 69, "haven": 69, "pope": 69, "cathol": 69, "improb": 69, "garner": 69, "p_ip_j": 69, "p_j": 69, "addabl": 69, "tradit": 69, "ensembl": 69, "surpris": [69, 84], "shannon": [69, 87], "thermodynam": 69, "delv": 69, "rich": 69, "knew": 69, "unbias": 69, "shortcut": 69, "1948": 69, "claud": [69, 89], "desiderata": 69, "composit": 69, "law": [69, 81], "extend": [69, 89], "cross": [69, 72], "q_i": [69, 87], "govern": [69, 77, 78], "kl": [69, 87, 90], "d_": [69, 87, 90], "sum_ip_i": 69, "m_a": 69, "m_b": 69, "awkward": 69, "_i": [69, 72, 79, 81, 83, 84], "nf_m": 69, "elppd": 69, "lpd": 69, "lppd": 69, "_j": [69, 72, 81], "_t": 69, "overestim": [69, 79, 87], "discrep": [69, 79], "p_": [69, 72], "gabri": [69, 72], "arxiv": [69, 72], "therein": 69, "incred": 69, "histor": [69, 72], "held": 69, "remain": [69, 82, 87, 89], "pleasant": 69, "expens": [69, 79, 87], "pacakg": 69, "criteria": [69, 70, 72], "m_i": 69, "m_j": 69, "w_i": [69, 72], "plai": 69, "immens": 69, "invis": 69, "log_lik": [70, 72], "normal_lpdf": 70, "sm_indep": 70, "indep_s": 70, "sm_con": 70, "cons_tubulin": 70, "samples_indep": 70, "samples_con": 70, "ic": [70, 72], "devianc": [70, 72, 81], "elpd_loo": [70, 72], "p_loo": [70, 72], "elpd_diff": [70, 72], "se": [70, 72, 81, 82, 83, 84, 86], "dse": [70, 72], "3662": 70, "643494": 70, "260725": 70, "000000": [70, 72], "354190": 70, "00000": 70, "4003": 70, "001053": 70, "950445": 70, "340": 70, "357559": 70, "379594": 70, "52863": 70, "elpd": 72, "kullback": [72, 87, 90], "leibler": [72, 87, 90], "watanab": 72, "akaik": 72, "criterion": 72, "terribli": 72, "prospect": 72, "straightforward": [72, 73, 78, 90], "easiest": [72, 78, 82], "scientist": [72, 89], "aim": [72, 81], "yao": 72, "pure": [72, 81, 83], "academ": 72, "spectacularli": 72, "neg_binomial_rng": [72, 80], "neg_binom": 72, "doesn": 72, "n_ppc_dim_0": [72, 80], "9mb": 72, "log_lik_dim_0": 72, "2kb": 72, "274": 72, "275": 72, "276": 72, "277": 72, "278": 72, "24t05": 72, "208975": 72, "1000log_lik_dim_0": 72, "279coordin": 72, "278arrai": 72, "871": 72, "571": 72, "006arrai": 72, "9195": 72, "87102": 72, "68695": 72, "26063": 72, "48547": 72, "87587": 72, "86585": 72, "88487": 72, "24419": 72, "48612": 72, "91271": 72, "66727": 72, "93771": 72, "63568": 72, "34274": 72, "58902": 72, "79424": 72, "68369": 72, "92896": 72, "68832": 72, "29315": 72, "55258": 72, "86131": 72, "83427": 72, "8913": 72, "70419": 72, "25863": 72, "50083": 72, "89138": 72, "72091": 72, "92151": 72, "6401": 72, "32705": 72, "56721": 72, "8041": 72, "69304": 72, "9281": 72, "75358": 72, "24444": 72, "5209": 72, "94195": 72, "63444": 72, "94668": 72, "80166": 72, "22269": 72, "52082": 72, "99609": 72, "90389": 72, "8773": 72, "59252": 72, "33818": 72, "53827": 72, "75795": 72, "83866": 72, "892": 72, "73364": 72, "23837": 72, "48808": 72, "92752": 72, "44289": 72, "99838": 72, "74154": 72, "30305": 72, "61111": 72, "90777": 72, "69926": 72, "9251": 72, "67632": 72, "29999": 72, "55376": 72, "84761": 72, "72413": 72, "91933": 72, "65612": 72, "3123": 72, "5567": 72, "82437": 72, "47554": 72, "99033": 72, "81682": 72, "24099": 72, "56584": 72, "0027": 72, "65642": 72, "93676": 72, "68018": 72, "30494": 72, "56586": 72, "84914": 72, "7639": 72, "90806": 72, "69262": 72, "2766": 72, "52578": 72, "87242": 72, "91387": 72, "87357": 72, "60488": 72, "32544": 72, "52772": 72, "77417": 72, "45548": 72, "99638": 72, "82115": 72, "2423": 72, "57115": 72, "00638": 72, "log_lik_dim_0pandasindexpandasindex": 72, "269": 72, "270": 72, "273": 72, "tradition": 72, "deviance_wa": 72, "3281": 72, "p_waic": 72, "single_loo": 72, "deviance_loo": 72, "pct": 72, "wider": 72, "_logpmf": 72, "uniform_rng": 72, "sm_mix": 72, "neg_binom_mix": 72, "samples_mix": 72, "004040383981042": 72, "318": 72, "7069921736581": 72, "836302265033044": 72, "2393686900295": 72, "432640073574931": 72, "12692598049735": 72, "210628341260978": 72, "183": [72, 87], "7239430399982": 72, "432641423716465": 72, "12692598048358": 72, "210629331032064": 72, "72394304000517": 72, "1460975400222795": 72, "170": [72, 87], "8943375375399": 72, "3240338139575638": 72, "3286803456589167": 72, "6654700530731357": 72, "72055885067414": 72, "665470122994841": 72, "7205589366050218": 72, "7356984105623074": 72, "oof": [72, 80, 84, 87], "2774578420000005": 72, "23979613": 72, "64700481": 72, "16986432480000002": 72, "nicer": 72, "3191": 72, "mix_loo": 72, "89": 72, "33459299576725": 72, "d_loo": 72, "w_singl": 72, "w_mix": 72, "99245113565338e": 72, "agreement": 72, "884444": 72, "778852": 72, "983497": 72, "718306": 72, "219037": 72, "927518": 72, "334593": 72, "016503": 72, "315398": 72, "565504": 72, "hyperprior": [73, 75, 77, 78, 81, 86], "theta_k": [73, 77, 81, 82, 83, 86], "permut": 73, "permuat": 73, "nuanc": 73, "advanc": 73, "recov": [73, 79], "nonhierarch": 73, "kappa": [73, 75], "hyperparamet": [74, 75, 77, 78, 81, 83, 84, 85, 87], "portion": [74, 84, 89], "d3": 75, "synthet": [75, 84], "110": 75, "660": 75, "worm_hier": 75, "adapt_delta": [75, 78, 81, 84, 87], "2000": [75, 80, 87, 90], "global": [75, 77, 87], "diamond": 75, "650": 75, "theta_dim_0": 75, "\u03b2": 75, "theta_map": 75, "bottom_right": [75, 78], "significantli": [75, 87], "240": 75, "292": 75, "disfavor": 77, "indirectli": 77, "dig": 78, "mondai": [78, 87, 89, 92], "batch": [78, 87], "plate": 78, "coloni": [78, 87], "mount": 78, "slide": [78, 88], "wednesdai": [78, 87, 89, 92], "thursdai": [78, 87, 89, 92], "diagram": 78, "phantom": 78, "theta_3": [78, 87], "condition": 78, "j_1": [78, 87], "j_2": [78, 87], "j_k": 78, "j_3": [78, 87], "straight": 78, "clariti": 78, "index_1": [78, 87], "index_2": [78, 87], "index_3": [78, 87], "fabric": [78, 89], "weird": 78, "compact": 78, "data_str": [78, 87], "41": [78, 87, 90], "nw": [78, 87], "42": [78, 87], "nr": [78, 87], "73": [78, 87], "stringio": [78, 87], "daybatchcolonyystri64i64f64": 78, "1111": 78, "1110": 78, "1112": 78, "metadata": 78, "cat": [78, 80, 84, 87, 90], "color_column": [78, 80, 87], "marker_kwarg": [78, 80, 84, 87], "adher": 78, "categor": [78, 80, 90], "df_to_datadict_hi": [78, 87], "convei": 78, "level_col": [78, 87], "data_col": [78, 87], "hellip": [78, 87], "129": [78, 87], "1210": 78, "1310": 78, "1412": 78, "sm_center": 78, "samples_cent": 78, "hopefulli": [78, 80, 87], "dianost": 78, "120": 78, "6206946627826": 78, "193": [78, 87], "46855809117585": 78, "0181667967555237": 78, "0104461055496787": 78, "17398128059170156": 78, "09851564271989993": 78, "12373822952024313": 78, "07573497349280298": 78, "whew": 78, "strikingli": [78, 80], "theta_1_dim_0": 78, "theta_2_dim_0": 78, "theta_3_dim_0": 78, "allevi": 78, "_1": [78, 81, 82, 83], "_2": [78, 82, 83], "_3": 78, "theta_1_tild": 78, "theta_2_tild": 78, "theta_3_tild": 78, "sm_noncent": 78, "samples_noncent": 78, "gone": 78, "y_axis_typ": [78, 80, 83], "articl": 79, "unsatisfi": 79, "reliabl": [79, 80], "ground": [79, 80], "truth": [79, 80], "talt": 79, "umbrella": 79, "abus": [79, 81], "forgiv": 79, "ant": 79, "experimentum": 79, "hundr": 79, "uncertainti": [79, 81], "z_i": 79, "rangle_": 79, "sign": 79, "overfit": [79, 80], "s_i": 79, "drift": 79, "permit": 79, "coverag": [79, 80], "surround": 79, "diagnosi": 79, "empir": 80, "justif": 80, "prior_pr": 80, "choke": 80, "samples_prior_pr": 80, "range1d": 80, "3e5": 80, "nanmax": 80, "poissonian": 80, "dispers": 80, "upward": 80, "mammalian": 80, "ingredi": 80, "requisit": [80, 89], "df_sbc": 80, "prior_predictive_model": 80, "posterior_model": 80, "prior_predictive_model_data": 80, "posterior_model_data": 80, "measured_data": 80, "measured_data_dtyp": 80, "progress_bar": 80, "07it": 80, "ground_truthrank_statisticmeansdshrinkagez_scorerhatessess_per_itertail_esstail_ess_per_itern_divergencesn_bad_ebfmin_max_treedepthwarning_codeltrialerrorparameterf64i64f64f64f64f64f64f64f64f64f64i64i64i64i64i64i64strstr0": 80, "002862101": 80, "0053340": 80, "0052541": 80, "0190": 80, "8112971": 80, "0023851662": 80, "3330420": 80, "4155831245": 80, "9198970": 80, "31148000040000": 80, "592778483": 80, "8443910": 80, "3097990": 80, "9999590": 80, "8122061": 80, "004025732": 80, "4173080": 80, "183104694": 80, "8219580": 80, "173705000040001": 80, "2772539031": 80, "1166130": 80, "0717330": 80, "999998": 80, "2393821": 80, "004734780": 80, "7275920": 80, "1951821050": 80, "450650": 80, "262613200440002": 80, "62861396101": 80, "20665711": 80, "1994990": 80, "9459420": 80, "4087731": 80, "005957512": 80, "1181450": 80, "12803548": 80, "8116860": 80, "137203000040003": 80, "91851601": 80, "0684490": 80, "0510140": 80, "9999992": 80, "9390361": 80, "001264807": 80, "4313030": 80, "201858936": 80, "5215790": 80, "23413100440004": 80, "warning_cod": 80, "succinct": 80, "parse_warning_cod": 80, "treedepth": 80, "tooltip": [80, 90], "sub_df": 80, "1f77b4": 80, "group_bi": 80, "z_score": 80, "evidenc": 80, "good_z": 80, "ground_truth": 80, "jitter": [80, 84], "abort": 80, "002": 80, "5000": 80, "problemat": 80, "sm_prior_pred_2": 80, "prior_pred_2": 80, "1e6": 80, "sm_2": 80, "model_2": 80, "posterior_predictive_var_nam": 80, "48it": 80, "warning_codeleni64u32087721073818": 80, "sampling_kwarg": 80, "93it": 80, "warning_codeleni64u32210999": 80, "decent": 80, "sbc_rank_ecdf": 80, "hadn": 81, "untest": 81, "amplitud": [81, 82, 84], "methylglucopyranosid": 81, "hydrolysi": 81, "cellulos": 81, "wolfenden": [81, 82, 84, 86], "snider": [81, 82, 86], "enzym": 81, "catalyst": 81, "glucosid": 81, "temperatur": [81, 82, 84, 86], "wolfenden_arrheniu": [81, 82, 84, 86], "chemic": [81, 84, 86], "arrheniu": 81, "e_a": 81, "k_bt": 81, "t_i": [81, 83, 84], "k_i": 81, "fun": [81, 90], "t_ppc": 81, "log10_ea": 81, "log10_a": 81, "ea": 81, "k_ppc": [81, 82, 86], "uncatalyz": 81, "reaction": 81, "530": 81, "sm_parametr": 81, "max_treedepth": [81, 84], "16000": 81, "k_ppc_dim_0": 81, "sec": 81, "meaning": 81, "kinet": [81, 84], "capit": 81, "epsilon_i": 81, "primarili": 81, "_n": 81, "latent": [81, 86, 87, 90], "semi": 81, "hugo": 81, "bown": 81, "anderson": 81, "arithmet": 81, "gram": 81, "sigma_b": 81, "polynomi": 81, "sigma_p": 81, "vert": 81, "vert_2": 81, "mat\u00e9rn": 81, "sin": [81, 84], "modifi": [81, 83, 87], "bessel": [81, 83], "quadrat": 81, "radial": 81, "spirit": 81, "realiz": [81, 90], "rough": [81, 83], "farther": 81, "apart": 81, "unrel": 81, "tunabl": 81, "multinorm": [81, 82, 83, 84, 86, 87], "nstar": [81, 82, 83, 84, 86], "xstar": [81, 82, 83, 84, 86], "gp_exp_quad_cov": [81, 82, 83, 84, 86], "diag_matrix": [81, 82, 83, 84, 86], "rep_vector": [81, 82, 83, 84, 86], "choleski": [81, 82, 84, 86], "decomposit": [81, 82, 84, 86], "cholesky_decompos": [81, 82, 83, 84, 86], "multi_normal_cholesky_rng": [81, 83, 86], "gp_cov_exp_quad": 81, "stabil": 81, "sm_prior": 81, "gp_prior_fixed_rho_alpha": 81, "\u03c1": [81, 82, 83], "rougher": [81, 83], "cov_matern": [81, 83], "rg": 81, "spaghetti": 81, "cov_exp_quad": [81, 82, 83, 86], "multi_lin": 81, "mult_kern": 81, "x1": 81, "x2": 81, "rho_s": 81, "rho_per": 81, "periodic_kernel": 81, "se_kernel": 81, "cov_from_kernel": 81, "add_kern": 81, "linear_kernel": 81, "c_1": 81, "c_2": 81, "iptg": 81, "poi": 81, "c_i": 81, "heteroscedast": 81, "lll": 81, "diag": [81, 82, 83], "unmeasur": 81, "5em": 81, "triangular": 81, "stabli": 81, "shade": 81, "k_scale": [81, 82, 84, 86], "t_scale": [81, 82, 83, 84, 86], "t_rang": [81, 82, 84, 86], "manipul": [81, 86, 87], "posterior_mean_cov": [81, 82, 83], "mstar": [81, 82, 83, 86], "sigmastar": [81, 82, 83, 86], "unscal": [81, 82, 83, 84, 86], "tstar": [81, 82, 83, 84, 86], "kstar": [81, 82, 83, 86], "show_lin": [81, 82, 83], "exent": 81, "muster": 81, "dampen": 81, "favor": [81, 83], "flatter": 81, "simplif": 81, "gp": [82, 85], "stipul": 82, "wiggli": 82, "outlier": 82, "contort": 82, "invgamma": [82, 83, 84, 86], "singular": [82, 83], "diag_to_add": [82, 83], "ky": [82, 83, 86], "4f": [82, 83], "5887": 82, "5791": 82, "0886": 82, "miniconda3": [82, 83, 90], "env": [82, 83, 90], "bebi103_build": [82, 83, 90], "lib": [82, 83, 90], "python3": [82, 83, 90], "_optim": [82, 83, 90], "py": [82, 83, 90], "2472": [82, 90], "runtimewarn": [82, 83, 90], "tmp2": [82, 83, 90], "fx": [82, 83, 90], "fw": [82, 83, 90], "nonparametr": [82, 83, 84, 86], "draw_gp_ppc": 82, "y_mean": 82, "y_std": 82, "nonparameter": 82, "inv_gamma": [82, 83, 84, 86], "multi_normal_choleski": [82, 83, 86], "gp_kinetics_no_ppc": [82, 86], "optimized_params_dict": 82, "ordereddict": 82, "lp__": [82, 87], "79106": 82, "40338": 82, "25657": 82, "0893158": 82, "optimized_params_pd": 82, "od": 83, "remark": 83, "peter": 83, "swain": 83, "tom": 83, "r\u00f6schinger": 83, "roeschinger_growth_rate_data": 83, "tetracycline_conc_\u00b5g_per_ml": 83, "mg1655": 83, "a01": 83, "time_min": 83, "od600": 83, "hr": 83, "extrapol": 83, "od600_scal": 83, "solak": 83, "ourselv": 83, "2_x": 83, "z_j": 83, "partial_1": 83, "partial_2": 83, "pertin": 83, "matern": 83, "1420": 83, "5917": 83, "0118": 83, "2473": [83, 90], "augment": 83, "posterior_mean_cov_deriv": 83, "exp_quad_kernel": 83, "gstar": 83, "sigma_g_star": 83, "od600star": 83, "deriv_high": 83, "deriv_low": 83, "deriv_star": 83, "dt": 83, "2_z": 83, "mu_z": 83, "mu_x": 83, "2_y": 83, "shortli": 83, "growth_rat": 83, "sigma_growth_r": 83, "gr_high": 83, "gr_low": 83, "redefin": 83, "matern_kernel": 83, "wiggl": 83, "gp_one_dimension": [83, 86], "stanfunct": 83, "fstar": [83, 84, 86], "dfstar": 83, "y_ppc": [83, 84, 86], "kstarstar": [83, 86], "d1_kstar": 83, "d1_cov_exp_quad": 83, "d1_d2_kstarstar": 83, "d1_d2_cov_exp_quad": 83, "gp_posterior_mstar": [83, 86], "lstar": [83, 86], "gp_posterior_sigmastar_choleski": [83, 86], "sigmag": 83, "l_g_star": 83, "gp_growth_curv": 83, "stanc_opt": [83, 86], "include_path": [83, 86], "y_ppc_dim_0": [83, 86], "od600_ppc": 83, "dfstar_scal": 83, "dfstar_dim_0": 83, "fstar_scal": [83, 84, 86], "fstar_dim_0": [83, 86], "experienc": 83, "unmargin": 84, "f_i": 84, "layer": 84, "hyperparamat": 84, "preprocess": 84, "xstar_ind": 84, "f_tild": 84, "append_sort_index": 84, "index_origin": 84, "duplic": 84, "indici": 84, "73988004": 84, "67222743": 84, "60457482": 84, "58919923": 84, "53692222": 84, "46926961": 84, "401617": 84, "3339644": 84, "26631179": 84, "22693001": 84, "19865918": 84, "13100658": 84, "06335397": 84, "99570136": 84, "96124699": 84, "92804876": 84, "86039615": 84, "79274354": 84, "72509093": 84, "65743833": 84, "58978572": 84, "52324311": 84, "52213311": 84, "45448051": 84, "3868279": 84, "31917529": 84, "25152269": 84, "18459205": 84, "18387008": 84, "11621747": 84, "04856487": 84, "01908774": 84, "08674035": 84, "15439295": 84, "22204556": 84, "28969817": 84, "35735077": 84, "42500338": 84, "49265599": 84, "50367757": 84, "56030859": 84, "6279612": 84, "69561381": 84, "76326641": 84, "81156517": 84, "83091902": 84, "89857163": 84, "96622423": 84, "03387684": 84, "10152945": 84, "16918205": 84, "23683466": 84, "2418742": 84, "30448727": 84, "37213987": 84, "42441689": 84, "43979248": 84, "50744509": 84, "57509769": 84, "526": 84, "97268063": 84, "522": 84, "8398459": 84, "513": 84, "09748852": 84, "12679808": 84, "490": 84, "5441167": 84, "482": 84, "87692992": 84, "472": [84, 87], "96035845": 84, "466": 84, "94519538": 84, "458": 84, "74328484": 84, "leapfrog": [84, 87], "gp_kinetics_no_marg": 84, "84": 84, "dial": 84, "475": 84, "f_dim_0": 84, "data_kwarg": [84, 86], "1f78b4": [84, 86], "contriv": [84, 87], "scenario": [84, 90], "a_0": 84, "varying_funct": 84, "a0": 84, "a1": 84, "\u03bb": 84, "time_point": 84, "n_cell": 84, "astyp": [84, 90], "plop": 84, "fram": 84, "q_axi": 84, "600": [84, 87], "t_ind": 84, "log_f_tild": 84, "log_f": 84, "poisson_log": 84, "poisson_log_rng": 84, "gp_transcript_count": 84, "184": [84, 87], "3782": 84, "log_fstar": 84, "log_f_dim_0": 84, "mdivide_left_tri_low": 86, "mdivide_right_tri_low": 86, "sigma_star": 86, "po": 86, "wherev": 86, "suffix": 86, "stan_includ": 86, "comma": 86, "gp_kinet": 86, "pathto": 86, "force_compil": 86, "k_ppc_scale": 86, "heidi": 87, "klump": 87, "adopt": 87, "interchang": 87, "blei": 87, "dissimilar": 87, "leiber": 87, "resembl": 87, "poorli": 87, "prod_i": 87, "phi_i": 87, "partit": 87, "neq": 87, "q_j": 87, "hurdl": 87, "q_": 87, "randon": 87, "advi": 87, "alp": 87, "kucukelbir": 87, "zeta": 87, "zeta_i": 87, "meanfield": 87, "optimum": 87, "samples_vi": 87, "pertain": 87, "stdout_fil": 87, "runset": 87, "_stdout_fil": 87, "10000": 87, "grad_sampl": 87, "elbo_sampl": 87, "tol_rel_obj": 87, "eval_elbo": 87, "output_sampl": 87, "tmpcshdblkp": 87, "01ufoem2": 87, "json": 87, "spindlezaxcnbxg": 87, "20240727161414": 87, "diagnostic_fil": 87, "sig_fig": 87, "profile_fil": 87, "save_cmdstan_config": 87, "num_thread": 87, "unstabl": 87, "buggi": 87, "gradient": 87, "000392": 87, "ascent": 87, "delta_elbo_mean": 87, "delta_elbo_m": 87, "6093": 87, "3580": 87, "851": 87, "3473": 87, "163": 87, "578": 87, "702": 87, "3406": 87, "187": 87, "438": 87, "3310": 87, "589": 87, "356": 87, "031": 87, "3197": 87, "393": 87, "303": 87, "035": 87, "700": 87, "3119": 87, "716": 87, "263": 87, "800": 87, "3118": 87, "230": 87, "900": 87, "3055": 87, "396": 87, "207": 87, "029": 87, "3007": 87, "033": 87, "1100": 87, "2958": 87, "594": 87, "090": 87, "1200": 87, "2882": 87, "045": 87, "022": 87, "1300": 87, "2825": 87, "802": 87, "021": 87, "1400": 87, "2755": 87, "1500": 87, "2656": 87, "2549": 87, "177": 87, "023": 87, "1700": 87, "2429": 87, "026": 87, "1800": 87, "2310": 87, "505": 87, "027": 87, "1900": 87, "2205": 87, "968": 87, "037": 87, "2103": 87, "036": 87, "042": 87, "2100": 87, "2027": 87, "055": 87, "039": 87, "2200": 87, "1952": 87, "219": 87, "2300": 87, "1908": 87, "2400": 87, "1881": 87, "840": 87, "2500": 87, "1870": 87, "947": 87, "2600": 87, "1869": 87, "602": 87, "032": 87, "2700": 87, "1859": 87, "828": 87, "2800": 87, "1852": 87, "081": 87, "2900": 87, "1855": 87, "085": 87, "3000": 87, "1848": 87, "013": 87, "variational_sample_pd": 87, "df_vi": 87, "1_546": 87, "lp__log_p__log_g__phigamma_sigma_0mu": 87, "164": 87, "165": 87, "166": 87, "167": 87, "168": 87, "169": 87, "171": 87, "172": 87, "173": 87, "174": 87, "175": 87, "178": 87, "180": 87, "182": 87, "185": 87, "186": 87, "189": 87, "191": 87, "192": 87, "194": 87, "195": 87, "197": 87, "198": 87, "199": 87, "f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64": 87, "f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f64f640": 87, "1835": 87, "33121238": 87, "2270": 87, "8426290": 87, "11378121": 87, "410822": 87, "116822": 87, "863123": 87, "818223": 87, "818224": 87, "107224": 87, "221524": 87, "391524": 87, "5625": 87, "109525": 87, "217225": 87, "377425": 87, "483325": 87, "640725": 87, "796425": 87, "899425": 87, "899426": 87, "052426": 87, "153526": 87, "303726": 87, "40326": 87, "403": 87, "248343": 87, "154236": 87, "822544": 87, "668738": 87, "665544": 87, "02741": 87, "527232": 87, "699924": 87, "670637": 87, "833836": 87, "934941": 87, "205144": 87, "229931": 87, "700542": 87, "786742": 87, "284843": 87, "183633": 87, "922841": 87, "924440": 87, "99631": 87, "870935": 87, "84937": 87, "39738": 87, "296335": 87, "662538": 87, "725243": 87, "700342": 87, "188434": 87, "516936": 87, "389942": 87, "901239": 87, "483443": 87, "509634": 87, "06443": 87, "242134": 87, "12140": 87, "64320": 87, "1840": 87, "78530839": 87, "15010": 87, "8652280": 87, "11209321": 87, "974922": 87, "698523": 87, "463224": 87, "441524": 87, "737524": 87, "854625": 87, "028725": 87, "201225": 87, "763925": 87, "874125": 87, "874126": 87, "038126": 87, "146526": 87, "307626": 87, "46726": 87, "572426": 87, "72926": 87, "832426": 87, "986227": 87, "087827": 87, "0878": 87, "852838": 87, "859240": 87, "255547": 87, "723140": 87, "816530": 87, "954534": 87, "280637": 87, "754237": 87, "441734": 87, "807737": 87, "139236": 87, "539429": 87, "180541": 87, "470439": 87, "744540": 87, "545239": 87, "189340": 87, "0141": 87, "243634": 87, "44339": 87, "726140": 87, "452141": 87, "051329": 87, "214242": 87, "083739": 87, "000348": 87, "029239": 87, "175628": 87, "694240": 87, "588942": 87, "45241": 87, "212443": 87, "891929": 87, "079348": 87, "109934": 87, "261135": 87, "85890": 87, "1858": 87, "3135140": 87, "27760": 87, "8440270": 87, "12307621": 87, "626222": 87, "358723": 87, "135824": 87, "134924": 87, "438324": 87, "558524": 87, "914925": 87, "49525": 87, "608925": 87, "778525": 87, "890726": 87, "057726": 87, "223126": 87, "332526": 87, "495326": 87, "60326": 87, "763126": 87, "86926": 87, "869": 87, "305746": 87, "086545": 87, "675337": 87, "458641": 87, "120538": 87, "046242": 87, "214834": 87, "958247": 87, "576935": 87, "842340": 87, "759945": 87, "705848": 87, "77944": 87, "312848": 87, "809835": 87, "705734": 87, "544637": 87, "255641": 87, "519542": 87, "743345": 87, "759829": 87, "798840": 87, "612251": 87, "127443": 87, "244447": 87, "42946": 87, "350742": 87, "102934": 87, "758235": 87, "285637": 87, "087235": 87, "45129": 87, "324637": 87, "891744": 87, "517646": 87, "607338": 87, "60070": 87, "57": 87, "2506237": 87, "61070": 87, "8235380": 87, "12039920": 87, "9521": 87, "643522": 87, "376723": 87, "315823": 87, "600123": 87, "712623": 87, "879923": 87, "879924": 87, "045724": 87, "586724": 87, "692824": 87, "850524": 87, "954825": 87, "109825": 87, "263325": 87, "364725": 87, "515525": 87, "615225": 87, "763325": 87, "861125": 87, "8611": 87, "700133": 87, "765741": 87, "01630": 87, "692931": 87, "122833": 87, "522642": 87, "145236": 87, "1543": 87, "160140": 87, "126942": 87, "508540": 87, "00243": 87, "993937": 87, "575338": 87, "000436": 87, "304840": 87, "071936": 87, "101739": 87, "003932": 87, "224645": 87, "635435": 87, "53938": 87, "868137": 87, "839935": 87, "145742": 87, "555744": 87, "950539": 87, "690740": 87, "796237": 87, "734439": 87, "588133": 87, "151932": 87, "761429": 87, "640840": 87, "012242": 87, "179343": 87, "35860": 87, "1837": 87, "70917538": 87, "33510": 87, "8371120": 87, "11236821": 87, "305322": 87, "011622": 87, "758623": 87, "715523": 87, "715524": 87, "005224": 87, "119824": 87, "290424": 87, "459425": 87, "01125": 87, "119125": 87, "279925": 87, "386325": 87, "544425": 87, "700925": 87, "804325": 87, "958125": 87, "958126": 87, "059826": 87, "210826": 87, "310726": 87, "3107": 87, "389538": 87, "487935": 87, "552138": 87, "478339": 87, "257242": 87, "376948": 87, "535439": 87, "861436": 87, "31238": 87, "527838": 87, "715338": 87, "726839": 87, "719838": 87, "526837": 87, "728746": 87, "05735": 87, "144146": 87, "713130": 87, "492937": 87, "246445": 87, "322936": 87, "658942": 87, "086337": 87, "391944": 87, "149438": 87, "827439": 87, "504842": 87, "60740": 87, "123337": 87, "005437": 87, "151228": 87, "840532": 87, "462543": 87, "715541": 87, "509742": 87, "00435": 87, "4243": 87, "legaci": 87, "log_p__": 87, "log_g__": 87, "variational_params_pd": 87, "4521": 87, "853254": 87, "116228": 87, "6552": 87, "3666": 87, "1182": 87, "0794": 87, "4477": 87, "673": 87, "7122": 87, "381": 87, "9442": 87, "6642": 87, "0142": 87, "2081": 87, "4419": 87, "1546": 87, "plot_marginal_ecdf": 87, "p_phi": 87, "p_gamma": 87, "fullrank": 87, "3251": 87, "88812": 87, "noncent": 87, "hier_lognorm": 87, "32520": 87, "require_converg": 87, "tendenc": 87, "underestim": 87, "p_theta": 87, "p_sigma": 87, "p_tau": 87, "gridplot": 87, "ncol": 87, "custom": 87, "ranganath": 87, "morn": 89, "noon": [89, 92], "kerckhoff": [89, 92], "b123": [89, 92], "attend": 89, "recit": [89, 92], "offic": [89, 92], "tuesdai": [89, 92], "dilig": 89, "golden": 89, "opportun": 89, "submit": [89, 92], "schedul": 89, "skill": 89, "_lastname_firstnam": 89, "pacif": 89, "sundai": 89, "perfectli": 89, "aspect": 89, "fridai": 89, "hw": 89, "restart": 89, "runnabl": 89, "submitt": 89, "credit": 89, "name_of_datafil": 89, "embed": 89, "mathjax": 89, "latex": 89, "inversegamma": 89, "justifi": 89, "guidelin": 89, "adjac": 89, "explanatori": 89, "markdown": 89, "header": 89, "delin": 89, "late": 89, "grace": 89, "penalti": 89, "saturdai": 89, "ill": 89, "health": 89, "cass": 89, "accommod": 89, "coursework": 89, "exam": 89, "announc": 89, "offici": 89, "passag": 89, "nullifi": 89, "violat": 89, "publicli": 89, "unpublish": 89, "institut": 89, "faith": 89, "imper": 89, "dissemin": 89, "classmat": 89, "whom": 89, "consult": 89, "websit": 89, "materi": 89, "cite": 89, "llm": 89, "chatgpt": 89, "gpt": 89, "llama": 89, "gemini": 89, "cursor": 89, "copilot": 89, "ai": 89, "engin": [89, 91], "deni": 89, "contrari": 89, "basal": 89, "compet": 89, "reiter": 89, "chatbot": 89, "privat": 89, "email": 89, "shot": 89, "anonym": 89, "spur": 89, "incomplet": 90, "classic": 90, "tanner": 90, "unobserv": 90, "coloneqq": 90, "auxiliari": 90, "dx": 90, "geq": 90, "jensen": 90, "inequ": 90, "concav": 90, "rewritten": 90, "mathbb": 90, "theta_t": 90, "max_": 90, "leq": 90, "negligibli": 90, "statit": 90, "decompos": 90, "distributio": 90, "substit": 90, "cluster": 90, "distinct": 90, "g1": 90, "g2": 90, "g3": 90, "from_dict": 90, "orient": 90, "reset_index": 90, "level_0": 90, "807034": 90, "406405": 90, "321243": 90, "538124": 90, "905978": 90, "pi_": 90, "pi_1": 90, "pi_k": 90, "mu_k": 90, "sigma_k": 90, "dy": 90, "pi_jf": 90, "assig": 90, "helper": 90, "r0": 90, "q_function": 90, "params_old": 90, "resp": 90, "log_complete_likelihood": 90, "dirichlet": 90, "spars": 90, "alpha_k": 90, "simplex": 90, "10e": 90, "lik": 90, "calculu": 90, "ik": 90, "beta_0": 90, "alpha_0": 90, "tau_0": 90, "mu_0": 90, "update_mu": 90, "hyper_mu": 90, "hyper_tau": 90, "mu_new": 90, "update_pi": 90, "hyper_alpha": 90, "probabilit": 90, "pi_new": 90, "update_sigma": 90, "hyper_beta": 90, "sigma_new": 90, "compos": 90, "e_step": 90, "m_step": 90, "new_mu": 90, "new_sigma": 90, "new_pi": 90, "em_algorithm": 90, "params_init": 90, "max_it": 90, "q_old": 90, "rp": 90, "break": 90, "n_compon": 90, "sigma_init": 90, "pi_init": 90, "mu_init": 90, "mode_posterior": 90, "u03bc": 90, "\u03c3\u00b2": 90, "u03c0": 90, "\u03c0": 90, "rsp": 90, "em_predict": 90, "argmax": 90, "group_estim": 90, "groupbi": 90, "df_plot": 90, "factorrang": 90, "toolbar_loc": 90, "vbar": 90, "categori": 90, "map_posterior": 90, "tmp1": 90, "3rd": 91, "freeli": 91, "video": 91, "2nd": 91, "richard": 91, "mcelreath": 91, "ben": 91, "lambert": 91, "beginn": 91, "press\u00e9": 91, "sgourali": 91, "exposit": 91, "phil": 91, "supplement": 91, "kerkchoff": 92, "februari": 92, "march": 92, "martin": 92, "luther": 92, "king": 92, "presid": 92}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"homework": [0, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15, 17, 89, 92], "1": [0, 1, 2, 5, 8, 11, 14, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 34, 64, 87], "first": 0, "attempt": 0, "bayesian": [0, 31, 37, 38, 41, 47, 81, 87, 90], "gener": [0, 1, 36, 52, 53, 57, 60, 64, 74, 78, 80, 84], "model": [0, 1, 32, 37, 38, 41, 42, 43, 46, 48, 57, 59, 60, 61, 64, 65, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 80, 84, 87, 90], "70": [0, 8], "pt": [0, 2, 3, 5, 6, 8, 9, 11, 12, 14, 15], "intuit": 1, "2": [2, 3, 4, 6, 9, 12, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 41, 64, 87], "overwhelm": 2, "prior": [2, 3, 31, 37, 38, 40, 57, 64, 66, 73, 80, 81, 82], "45": 2, "exponenti": [3, 83], "conjug": [3, 40, 44], "55": 3, "analyt": [4, 42, 43, 81], "graphic": 4, "method": [4, 40, 63], "analysi": [4, 46, 57, 79], "posterior": [4, 31, 38, 42, 44, 46, 47, 57, 61, 63, 65, 69, 81, 82, 86], "3": [5, 6, 7, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 42, 64], "least": 5, "squar": [5, 83], "20": [5, 24, 78], "map": [6, 46, 47, 82], "estim": [6, 7, 37, 45, 46, 47, 48, 57, 69, 81, 86], "zero": 6, "inflat": 6, "drop": 6, "seq": 6, "control": 6, "80": 6, "maximum": [7, 47], "posteriori": 7, "paramet": [7, 37, 42, 45, 46, 47, 48, 57, 61, 64, 77, 81], "4": [8, 9, 10, 18, 19, 20, 21, 22, 23, 24, 26, 27, 43], "write": 8, "your": [8, 27, 30, 58], "own": 8, "mcmc": [8, 9, 10, 11, 15, 16, 50, 52, 55, 56, 57, 59, 60, 61, 62, 63, 67, 84, 86], "sampler": [8, 67], "boolean": [9, 11], "data": [9, 11, 42, 46, 57, 64, 67, 77, 78, 81, 83], "30": 9, "sampl": [10, 28, 57, 58, 59, 60, 61, 63, 67, 68, 78, 80, 81, 82, 83, 84], "5": [11, 12, 13, 18, 19, 22, 24, 27, 44], "stan": [11, 13, 30, 56, 57, 58, 60, 64, 78, 81, 82, 83, 84, 86, 87], "25": [11, 26, 87], "microtubul": 12, "catastroph": 12, "75": 12, "infer": [13, 17, 31, 81, 87, 90], "6": [14, 15, 16, 19, 23, 27, 45], "surviv": 14, "osmot": 14, "shock": 14, "40": 14, "diagnos": 15, "nonidentifi": 15, "60": 15, "ion": 16, "channel": 16, "BE": 17, "bi": 17, "103": 17, "b": 17, "statist": [17, 31, 65, 67, 79], "biolog": 17, "scienc": [17, 31], "us": [17, 27, 28, 40, 47, 58, 60, 81, 83, 84, 86], "link": 17, "peopl": 17, "lesson": [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 89, 92], "schedul": [17, 92], "polici": [17, 89], "resourc": [17, 29], "previou": 17, "edit": 17, "cours": [17, 89], "e1": 18, "To": [18, 19, 20, 21, 22, 23, 24, 25, 26], "complet": [18, 19, 20, 21, 22, 23, 24, 25, 26], "after": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27], "exercis": [18, 19, 20, 21, 22, 23, 24, 25, 26, 89, 92], "e2": 19, "e3": 20, "10": [20, 60], "e4": 21, "13": [21, 65], "e5": 22, "16": [22, 68], "e6": 23, "18": [23, 71], "e7": 24, "7": [24, 27, 51], "e8": 25, "22": [25, 80], "8": [25, 27, 56], "e9": 26, "9": [26, 27, 59], "aw": 27, "setup": 27, "usag": 27, "creat": 27, "an": [27, 36, 42, 72, 80, 81], "amazon": 27, "web": 27, "servic": 27, "account": 27, "launch": 27, "instanc": 27, "connect": 27, "jupyterlab": 27, "copi": 27, "result": [27, 62, 63], "from": [27, 37, 83], "local": 27, "machin": [27, 30], "exit": 27, "serious": 27, "stop": 27, "you": 27, "ar": [27, 58], "them": 27, "again": 27, "termin": 27, "class": 27, "i": [27, 31, 46, 64], "over": 27, "googl": 28, "colab": 28, "watchout": 28, "when": 28, "softwar": [28, 91], "A": [28, 42, 48, 68, 77, 78, 79, 84, 87, 90], "calcul": [28, 42, 72, 83], "comput": [28, 29, 30, 42, 43, 44, 46, 47, 48, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 80, 81, 82, 83, 84, 86, 87], "environ": [28, 30, 42, 43, 44, 46, 47, 48, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 70, 72, 75, 80, 81, 82, 83, 84, 86, 87], "0": 29, "set": [29, 42, 57, 64, 66, 67, 78, 81], "up": [29, 54, 58, 59, 78, 88], "configur": 30, "instal": 30, "python": 30, "packag": 30, "c": 30, "toolchain": 30, "maco": 30, "window": 30, "linux": 30, "cmdstanpi": 30, "check": [30, 48, 64, 65, 66, 67, 69, 78, 80, 86], "probabl": [31, 34, 36], "logic": [31, 34], "what": 31, "The": [31, 37, 38, 40, 42, 43, 44, 48, 52, 53, 57, 61, 64, 65, 67, 69, 77, 80, 81, 87], "problem": 31, "frequentist": 31, "desiderata": 31, "sum": 31, "rule": 31, "product": 31, "condit": [31, 36, 73], "applic": [31, 90], "scientif": [31, 34], "measur": [31, 37], "bay": [31, 32, 33, 36], "": [31, 32, 33, 36, 64, 66], "theorem": [31, 32, 33, 36], "likelihood": [31, 37, 39, 42, 46, 64, 72, 81, 84, 86], "evid": 31, "learn": 32, "notat": 33, "part": 33, "reason": 34, "margin": [35, 42, 43, 57, 61], "distribut": [36, 37, 61, 63, 66, 73, 81], "joint": 36, "pdf": 36, "chang": 36, "variabl": [36, 66, 84], "formula": 36, "continu": 36, "multipl": 36, "dimens": 36, "exampl": [36, 37, 40, 70, 72, 81, 87, 90], "anoth": [36, 37], "log": [36, 42, 69, 72], "normal": [36, 37, 42, 46, 47, 48, 81, 84, 86, 90], "repeat": [37, 77], "revisit": 37, "choic": [37, 73], "succinctli": 37, "state": 37, "task": 38, "build": [38, 57, 64, 79], "role": 38, "make": 38, "sens": 38, "choos": [39, 40, 53, 66, 73, 87], "uniform": 40, "jeffrei": 40, "why": [40, 47, 55, 58, 90], "weakli": 40, "inform": [40, 69], "bet": 40, "farm": 40, "specifi": 40, "introduct": [41, 51, 56, 81, 90], "plot": [42, 44, 57, 59, 61, 79, 81], "spindl": [42, 64, 87], "size": [42, 46, 57, 64, 65, 67, 87], "singl": 42, "numer": [42, 43], "quadratur": [42, 43], "prescript": 42, "1d": 42, "express": [42, 83], "2d": 42, "asid": [42, 78, 86], "speed": 42, "tubulin": [43, 48, 64, 65], "conserv": [43, 48, 65], "curs": 43, "dimension": 43, "overcom": 43, "conjugaci": 44, "beta": 44, "binomi": 44, "pair": [44, 61], "find": 44, "comment": 44, "optim": [45, 46, 47, 48, 82, 83], "case": [46, 68], "studi": [46, 68], "exploratori": 46, "independ": [46, 64, 65, 77], "approxim": [46, 47, 48], "credibl": [46, 47], "interv": [46, 47], "how": [46, 63], "good": 46, "approach": 47, "summar": [47, 63], "its": 47, "demonstr": 47, "mai": 47, "skew": 47, "variat": [48, 60, 87], "covari": [48, 60, 81, 83], "displai": [48, 57, 58, 61, 62, 63], "best": [48, 57, 77], "fit": [48, 57], "line": 48, "further": 50, "read": [50, 91], "markov": [51, 57], "chain": [51, 57], "mont": [51, 57, 67], "carlo": [51, 57, 67], "random": 52, "number": [52, 66, 81], "basic": [52, 58], "idea": [52, 87], "behind": 52, "transit": 53, "kernel": [53, 81, 83], "metropoli": 53, "hast": 53, "algorithm": [53, 87, 90], "detail": 53, "balanc": 53, "warm": 54, "our": [57, 80], "engin": 57, "ecdf": [57, 79, 80], "mrna": [57, 80], "count": [57, 80], "burst": 57, "inter": 57, "time": 57, "all": [57, 64, 90], "gene": 57, "hello": 58, "world": [58, 77], "program": 58, "sai": 58, "hi": 58, "pars": [58, 59], "output": [58, 59], "arviz": [58, 61], "direct": 58, "we": 58, "code": [58, 59, 78, 89], "save": 58, "clean": 58, "shrapnel": 58, "mixtur": [59, 72, 90], "label": 59, "switch": 59, "initi": 59, "walker": 59, "conclus": [59, 78, 80, 81], "updat": 60, "visual": 61, "examin": 61, "trace": 61, "bebi103": 61, "interpet": 61, "parallel": 61, "coordin": 61, "intepret": 61, "one": [61, 69], "iqplot": 61, "two": 61, "corner": 61, "11": 62, "report": 63, "summari": [63, 65, 87], "some": 63, "error": [63, 67], "bar": 63, "rel": 63, "merit": 63, "each": 63, "text": 63, "12": 64, "predict": [64, 65, 69, 81, 82, 86], "droplet": 64, "take": 64, "depend": 64, "total": 64, "concentr": 64, "indentifi": 64, "limit": 64, "behavior": 64, "assumpt": 64, "v_": 64, "mathrm": 64, "v_0": 64, "ll": 64, "do": 64, "have": 64, "same": 64, "aspect": 64, "ratio": 64, "k": 64, "bewar": 65, "14": 66, "collector": 66, "box": 66, "out": [66, 68, 69, 81], "explor": 66, "start": 66, "simpl": 66, "ad": 66, "flexibl": 66, "support": 66, "posit": 66, "real": 66, "15": 67, "diagnost": [67, 68, 78, 79], "ani": 67, "gelman": 67, "rubin": 67, "r": 67, "hat": 67, "effect": 67, "standard": 67, "hmc": 67, "diverg": [67, 69], "tree": 67, "depth": 67, "e": 67, "bfmi": 67, "quickli": 67, "artifici": 68, "funnel": 68, "hell": 68, "conquer": 68, "adjust": [68, 80], "adapt_delta": 68, "noncent": [68, 78, 84], "hierarch": [68, 73, 74, 75, 76, 77, 78, 87], "featur": 68, "17": 69, "comparison": [69, 71, 72], "metric": 69, "assess": 69, "close": 69, "entropi": 69, "kullback": 69, "leibler": 69, "expect": 69, "pointwis": [69, 72], "densiti": 69, "watanab": 69, "akaik": 69, "criterion": 69, "leav": 69, "elpd": 69, "weight": [69, 72], "select": 70, "regress": 70, "practic": [71, 72, 80, 83], "waic": 72, "loo": 72, "exchang": 73, "implement": [75, 78, 85], "19": 76, "experi": 77, "revers": 77, "pool": 77, "ident": 77, "both": 77, "structur": 78, "quick": 78, "input": 78, "draw": 78, "parametr": 78, "21": 79, "principl": 79, "pipelin": 79, "workflow": 79, "refer": 79, "terminologi": 79, "simul": [79, 80], "base": [79, 80], "calibr": [79, 80], "z": 79, "score": 79, "shrinkag": 79, "v": 79, "rank": 79, "histogram": 79, "full": 79, "relat": 80, "perform": 80, "sbc": 80, "new": 80, "23": 81, "gaussian": [81, 82, 84, 85], "process": [81, 82, 84, 85], "nonparametr": 81, "finit": 81, "point": 81, "mean": 81, "function": [81, 87], "center": 81, "scale": 81, "matrix": 81, "gp": [81, 83, 84, 86], "numpi": 81, "compos": 81, "valu": 81, "hyperparamet": [82, 86], "scipi": 82, "obtain": 82, "hyperprior": 82, "deriv": 83, "mat\u00e9rn": 83, "gradient": 83, "non": 84, "latent": 84, "poisson": 84, "24": 85, "includ": 86, "file": 86, "main": 87, "q": 87, "\u03b8": 87, "vi": 87, "automat": 87, "differenti": 87, "volum": 87, "multilevel": 87, "26": 88, "wrap": 88, "meet": 89, "lab": 89, "session": 89, "submiss": 89, "assign": 89, "grade": 89, "collabor": 89, "honor": 89, "commun": 89, "ediquett": 89, "em": 90, "descript": 90, "doe": 90, "work": 90, "put": 90, "togeth": 90, "algorigthm": 90, "tutori": 91, "overview": 92, "due": 92, "date": 92, "weekli": 92}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.todo": 2, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"Homework 1.1: First attempts at Bayesian generative modeling (70 pts)": [[0, "Homework-1.1:-First-attempts-at-Bayesian-generative-modeling-(70-pts)"]], "1. Intuitive generative modeling": [[1, "intuitive-generative-modeling"]], "Homework 2.1: Overwhelming a prior (45 pts)": [[2, "Homework-2.1:-Overwhelming-a-prior-(45-pts)"]], "Homework 2.2: Exponential conjugate prior (55 pts)": [[3, "Homework-2.2:-Exponential-conjugate-prior-(55-pts)"]], "2. Analytical and graphical methods for analysis of the posterior": [[4, "analytical-and-graphical-methods-for-analysis-of-the-posterior"]], "Homework 3.1: Least squares (20 pts)": [[5, "Homework-3.1:-Least-squares-(20-pts)"]], "Homework 3.2: MAP estimates and zero-inflation for Drop-Seq controls (80 pts)": [[6, "Homework-3.2:-MAP-estimates-and-zero-inflation-for-Drop-Seq-controls-(80-pts)"]], "3. Maximum a posteriori parameter estimation": [[7, "maximum-a-posteriori-parameter-estimation"]], "Homework 4.1: Writing your own MCMC sampler (70 pts)": [[8, "Homework-4.1:-Writing-your-own-MCMC-sampler-(70-pts)"]], "Homework 4.2: MCMC with Boolean data (30 pts)": [[9, "Homework-4.2:-MCMC-with-Boolean-data-(30-pts)"]], "4. Sampling with MCMC": [[10, "sampling-with-mcmc"]], "Homework 5.1: MCMC with Boolean data with Stan (25 pts)": [[11, "Homework-5.1:-MCMC-with-Boolean-data-with-Stan-(25-pts)"]], "Homework 5.2: Microtubule catastrophe (75 pts)": [[12, "Homework-5.2:-Microtubule-catastrophe-(75-pts)"]], "5. Inference with Stan": [[13, "inference-with-stan"]], "Homework 6.1: Surviving osmotic shock (40 pts)": [[14, "Homework-6.1:-Surviving-osmotic-shock-(40-pts)"]], "Homework 6.2: Diagnosing nonidentifiability with MCMC (60 pts)": [[15, "Homework-6.2:-Diagnosing-nonidentifiability-with-MCMC-(60-pts)"]], "6. MCMC with ion channels": [[16, "mcmc-with-ion-channels"]], "BE/Bi 103 b: Statistical Inference in the Biological Sciences": [[17, "be-bi-103-b-statistical-inference-in-the-biological-sciences"]], "Useful links": [[17, "useful-links"]], "People": [[17, "people"]], "Lessons": [[17, null]], "Homework": [[17, null], [89, "homework"]], "Schedule": [[17, null]], "Policies": [[17, null]], "Resources": [[17, null]], "Previous editions of the course": [[17, "previous-editions-of-the-course"]], "E1. To be completed after lesson 5": [[18, "E1.-To-be-completed-after-lesson-5"]], "Exercise 1.1": [[18, "Exercise-1.1"]], "Exercise 1.2": [[18, "Exercise-1.2"]], "Exercise 1.3": [[18, "Exercise-1.3"]], "Exercise 1.4": [[18, "Exercise-1.4"]], "E2. To be completed after lesson 6": [[19, "E2.-To-be-completed-after-lesson-6"]], "Exercise 2.1": [[19, "Exercise-2.1"]], "Exercise 2.2": [[19, "Exercise-2.2"]], "Exercise 2.3": [[19, "Exercise-2.3"]], "Exercise 2.4": [[19, "Exercise-2.4"]], "Exercise 2.5": [[19, "Exercise-2.5"]], "E3. To be completed after lesson 10": [[20, "E3.-To-be-completed-after-lesson-10"]], "Exercise 3.1": [[20, "Exercise-3.1"]], "Exercise 3.2": [[20, "Exercise-3.2"]], "Exercise 3.3": [[20, "Exercise-3.3"]], "Exercise 3.4": [[20, "Exercise-3.4"]], "E4. To be completed after lesson 13": [[21, "E4.-To-be-completed-after-lesson-13"]], "Exercise 4.1": [[21, "Exercise-4.1"]], "Exercise 4.2": [[21, "Exercise-4.2"]], "Exercise 4.3": [[21, "Exercise-4.3"]], "Exercise 4.4": [[21, "Exercise-4.4"]], "E5. To be completed after lesson 16": [[22, "E5.-To-be-completed-after-lesson-16"]], "Exercise 5.1": [[22, "Exercise-5.1"]], "Exercise 5.2": [[22, "Exercise-5.2"]], "Exercise 5.3": [[22, "Exercise-5.3"]], "Exercise 5.4": [[22, "Exercise-5.4"]], "E6. To be completed after lesson 18": [[23, "E6.-To-be-completed-after-lesson-18"]], "Exercise 6.1": [[23, "Exercise-6.1"]], "Exercise 6.2": [[23, "Exercise-6.2"]], "Exercise 6.3": [[23, "Exercise-6.3"]], "Exercise 6.4": [[23, "Exercise-6.4"]], "E7. To be completed after lesson 20": [[24, "E7.-To-be-completed-after-lesson-20"]], "Exercise 7.1": [[24, "Exercise-7.1"]], "Exercise 7.2": [[24, "Exercise-7.2"]], "Exercise 7.3": [[24, "Exercise-7.3"]], "Exercise 7.4": [[24, "Exercise-7.4"]], "Exercise 7.5": [[24, "Exercise-7.5"]], "E8. To be completed after lesson 22": [[25, "E8.-To-be-completed-after-lesson-22"]], "Exercise 8.1": [[25, "Exercise-8.1"]], "Exercise 8.2": [[25, "Exercise-8.2"]], "Exercise 8.3": [[25, "Exercise-8.3"]], "E9. To be completed after lesson 25": [[26, "E9.-To-be-completed-after-lesson-25"]], "Exercise 9.1": [[26, "Exercise-9.1"]], "Exercise 9.2": [[26, "Exercise-9.2"]], "Exercise 9.3": [[26, "Exercise-9.3"]], "Exercise 9.4": [[26, "Exercise-9.4"]], "AWS setup and usage": [[27, "AWS-setup-and-usage"]], "1. Create an Amazon Web Services account": [[27, "1.-Create-an-Amazon-Web-Services-account"]], "2. Launch your instance": [[27, "2.-Launch-your-instance"]], "3. Connect to your instance": [[27, "3.-Connect-to-your-instance"]], "4. Launch JupyterLab": [[27, "4.-Launch-JupyterLab"]], "5. Copying results to and from AWS to your local machine": [[27, "5.-Copying-results-to-and-from-AWS-to-your-local-machine"]], "6. Exiting": [[27, "6.-Exiting"]], "7. Seriously. Stop your instances if you are not using them.": [[27, "7.-Seriously.-Stop-your-instances-if-you-are-not-using-them."]], "8. Using your instance again": [[27, "8.-Using-your-instance-again"]], "9. Terminate your instances after the class is over": [[27, "9.-Terminate-your-instances-after-the-class-is-over"]], "Using Google Colab": [[28, "Using-Google-Colab"]], "Watchouts when using Colab": [[28, "Watchouts-when-using-Colab"]], "Software in Colab": [[28, "Software-in-Colab"]], "A sample calculation": [[28, "A-sample-calculation"]], "Computing environment": [[28, "Computing-environment"], [30, "Computing-environment"], [42, "Computing-environment"], [43, "Computing-environment"], [44, "Computing-environment"], [46, "Computing-environment"], [47, "Computing-environment"], [48, "Computing-environment"], [57, "Computing-environment"], [58, "Computing-environment"], [59, "Computing-environment"], [60, "Computing-environment"], [61, "Computing-environment"], [63, "Computing-environment"], [64, "Computing-environment"], [65, "Computing-environment"], [67, "Computing-environment"], [68, "Computing-environment"], [70, "Computing-environment"], [72, "Computing-environment"], [75, "Computing-environment"], [80, "Computing-environment"], [81, "Computing-environment"], [82, "Computing-environment"], [83, "Computing-environment"], [84, "Computing-environment"], [86, "Computing-environment"], [87, "Computing-environment"]], "0. Setting up computing resources": [[29, "setting-up-computing-resources"]], "Configuring your machine": [[30, "Configuring-your-machine"]], "Installing Python packages": [[30, "Installing-Python-packages"]], "Stan installation": [[30, "Stan-installation"]], "Configuring a C++ toolchain for MacOS": [[30, "Configuring-a-C++-toolchain-for-MacOS"]], "Configuring a C++ toolchain for Windows": [[30, "Configuring-a-C++-toolchain-for-Windows"]], "Configuring a C++ toolchain for Linux": [[30, "Configuring-a-C++-toolchain-for-Linux"]], "Installing Stan with CmdStanPy": [[30, "Installing-Stan-with-CmdStanPy"]], "Checking your Stan installation": [[30, "Checking-your-Stan-installation"]], "Probability as the logic of science": [[31, "probability-as-the-logic-of-science"]], "What is statistical inference?": [[31, "what-is-statistical-inference"]], "The problem of probability": [[31, "the-problem-of-probability"]], "Frequentist probability.": [[31, "frequentist-probability"]], "Bayesian probability.": [[31, "bayesian-probability"]], "Desiderata for Bayesian probability": [[31, "desiderata-for-bayesian-probability"]], "The sum rule, the product rule, and conditional probability": [[31, "the-sum-rule-the-product-rule-and-conditional-probability"]], "Application to scientific measurement": [[31, "application-to-scientific-measurement"]], "Bayes\u2019s Theorem": [[31, "bayess-theorem"]], "The prior probability.": [[31, "the-prior-probability"]], "The likelihood.": [[31, "the-likelihood"]], "The evidence.": [[31, "the-evidence"]], "The posterior probability.": [[31, "the-posterior-probability"]], "Bayes\u2019s theorem as a model for learning": [[32, "bayes-s-theorem-as-a-model-for-learning"]], "Notation of parts of Bayes\u2019s Theorem": [[33, "notation-of-parts-of-bayess-theorem"]], "1. Probability and the logic of scientific reasoning": [[34, "probability-and-the-logic-of-scientific-reasoning"]], "Marginalization": [[35, "marginalization"]], "Probability distributions": [[36, "probability-distributions"]], "Joint and conditional distributions and Bayes\u2019s theorem for PDFs": [[36, "joint-and-conditional-distributions-and-bayess-theorem-for-pdfs"]], "Change of variables formula for continuous distributions": [[36, "change-of-variables-formula-for-continuous-distributions"]], "Generalization to multiple dimensions": [[36, "generalization-to-multiple-dimensions"]], "An example of change of variables": [[36, "an-example-of-change-of-variables"]], "Another example of change of variables: the Log-Normal distribution": [[36, "another-example-of-change-of-variables-the-log-normal-distribution"]], "Bayesian modeling example: parameter estimation from repeated measurements": [[37, "bayesian-modeling-example-parameter-estimation-from-repeated-measurements"]], "The likelihood": [[37, "the-likelihood"], [64, "The-likelihood"]], "The Normal distribution": [[37, "the-normal-distribution"]], "The likelihood revisited: and another parameter": [[37, "the-likelihood-revisited-and-another-parameter"]], "Choice of prior": [[37, "choice-of-prior"]], "Succinctly stating the model": [[37, "succinctly-stating-the-model"]], "Tasks of Bayesian modeling": [[38, "tasks-of-bayesian-modeling"]], "Model building": [[38, "model-building"]], "The role of the prior": [[38, "the-role-of-the-prior"]], "Making sense of the posterior": [[38, "making-sense-of-the-posterior"]], "Choosing likelihoods": [[39, "choosing-likelihoods"]], "Choosing priors": [[40, "choosing-priors"]], "Uniform priors": [[40, "uniform-priors"]], "Jeffreys priors": [[40, "jeffreys-priors"]], "Example Jeffreys priors": [[40, "example-jeffreys-priors"]], "Why not use Jeffreys priors?": [[40, "why-not-use-jeffreys-priors"]], "Weakly informative priors": [[40, "weakly-informative-priors"]], "Conjugate priors": [[40, "conjugate-priors"]], "The bet-the-farm method of specifying weakly informative priors": [[40, "the-bet-the-farm-method-of-specifying-weakly-informative-priors"]], "2. Introduction to Bayesian modeling": [[41, "introduction-to-bayesian-modeling"]], "3. Plotting posteriors": [[42, "3.-Plotting-posteriors"]], "The data set": [[42, "The-data-set"], [57, "The-data-set"], [64, "The-data-set"], [67, "The-data-set"]], "Models for spindle size": [[42, "Models-for-spindle-size"]], "Plotting the posterior for a single parameter": [[42, "Plotting-the-posterior-for-a-single-parameter"]], "Analytically marginalizing": [[42, "Analytically-marginalizing"]], "Computing and plotting the marginalized posterior": [[42, "Computing-and-plotting-the-marginalized-posterior"]], "Normalizing by numerical quadrature": [[42, "Normalizing-by-numerical-quadrature"]], "A prescription for plotting 1D posteriors": [[42, "A-prescription-for-plotting-1D-posteriors"]], "An analytical expression for the marginal posterior": [[42, "An-analytical-expression-for-the-marginal-posterior"]], "Plotting a 2D posterior": [[42, "Plotting-a-2D-posterior"]], "Aside: Speed of likelihood calculation": [[42, "Aside:-Speed-of-likelihood-calculation"]], "Computing the log of a 2D posterior": [[42, "Computing-the-log-of-a-2D-posterior"]], "4. Marginalization by numerical quadrature": [[43, "4.-Marginalization-by-numerical-quadrature"]], "The tubulin conservation model": [[43, "The-tubulin-conservation-model"], [48, "The-tubulin-conservation-model"], [65, "The-tubulin-conservation-model"]], "Analytical marginalization": [[43, "Analytical-marginalization"]], "Numerical marginalization": [[43, "Numerical-marginalization"]], "The curse of dimensionality and overcoming it": [[43, "The-curse-of-dimensionality-and-overcoming-it"]], "5. Conjugacy": [[44, "5.-Conjugacy"]], "The Beta-Binomial conjugate pair": [[44, "The-Beta-Binomial-conjugate-pair"]], "Finding the conjugate": [[44, "Finding-the-conjugate"]], "Plots of the posteriors": [[44, "Plots-of-the-posteriors"]], "Comments on conjugates": [[44, "Comments-on-conjugates"]], "6. Parameter estimation by optimization": [[45, "parameter-estimation-by-optimization"]], "Parameter estimation by optimization case study: Normal likelihood": [[46, "Parameter-estimation-by-optimization-case-study:-Normal-likelihood"]], "Exploratory data analysis": [[46, "Exploratory-data-analysis"]], "Independent size model": [[46, "Independent-size-model"]], "Estimation of the MAP parameters": [[46, "Estimation-of-the-MAP-parameters"]], "Normal approximation of the posterior": [[46, "Normal-approximation-of-the-posterior"]], "Credible intervals": [[46, "Credible-intervals"], [47, "Credible-intervals"]], "How good is the approximation?": [[46, "How-good-is-the-approximation?"]], "Bayesian approach to parameter estimation by optimization": [[47, "Bayesian-approach-to-parameter-estimation-by-optimization"]], "Summarizing the posterior near its maximum": [[47, "Summarizing-the-posterior-near-its-maximum"]], "Demonstration of the Normal approximation": [[47, "Demonstration-of-the-Normal-approximation"]], "Credible intervals may be skewed": [[47, "Credible-intervals-may-be-skewed"]], "Why use the MAP for parameter estimation?": [[47, "Why-use-the-MAP-for-parameter-estimation?"]], "Parameter estimation by optimization: A variate-covariate model": [[48, "Parameter-estimation-by-optimization:-A-variate-covariate-model"]], "Parameter estimation": [[48, "Parameter-estimation"]], "Checking the Normal approximation": [[48, "Checking-the-Normal-approximation"]], "Displaying the best fit line": [[48, "Displaying-the-best-fit-line"]], "Further reading on MCMC": [[50, "further-reading-on-mcmc"]], "7. Introduction to Markov chain Monte Carlo": [[51, "introduction-to-markov-chain-monte-carlo"]], "Random number generation": [[52, "random-number-generation"]], "The basic idea behind MCMC": [[52, "the-basic-idea-behind-mcmc"]], "Generating a transition kernel: The Metropolis-Hastings algorithm": [[53, "generating-a-transition-kernel-the-metropolis-hastings-algorithm"]], "The algorithm/kernel": [[53, "the-algorithm-kernel"]], "Detailed balance": [[53, "detailed-balance"]], "Choosing the transition kernel": [[53, "choosing-the-transition-kernel"]], "Warm-up": [[54, "warm-up"]], "Why MCMC?": [[55, "why-mcmc"]], "8. Introduction to MCMC with Stan": [[56, "introduction-to-mcmc-with-stan"]], "Parameter estimation with Markov chain Monte Carlo": [[57, "Parameter-estimation-with-Markov-chain-Monte-Carlo"]], "Stan: Our MCMC engine": [[57, "Stan:-Our-MCMC-engine"]], "ECDFs of mRNA counts": [[57, "ECDFs-of-mRNA-counts"], [80, "ECDFs-of-mRNA-counts"]], "Building a generative model": [[57, "Building-a-generative-model"], [64, "Building-a-generative-model"]], "Priors for burst size and inter-burst time": [[57, "Priors-for-burst-size-and-inter-burst-time"]], "Sampling the posterior": [[57, "Sampling-the-posterior"]], "Plots of the samples": [[57, "Plots-of-the-samples"]], "Marginalizing the posterior": [[57, "Marginalizing-the-posterior"]], "Analysis for all genes": [[57, "Analysis-for-all-genes"]], "Display of \u201cbest fit\u201d": [[57, "Display-of-%22best-fit%22"]], "\u201cHello, world\u201d \u2014Stan": [[58, "%22Hello,-world%22-\u2014Stan"]], "Basics of Stan programs": [[58, "Basics-of-Stan-programs"]], "Say hi, Stan": [[58, "Say-hi,-Stan"]], "Parsing output with ArviZ": [[58, "Parsing-output-with-ArviZ"]], "Direct sampling": [[58, "Direct-sampling"]], "Why are we using that?": [[58, "Why-are-we-using-that?"]], "Displaying your Stan code": [[58, "Displaying-your-Stan-code"]], "Saving samples": [[58, "Saving-samples"]], "Cleaning up the shrapnel": [[58, "Cleaning-up-the-shrapnel"]], "9. Mixture models and label switching with MCMC": [[59, "9.-Mixture-models-and-label-switching-with-MCMC"]], "Mixture models": [[59, "Mixture-models"]], "Coding up a mixture model": [[59, "Coding-up-a-mixture-model"]], "Parsing the output": [[59, "Parsing-the-output"]], "Plotting the samples": [[59, "Plotting-the-samples"]], "Label switching": [[59, "Label-switching"]], "Initializing walkers": [[59, "Initializing-walkers"]], "Conclusions": [[59, "Conclusions"], [78, "Conclusions"], [80, "Conclusions"], [81, "Conclusions"]], "10. Variate-covariate models with MCMC": [[60, "10.-Variate-covariate-models-with-MCMC"]], "Updated generative model": [[60, "Updated-generative-model"]], "Using Stan to sample": [[60, "Using-Stan-to-sample"]], "Display of MCMC samples": [[61, "Display-of-MCMC-samples"]], "Visualization with ArviZ": [[61, "Visualization-with-ArviZ"]], "The model and samples": [[61, "The-model-and-samples"]], "Examining traces": [[61, "Examining-traces"]], "Trace plots": [[61, "Trace-plots"]], "Trace plots with ArviZ": [[61, "Trace-plots-with-ArviZ"]], "Trace plots with bebi103": [[61, "Trace-plots-with-bebi103"]], "Interpetation of trace plots": [[61, "Interpetation-of-trace-plots"]], "Parallel coordinate plots": [[61, "Parallel-coordinate-plots"]], "Parallel coordinate plots with ArviZ": [[61, "Parallel-coordinate-plots-with-ArviZ"]], "Parallel coordinate plots with bebi103": [[61, "Parallel-coordinate-plots-with-bebi103"]], "Intepretation of parallel coordinate plots": [[61, "Intepretation-of-parallel-coordinate-plots"]], "Plots of marginalized distributions": [[61, "Plots-of-marginalized-distributions"]], "Plotting marginalized distributions of one parameter": [[61, "Plotting-marginalized-distributions-of-one-parameter"]], "Plotting marginalized distributions with ArviZ": [[61, "Plotting-marginalized-distributions-with-ArviZ"]], "Plotting marginalized distributions with iqplot": [[61, "Plotting-marginalized-distributions-with-iqplot"]], "Marginal posteriors of two parameters and corner plots": [[61, "Marginal-posteriors-of-two-parameters-and-corner-plots"]], "Pair plots with ArviZ": [[61, "Pair-plots-with-ArviZ"]], "Corner plots with bebi103": [[61, "Corner-plots-with-bebi103"]], "11. Display of MCMC results": [[62, "display-of-mcmc-results"]], "Reporting summaries of the posterior": [[63, "Reporting-summaries-of-the-posterior"]], "Reporting summaries of MCMC samples": [[63, "Reporting-summaries-of-MCMC-samples"]], "Some distributions to sample": [[63, "Some-distributions-to-sample"]], "Summarizing the \u201cMCMC\u201d results with error bars": [[63, "Summarizing-the-%22MCMC%22-results-with-error-bars"]], "Relative merits of each method": [[63, "Relative-merits-of-each-method"]], "How to display the summary in text.": [[63, "How-to-display-the-summary-in-text."]], "12. Model building with prior predictive checks": [[64, "12.-Model-building-with-prior-predictive-checks"]], "Model 1: Spindle size is independent of droplet size": [[64, "Model-1:-Spindle-size-is-independent-of-droplet-size"]], "The prior": [[64, "The-prior"]], "The prior, take 2": [[64, "The-prior,-take-2"]], "Prior predictive checks": [[64, "Prior-predictive-checks"], [64, "id1"]], "The prior, take 3": [[64, "The-prior,-take-3"]], "Prior predictive checks, take 2": [[64, "Prior-predictive-checks,-take-2"]], "Prior predictive checks with Stan": [[64, "Prior-predictive-checks-with-Stan"]], "Model 2: Spindle size dependent on total tubulin concentration": [[64, "Model-2:-Spindle-size-dependent-on-total-tubulin-concentration"]], "Indentifiability of parameters": [[64, "Indentifiability-of-parameters"]], "Limiting behavior": [[64, "Limiting-behavior"]], "Generative model": [[64, "Generative-model"]], "Checking model assumptions": [[64, "Checking-model-assumptions"]], "Is V_\\mathrm{s} / V_0 \\ll 1?": [[64, "Is-V_\\mathrm{s}-/-V_0-\\ll-1?"]], "Do all spindles have the same aspect ratio k?": [[64, "Do-all-spindles-have-the-same-aspect-ratio-k?"]], "13. Posterior predictive checks": [[65, "13.-Posterior-predictive-checks"]], "The independent size model": [[65, "The-independent-size-model"]], "Beware the summary statistic": [[65, "Beware-the-summary-statistic"]], "14. Collector\u2019s box of distributions": [[66, "collector-s-box-of-distributions"]], "Check out the Distribution Explorer": [[66, "check-out-the-distribution-explorer"]], "Choosing distributions": [[66, "choosing-distributions"]], "Starting simple and adding flexibility": [[66, "starting-simple-and-adding-flexibility"]], "Priors for variables with support on the set of positive real numbers": [[66, "priors-for-variables-with-support-on-the-set-of-positive-real-numbers"]], "15. MCMC diagnostics": [[67, "15.-MCMC-diagnostics"]], "The model": [[67, "The-model"]], "Diagnostics for any MCMC sampler": [[67, "Diagnostics-for-any-MCMC-sampler"]], "The Gelman-Rubin R-hat statistic": [[67, "The-Gelman-Rubin-R-hat-statistic"]], "Effective samples size": [[67, "Effective-samples-size"]], "Monte Carlo standard error": [[67, "Monte-Carlo-standard-error"]], "Diagnostics for HMC": [[67, "Diagnostics-for-HMC"]], "Divergences": [[67, "Divergences"]], "Tree depth": [[67, "Tree-depth"]], "E-BFMI": [[67, "E-BFMI"]], "Quickly checking the diagnostics": [[67, "Quickly-checking-the-diagnostics"]], "16. A diagnostics case study: Artificial funnel of hell": [[68, "16.-A-diagnostics-case-study:-Artificial-funnel-of-hell"]], "Sampling out of the funnel": [[68, "Sampling-out-of-the-funnel"]], "Conquering the Funnel of Hell": [[68, "Conquering-the-Funnel-of-Hell"]], "Adjusting adapt_delta": [[68, "Adjusting-adapt_delta"]], "Noncentering": [[68, "Noncentering"], [84, "Noncentering"]], "Hierarchical models feature a Funnel of Hell": [[68, "Hierarchical-models-feature-a-Funnel-of-Hell"]], "17. Model comparison": [[69, "model-comparison"]], "Metrics for model assessment": [[69, "metrics-for-model-assessment"]], "Posterior predictive checks": [[69, "posterior-predictive-checks"]], "Closeness metrics": [[69, "closeness-metrics"]], "Entropy and the Kullback-Leibler divergence": [[69, "entropy-and-the-kullback-leibler-divergence"]], "The expected log pointwise predictive density": [[69, "the-expected-log-pointwise-predictive-density"]], "The Watanabe-Akaike information criterion": [[69, "the-watanabe-akaike-information-criterion"]], "Leave-one-out estimates of elpd": [[69, "leave-one-out-estimates-of-elpd"]], "The Akaike weights": [[69, "the-akaike-weights"]], "Example model selection: regression": [[70, "Example-model-selection:-regression"]], "18. Model comparison in practice": [[71, "model-comparison-in-practice"]], "Model comparison in practice": [[72, "Model-comparison-in-practice"]], "An example model comparison": [[72, "An-example-model-comparison"]], "Computing the pointwise log likelihood": [[72, "Computing-the-pointwise-log-likelihood"]], "Computing the WAIC and LOO": [[72, "Computing-the-WAIC-and-LOO"]], "Calculations with the mixture model": [[72, "Calculations-with-the-mixture-model"]], "Computing the weights": [[72, "Computing-the-weights"]], "Choosing a hierarchical prior": [[73, "Choosing-a-hierarchical-prior"]], "Exchangeability": [[73, "Exchangeability"]], "Choice of the conditional distribution": [[73, "Choice-of-the-conditional-distribution"]], "Generalization of hierarchical models": [[74, "Generalization-of-hierarchical-models"]], "Implementation of a hierarchical model": [[75, "Implementation-of-a-hierarchical-model"]], "19. Hierarchical models": [[76, "hierarchical-models"]], "Modeling repeated experiments": [[77, "Modeling-repeated-experiments"]], "A model for reversals": [[77, "A-model-for-reversals"]], "Pooled data: identical parameters": [[77, "Pooled-data:-identical-parameters"]], "Independent parameters": [[77, "Independent-parameters"]], "The best of both worlds: A hierarchical model": [[77, "The-best-of-both-worlds:-A-hierarchical-model"]], "20. Implementation of hierarchical models": [[78, "20.-Implementation-of-hierarchical-models"]], "Hierarchical model structure": [[78, "Hierarchical-model-structure"]], "Coding up the hierarchical model in Stan": [[78, "Coding-up-the-hierarchical-model-in-Stan"]], "A quick aside: generating a data set": [[78, "A-quick-aside:-generating-a-data-set"]], "Generating input data for Stan": [[78, "Generating-input-data-for-Stan"]], "Drawing samples and checking diagnostics": [[78, "Drawing-samples-and-checking-diagnostics"]], "A noncentered parametrization": [[78, "A-noncentered-parametrization"]], "21. Principled analysis pipelines": [[79, "21.-Principled-analysis-pipelines"]], "Building a workflow": [[79, "Building-a-workflow"]], "References and terminology": [[79, "References-and-terminology"]], "Simulation-based calibration": [[79, "Simulation-based-calibration"]], "Diagnostics": [[79, "Diagnostics"]], "z-score": [[79, "z-score"]], "Shrinkage": [[79, "Shrinkage"]], "Shrinkage vs. z-score plot": [[79, "Shrinkage-vs.-z-score-plot"]], "Rank statistics": [[79, "Rank-statistics"]], "A rank statistic ECDF plot": [[79, "A-rank-statistic-ECDF-plot"]], "Rank statistic histograms": [[79, "Rank-statistic-histograms"]], "A full principled pipeline": [[79, "A-full-principled-pipeline"]], "22: Simulation based calibration and related checks in practice": [[80, "22:-Simulation-based-calibration-and-related-checks-in-practice"]], "The generative model": [[80, "The-generative-model"]], "Performing SBC": [[80, "Performing-SBC"]], "An adjusted prior": [[80, "An-adjusted-prior"]], "Sampling with our new model": [[80, "Sampling-with-our-new-model"]], "23. Introduction to Gaussian processes": [[81, "23.-Introduction-to-Gaussian-processes"]], "Predicting using posterior estimates": [[81, "Predicting-using-posterior-estimates"]], "An example data set": [[81, "An-example-data-set"]], "Processes and nonparametric Bayesian inference": [[81, "Processes-and-nonparametric-Bayesian-inference"]], "Gaussian processes with a finite number of points": [[81, "Gaussian-processes-with-a-finite-number-of-points"]], "The mean function and centering and scaling": [[81, "The-mean-function-and-centering-and-scaling"]], "The kernel and covariance matrix": [[81, "The-kernel-and-covariance-matrix"]], "Sampling out of a Gaussian process prior": [[81, "Sampling-out-of-a-Gaussian-process-prior"]], "Sampling out of a GP prior using Stan": [[81, "Sampling-out-of-a-GP-prior-using-Stan"]], "Sampling out of a GP prior using Numpy": [[81, "Sampling-out-of-a-GP-prior-using-Numpy"]], "Composing kernels": [[81, "Composing-kernels"]], "Inference with GPs": [[81, "Inference-with-GPs"]], "Normal likelihoods with Gaussian process priors": [[81, "Normal-likelihoods-with-Gaussian-process-priors"]], "The posterior predictive distribution of function values": [[81, "The-posterior-predictive-distribution-of-function-values"]], "Computing the parameters of the posterior predictive distribution": [[81, "Computing-the-parameters-of-the-posterior-predictive-distribution"]], "Plotting an analytical posterior": [[81, "Plotting-an-analytical-posterior"]], "Gaussian process hyperparameters by optimization": [[82, "Gaussian-process-hyperparameters-by-optimization"]], "Priors for hyperparameters": [[82, "Priors-for-hyperparameters"]], "Computing the MAP with SciPy": [[82, "Computing-the-MAP-with-SciPy"]], "Posterior predictive samples": [[82, "Posterior-predictive-samples"]], "Obtaining hyperpriors by optimizing with Stan": [[82, "Obtaining-hyperpriors-by-optimizing-with-Stan"]], "Calculating derivatives from data with GPs": [[83, "Calculating-derivatives-from-data-with-GPs"]], "Derivatives of GPs": [[83, "Derivatives-of-GPs"]], "Derivative of the squared exponential kernel": [[83, "Derivative-of-the-squared-exponential-kernel"]], "Derivatives of the Mat\u00e9rn kernel": [[83, "Derivatives-of-the-Mat\u00e9rn-kernel"]], "Expressions for the gradient and covariance of the gradient": [[83, "Expressions-for-the-gradient-and-covariance-of-the-gradient"]], "Derivatives of GPs in practice using optimization": [[83, "Derivatives-of-GPs-in-practice-using-optimization"]], "Derivatives with a Mat\u00e9rn kernel": [[83, "Derivatives-with-a-Mat\u00e9rn-kernel"]], "Sampling derivatives with Stan": [[83, "Sampling-derivatives-with-Stan"]], "Gaussian processes with non-Normal likelihoods": [[84, "Gaussian-processes-with-non-Normal-likelihoods"]], "Generating samples of latent variables using MCMC": [[84, "Generating-samples-of-latent-variables-using-MCMC"]], "A GP generative model": [[84, "A-GP-generative-model"]], "Sampling latent variables with Stan": [[84, "Sampling-latent-variables-with-Stan"]], "Sampling with a Poisson likelihood": [[84, "Sampling-with-a-Poisson-likelihood"]], "24. Implementation of Gaussian processes": [[85, "implementation-of-gaussian-processes"]], "MCMC with GPs with Normal likelihoods": [[86, "MCMC-with-GPs-with-Normal-likelihoods"]], "Hyperparameter estimation using MCMC": [[86, "Hyperparameter-estimation-using-MCMC"]], "Posterior predictive checks with GPs": [[86, "Posterior-predictive-checks-with-GPs"]], "Aside: Stan include files": [[86, "Aside:-Stan-include-files"]], "25. Variational Bayesian inference": [[87, "25.-Variational-Bayesian-inference"]], "The main ideas of variational inference": [[87, "The-main-ideas-of-variational-inference"]], "Choosing Q(\u03b8)": [[87, "Choosing-Q(\u03b8)"]], "Summary of VI algorithm": [[87, "Summary-of-VI-algorithm"]], "Automatic Differentiation Variational Inference and Stan": [[87, "Automatic-Differentiation-Variational-Inference-and-Stan"]], "Examples": [[87, "Examples"]], "Example 1: Spindle size as a function of volume": [[87, "Example-1:-Spindle-size-as-a-function-of-volume"]], "Example 2: A multilevel hierarchical model": [[87, "Example-2:-A-multilevel-hierarchical-model"]], "26: Wrap-up": [[88, "wrap-up"]], "Meetings": [[89, "meetings"]], "Lab sessions": [[89, "lab-sessions"]], "Submission of assignments": [[89, "submission-of-assignments"]], "Lessons and lesson exercises": [[89, "lessons-and-lesson-exercises"]], "Grading": [[89, "grading"]], "Collaboration policy and Honor Code": [[89, "collaboration-policy-and-honor-code"]], "Course communications": [[89, "course-communications"]], "\u201cEdiquette\u201d": [[89, "ediquette"]], "Introduction to the EM Algorithm": [[90, "Introduction-to-the-EM-Algorithm"]], "Description of the EM algorithm": [[90, "Description-of-the-EM-algorithm"]], "Why does the EM algorithm work?": [[90, "Why-does-the-EM-algorithm-work?"]], "Putting it all together": [[90, "Putting-it-all-together"]], "Application of the EM Algorigthm to Bayesian Inference": [[90, "Application-of-the-EM-Algorigthm-to-Bayesian-Inference"]], "Example: A Normal-Mixture Model": [[90, "Example:-A-Normal-Mixture-Model"]], "Software": [[91, "software"]], "Reading/tutorials": [[91, "reading-tutorials"]], "Schedule overview": [[92, "schedule-overview"]], "Homework due dates": [[92, "homework-due-dates"]], "Lesson exercise due dates": [[92, "lesson-exercise-due-dates"]], "Weekly schedule": [[92, "weekly-schedule"]]}, "indexentries": {}})