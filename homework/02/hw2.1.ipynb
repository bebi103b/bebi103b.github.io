{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2.1: Overwhelming a prior (45 pts)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr >\n",
    "\n",
    "As we will see as we continue in this class, it is important to carefully choose the prior distribution when building your generative models. Nonetheless, for many parameter estimation problems where there are many data, the contribution of the prior is overwhelmed by the likelihood, so the exact details (within some constraints) of the prior are less important. We will explore this computationally in this problem.\n",
    "\n",
    "To do this exploration, we will work with a data set that comes from [David Prober's lab](http://www.proberlab.caltech.edu). In the Prober lab, they monitor activity of zebrafish larvae of different genotypes in efforts to understand how sleep is controlled. In one experiment, published in [Gandhi, et al., 2015](https://doi.org/10.1016/j.neuron.2015.02.016), the measured how many minutes of activity each of 17 fish larvae had over the course of the nine hours of their third night. The results are most easily loaded directly into a Numpy array into a variable we will call `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(\n",
    "    [200, 190, 200, 249, 232, 319, 104, 93, 233, \n",
    "     287, 49, 311, 225, 243, 113, 133, 179]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our generative model, we will use a Normal likelihood; that is, we model the data as drawn from a Normal distribution with location parameter $\\mu$ and scale parameter $\\sigma$.\n",
    "\n",
    "\\begin{align}\n",
    "\\{y_i\\} \\mid \\mu, \\sigma \\sim \\text{Norm}(\\mu, \\sigma)\\;\\forall i.\n",
    "\\end{align}\n",
    "\n",
    "Your task in this problem is to plot the posterior distribution, $g(\\mu, \\sigma \\mid \\{y_i\\})$ for each of the following priors.\n",
    "\n",
    "**a)** For your first prior, we will use improper uninformative priors. We say they are uninformative because they are very broad (infinitely so; they are not even normalizable).\n",
    "\n",
    "\\begin{align}\n",
    "&g(\\mu) = \\text{constant},\\\\[1em]\n",
    "&g(\\sigma) = 1/\\sigma.\n",
    "\\end{align}\n",
    "\n",
    "Of course, both $\\mu$ and $\\sigma$ are assumed to be nonnegative.\n",
    "\n",
    "**b)** Again assume $g(\\sigma) = 1/\\sigma$. Now use a Normal prior for $\\mu$ with a location parameter of 225 minutes and a scale parameter of 150 minutes.\n",
    "\n",
    "\\begin{align}\n",
    "\\mu \\sim \\text{Normal}(225 \\text{ min}, 150 \\text{ min}).\n",
    "\\end{align}\n",
    "\n",
    "What effect does choosing this prior as opposed to a uniform prior have on the posterior probability?\n",
    "\n",
    "**c)** Now assume a scale parameter of 20 minutes for the prior for $\\mu$. That is, again take $g(\\sigma) = 1/\\sigma$, but take\n",
    "\n",
    "\\begin{align}\n",
    "\\mu \\sim \\text{Normal}(225 \\text{ min}, 20 \\text{ min}).\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "How is the posterior effected? Comment on why you see the effect you do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
